制造非凡的音频效果
音频效果最佳实践和API指南
好
下午好
多少人想开发一款音频效果特别棒的应用
但觉得可能会很困难？
或者 多少人想要更多地
关注应用程序整体的用户体验
但最终在音频上多花费了一点时间？
我们一直以来都在努力帮助你轻松解决这些问题
我叫SaleemCore Audio团队的技术人员
欢迎大家来到今天
关于制造非凡音频效果的会议环节
让我们整体看下今天我们为大家准备了什么
我们会先开始介绍AVFoundation框架
我们有种类广泛的高层API
可以让你轻松播放和录制音频
对于更高级的用例 我们提供AudioToolbox框架
你可能听说过AudioUnits
这些是基本的组成模块
如果你必须使用MIDI设备或MIDI数据
我们还提供CoreMIDI框架
对于游戏开发我们提供OpenAL
在过去两年里我们也一直在添加
很多新的API和功能
你可以看到你可以通过很多方法
在你的应用中使用音频
所以 我们今天的目标是指导你
针对你的应用需求选择正确的API
但不必担心 我们也有一些新东西与大家分享
所以 按今天的日程表
我们会先了解我们几个平台的一些基本的设置步骤
然后 我们会直接深入了解一些简单和高级的播放
和录制情景
我们会简要讨论下多声道音频
在随后的介绍中我们将了解下实时音频
以及你制造自己音频效果、乐器和生成器的方法
最后以MIDI的介绍结尾
好 让我们开始吧
iOS、watchOS和tvOS都有相当丰富的音频功能
以及众多写入功能
这样 用户才能拨打电话播放音频、玩游戏
和使用各种提高效率的应用
用户可以同时或独立进行这些操作
所以操作系统管理了大量默认的音频行为
以便提供一致的用户体验
让我们通过图表了解为什么音频是一种基于管理的服务
所以 你拥有一件设备
设备有若干的输入和输入
然后 有操作系统
操作系统可能包含大量应用有些应用使用音频
最后 这里是你的应用
所以AVAudioSession是你的开发者界面
你可以通过该界面向系统表达你的应用需求
让我们了解下这方面的详细内容
类别表达应用的高级别需求
我们提供模式和类别选项
可以帮助你进一步定制和专门设计你的应用
如果你喜欢一些更高级的用例
比如输入选择你可能需要能够选择
iPhone的前置麦克风而不是底部麦克风
如果你处理的是多声道音频
以及tvOS上的多声道内容你可能对声道数
这样的东西感兴趣
如果你将USB音频设备连接到iPhone
你可能对采样率这样的东西感兴趣
所以 当你的应用准备好经配置可使用音频时
它会通知系统应用会话
该过程会配置设备的硬件
从而满足你应用的需求
并且实际可能对系统中其它音频应用造成干扰
或者相互混杂 或者降低其它音频应用的音量
了解下AVAudioSession的一些基本使用步骤
第一步是注册以获取通知
三种最重要的通知是中断通知
路径变更通知以及mediaServicesWereReset通知
你可以在激活会话之前注册以接收这些通知
通过几张幻灯片我将展示如何管理通知
接下来 基于你应用的高级别需求
你将需要设置适当的类别模式和选项
那么 让我们看几个例子
假如 我正在开发一款提高效率的应用
在这个应用中我想要在用户保存文档时
播放简单的声音
这里 我们知道音频能够增强体验
但却不是必要的
在这种情况下 我想使用AmbientCategory
这个类别遵循振铃开关
音频不在后台播放
而始终与其它应用音频混杂
若我在开发播客应用我应该使用PlaybackCategory
SpokenAudio模式
这里 我们能看到这个应用位置将干扰
系统上的其它应用
现在 如果你希望音频继续在后台播放
你也需要在info.plist中指定后台音频键
这本质上也是会话属性
只不过是通过不同的方式表达
而对于导航应用
让我们了解一下如何配置导航提示
你应使用PlaybackCategory
以及DefaultMode
这里有几个相关的选项
你应同时使用InterruptSpokenAudio
AndMixWithOthers以及duckOthers
所以 如果你正在收听播客 同时进行导航
就会出现导航提示表明
500英尺后左转
提示实际上会中断播客应用
如果你在听音乐
提示会降低音乐音量并混杂在音乐中
对于这种应用 你也应使用后台音频键
接下来 让我们看看如何对会话激活进行管理
所以 激活意味着什么？
激活你的会话 会通知系统
配置硬件以适应应用的需求
比如我有一个应用
类别为PlayAndRecord
当我激活我的会话系统会配置硬件
使用输入和输出
现在 如果我在使用音乐应用听音乐时
激活会话 会怎么样？
这里 我们可以看到系统当前状态设置为仅播放
所以 当我激活会话时
我通知系统 针对输入和输出进行硬件配置
而且 既然我处在不可混杂的应用位置
我中断了音乐应用
所以 比如我的应用进行了快速录音
一旦完成 我就停用会话
如果我选择通知其它应用我已经停用会话
我们将看到音乐应用恢复播放
接下来 让我们看下如何处理我们注册接收的通知
我们首先看一下中断通知
我们会研究一个案例案例中 你的应用
没有播放UI
首先获取interruptionType
如果这是中断的开始
你的会话已经停用
所以播放器已经暂停
你将利用这段时间更新你的任何内部状态
如果你收到结束中断
你会去激活会话
启动播放器同时更新内部状态
我们看下这个过程在拥有播放UI的应用中有什么不同
你接收开始中断的通知
你的会话停用你更新内部状态
而且这次要同时更新UI
如果你有播放/暂停按钮
这种情况下 你应接着将按钮设置为“播放”
现在 当你接收到结束中断通知
你应该查看并了解shouldResume选项是否提交进来
如果已经提交进来 那么你可以继续激活你的会话
开始播放 同时更新内部状态和UI
如果没有提交进来
你应等到用户明确地恢复播放后
应特别注意的是你的中断不一定是配对的
所以 不是每个开始中断随后都匹配一个结束中断
一个例子就是彼此中断的媒体播放器应用
现在 让我们看下如何处理路径变更
路径变更的发生原因有很多：
可能是连接设备变化了可能是类别变化了
可能是你选择了不同的数据源或端口
首先要获取routeChangeReason
如果你得到的原因是媒体播放器应用中
原有设备不可用
此时你应停止播放
这种情况的一个例子是如果你的用户使用耳机
收听音乐然后拔下耳机
他们不会想让音乐立即通过
扬声器恢复播放
对于更高级的用例 若你收到oldDeviceUnavailable
或newDeviceAvailablerouteChangeReason
你可能需要在特定会话属性应用到你的应用时
重新评估这些属性
最后 让我们看下如何处理设置了通知的
媒体服务
这种通知很少发生但也确实会收到
因为我们不能确保demon程序永远运行
这里需要特别注意的是
你的AVAudioSessionsharedInstance仍有效
你将需要重置类别模式和其它选项
你也需要破坏和重建你的播放器对象
如AVAudioEngine
远程I/O以及其它播放器对象
我们提供在设备上进行此测试的途径
路径是设置——开发者——重设媒体服务
好 大致重述下使用AVAudioSession的
四大步骤基本步骤
你注册以接收通知
你设置适当的类别模式和选项
你对会话激活进行管理
并且处理各种通知
让我们了解下今年的一些新内容
今年的新内容中 我们添加了两个新的类别选项：
将allowAirPlay和allowBluetoothA2DP添加到PlayAndRecord类别
所以 这意味着你现在可以在使用蓝牙或AirPlay终端
播放时 同时使用麦克风
如果这是你应用的用例
继续操作 设置类别和选项
然后允许用户从
MPVolumeView或 “控制中心”中选择路径
我们同时为AVAudioSessionPortDescription
上的VoIP应用添加了新属性
可以决定当前路径是否已经激活
硬件语音处理
所以 如果你的用户连接到拥有硬件语音处理的
CarPlay系统或蓝牙免提耳机
你可以使用该属性禁用你的软件语音处理功能
这样你就不会对音频重复处理了
如果你已经使用Apple的内置语音处理输入/输出设备
你无需担心这一点
今年新内容中 我们也引进了CallKit框架
为使你了解如何使用CallKit增强你的VoIP应用
本周早些时候安排了场演讲
如果你错过了可以到网上收看
所以 这只是AVAudioSession的概况
在之前的演讲中 我们对此话题进行了许多深入介绍
所以 我们鼓励你到网上查看之前的视频和编程指南
好 我们继续
AVAudioSession适用于你平台的情况下 你完成设置
现在 我们看下如何在应用中进行简单的音频播放和录制
我们先看一下AVFoundation框架
这里有很多级别可以处理这种任务
我们有AVAudioPlayer
AVAudioRecorder以及AVPlayer等级别
AVAudioPlayer是文件中播放音频的最简单方法
我们支持各种格式
我们提供所有基本的播放操作
我们同时支持一些高级的操作
比如 设置音量
你可以按照声道获得计量
你可以循环播放调整播放速度
进行立体声调制
如果你使用iOS或tvOS你可以进行声道分配
如果你有多个文件要进行播放
你可以使用多个AVAudioPlayer对象
也可以同步你的播放
今年新内容中加入了一种方法 可以允许你
在特定时间内逐渐降到某个音量
看下代码示例 了解你在应用中如何使用AVAudioPlayer
比如 我还是在开发和构建一个简单的提高效率的应用
我想要在用户保存文档时
播放确认音频
这种情况下 我有AVAudioPlayer和链接到我级别中资源的URL
在设置功能中 我继续操作使用我URL的内容
创建AVAudioPlayer对象同时我准备好播放器进行播放
在saveDocument功能中我可能进行一些工作
了解下文档是否保存成功
如果已保存 我只需播放文件
非常简单
现在 让我们看下AVAudioRecorder
这是将音频录制到文件的最简单方法
你可以录制指定的时长
或者录制到用户明确要求停止的时候
你基于声道获得计量
我们支持各种编码格式
所以 要设置格式 我们使用Recorder Settings Dictionary
这是由键组成的字典
包含的键列表可使你设置各种格式参数
例如采样率和声道数
若你使用Linear PCM数据
你可以调整位深度和字节顺序等
如果你使用编码格式
你可以调整质量和比特率等
让我们看下代码示例 了解如何使用AVAudioRecorder
所以 我首先做的是创建格式设置
这里 我创建了一个比特率相当高的AAC文件
然后 我要做的是创建AVAudioRecorder对象
包含指向文件位置的URL
以及我刚刚定义的格式设置
在这个例子中有一个简单的按钮
我可以用它来切换录音机的状态
所以我按下这个按钮时如果录音机正在录制
我接着操作 停止录制
我开始录制
我可以使用录音机的内置仪表向UI提供反馈
最后让我们看下AVPlayer
AVPlayer不仅适用于本地文件而且适用于流媒体内容
你拥有所有的标准控件
我们同时提供你可以直接
使用的内置用户界面比如AVPlayerView
以及AVPlayerViewController
AVPlayer也适用于视频内容
今年 我们在AVPlayer中添加了若干新功能
如果想了解我们做出的改进
你可查看AVFoundationPlayback的新进展
如果你错过了那部分你可以到网上进行观看
高级播放和录制
好 目前我们已经了解了一些非常简单的
播放和录制案例
现在 让我们看一下一些更高级的用例
高级用例不仅包括从文件中播放音频
而且包括处理缓冲音频数据
你可能感兴趣的是音频处理
应用特定的音效以及将多个来源的音频混合
或者你可能对实施3D音效感兴趣
这方面的应用案例包括开发经典的卡拉OK应用
开发具有超高音效的DJ应用
或者开发一款让用户完全沉浸其中的游戏
对于这种高级用例
我们在AVFoundation中有叫AVAudioEngine的级别
AVAudioEngine是一款强大
功能丰富的Objective-C和Swift API
它是一种实时音频系统
可以通过向你提供非实时界面
简化实时音频的处理工作
所以 处理实时音频涉及很多复杂的操作
而AVAudioEngine可以使你的代码更加简单
AVAudioEngine管理一个节点图表
这些节点使你得以播放和录制音频
你可以以各种方式连接这些节点
从而形成多个不同的处理链条
并进行混音
你也可以在处理链条的任意一点捕获音频
我们提供一个专门的节点可以使你实现音频的空间化
那么 让我们看一下根本的组成部分——AVAudioNode
我们有三类节点
我们有源节点可以提供用于呈现的数据
例如你的PlayerNode
InputNode或者抽样单位
我们有处理节点可以使你处理音频数据
所以 你客户处理的效果包括延迟、失真以及混音
我们有目标节点
即你图表中的终端节点
它与输出硬件直接连接
让我们看一下设置示例
比如 我正在构建一款经典的卡拉OK应用
在这个例子中我有三个源节点
我使用InputNode捕获用户声音
使用PlayerNode播放伴奏曲
使用另一个PlayerNode播放其它音效
和对用户使用的反馈
对于处理节点
我可能会对用户声音应用特定的EQ
然后我会使用混音器
将三个源合成为单个输出内容
然后这单个输出内容将通过OutputNode播放
然后传递到输出硬件
我也可以捕获用户的声音并进行一定的分析
从而了解安装TapBlock后他们的表现情况
然后基于此我可以无条件地安排
播放出这些反馈队列
现在 让我们看一下游戏设置示例
这里主要相关节点是EnvironmentNode
它可以模拟3D空间
并将相连的源空间化
引擎设置示例游戏
在这个例子中 我使用InputNode以及PlayerNode作为源
你也可以调整你源上的各种3D混音属性
比如位置和闭塞
而对于EnvironmentNode你也可以在那里调整属性
如listenerPosition以及其它混响参数
所以 该3D空间然后可以与伴奏曲混合
然后通过输出设备播放
核心级别
在进一步介绍AVAudioEngine前
我想再介绍下Engine广泛使用的
一些根本的核心级别
我从AVAudioFormat开始
AVAudioFormat描述音频文件或音频流中的
数据格式
所以我们有标准格式通用格式
以及压缩格式
该级别也包含AVAudioChannelLayout
你在处理多声道音频时可能会用到
它是我们的现代界面 连接到AudioStreamBasicDescription结构
以及AudioChannelLayout结构
现在 让我们看下AVAudioBuffer
AVAudioBuffer核心级别
该级别有两个子级别
AVAudioPCMBuffer可用于缓冲PCM数据
包括AVAudioCompressBuffer
可用来缓冲压缩音频数据
这两个级别均提供现代界面 连接到我们的
AudioBufferList以及AudioStreamPacketDescription
让我们看一下AVAudioFile
该级别允许你从任何支持的格式进行读写
允许你将数据读入PCM缓存并从PCM缓存
将数据写入文件
这样 它可以透明化地处理任何编码和解码
它现在取代我们的AudioFile和ExtAudioFile API
最后 让我们看下AVAudioConverter
AVAUDIO转换器核心级别
该级别处理音频格式转换
所以 你可以在两种PCM数据格式间转换
也可以在PCM以及压缩音频格式间转换
其中 转换器帮你进行编码和解码
这一级别取代我们的AudioConverter API
今年新内容中 我们也添加了
最小相位采样速率转换器算法
所以 你可以看到当与音频数据相连时
所有核心级别能很好地协作
让我们看下这些级别然后怎样与AVAudioEngine交互
若你观察AVAudioNode发现它有输入和输出AVAudio格式
如果你观察PlayerNode它可以通过AVAudioFile
或AVAudioPCMBuffer使连接到Engine
如果你安装NodeTap该部分以PCM缓存的形式
向你提供音频数据
你可以使用它进行分析
或者你可以使用AVAudio文件将它保存在文件中
如果你处理的是压缩流
你可以将它分解为压缩缓存
用AVAudioConverter将它转换为PCM缓存
然后通过PlayerNode将它提供给Engine
今年新内容中我们为Watch带来了AVAudioEngine子集
与此同时 我们也添加了AVAudioSession子集
以及你刚刚看到的所有核心级别
我相信你一定想看一下演示
我们为你准备了演示
我们直接使用SceneKit和AVAudioEngine开发了简单的游戏
在这个游戏中 我的举动是将小行星发射到太空
在屏幕底端有一团火焰
我可以使用Watch的数码表冠控制火焰
现在 如果行星接触到火焰
就会播放特别大的爆炸声
所以 让我们来看看
演示WATCHOS上的AVAUDIOENGINE
我肯定这个游戏违背了基本的物理定律
因为它在太空中播放音频对吧？这是不可能的
好 那让我快速看一下游戏中的AVAudioEngine代码
在我的级别中我有AVAudioEngine
我有两个PlayerNode
一个播放爆炸声
一个播放发射声
我也有连接到我音频资源的URL
在这个例子中 我使用缓存向引擎提供数据
让我们看下如何设置引擎
首先要做的是附加我的PlayerNode
所以 我触摸explosionPlayer和launchPlayer
接下来 我将使用核心级别
我将从我资产的URL创建一个AVAudio文件
然后我将创建一个PCM缓存
我将把文件中的数据读入PCM缓存
之所以能这样做是因为我的音频文件非常短
接下来 我继续操作连接源节点
以及引擎的主要混音器
所以 当游戏即将开始时我接着开启引擎
并开启播放器
当发射小行星时我只是安排launchBuffer
在launchPlayer上播放
当小行星接触到火焰时
只需安排explosionBuffer在explosionPlayer上播放
这样 只需几行代码
我就能为watchOS上的游戏
创造非常丰富的音频体验
这只是个简单的例子
我们非常期待能看到你制造的效果
多声道音频
结束AVAudioEngine介绍之前 我要谈论下多声道音频
具体的是 它如何与tvOS关联的
去年十月 我们发布了tvOS
以及第四代Apple TV
所以这是在全球开发者大会上我们首次可以谈论该话题
有关Apple TV上音频有趣的一点是
很多用户已经连接到多声道硬件
这是因为很多家庭影院系统已经支持
5.1或7.1环绕立体声系统
今天 我只是想略微展示下你怎样使用AVAudioEngine
来呈现多声道音频
首先 让我们回顾下AVAudioSession的设置
我首先设置我的类别和其他选项
然后激活会话以便配置硬件
满足我的应用需求
现在 按照我想使用的呈现格式
我首先需要查看当前路径是否支持该格式
要查看这一点我需要查看我想要的声道数
是否小于或等于最大输出声道数
如果是 那么我可以继续设置我想要的输出声道数
接着 我可以从会话中查询得到实际的声道数
然后使用它继续操作
或者 我可以查看当前端口上的ChannelDescription阵列
每个ChannelDescription向我提供一个channelLabel
和一个channelNumber
所以 我可以使用该信息了解确切的格式
以及如何将内容映射到连接的硬件上
现在我们换回AVAudioEngine设置话题
这里有两个用例
第一个用例是如果你已经拥有多声道内容
第二个用例是如果你拥有单声道内容
并且想对它空间化
这通常是为游戏准备的
所以 在第一个用例中
我拥有多声道内容以及多声道硬件
我只需获得硬件格式
我将它设置为我的混音器和我的OutputNode间的连接
在源端我获得了内容格式
并将它设置为我的SourceNode和混音器间连接
这里混音器为你处理声道映射
现在 在第二个用例中我们有一堆单声道源
我们将使用EnvironmentNode对其空间化
跟之前一样我们获取硬件格式
但在设置兼容格式前我们必须将其映射到
EnvironmentNode支持的格式
要了解支持的格式列表你可以查询我们的网上文件
所以 我设置好兼容格式
现在 在源端像之前一样 我获得内容格式
并将其设置为我的播放器和EnvironmentNode之间的连接
最后 我也必须将多声道呈现算法设置为
SoundField 它目前受EnvironmentNode支持
此时 我可以启动引擎开始播放
然后调整我们支持的所有各种3D混音属性
好 简单回顾下
AVAudioEngine是功能丰富强大的API
它简化了实时音频的处理工作
它使你能够处理多声道音频和3D音频
现在 你可以在Watch上
开发具有丰富音频体验的游戏
它取代了我们的AUGraph和OpenAL API
我们在之前演讲中简要介绍了Engine
我们鼓励你尽量了解与此相关的内容
现在 我要将舞台交给我的同事Doug
让他接着介绍
Doug？
谢谢 Saleem
好 我想在此继续介绍音频API
我们介绍AVAudioEngine时顺便说到了实时音频
Saleem强调
尽管音频处理在实时环境中发生
我们却是在非实时环境中进行控制
这就是操作简化的本质
但有的时候你实际想要
在实时过程或环境下工作
所以 我想进一步介绍下这点
那么 什么是实时音频
有的用例中我们需要实时操作
这种用例的特点是低延迟
可能我所熟悉的我们平台上
最早的应用例子是音乐应用
比如当用户按下MIDI键盘上的
一个键时你可能正在合成声音
我们想要尽量减少
从按下MIDI音符到播放音符的时间
我们有像吉他踏板一样的实时音频效果
我们想要尽量减少从吉他音频
输入进电脑
到我们在电脑中处理音频应用延迟、变形
然后将音频发回到扩音器所花费的时间
所以这种情况下我们需要低延迟以实现乐器的快速响应
电话也具有要求低延迟的特征
我们都曾经跟其他国家的人打电话
而且经历过高延迟的情况
高延迟在电话中是不好的
我们进行很多信号处理
我们需要降低延迟
同样 在游戏引擎中我们也希望降低延迟
用户在进行操作与控制杆等交互
我们想要尽快产生相应声音
有时候我们想要在声音呈现时
控制这些声音
或者 也许我们就已经有了游戏引擎
在所有这些案例中我们都需要写出能够
在实时环境中运行的代码
在这种实时环境中
我们受到约束的
一个主要特征是我们的操作是有时限的
对吧？每隔几毫秒
系统都会叫醒我们要求我们发出
持续同样短暂时间的声音
也许 我们能够完成任务产生无缝对接的音频
也许 我们任务失败花费过长时间产生音频
因而输出内容产生缺陷
用户听到的是故障的声音
我们制造音频所能使用的时间间隔很短
我们的期限通常短至3毫秒
而iOS中默认的20毫秒
也仍然是非常紧张的期限
所以 在这样的环境中我们必须特别小心自己的操作
我们不能停滞我们不能分配内存
我们不能使用互斥体
我们不能访问文件系统或者套接字
我们不能记录
我们甚至不能调用分派“async”因为它会分配续延
我们必须小心不要与Objective-C
Swift运行时交互 因为它们二者并不完全实时安全
有些情况下 它们也会采取互斥体
这是部分列表还有其它操作我们不能做
你要问自己最重要的事情是
我进行的操作分配内存或使用互斥体吗？
如果答案是“是”那操作就不是实时安全的
那么 我们能做什么呢
过会儿 我会向大家展示这方面的例子
不过 首先 我想只是讨论下如何管理
打包实时音频组件的问题
我们通过叫做Audio Unit的API集实现打包
所以 这是我们打包的方式
而对于你 关于此问题作为其他开发者
你可以通过它打包你在其它应用中会再次使用的
信号处理和模块
而且它也提供一个API可以管理
你非实时环境和实时呈现环境之间的
转变和交互
所以 作为应用开发者你可以托管Audio Unit
这意味着你可以允许用户选择一个单元
或者你可以简单的使用指向系统内置单元的硬编码引用
你也可以构建自己的Audio Unit
可以将它们构建为应用扩展或插件
你也可以简单地私下对你的应用
注册一个Audio Unit
这样很有用 比如如果你有一些小块的
信号处理想要在
AVAudioEngine环境中使用
所以 在Audio Unit下
我们有更根本的API
叫做音频组件
这是AudioToolbox框架内的一组API
框架维护了系统上所有组件的记录
AUDIO UNITS：组件
每个组件都有一种类型子类型以及制造商
这些是包含4个字符的代码
它们作为发现并注册组件的键
有很多种不同的音频组件类型
两种主要的类型是AudioUnits和Audio Codecs
但在Audio Unit中我们又有输入/输出单元
生成器、效果、乐器
转换器以及混音器
在codecs编码解码器中我们又有编码器和解码器
在macOS上我们还有音频文件组件
关于组件的实施
组件的实施有很多不同的方法
有一些是如果你用它写代码时需要了解的
而另外一些 不过是背景知识
现在创建组件最好的方法
若是Audio Unit 最好是创建Audio Unit应用扩展
通过10.11和9.0版本我们去年对此进行了介绍
所以 那些是应用扩展
而那之前 Audio Units是打包在组件捆绑包里的
audio codecs等也是如此
那大概要回溯到Mac OS 10.1了
有趣的是 音频组件也包括iOS上应用间的音频节点
节点应用使用
组件子类型和制造商密钥进行注册
主应用程序通过AudioComponent Manager
发现节点应用程序
最终 你能够注册——像我之前提到的——
你能够注册自己的组件以便用于你自己的应用程序
只是补充下有一些Apple内置组件
在iOS上 它们连接到AudioToolbox
所以 以上就是组件实施的情况
现在 这里 我要将焦点仅仅集中到一种组件——
音频输入/输出单元
这是Audio Unit
音频输入/输出单元最常用
如果你只使用一种组件这很可能就是
你会使用的组件
其中的原因是这是连接到系统基本
音频输入/输出路径的首选界面
现在 在macOS上 该基本路径位于Core Audio框架
我们称之为Audio HAL
这是非常低级别的界面
比如 它能使客户处理在多声道设备上
有趣的流媒体类型
所以通过音频输入/输出单元
能够非常轻松地处理Audio HAL界面
在iOS上 你甚至不需要Core Audio框架的访问权限
在那里 它不是公共的
你必须使用音频输入/输出单元
作为你将音频输入和输出系统的低级别方式
我们现在音频输入/输出
单元的首选界面是AUAudioUnit
及AudioToolbox框架
如果你使用我们的API已经有一段时间
你熟悉第2版Audio Units它是macOS上AUHAL系统
以及iOS和Watch上AURemoteIO系统的
一部分——
实际上 我不确定Watch上有没有
不过不论如何AUAudioUnit是你连接到
低级别I/O机制的全新现代界面
所以 我要向你展示使用
AUAudioUnit进行AudioIO操作的情况
所以 这里我用Swift写好了
产生方波的简单程序
这是我的信号处理
像之前提到的 我要展示你在这儿可以做什么
所以 这个波形信号发生器向你展示
你基本上可以读取内存写入内容并进行数学运算
这是这里进行的所有操作
即产生最简单的波形 ——方波——
至少从计算机的角度来说最简单
所以 这种级别叫做SquareWaveGenerator
让我们看看如何使用AUAudioUnit播放SqaureWaveGenerator
首先 我们创建一条音频组件描述
这条描述告诉我们寻找哪个组件
类型是输出
子类型是我根据平台在这里做出的选择——
RemoteIO或HalOutput
这里有Apple制造商以及一些未使用的标记
然后我可以使用组件描述创建AUAudioUnit
这样我就能得到想要的单元
现在 打开了我可以开始配置
这里我要做的第一件事是搞清楚
系统上有多少音频声道
这可以使用多种方法通过iOS上的AVAudioSession实现
不过 最简单和便捷的是
你可以简单地查询
输入/输出单元的outputBusses
而outputBus[0]是输出指向的流
所以我将获取它的格式那是我的硬件格式
那么 这个硬件格式可能是比较奇异的东西
比如 它可能显示惰性
我不知道是不是要处理它
所以我只是创建一个renderFormat
这是具有相同采样率的标准格式
以及一些声道
为快速简单起见我只呈现两个波段
而不论硬件声道数是多少
好 那就是我的renderFormat
现在 我可以告诉I/O单元
这是我想要在inputBus[0]上给你的格式
完成该操作后 该单元现会把我的renderFormat
转换成hardwareFormat
在该例中 在我的MacBook上
该单元会获取该去交错的浮点
并将其转换成交错浮点缓冲器
好 接下来 我将构建我的方波生成器
如果你是像我一样的音乐和数学迷
你知道代码中有A440该数值乘以
1.5后增长20%
所以 我将在左声道呈现A
右声道呈现E
这里是会在实时环境中运行的代码
其中有很多参数
而实际上我只需要其中的几个
我只需要frameCount和rawBufferList
rawBufferList是一种高难度的低级别C结构
我可以使用SDK上的覆盖在Swift语言中对其重包装
这样拿走了音频bufferList
让它看起来像是矢量或数组/阵列
将rawBufferList转换成
不错的Swift包装后我可以查询它的数量
如果我得到至少一个缓冲器那么 我就能呈现左声道
如果我得到至少两个缓冲器我就能够呈现右声道
这就是我现在要做的所有工作
当然 波形信号发生器内还有更多的工作要做
不过上述就是实时环境下的所有工作
所以 现在 我都设置好了准备好呈现了
我会告诉I/O单元
进行所有必要的分配以便开始呈现
然后I/O单元实际会让硬件
运行3秒 然后停止
这个简单的程序到此结束
这就是AUAudioUnit
接下来 我要简单讲一下其它一些Audio Unit
我们有效果 可以获取音频输入 产生音频输出
有乐器 可以获取类似MIDI的东西作为输入
同时也能产生音频输出
有生成器 能够产生音频输出
而不输入任何东西除了一些可能的参数控制
如果我要将我的方波生成器重新打包为Audio Unit
我会做成生成器
要托管这些种类的Audio Unit
你也可以使用AUAudioUnit
你可以使用单独的部分向它提供输入
这跟你在I/O单元上看到的
输出供应块非常相似
你可以将这些单元呈现部分连接起来
创建你自己的定制化类型
你可以使用参数控制这些单元
而且 很多单元尤其是第三方单元
都有很好的用户界面
作为主应用程序你可以获取
audio unit视图在你的应用程序中显示
并让用户与其交互
若你想编写自己的Audio Unit
我首先的做法很简单就是在应用的环境中
构建Audio Unit
这样你可以进行调试而无需担心流程间的通信问题
全部在一个过程中完成
你首先将AUAudioUnit划入子级别
使用AUAudioUnit的这一级别方法将其注册为组件
然后你可以对其进行调试
一旦完成——
如果你确定了要将其作为
Audio Unit扩展分布
你就可以采取同样的AUAudioUnit子级别
你可以对其微调和进一步修饰
不过然后你将需要多花一点功夫
将其打包为Audio Unit扩展
所以 你就获得一个扩展程序你可以把它嵌入某个应用程序
也可以在App Store出售该应用程序
好 我想邀请我的同事Torrey
向你展示下Audio Unit扩展的一些威力
过去一年我们一些开发者使用它
做了不少很酷的事情
大家可好？ 
参加WWDC可开心？
好
让我们制造些声响吧
我会从这儿开始 启动——
首先我的乐器在这儿
这是我的iPad Pro我首先启动Arturia iSEM
这是非常强大的合成器应用
这里是我喜欢的合成喇叭声音
我很喜欢这个声音 我想把它放到我正在编辑的曲目中
这个将作为我们的AudioUnit插件应用
现在 我要启动GarageBand
它将作为我们的Audio Unit主应用程序
现在GarageBand中有个我正编辑的sick beat
我将它命名为WWDC Demo
让我们听一下
好 接下来我们看一下辞句部分
接着 我们将处理和声部分
这应该是歌曲的高潮部分
我希望多一点动感多一点张力
让我们通过Audio Unit制造这种效果
我将在这里添加一个新曲目
添加新乐器 我会看到这里有Audio Unit选项
如果我选择它 接下来我会在这里看到系统上
寄存所有的Audio Unit
我看到的是Arturia iSEM因为我在家里练习这个
选择iSEMGarageBand现在将
在这里显示屏幕上的MIDI控制器以供我使用
它有完整的尺度变化以及琶音器 就在这里
我会充分利用这些工具因为我很喜欢动感的音乐
在这里的左边你可以看到音调/修正滚轮
你甚至可以修改速度
Audio Unit在这里向我提供的视图
其实我可做小的调整
而现在 我要在这里录制一小段音频
然后看一下它在整个曲子中的效果
那么——
好了 不错
让我们听一下它在整个曲子中的效果
好了这就是我想要的张力
现在 让我进行更深入的介绍向大家展示我进行的操作
我会在这里进行编辑
我会更仔细地观察循环曲目
这里 我希望大家注意两点
第一点是这些是MIDI事件
使用跨应用音频与将Audio Unit作为插件使用
的不同点是你实际可以在这里看到
MIDI音符 这就使事后的编辑更简单
我希望大家在这里注意的另外一点是
你可以在这里看到单个MIDI音符
但是之前你看到的是我弹奏巨大粗厚的和弦
这是因为我利用了
GarageBand内置的琶音器
所以我才得到了这些单个音符
如果愿意我可以随意更改
使音符听起来更人性化
不过我对曲子现在的效果已经很满意
这里 我最后要向大家显示的实际是 首先
我会将这个复制到临近的单元格
我之前跟你提过这里提供的Audio Unit视图
实际是交互式的
它不仅是外观漂亮的图片
所以 如果你喜欢探索你甚至可以尝试
为朋友演奏一曲
略微提高音量
让我们收尾
我的演示就到这里
我想感激大家所付出的时间和精力
始终感谢大家写出炫酷的应用
演示Audio Unit扩展
谢谢Torrey
好 这里简单回顾下
你能看到我们去年关于Audio Unit扩展的介绍
其中更详细地介绍了API的构造
这里我们只是想向你展示
由于Audio Unit炫酷的功能人们利用它都做了什么
好 说到MIDI我们看到GarageBand怎样
将Torrey的演奏录制成MIDI
我们的系统中有很多API是
使用MIDI通信的而要在什么时候使用
哪些API并不总是很清楚
所以我希望能够帮助大家稍稍澄清这一点
现在 你可能就有一个标准的MIDI文件
比如 难听的手机铃声
不过MIDI文件在音乐教学中十分有用
我可以获得我想学习乐曲的MIDI文件
我可以看到所有的音符
若你有一个MIDI文件 你可用AVAudioSequencer
播放该文件
这样会在AVAudioEngine环境中播放文件
如果你想要控制软件合成器
如我们看到GarageBand控制iSEM的情形
能使用的最好的API是AUAudioUnit
而且如果你想要AUAudioUnit回放到
AVAudioEngine你可以使用AVAudioMIDIInstrument
现在 有MIDI核心框架
人们经常认为该框架会做一些
其它较高级别的任务
但实际上 它是非常底层的API
基本上只是用于与MIDI硬件通信
比如 外部USB的MIDI接口
或者蓝牙MIDI键盘
我们也提供MIDI网络驱动
你可以使用它发送原始MIDI消息 比如在iPad
和MacBook之间发送
你也可以使用核心MIDI框架
在流程之间实时发送MIDI
这有时会涉及一个灰色地带
人们会问：“好吧 我该使用核心MIDI在我的
排序器以及正在收听MIDI和
合成的应用之间通信吗？”
我会说那可能不是适合于这种情况的API
如果你正在同时使用MIDI和音频
我会使用AUAudioUnit
情况应该是当你在两个应用中
或者一个应用的两个实体中
操作纯MIDI时——或许其中一个是来自
另一开发者的静态库
在上述情况下 你可以将核心MIDI用于流程间
或实体间的实时MIDI
这里就到了我们音频API长篇介绍的尾声
我们从应用程序开始——在底端是
CoreAudio框架和驱动
介绍了AVAudioEngine如何用AVAudioSession
在我们除了macOS之外的所有平台上完成设置
我们介绍了你可以怎样使用AVAudioPlayer
及AVAudioRecorder从文件中
进行简单的播放和录制操作
或者如果你的文件或网络流媒体涉及视频
你可以使用AVPlayer
AVAudioEngine是构建复杂处理图表的
优质高级别界面
可以处理很多问题
你通常无需使用任何较低级别的API
不过如果使用了 我们介绍了AudioToolbox中的
AUAudioUnit 它可以让你直接与I/O循环
与第三方或与你自己的乐器效果和生成器通信
最后 我们简要介绍了核心MIDI框架
我今天在此的介绍结束了
你可以访问此链接了解更多信息
我们在此提供了很多相关介绍
非常感谢