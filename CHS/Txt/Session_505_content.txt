使用Core Image编辑Live Photo和RAW处理
非常感谢各位 早上好
我叫David Hayward今天我要讲的是
关于使用Core Image编辑Live Photos和Raw图片
我们今天要讲很多不错的东西
首先我简单介绍一下Core Image
如果你对它一无所知的话
接下来我们会谈下我们今早的三个主要话题
第一 在iOS上调整RAW图片
第二 编辑Live Photos
第三 如何扩展Core Image
通过全新的方式 即利用CIImageProcessor节点
首先 是对于Core Image的简单介绍
选择Core Image的原因是它提供了一个非常简单
高性能的API来将滤镜应用到图片上
基本的想法就是你开始有一张图片
其来自于JPEG或某个文件或内存你可以选择
对其应用一个滤镜 结果就是输出图片
在你的代码中实现是非常非常简单的
你只需要调取你的图片调用applyingFilter
并声明滤镜的名字
以及其他适用于该滤镜的参数
这非常简单
当然了你可以完成更复杂的事情
你可以将多个滤镜链在一起使用...
应用到序列或是图片上并获得非常复杂的效果
Core Image的一个非常棒的特性就是它提供了自动颜色管理
这对于现如今很重要
我们现在有很多设备
支持宽色域的输入和输出
Core Image所做的就是它会自动插入
恰当的节点到渲染图中去
以便它与你的输入图像匹配
到Core Image的工作域
而到了要显示的时候
它会从工作域匹配到显示域
这是你应该特别注意的
因为宽色域图片和宽色域显示现在都很常见了
而很多做图像处理的开源库
不会自动处理它
这是Core Image很棒的特性因为它处理了所有这些
让你很容易的使用
另一个要注意的是每个滤镜
实际上是附带着一小段代码的
叫做kernel的小小子程序
我们所有内置滤镜都有这些kernel
一个不错的特性是如果你将一个序列的滤镜链在一起
Core Image会自动连接这些
子程序成单个程序
这么做是为了提高性能
通过减少
通过减少中间缓存的数量
Core Image有逾180个内置滤镜
它们在我们的所有平台上都是一样的
不管是macOS tvOS还是iOS
我想谈下今年我们新发布的一些滤镜
其中一个是用来生成色彩饱和度和梯度
它会生成色彩和饱和度的梯度
然后你可以声明一个参数
关于图片的亮度
也声明了颜色轮内的色域
如你所料此滤镜目前在用在macOS上
作为颜色选择器的基础
目前可以识别几个不同类型的显示色域
另一个新滤镜是CINinePartStretched and NinePartTiled
你可能有一个小的资源
像是这个画框
而你想要拉伸它使其适应一个特定尺寸
这个滤镜非常容易使用
你需要提供一个输入图片和四个断点
水平的两个 垂直的两个
一旦你声明了这些点之后 你可以声明
你想让其拉伸到多大的尺寸
它非常容易用
第三个新滤镜很有意思
开始时我们有个很小的输入图片
在这里有一个包含有颜色数据的图片
但它也可以包含参数数据
假设你有一个小的颜色或者参数集合
可能只有6乘7个像素
你想要扩展到全尺寸的图片上
我们要做的是扩展颜色图像这个小的颜色图像
但是维护底图图形的边
如果你不维护底图图形而只是拉伸
小的图片和全尺寸的图像一边大
你只会得到一张混合颜色的图片
但利用这个滤镜你可得到更多东西
你可以得到
维护边和颜色的图片
这对于很多其他类型的算法来说也是个有用的特性
事实上我们在新版本的照片应用里就用到了它
来提高调光滑条的表现
我期待看到你在你的应用里会怎么用
我们今年也做了一些新的性能控制
今年还对Core Image性能做了改善
其中一个就是我们默认打开了Metal功能
所以如果你用了任何一个我们内置的180个滤镜
或者你自定义的kernel
所有的kernel都会被快速转换为Metal的供你使用
这是个不错的方式来利用
Metal的作用而你几乎不用做什么
我们还对一个重要的API做了很大的改进
从CIImage中创造了UIImage
相比原来它的性能提高很多
因此你可用它高效地在UIImage视图中使一个图片动画化
另一个新特性是
Core Image现支持了一个新Core Graphics特性
就是Core Graphics现支持半浮点数了
让我们谈谈像素格式因为这会引出一个很有意思的点
我们对于传统的像素格式RGBA8都很熟悉
它仅需要花费每像素4字节来存储拥有8比特的深度
并且可以在0到1范围内编码
然而 这个格式不利于呈现宽色域数据
因为它只有8比特而且值被限定在0到1的范围内
过去的替代方案是使用RGBAfloat
它每像素有16字节 需要四倍的内存
但会带给你想要的深度和范围
另一个特性是它使用了浮点数
也就是会分层 它是呈对数分布的
这很好地适应了人眼感应颜色的方式
还有个Core Image支持的新特性
Core Graphics现也支持
我将其成为Goldilocks像素格式 即RGBAh
这会让你在每像素8字节的情况下
存储10比特深度的数据
允许的值区间是负65000到正65000
这些值是对数性量化的
它对于存储线性数据很好
这些数据是不会被识别为量子化的
因此我高度推荐这个像素格式
另一个我要提到的新格式是
Core Video支持新像素格式
它名字很长 叫做30RGBLEPackedWideGamut
它也支持10比特的深度
但通过牺牲alpha信道它只需要每像素4字节就能存储
它对于很多情况都很有用
Core Image支持或是渲染自
或者渲染到CV像素缓存利用这个格式
接下来我想谈下一个主要的话题
关于利用Core Image调整RAW图片
我很高兴今天能讲下这个
我们致力于此已经很长时间了
它包含了我们大量的辛苦工作我很兴奋
我们将其引入了iOS中
我要先说下什么是RAW文件
如何使用CIRAWFilter API
一些关于支持宽色域输出的说明
还有关于管理内存的技巧
那么首先 什么是RAW文件呢
大部分相机的运作方式都包括两个关键的部件
颜色过滤阵列和传感器阵列
其工作原理就是光线从场景内进入
通过颜色过滤阵列并被传感器阵列所计数
当然了该数据实际上是一个更大图像的一部分
但是为了将其转换为可用的图像
需要进行大量的图像处理
以便为用户生成一张不错的图片
我想谈一下这个 其主要思路就是
如果你获取由传感器所捕捉的数据那就是RAW文件
如果你获取的数据是捕获于
图像处理之后那就是一张TIFF或者JPEG图片
RAW存储着未处理的场景数据
而JPEG文件存储处理过的输出图像
换句话说
RAW存储的是你要生成一张图片的原料
而JPEG存储的是原料的结果
将这些原料烤成漂亮的蛋糕后
为了从原料
做成最终的蛋糕是需要很多阶段的
让我大概说下其中的几个
首先 我们要提取文件中的元数据
其会告诉我们要花多久来做蛋糕接着刚才的比喻来说
我们还需要将从传感器中获得的RAW数据解码
我们需要将图像去马赛克以重构整张有色图
从所获取的数据中
每个像素位置只有一个RGB值
我们需要应用几何畸变来进行镜头矫正
减少噪点 也是处理中的一个重要点
我们需要从场景数据中做颜色匹配
这些由传感器捕获的数据会传到输出数据用以显示图像
接下来我们要做的事就是诸如调整曝光
色温 还有色调
最后 非常重要的是 增强锐度
对比度和饱和度来使图片看起来更漂亮
这么多阶段可真不少
RAW的优点有哪些呢？
最大的优点就是
RAW文件包含了线性的深度像素数据
这使得可编辑性很好
RAW的另一个特性是它的图像处理每年都变得更好
因此也就保证了利用RAW你昨天所拍的照片
可能在你来年处理它时效果更好
RAW文件还有色彩空间的不可知性
它们可以被渲染到任何目标的输出空间
这对于我们如今诸多的显示标准来说是个不错的特性
用户可以选择使用不同的软件
来解释RAW文件
就像是把相同原料交给两个不同的厨师
你会得到两个不同的结果
有些用户可能更喜欢另一个厨师
JPEG也是有很多优点的
首先就是由于已经处理过了
它们加载和显示非常快
它们包含针对特定输出的颜色和调整
这可能很有用
它也会给你可预见的结果
还有值得一提的是如今的相机表现出色
对于拍摄JPEG照片来说
并且我们的iOS相机尤其是一个好例子
说到RAW 让我再说一点
关于我们的平台是如何支持RAW的吧
好消息是我们现在在iOS上完全支持了RAW
即将到来的tvOS推送也是
这意味着我们支持超过400个独特的相机型号
来自于16个不同的厂商
我们也支持被捕获的DNG文件
用我们自己的iOS设备
iOS设备包括iPhone 6S、6S Plus
SE 还有iPad Pro 9.7
这真让人兴奋
我推荐如果你们还没有看回去看看
iOS摄影进阶
那个演讲是关于
可在这些设备上捕捉RAW照片的API
另一个很棒的东西是我们现在拥有了同样同性能的RAW管道
iOS平台 如我们在macOS完成的一样 可算是一个成就了
我那天计算了一下我们的管道
它包含了超过4500行的CIKernel代码
而且运行的很高效
它是我们能力的确切证明 也是
Core Image可以处理复杂渲染场景的证明
我们iOS上的管道需要A8或以上的设备
你可以通过你的应用来测试
通过检查iOSGPU Family 2
另一个关于平台支持的说明是
我们一直在增加对新相机的支持从它一上市就开始
而且也在改进对已支持相机的支持质量
新相机被加到未来的软件更新中
我们也在周期性的改进我们的管道
我们的管道有不同的版本你既可以用我们的最新版本
也可以倒回使用你想要的旧版本
为了避免后面的麻烦 我想做个演示
它看起来是怎么样的
我这里有些示例代码有一个早前版本的
可供下载 它叫RAWExposed
它是个应用 同时最新版本也是
相片编辑扩展
我们可以进入Photos程序并实际运用这段示例代码
我们有三张24兆像素的RAW照片
是用Canon 5DMark III拍的
你可以看出来这张照片有点过曝了
RAW的一个很棒的特性就是你可以修补这样的照片
我们来这里 点“编辑” 然后...
用我们的照片编辑扩展程序来编辑这个RAW文件
那么现在既然我们是在将其当做RAW文件来编辑 就可以做些调整
［听不清］
我们可以上下调整曝光量
我们可以在这24兆像素上浏览
而且得到了不错的结果
我现在对这张照片很满意看上去比之前强多了
我会点击“完成” 之后它会生成
一张新的全分辨率照片 它会显示在
Photos应用中
另一个关于RAW文件不错的特性是你可以做出不错的调整
对于一张照片的白平衡
这张照片不错 但是有点不正而且白平衡也是关闭的
我要进到这里
稍微调整下白平衡
以此得到一张好看得多的照片我们可以放大来看看成果
我们可以实时地调整这些结果
然后点击“完成”以保存
另一张我想展示的照片
是张噪点很多的
我想向你们展示一下我们的噪点减少算法
我们的4500行kernel代码有超过一半是涉及到噪点减少的
我要进到这里 编辑下这张照片
你们可以看到 至少在前排的人可以
照片上的颗粒
我们API中的一个特性就是可以
关掉我们的噪点减少算法
然后你就可以看到RAW文件中噪点的自然呈现
这是个挺有挑战性的任务
既要对照片实施噪点减少
使其没有这些带颜色的点还要保留颜色边缘
照片所倾向于保留的
我保存下照片
最后 我想演示一下
我们这周早些时候拍的一张照片
在大堂里 用这个iPad拍的
我就是那些拿iPad拍照的人其中之一
在此我想展示给你
一张本身就带有挑战性的照片
因为它有些地方太暗而有些地方过曝了
我有个能做的事情就是
降低曝光量
我有个高光的滑动条可让我把高光调高一点
我也可以降低曝光量
现在我能看到窗外发生了什么
但是现在影子太暗了我可以调高一下那块
这里展现了你可以对RAW文件做些什么调整
这是你像素数据拥有更深精确度的优势
这是RAW文件所带来的
我要点击下“完成”
这就是我们关于iOS上RAW的演示
非常感谢我们的团队使这一切成真
让我谈下API 因为它仅仅是
提供一个演示程序是不够的
我们想要使你们的应用也能用到它
我们有一个相关的API叫CIRAWFilter API
它为你的应用提供了一些关键性的东西
它为你的应用提供一个CIImage拥有宽色域
扩展的区间 半浮点精度运算
它也赋予你对于很多个阶段的控制权
就比如我刚才演示过的RAW演示管道
它也利用GPU提供快速交互表现
在我们的所有设备上
这是怎么实现的呢 API其实很简单
你开始有一个输入可以使文件URL或者数据
甚至是利用我们下次推送中会带来的CVPixelBuffer API
这是我们的输入
我们会通过输入来创建一个CIRAWFilter的实例
过滤器被实例化的时候它将会
给所有用户可调整的参数赋上默认值
而这些是你应该想呈现给用户的
你有了CIRAWFilter以后你可以
向它请求一个CIImage你可在这里开始做很多事
让我给你展示一下代码看看它多简单就能实现
我们只需要给它一个URL
我们要创建一个接受该URL的CIFilter实例
接下来 如果我们想获得值
该值是关于当前的噪点减少量我们可以获取该值
forKey: kCIInputImageNoiseReductionAmount
如果我们想改变它非常的简单
我们只需给该键设一个新值
做完这些改变后请求outputImage就完成了
我们就需要做这些
你可能想要显示这张照片
通常你会获取这张照片 并将其显示在
UIImage或MetalKit视图或其他类型的显示系统中
用户可能会提出
可能这张照片有点过曝了
所以在你的UI中应该有调整曝光的滑条
以便用户可以做出调整
你可将其作为一个新值传给CIRAWFilter
然后你可以请求一个CIImage
然后你就可以显示这张曝光调整稍微亮一些的新照片
这也非常容易
你还可能想获得你的CIImage——
有些时候可能你想将你的照片导出到背景
来生成一张全尺寸的照片
或者你可能要导出几张照片到背景
在这些情况下 你应该
或是创建一个CGImage用来将其传到其他API
或直接用JPEG或TIFF我们现有很容易用的API来实现这个
如果你要实现诸如RAW这类大文件的后台处理
我们推荐创建一个CIContext来明确用于此目的
你要声明一个上下文
被保存在一个单例变量中
不需要给每张照片都创建一个新的上下文
这使得CI可以缓存所有涉及到的kernel的编译文件
不过因为我们只需要渲染一张照片一次
我们不需要Core Image来缓存中间文件
所以你可以在这声明为假
这会帮助减少此场景下的内存需求
还有一个设置是关于你想要使用低优先级的GPU渲染
如果你是要做一个后台保存
你不会想让所需的GPU使用度
对于该后台操作会拖慢性能
对于你的前台UI
不管在Core Image或Core Animation中被完成的
这对于后台处理很棒
我们今年要发布的一个很棒的东西就是
该选项对于macOS也可用
一旦你有了上下文就很简单了
你要决定你要渲染的颜色空间是什么
例如 DisplayP3颜色空间
我们有个新的很方便的API
用来生成CIImage然后将其写成JPEG
非常容易 你要声明CIImage
目标URL和颜色空间
在此你也正好可以决定要给JPEG用什么样的压缩质量
在这里会生成一个JPEG图片
其已经被标记于P3空间
这是个不错的方式来生成宽色域图片
它会正确显示
在任何支持基于ICC颜色管理的平台
如果你觉得你的照片会出现在一个平台
其并不支持颜色管理
我们还有一个新选项供你选择
该选择是作为CGImageDestination API的一部分
并且它是CGImageDestinationOptimizeForSharing
它会存储所有的颜色
这些颜色都在P3颜色空间内
但是将它们这样存储并有一个定制的档案
以便该照片仍然会被正确显示
若这张照片的接收者不支持颜色管理
所以这也是个不错的特性
还有若你想要创建一个CGImage
从CIImage 我们有一个新API和一些新选项
我们的这个方便的API可以使你
声明什么颜色空间和像素格式
你想要渲染
你可以选择创建一个CGImage
其格式为RGBAh
也就是我之前谈到的Goldilocks像素格式
在这种情况下你也可以选择使用一个特殊的颜色空间
也就是extendedLinearSRGB空间
因为像素格式支持0到1区间之外的值
你要让颜色空间也是如此
另一个新选项是可以声明
创建CGImage的行动
是要延迟还是立即进行
如果你声明要延迟 则相关的工作
用来渲染CIImage到CGImage
会在CGImage绘制完成后进行
这样会很好的减少内存占用
特别是如果你之后只会画CGImage的一部分
或者只画一次
然而如果你要渲染那张照片很多次的话
你可以把延迟设为假
在此情况下Core Image会完成
将其渲染到CGImage的工作当此方法被调用时
这是个我们给你们的应用配备的很棒且灵活的新API
另一个关于Core Image过滤器API的高级特性
我今天想谈下的就是 这个
如我之前所说的管道有很长的阶段
用来处理RAW文件 有很多人问我
我如何将我自己的处理加入到管道上
一个常见的开发者想要加入
处理到RAW管道上中间某处
在去马赛克完成后
但是在所有非线性操作之前 像是锐化
还有对比度和颜色加速完成后
对此我们有个API
它是CIRAWFilter一个属性
可以允许你声明一个可插入的过滤器
其被插入到图表的中间
我希望看到你们可以想象
并思考什么被带到了该位置
一些我之前提过的关于宽色域输出的说明
CIKernel语言将浮点精度作为一门语言来支持
不过当CIFilter需要被渲染到
中间过滤器时 我们会用能用的格式
基于当前的CIContext
macOS上默认可用的格式是RGBA
我们的Goldilocks格式
在iOS和tvOS上我们的默认格式还是BGRA8
其性能良好
但是如果你要渲染扩展区间数据
这可能不是你想要做的
记住我们的RAW管道
我们管道的所有kernel
强制使用RGBA半浮点精度
这对于RAW文件很关键
但如果你担心
宽色域输入和输出
要在渲染图上保留该数据
那么你应该修改CIContext当你创建它来声明
你想要一个可用的格式也就是RGBAh时
我想再提一下Core Image支持很广泛的
宽色域输出空间
例如 你可以渲染到
extendedLinearSRGB或Adobe RGB或DisplayP3 无论哪种都行
如我之前提到的我要演示一张24兆像素的照片
RAW文件可以比你想象的大得多
RAW文件除了大也需要
一些中间缓存来渲染管道的所有阶段
这很重要
以便减少你程序中的高度占用内存的水印
通过使用我今天谈到的这些API
比如当你不需要的时候关掉中间缓存
或者使用新的JPEG写入形式其非常高效
或是当创建CGImage时声明延迟渲染
这是些关于RAW文件限制的说明
其支持内存大于2GB的iOS设备
我们支持最大120万像素的RAW文件
我们很骄傲能将其实现
对于运行在1GB内存设备的应用我们支持
处理最大60兆像素的照片这也很惊人了
这对于照片编辑扩展也适用
会使其花费更少的内容就可以运行
这就是关于RAW的讨论
我很容易今天可以为你们做演示
接下来我要把讲台交给Etienne
和你们讲下另一个很棒的新图片格式
以及你们如何在程序中编辑Live Photos 谢谢
谢谢你 David
大家好
我很高兴今天站在这里
跟你们谈谈如何在程序中编辑Live Photos
首先我们要进行一个简要的介绍
什么是Live Photos然后看看你都可以编辑什么
接下来我们会一步步的看看代码
看看你如何得到一张Live Photo以供编辑
你如何设置Live Photo编辑环境
你如何将Core Image滤镜应用到Live Photo上
以及你如何在你的程序中预览Live Photo
最后就是你如何将编辑好的Live Photo保存到照片库
我们最后会做个快速的演示
那么让我们开始吧
正如你所知 Live Photos
就是包含动作和声音的照片
从拍摄前到拍摄后
Live Photos可以用新的设备拍摄
如iPhone 6S、6S PlusiPhone SE和iPad Pro
事实上 Live Photo是这些设备上的默认拍摄模式
因此你可以预期你的用户
已在他们的照片库有大量的Live Photos了
今年Live Photos有何新特性？
首先是用户可以在Photos中完全编辑Live Photos了
他们可以做出所有的调整
如普通照片那样应用到Live Photo上
我们有新API用以在你应用中拍摄Live Photos
更多关于此的信息
我强烈推荐你们去看下进阶
本周早些时候举行的iOS摄影演讲
它也包含了关于Live Photos的许多信息
基于拍摄者的角度
最后我们有新API编辑Live Photos
这也是我为什么今天要站在这讲的原因
好了
到底什么能被编辑呢
首先就是你可以编辑照片的内容
而且你还可以编辑视频的所有帧
你也可以调整音频的音量
你可改变Live Photo的大小
你不能实现的就是
你不能改变Live Photo的持续时间
为了获得可供编辑的Live Photo
首先就是要从照片库中获得一张Live Photo
有两种方法可以实现
取决于你是要创建一个照片编辑扩展
还是一个PhotoKit应用
如果是照片编辑扩展的话
你若要实现Live Photo编辑首先需要
添加LivePhoto字符串
为你的扩展将其加入支持的媒体类型数组
然后在startContentEditing实现中
它会被自动调用
你会得到你收到的编辑输入的内容
你还可以检查媒体类型以及媒体子类型
以确保它是张Live Photo
好的
另一方面如果你创建一个PhotoKit应用
你已从PHAsset请求了contentEditingInput
那么你就可以以同样方式来检查媒体类型和媒体子类型
接下来要设置一个LivePhotoEditingContext
一个LivePhotoEditingContext包含所有资源
即编辑Live Photos所需的
它包含有关Live Photo信息
诸如照片的持续时间
Live Photo的尺寸还有方向性
它也有帧处理器属性
你可以用来编辑Live Photo的内容
我会后面再跟你们多介绍一些
你也可以调整音频的音量
你可请求LivePhotoEditingContext来为Live Photo准备回放
你可以请求LivePhotoEditingContext
来保存和处理Live Photo用来保存到照片库
创建一个LivePhotoEditingContext非常简单
你只需要创建一个新的
从LivePhotoEditingInput为了Live Photo
好了
现在让我们来看下如何
使用我之前提到的帧处理器
我会通过描述一个PHLivePhotoFrame对象来介绍Live Photo的帧
其包含了输入图像也就是该帧的CIImage
类型 即它是一个视频帧还是相片帧
和Live Photo中的时间帧
还有该帧被渲染时的分辨率
为了实现一个帧处理器
你要在LivePhotoEditingContext中设置帧处理器属性
使其成为一个块来以参数形式接收一帧
并返回一张图片或者报错
我们刚返回了帧的输入图片
它其实就是节点帧处理器
现在让我们看看真实的例子
这是张Live Photo就像你在Photos中看到的
我可以播放一下
就是这
还有
假如我们想要对Live Photo做个简单的调整
就从一个简单的矩形剪切功能开始吧
这里是如何实现
对于你帧处理器的实现
你要从帧的输入图像开始入手
然后你需要计算剪切矩形的数据
然后你可以用这里的方法来剪切图片
即对rect调用剪切然后返回剪切完成的图片
这样就可以完成编辑和剪切Live Photo
这里是得到的结果
我可以放侧面图你可以看出照片是被剪切过的
而我播放的视频也是被剪切过的
好了
这就是关于非常基本的静态调整的例子
如果我们想要做个更动态的调整
这张照片依时间而改变
Live Photo播放时随之改变
你也可以实现这个
让我们做个剪切的例子来实现动态剪切
这里是我们要如何实现
首先我们需要获得一些信息
关于Live Photo的时间选择像是照片的确切时间
因为我们想保持相同的效果
让你的剪切矩形位于Live Photo中心位置
接下来是我们捕获Live Photo的时长
你会注意到我们是在帧处理器代码块之外完成它的
以此来避免循环依赖
在这代码块里我们可以请求关于该帧确切的时间
然后我们可以写一个时间的方法
使用所有这些信息来帮助运行矩形剪切
这里是——
结果 看得出来Live Photo以相同方式被剪切
就如照片一样 但当我播放它时
你可以看到矩形剪切现在从底部移动到了顶部
这里是一个基于时间调整的例子
现在让我们看点别的
这个效果很有意思
因为它是一个依赖于分辨率的效果
意思就是滤镜的参数是怎么声明的
它们在像素中被声明
也就意味着你需要额外的仔细
当你应用这类效果时要确保
此效果是视觉上一致的
无论Live Photo所渲染的分辨率是多少
在此我播放它 你可以看见视频
特效被如应用到照片那样应用到视频上
真不错
让我们看看怎么能正确实现
在你的帧处理器中你要注意
帧上的renderScale属性
它会给你当前帧的分辨率
与Live Photo中的一比一全尺寸的静态图片相比
所以请记住
视频帧和图片也是不同的尺寸
通常视频会比照片小得多
因此你要确保能正确的实现它
为了实现这个目的
你可以使用这的比例尺
来案例比缩小宽度参数以便一比一
的全尺寸照片的参数将会是50
但它会在小分辨率下变得更小
另一个可以用来做出依赖分辨率的调整的方法就是
使用
利用图片的范围就如我现在这里做的那样——
对inputCenter参数
我实际上使用了图片的中点 这也成功
正确的缩放了
好的
对于这张图片还有一个编辑的地方
你们可以注意到我在这边做了一个标识
可能看上去很熟悉 当我播放它时
你会看到标识从视频中消失了
就是关于如何将一个调整只应用到照片上
而不是视频中
这里是如何实现的
在你帧处理器的实现中
你要看一下帧类型在此我们要检查下它是不是一张图片
然后我们将静态标识整合到图片中去而不是视频中
就是这么容易
你们或许知道 有一些调整
可能是一个本地广告或是单个广告
你不想或者不能应用到视频中
而这么做就能很好的实现这一功能
好了
我们现有了一张编辑过的Live Photo
让我们看看如何在应用中预览它吧
你用PHLivePhotoView来预览一张Live Photo
这个视图在iOS中早就可用了而今年引入了macOS中
为了预览Live Photo你需请求LivePhotoEditingContext
以准备回放一张Live Photo你要传入
目标尺寸也就是你视图的像素尺寸
然后你要异步地回调
附着一张渲染过的Live Photo在主线程上
接下来你要做的就是设置
LivePhotoView的Live Photo属性
以便你的用户可与其Live Photo交互且获得
编辑过的Live Photo看起来如何的印象
现在
最后一步就是将其保存到照片库中
这取决于你开发的是一个照片编辑
扩展或PhotoKit应用
若是照片编辑扩展 你就要实现finishContentEditing
第一步 创建一个新的contentEditingOutput
从你早先接收到contentEditingInput中
接下来你要请求LivePhotoEditingContext
以保存Live Photo到该输出中
这会处理全分辨率的Live Photo
以异步的方式 并且在主线程上回调
成功还是报错
如果所有都顺利的话
你还要确保你除了编辑的内容还保存了调整的数据
这将会允许你的用户回到
接下来在你的应用或者扩展中并继续在那编辑
最后要调用completionHandler
对于该扩展 然后你就完成了
若你开发的是PhotoKit应用步骤就很类似的
唯一的区别就在于你要
它们是来自于你本身的变化
使用PHAssetChangeRequest
现在我要给你们展示一个快速的演示
好了
我创建了一个Live Photo扩展的简单演示
我今天想要展示给你们看
我现在Photos应用里可以看到一些Live Photos
可以来挑选看看这些内容
我可以滑动来看它们活动起来
这就是我今天要编辑的照片
现在我要开始编辑了正如我之前提到的
我在Photos里就能编辑Live Photo
让我来编辑看看
我想要应用下David之前提到的这个新的亮度滑动条
好了
我可以在Photos应用中播放它
当然了 我可以
在这就停下但我想也应用下我的示例编辑
我要在这选择我的扩展
我们应用的是贯穿幻灯片所提的相同的调整
你们能看出来这是个挺简单的扩展
它显示LivePhotoView因此我可与之交互
我可以点按来播放它就像在我的扩展这样
这很简单
下面一步就是要点击“完成”来保存
而且要处理一个全分辨率的Live Photo
并将其发送回照片库
就是在Photos那儿
好了
这就是这个演示
现在回到幻灯片上
谢谢
好的
这里是我们今天目前为止所介绍的一个简要总结
我们已经学到如何获得一张Live Photo
从照片库中
如何使用和设置一个LivePhotoEditingContext
如何使用帧处理器来编辑Live Photo的内容
我们介绍了如何在你的应用中利用LivePhotoView来预览Live Photo
我们看到了如何将Live Photo保存到照片库中
我现在迫不及待地想看到你们会用这个新API做出些什么
有几点是需要记住的
首先如果你是要开发一个照片编辑扩展
别忘记...将LivePhotoEditing加到
你info.plist中来扩展
否则你得到的是一张静态图片而非Live Photo
就如我所说的你要确保保存了调整数据
以便你的用户们可以回到你的应用中
继续无损的编辑
最后 我觉得如果你已经有了一个照片编辑应用
采用Live Photo及添加对于LivePhotoEditing的支持
使用这新API实现就该非常容易
特别是如果你的应用已经使用了Core Image的情况下
如果没有Core Image里有个新API
可以让你将自定义的处理集成到Core Image里
我会请Alex上台给你们详细介绍
谢谢
谢谢 Etienne
我叫Alexandre Naaman
我今天要讲的是关于一些新功能
关于Core Image之前所没有的额外特效
这会用到一个叫CIImageProcessor的新API
就如David之前提到在Core Image中 你可实现很多东西
使用我们内置的180个滤镜
你还可通过编写自定义的kernel来做进一步的扩展
有CIImageProcessor我们能实现的就更多
我们可以在渲染图中插入一个新的节点
它能实现我们想要的一切
还与现存的图完美融合
我们可编写自定义的CPU代码...或是Metal代码
使用CIImageProcessor时
与编写通用kernel有类似
过去你写通用kernel要声明某些字符串
然后重写你CIFilter中的输出图像方法
并且提供范围 也就是
你要创建的输出图片尺寸
还有roiCallback函数
最后
无论你要将何参数传入kernel中
这与创建CIImageProcessors有许多的相似性
所以我们今天不会再深入讨论它们了
我们建议你去看看2014 WWDC的演讲515
若你想创建一个CIImageProcessors
我们强烈推荐你回去看下那个讲座
因为我们讨论了如何处理范围
和ROI参数
现在让我们看下这个API
用来创建CIImage处理器的是什么样的
这可能在将来更新中会有些许变化
但是它现在的样子
相似性是这些
我们需要提供范围
也就是我们要生成的输出图片的尺寸
给它一个输入图像
还有ROI
我们需要提供很多额外的参数
例如我们要创建的节点的描述
我们需要提供一个摘要有着某种哈希值
对于我们所有的输入参数
这对于Core Image很重要
因为这是Core Image如何决定
我们是否要缓存那些值
还有我们是否需要重渲染
你需要确保每次你的参数改变的时候
你要更新哈希值
接下来我们可以声明是输入格式
在这个例子中我们用了BGRA8
但你也可以声明为0
这意味着你会获得对于该上下文可用的格式——
作为一个输入图像格式
你也可以声明输出格式
在此我们用的是RGBAf因为我们详细介绍
的例子
需要精度很高因此我们需要在此使用全流量
最后我们要看下处理器代码块
在这我们有两个参数
CIImageProcessorInput和CIImageProcessorOutput
它们在这里面以便我们可以完成所需的所有工作
让我们看看如何来实现它
还有你为什么要实现它
CIImageProcessor特别有用
对于你有某个算法的时候或者你想用一个库
其实现了Core Image外某些东西
且还是对于CIKernel语言不合适的东西
一个好例子就是积分图像
积分图像就是凭借输出像素的图像
它包含了其上所有像素的总和
还有它左边的像素 包括它自身
这是个好例子 对于不能完成的事情
在数据平行类的着色器
也就是当你编写CIKernel时所写那种着色器
让我们来看下
关于积分图像的更多细节
如果我们从左边的输入图像开始
也就是说与某些单信道 8比特数据相对应
我们的积分图像会成为右边的图像
如果我们看下这边的像素的话
7
它实际上对应着左边所有像素的和
也就是1加4加0加2
对于另外的像素也是如此45对应的是和
也就是那些像素的上边 左边再加上它自己
让我们来看看你会做些什么
如果你要写CPU代码到图像处理器代码块的话
你也可以使用V Image
或是我们系统里有的其他任何库
首先重中之重的就是
我们要获取一些指针返回到输入数据
从CIImageProcessorInput我们会得到基地址
而且我们要确保使用8比特数据也就是UInt8
接着我们会得到outputPointer
也就是我们写入所有结果的地方
要作为浮点类型写入因为我们声明要写到RGBAf
接下来我们要确保考虑到
输入输出图像相关的偏移量
Core Image很可能提供给你
更大的输入图像
至少和你的输出图像不一样大
所以你要小心处理所有可能的偏移量
当你创建输出图像还有写for循环的时候
在这种情况下一旦我们弄清楚所需要的偏移量
就可以执行我们的for循环来计算输出值
通过使用i-j位置的输入
加上我们得到的偏移量
现在我们已经看到如何利用定制CPU循环来实现它
也看看如何利用Metal来实现
在这个例子中我们会使用
Metal性能着色器
在Metal性能着色器中有个很不错的初始点
来计算积分图像 叫做MPSImageIntegral
从CIImageProcessorOutput中我们可以得到commandBuffer
Metal command buffer 所以我们创建了一个MPSImageIntegral
利用那个commandBuffer
我们要小心留意需要处理的偏移量
然后对该commandBuffer编写相应kernel即可
还要提供我们得到的输入纹理作为输入
其是从CIImageProcessorInput得到的
还要将output.MetalTexture作为目的地
这就是我们如何使用Metal
在现存CIFilter图之内
现在让我们看看我们能完成什么
通过目前得到的积分图像
我们从像是这么一张图片开始
我们的目标是生成一张新的图片
其每像素变量都有盒装模糊
该张图片的每个像素都有不同的模糊量
我们利用积分图像很快就可以实现
我要说的是 盒状模糊是很有用的
对于实现快速盒状相加
如果我们就从这张输入图片开始 想要
得到这九个像素点的和 通常来讲
这需要进行九次读取也就意味着这是个n平方复杂度的问题
这可不会太快
这不完全对 如果你稍微聪明点的话
你可以通过多通道方法来实现它
通过两个n次读取来实现但你仍然要进行六次读取
也没有明显缩小多少
不过利用积分图像的话 我们就可以
如果想得到这九个像素点的和
我们只需要读取几个位置
我们要读取右下角的位置
然后再读取
从一个到最左边 所有值的和
然后再从中减去我们读取的头一个值
然后我们要读取一个像素点它就在我们所需的上面
并减去目前为止
所有像素相加所对应的行
你们现可看到我们将左上角设为高亮
设为1 因为我们已经减了两次那个值
所以我们要再把它加回来
这意味着我们可以创建一个任意尺寸的盒状模糊
就通过四次读取
如果我们要 谢谢你们
如果我们要手动做计算
你可以看出来这些数加起来是对的
也就是2加4加6等等 完全相同
和66减10减13加1
让我们回到Core Imagekernel语言
看看我们如何使用积分图像该图像或是我们利用CPU代码计算的
或使用Metal性能着色器基类型得到的
并继续实现创建盒状模糊特效
我们要做的第一件事就是计算左下角
和右上角 从我们的图片中
这会告诉我们需要要从哪进行加减
然后我们要计算一些其他的值
它们会帮助我们决定所需alpha值
也就是我们当前要生成的像素的透明度
我们取得四个角的样值
做了所需的加法和减法
再乘上所决定的合适的
对于该输出像素的透明度
该kernel接收单个参数
作为输入半径 也就是
如果你要在图片上调用它
你会在整个图片上应用相同的半径
不过我们可以简单
去创建一个盒装模糊变量
通过传入一个掩膜图像我们可以利用该掩膜图像
来决定多大
的半径对于每像素为基础合适
我们要传入一个额外的参数也就是掩膜图像
我们从中进行读取
我们来看下红信道中有什么
也可能从任何一个信道而来
然后我们要把它乘上半径
如果我们的半径是15而在当前像素位置的值是0.5
那么最终的半径是7.5
我们可以得到这些值后 传到
我们刚写好的盒状模糊kernel中
这就是我们如何创建一个盒状模糊变量
利用Metal性能着色器和CIImageProcessor节点
还有个我们今天没有提到的事情是
我们现在有了可以声明的属性
它们在你所写的CIKernels中
实际上我们现在就有一个 也就是输出格式
在这里我们要请求RGBAf不需要真的有用
关键是说你想要写
单信道还是双信道数据
所以如果你想要
如有些人所注意到有个好方法
来减少你的内存占用 也可以来声明
对于某个特定kernel你想要个确切的精度
在可能和图剩余部分不相对应的kernel
就如我们在iOS上处理RAW图片那样
我们的所有kernel都标记着RGBAh
另外 我们要创建此特效还得
提供某种掩膜图像
调用CIFilter(name,就可轻松实现
然后附带参数请求一个CIRadialGradient
也就是要决定有多大
的掩膜 还有它位于哪里
然后我们要在0和1间插入
非黑即白
然后我们要从CIFilter中请求输出图像
之后我们就有了一个完美可用的掩膜
现在让我们看看它实际看起来
运行在设备上时是什么样的
这是从iPhone 6S上录制的
如果我们从输入图像开始并看看掩膜的话
我们可以移动它
它非常具有可交互性
可以改变半径 甚至将其设为负数
如果我们使用此掩膜图像 并使用它在
我们的盒状模糊变量kernel代码中
就可以得到这个类型的结果它是非常可交互的
因为积分图像也需要计算一次
Core Image为你缓存这些结果
它几乎就是你现在所看到的这些东西
就包括四次读取 所以它非常的快
有些要你们记住的当你使用CIImageProcessor时
如果你要使用的在图像处理器中的数据
不是在当前workingColorSpace的上下文中
你就要调用CIImage.byColorMatching
WorkingSpace(to,来提供一个颜色空间
类似的 在出口处如果你想要数据
位于不同的颜色空间
你就要调取CIImage.byColorMatching
ColorSpace(toWorking,并给它一个颜色空间
现在我们已经看到如何创建CIImageProcessor
并使用它
让我们来看看会发生什么
当我们使用环境变量CI PRINT TREE时
我们用它来得到实际的图
我们渲染完会是什么样
它看起来就会是这样的
当你使用环境变量CI PRINT TREE时
而且将其值设为1
是自底向上读取 而且它可以很冗长
它从我们创建的radialGradient输入开始
接下来我们得到与工作空间相匹配的输入图像
然后就是我们的处理器节点被调用
此十六进制值就是我们已经计算过的摘要
处理器和颜色kernel结果
来自radialGradient的被传入variableBoxBlur中
最后我们对于输出显示做颜色匹配
这是我们的原始菜单
用来声明才特效但它不是实际被渲染的那个
如果我们将环境变量CI PRINT TREE设为8
就可以看到很多东西都已经被压塌了
并且处理看来参与的少了
我们还是有处理器节点
单独位于一行
也就意味着它需要一个中间缓存
这就是CIImageProcessors非常好的原因
不过你只应该在特定情况下才使用
当你要生成的特效 你所有的算法
不能在CIKernel语言内被表达时
如你所见处理的剩余部分都会被连接到一起
因此我们有variableBoxBlur来处理剩余的颜色匹配
还有clamptoalpha都在一次传值中完成
这也是为什么总要在这些API中有所取舍的原因
如果你可以的话就应该写在CIKernel语言内
这可能会有点难读
所以你也可以声明
使用了CI PRINTTREE 即graphviz
在这里我们使用了CI PRINT TREE=8
通过利用graphviz选项
我们可以看到处理器节点 还有其与
图的其他部分完全融合
我们还可以看到所请求的RGBAf输出
我们复习下今天都学了些什么吧
David给我们展示了如何在iOS上编辑RAW图像
然后Etienne跟我们讲了
你如何利用Core Image编辑Live Photos
最后我们看到了如何使用
CIImage上叫做CIImageProcessor的新API
还有如何在你的kernels上声明一个输出格式
借以减少内存占用
为了获取更多信息
请访问developer.apple.com
有一些相关的演讲你们可能会感兴趣
特别是如果你打算在iOS上做RAW处理的话
还有Etienne提到的“iOS摄影进阶”
今天晚些时候还有个讲座叫“用广色域来工作”
还是在这进行
非常感谢大家的到来
我希望你们在接下来的WWDC过得愉快