大家好 欢迎来到511会话
AVCapturePhotoOutput的基础功能拓展
本期节目是第501期的补充
即对iOS Photography新进展的演示及说明
我是Brad Ford
Apple核心多媒体撷取团队工程师
501会话重点讲解了AV foundations的摄影捕获API
特别是AVCapturePhotoOutput
它是iOS 10下新的拍照接口
该输出端支持实时图象捕获
RAW + DNG
宽色域内容
图片预览或缩略图
如果你还未看过501会话
建议你暂停一下 先去收看501会话
以便你能从本期节目中获得更多知识
在本期中 我们将会拓展AVCapturePhotoOutput基础
并讨论501会话中未讲解的两个重点
即 场景监控
以及资源分配与回收
最后 我们将花几分钟
讲解一个不相关 但很重要的东西
iOS 10下的相机隐私策略变化
简要的回顾一下
新的AVCapturePhotoOutput拥有增强型接口
可应对AVCaptureStillImangeOutput的一些设计挑战
使用一种功能化的程序模型
在可变数据与不可变数据之间有明确的界线
它使用独立的对象封装各相片设置
这些设置称为AVCapturePhotoSettings
当发出照片捕获请求时就需要调用它.
该设置使用委托式的接口
以跟踪照片捕获请求
这称为AVCapturePhoto的捕获委托协议
委托协议中的所有回调函数
将返回AVCaptureResolvedPhoto设置的一个实例
这是个不可变对象 其中所有相片设置
都已确定
AVCapturePhotoOutput还支持场景监控功能
运用刚才说过的那些捕获对象的子集
场景监控可让你呈现UI
该界面将场景特征告知用户
这些场景都是当前活动的场景
在这个Apple相机应用的截图中
用户明显处于光度低的环境
屏幕下方闪光灯图标
显示用户处于自动闪光模式下
意味着只有在情景需要时才能使用闪光功能
Apple相机应用是AVCapturePhotoOutput的客户端
进行场景监控
以驱动闪光灯激活为黄色闪光图标
你在屏幕正上方看见的
黄色的闪光图标表示
如果用户现在拍照的话闪光灯就会启动
AVCapturePhotoOutput执行场景监控功能
在两种情况下
第一种是闪光灯
当前Apple所有的iPhone型号
以及9.7英寸的iPad Pro
都配备了双色闪光灯以照亮黑暗的场景
通过后置视力相机
和retina闪光技术将你的视网膜显示器
变成双色闪光灯
将亮度提高到正常情况的三倍
以便将低亮度的自拍照变亮
支持场景监控的第二种类型是
静态图象稳定技术
静态图象稳定是一种多重图象融合的捕获技术
通过不同方式融合曝光图片以减少低亮度下的图片模糊
有一点可能还不是很清楚为什么静态图象稳定技术
具有低光度特点
这并是说你的手在黑暗中抖得更厉害
而仅仅是因为相机需要更长的曝光时间
以获取相同的光子数量
这要求摄影者得非常非常稳定才行
而静态图象稳定技术能解决这个问题
通过捕获不同曝光水平的多重图象
并将它们融合在一起以消除干扰与运动伪影
所以乍看起来 闪光灯的作用或静态图象稳定技术的作用
似乎是无关的,但事实上 它们密切相关
而这会造成接口冲突
从这张图上可以看到适用的光亮范围
在Flash Capture是否带有静态图象稳定时的对比情况
我将静态图象稳定技术简称为SIS
蓝条表示亮度级别
即照片输出使用闪关灯的亮度
如果你选择开启SIS的话
绿条表示适于闪光灯启动的光照强度
如果你选择关闭SIS的话
注意到 在开启SIS时
在相对黑暗的环境下能够不通过闪光灯来进行照片输出
这是因为SIS一定程度上降低了图象中的干扰
因此不需要闪光灯介入
如果你当前所处环境的光强度在此那么问题的答案是
闪光灯一定会介入
但如果光强度在此
那完全取决于你是否想开启静态图象稳定技术
反之亦然
那么 具体该怎么做呢？
AVCapturePhotoOutput并不知道你希望抓拍的类型
除非你向它提出要求
可如果开启场景监控就得不停运行
当前是SIS场景还是flash场景呢？
在AVCapturePhotoOutput中我们解决了这个问题
通过使用特定的场景监控端口
该端口叫做 关于场景监控的照片设置
并且我们提供了两项键值观察属性
该属性可对你进行非同步通知
当场景的适合性发生改变时
关于使用静态图像稳定技术还是闪光灯
你创建一个AVCapturePhotoSettings实例
具体来说是关于场景监控的实例
并明确你希望AVCapturePhotoOutput具备的功能
现在我将闪光灯设置为自动模式
这说明我希望在使用闪光灯时
它已处于适用状态
并且我还将AutoStillImageStabilization的Enabled属性
设置为true
那么 对SIS也应该进行同样设置
SIS会一贯地输出比flash质量更高的图片
那么当场景陷入一种交叉范围
该范围处于SIS与flash之间
photoOutput报告此种情况属于SIS场景
接下来我将该对象指定为照片设置
在SceneMonitoring属性中
该属性可在任何时候进行设置
甚至包括在你运行AVCaptureSession前
为获知闪光灯的变化情况
及静态图象稳定技术的价值
我对之前提及的isFlashScene添加了键值监测
并对isStillImageStabliziationScene也进行了该操作
然后随着场景值变化我进行了回调操作
对于那两个属性
现在我们来讨论场景监控的默认配置
photoSettingsforSceneMonitoring的属性是可空
并且该默认值为nil,
这意味着没有对场景进行监控
如果你在查询isStillImageStabilization
或isFlashScene时若没对场景监控功能进行相片设置配置
那么它们将会一直报告错误
一旦你为场景监控成功配置相片设定后
你可以查询或通过键值观察两种isScene的属性
并得到恰当的回复
但请注意如果你对场景监控进行的照片设置中
包含关闭的flash模式的话
isFlashScene将依旧报告错误
对于AutoStillImageStabilization的Enabled属性来说也一样
对于场景监控 我的建议很简单
如果你的应用不显示任何用户界面
仅显示用户正看到的场景
那么你没有必要启动场景监控功能.
但如果启动了该功能它将会监控你希望捕获的画面
比如你希望使用Auto Flash来拍摄而非SIS
那么带闪光模式的监控器设为自动或者自动SIS关闭
如果不这样做 将会使用户混淆
因为你的用户界面可能会报告目前不处于闪光灯场景
尽管在实际拍照时 闪光灯会被启动
以上为场景监控功能的内容
在接下来的课程中 将介绍
资源调配与回收功能
为了解按需资源调配功能的需要
我们来看看AVCaptureSession的正常数据流程图
当AVCaptureSession开始运行
数据即开始从各个AVCapture输入端
流向各个 AVCapture输出端
大部分输出端口对数据流形式的数据进行接收与处理
比如VideoPreviewLayer
该输出口将输入的数据不断地显示在屏幕上
或VideoDataOutput该输出口通过委托回调来缓存至应用
此类流输出
需要分裂性的捕获渲染管道重建
如果改变它们的结构
你就不得不为一种输出模式进行配置
在运行程序之前
而AVCapturePhotoOutput不同
因为它仅根据需要来从输入接受数据
当你通过CapturePhoto请求一张照片
并进行设置与代理
照片输出端仅输出一个结果或结果的集合
不像流输出口
照片输出具有充分的等待时间
因此能够在完美的位置上 按要求进行资源调配或回收
而不会造成扰乱性的渲染模式重组
虽然看不见 但整个调配过程却十分华丽
当然 资源调配过程并非免费的
AVCapturePhotoOutput的功能集很广
拍摄420像素的未压缩照片
这些照片都为AVCapture设备的原始格式
仅需要极少的一部分资源
像EGRA或JPEG这类经处理过后的输出格式
则需要另外一些资源
因为有格式转换功能介入
闪光拍摄则需要它们自己的硬件资源集
以传递与预闪光序列及频闪同图像
静态图象稳定功能需要对多个缓冲进行融合
拍摄RAW格式图片则需要十分大量的缓冲
RAW加JPEG格式的图片则需要大小资源的组合
Bracketed捕捉需要大量的缓冲
以便将多个图片返回到客户端
当然 许多这样的特征都能被混合并匹配
并需要资源超集
由于那么多适用的捕获特征
AVCapturePhotoOutput很难
估计需要预先准备多少资源
过度准备及准备不足都是不好的
我们将过度准备比喻成烤蛋糕
一年中的每天都在烤蛋糕以防止这一天就是你的生日
对我门而言 这需要付出很大努力
需要投入很多材料
扔掉很多没有吃过的蛋糕
造成视频预览可能每次来的更慢
而内存消耗则可能高得毫无必要
没作充分准备就算不比前者糟糕也不是件好事
如果我们没有准备好
使用所要求的特征集进行照片捕捉我们可能会错过这次拍摄
直到按要求分配资源
幸运的是, 我们提供了解决方案
AVCapturePhotoOutput会让你事先告知
你希望捕捉的类型
只需要启动setPreparedPhotoSettingsArray功能
传递AVCapturePhotoSettings的数组
包括各个代表不同捕捉类型的数据
你希望为之准备的
你可以选择性地传递完成处理程序
待准备完成时 即可调用该程序
照片输出端口还提供
一种只读属性的preparedPhotoSettingsArray
因此你可以查询最终设定的设置数组
setPreparedPhotoSettingsArray功能可以做很多事
它可以为所有的捕捉类型准备资源
在你的设置数组中
另外 如果存在不需要的资源该功能会对其进行回收
并且你还可以通过传递一个空数组来回收所有的资源
当所有资源准备完毕该功能会通知你
如果资源无法准备该功能会返回错误
整个数据传递都通过完成回调进行
preparedPhotoSettingsArray的默认值
是一种关于AVCapturePhotoSettings的默认函数
该函数将JPEG设置为输出格式
和AutoStillImageStabilization的enabled属性
preparedPhotoSettingsArray具备sticky属性
它会在AVCaptureSession的启动及结束之间
配置开始或确认期间持续存在并且你可以对其进行设置或忽略
如果你总是通过你的应用拍摄同种类型的照片
setpreparedPhotoSettingsArray的另一好处是
它能加入AVCaptureSession的
begin/commitConfiguration延期工作语义
也就是说如果你调用beginConfiguration
之后改变会话的拓扑模型
通过添加或移除输出端口或输入端口
之后设置新的preparedPhotoSettingsArray
然后确认配置
除非配置确认被调用否则不会进行准备程序
你可以按照原子的方式来对会话配置进行变更
并同时准备照片输出
为新的配置
你可以在运行AVCaptureSession前进行准备
以确保app处于准备捕捉相片的状态
只要视频预览开始运行
在会话停止时 如果你调用setPreparedPhotoSettingsArray
它不会立即回调完成处理程序
相反 完成处理程序会在准备完成时被调用
在你调用会话启动程序之后
如果你的会话被终止并且你已经准备了一组设定参数
之后 你改变了注意
使用另一组设定参数重新调用该程序
你最初的完成处理程序将即刻启动
通过设置为false的准备数据
实际上 这是对最初准备数据的注销
我们提三个简单的建议
关于如何使用我们准备的API
首先 准备
你可在不进行最初准备的情况下发出捕捉请求
但 如果未对照片输出
准备你希望捕捉的精确类型
则你可能会很慢地获取的第一张照片
第二 在启动你的会话程序之前进行准备
知道你感兴趣的捕捉类型
让会话程序为你分配最佳数量
在启动时
第三 仅在你的UI界面发生变更时重新进行准备
你不必在捕捉图片的各时刻重新进行准备
仅在你改变了将要捕捉的类型时
例如当你的用户将RAW Capture或Bracketed Capture
在应用中切换成打开或关闭
不是所有AVCapturePhotoOutput特征
都具有按需资源准备的资格
首当其冲的isHighResolutionCaptureEnabled
一些照相格式可以让你捕捉高清晰的静态图像
比该格式可支持的流分辨率还要大
比如 前置相机的照片格式
在iPhone 6s及6s Plus上的
支持五百万像素的静态图像
但仅能传输1280x960的图片
当相机配置该种格式
要么传输1280x960的静态图像
要么传输五百万像素的静态图像
根据你的照片设置是否规定了高分辨率捕捉
但事先必须对相机配置为五百万像素的静态图像
所以AVCapturePhotoOutput要求你选择其特征
在你准备启动程序前
通过设定isHighResolutionCaptureEnabled为true
一旦你选定 就可以在启动或未启动高分辨率捕捉功能的情况下 拍摄静态图
而不会造成复杂的图形重建
类似地  LivePhotoCapture涉及动态影片
及静态图像的拍摄
电影包含的样本来自过去
在你发出捕捉请求之前1.5秒
因此 对捕捉渲染模式的配置操作
必须在进行该项捕捉程序之前
最后 动态图像能够以智能及自动的方式在捕捉时间进行调整
如果检测到大幅度的目的性运动
比如某人将手臂放下 把设备装进口袋
如果你想捕获原始动态照片的整个过程
你必须在启动程序前退出自动调整功能
在你的AVCaptureSession上
今天最后要讨论的是
iOS 10中的相机隐私策略变更
让我们回顾一下Apple关于媒体的隐私策略
用户iOS设备上的照片与视频是个人的
私人的以及敏感的数据
照相机与麦克风的使用需要特别授权
必须经用户的明确授权
因此从iOS 7开始
用户被告知 首次使用的应用
照相机或麦克风都有一次被禁止使用的机会
这件事非常好
为了透明与信任
别为点击一次OK而恼怒 这是值得的
在iOS 10 我们要求应用在透明度方面多一步确认
通知用户为什么它们要访问敏感数据
有时 你的UI会做得很明显但有时却不会
你的原因字符串应没有任何歧义
例如：此处 AVCam告诉用户
它想要使用相机拍摄照片和视频
这非常明确的交代了它将用相机做什么
同样 iOS 10中的应用
必须提供原因字符串以使用麦克风
最后是Photos Library
你该在Photos Library的原因字符串中明确交代
你是把它用来读或写 还是两者兼而有之？
在Xcode的最新版本中
你会发现一连串的可能的隐私描述说明
不仅局限于摄像头、麦克风和照片
而是针对所有敏感数据的访问
为了使用这些服务你必须提供原因字符串
如果没有
你的应用将无法获得所需服务的访问权限
Capture的三个特殊关键要点是
NSCameraUsageDescription
NSMicrophone3UsageDescription
以及NSPhotoLibraryUsageDescription
下面让我们总结一下刚学习的内容
AVCapturePhotoOutput允许对场景监控行为进行精准控制
它还可以按需进行资源分配和回收
Capture客户端必须提供原因才能使用摄像头、麦克风
以及照片这些iOS 10功能组件的原因
想要了解更多详情 请访问URL
了解iOS Photography的新进展这期节目
也就是501会话
如果你还在观看节目我们邀请你访问
所有相关的三期节目
与摄影、RAW以及Wide Color相关
谢谢收看祝你捕获快乐瞬间
请继续享受其余会话