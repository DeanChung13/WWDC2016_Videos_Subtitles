00:00:20.087 --> 00:00:23.323
制造非凡的音频效果

00:00:23.457 --> 00:00:25.893
音频效果最佳实践和API指南

00:00:26.226 --> 00:00:27.060
好

00:00:28.962 --> 00:00:30.163
下午好

00:00:30.998 --> 00:00:34.334
多少人想开发一款
音频效果特别棒的应用

00:00:34.401 --> 00:00:35.903
但觉得可能会很困难？

00:00:36.803 --> 00:00:38.605
或者 多少人想要更多地

00:00:38.672 --> 00:00:40.774
关注应用程序
整体的用户体验

00:00:40.841 --> 00:00:43.010
但最终在音频上
多花费了一点时间？

00:00:43.777 --> 00:00:46.180
我们一直以来都在努力
帮助你轻松解决这些问题

00:00:46.580 --> 00:00:49.449
我叫Saleem
Core Audio团队的技术人员

00:00:49.516 --> 00:00:51.018
欢迎大家来到今天

00:00:51.084 --> 00:00:53.420
关于制造非凡音频效果的
会议环节

00:00:54.521 --> 00:00:57.191
让我们整体看下
今天我们为大家准备了什么

00:00:58.759 --> 00:01:00.961
我们会先开始介绍
AVFoundation框架

00:01:01.261 --> 00:01:04.230
我们有种类广泛的
高层API

00:01:04.665 --> 00:01:06.800
可以让你轻松
播放和录制音频

00:01:08.101 --> 00:01:12.739
对于更高级的用例 我们提供
AudioToolbox框架

00:01:13.607 --> 00:01:15.642
你可能听说过
AudioUnits

00:01:15.709 --> 00:01:17.778
这些是基本的
组成模块

00:01:19.246 --> 00:01:22.349
如果你必须使用
MIDI设备或MIDI数据

00:01:22.416 --> 00:01:23.951
我们还提供CoreMIDI框架

00:01:24.952 --> 00:01:27.521
对于游戏开发
我们提供OpenAL

00:01:29.790 --> 00:01:31.658
在过去两年里
我们也一直在添加

00:01:31.725 --> 00:01:33.694
很多新的API和功能

00:01:34.261 --> 00:01:35.896
你可以看到
你可以通过很多方法

00:01:35.963 --> 00:01:37.931
在你的应用中
使用音频

00:01:38.265 --> 00:01:40.434
所以 我们今天的目标是
指导你

00:01:40.501 --> 00:01:43.670
针对你的应用需求
选择正确的API

00:01:44.071 --> 00:01:47.307
但不必担心 我们也有
一些新东西与大家分享

00:01:50.277 --> 00:01:51.645
所以 按今天的日程表

00:01:51.712 --> 00:01:55.048
我们会先了解我们几个平台的
一些基本的设置步骤

00:01:55.816 --> 00:01:58.752
然后 我们会直接深入了解
一些简单和高级的播放

00:01:58.819 --> 00:02:00.153
和录制情景

00:02:00.921 --> 00:02:02.890
我们会简要讨论下多声道音频

00:02:03.790 --> 00:02:06.693
在随后的介绍中
我们将了解下实时音频

00:02:07.127 --> 00:02:10.297
以及你制造自己音频效果、
乐器和生成器的方法

00:02:10.364 --> 00:02:11.798
最后以MIDI的介绍结尾

00:02:12.266 --> 00:02:13.500
好 让我们开始吧

00:02:15.936 --> 00:02:20.274
iOS、watchOS和tvOS
都有相当丰富的音频功能

00:02:20.340 --> 00:02:22.209
以及众多写入功能

00:02:22.676 --> 00:02:27.114
这样 用户才能拨打电话
播放音频、玩游戏

00:02:27.314 --> 00:02:29.016
和使用各种提高效率的应用

00:02:29.082 --> 00:02:32.386
用户可以同时
或独立进行这些操作

00:02:33.287 --> 00:02:36.657
所以操作系统管理了
大量默认的音频行为

00:02:36.723 --> 00:02:39.560
以便提供一致的
用户体验

00:02:41.395 --> 00:02:44.665
让我们通过图表了解为什么
音频是一种基于管理的服务

00:02:46.433 --> 00:02:47.701
所以 你拥有一件设备

00:02:48.468 --> 00:02:51.138
设备有若干的
输入和输入

00:02:53.140 --> 00:02:55.075
然后 有操作系统

00:02:55.909 --> 00:02:59.246
操作系统可能包含大量应用
有些应用使用音频

00:03:00.147 --> 00:03:01.949
最后 这里是你的应用

00:03:03.951 --> 00:03:07.287
所以AVAudioSession是
你的开发者界面

00:03:07.387 --> 00:03:09.957
你可以通过该界面
向系统表达你的应用需求

00:03:11.024 --> 00:03:13.360
让我们了解下这方面的
详细内容

00:03:16.163 --> 00:03:19.266
类别表达
应用的高级别需求

00:03:19.800 --> 00:03:21.902
我们提供模式和类别选项

00:03:21.969 --> 00:03:25.205
可以帮助你进一步定制
和专门设计你的应用

00:03:28.175 --> 00:03:30.611
如果你喜欢一些
更高级的用例

00:03:30.677 --> 00:03:33.046
比如输入选择
你可能需要能够选择

00:03:33.113 --> 00:03:35.782
iPhone的前置麦克风
而不是底部麦克风

00:03:36.483 --> 00:03:38.051
如果你处理的是
多声道音频

00:03:38.118 --> 00:03:40.654
以及tvOS上的多声道内容
你可能对声道数

00:03:40.721 --> 00:03:42.189
这样的东西感兴趣

00:03:43.156 --> 00:03:45.692
如果你将USB音频设备
连接到iPhone

00:03:45.759 --> 00:03:47.995
你可能对采样率
这样的东西感兴趣

00:03:52.666 --> 00:03:56.303
所以 当你的应用准备好
经配置可使用音频时

00:03:56.570 --> 00:03:58.705
它会通知系统
应用会话

00:03:59.573 --> 00:04:01.575
该过程会配置
设备的硬件

00:04:01.642 --> 00:04:03.310
从而满足你应用的需求

00:04:03.577 --> 00:04:07.214
并且实际可能对系统中
其它音频应用造成干扰

00:04:07.381 --> 00:04:09.950
或者相互混杂 或者
降低其它音频应用的音量

00:04:14.054 --> 00:04:17.591
了解下AVAudioSession
的一些基本使用步骤

00:04:18.024 --> 00:04:20.459
第一步是
注册以获取通知

00:04:21.361 --> 00:04:24.364
三种最重要的通知是
中断通知

00:04:24.431 --> 00:04:27.634
路径变更通知以及
mediaServicesWereReset通知

00:04:28.902 --> 00:04:32.172
你可以在激活会话之前
注册以接收这些通知

00:04:32.239 --> 00:04:34.775
通过几张幻灯片
我将展示如何管理通知

00:04:37.244 --> 00:04:39.580
接下来 基于
你应用的高级别需求

00:04:39.646 --> 00:04:42.549
你将需要设置适当的
类别模式和选项

00:04:43.250 --> 00:04:45.018
那么 让我们看几个例子

00:04:46.854 --> 00:04:48.889
假如 我正在开发
一款提高效率的应用

00:04:48.956 --> 00:04:51.425
在这个应用中
我想要在用户保存文档时

00:04:51.491 --> 00:04:53.193
播放简单的声音

00:04:53.961 --> 00:04:56.496
这里 我们知道音频
能够增强体验

00:04:56.563 --> 00:04:58.332
但却不是必要的

00:04:58.699 --> 00:05:01.401
在这种情况下 我想
使用AmbientCategory

00:05:02.669 --> 00:05:04.938
这个类别遵循振铃开关

00:05:05.472 --> 00:05:07.441
音频不在后台播放

00:05:07.708 --> 00:05:09.343
而始终与其它应用音频混杂

00:05:12.679 --> 00:05:16.149
若我在开发播客应用
我应该使用PlaybackCategory

00:05:17.317 --> 00:05:18.652
SpokenAudio模式

00:05:19.586 --> 00:05:21.722
这里 我们能看到
这个应用位置将干扰

00:05:21.822 --> 00:05:23.690
系统上的其它应用

00:05:25.559 --> 00:05:28.562
现在 如果你希望音频继续
在后台播放

00:05:28.629 --> 00:05:32.199
你也需要在info.plist中
指定后台音频键

00:05:32.399 --> 00:05:34.668
这本质上也是
会话属性

00:05:34.735 --> 00:05:36.904
只不过是通过
不同的方式表达

00:05:39.907 --> 00:05:41.041
而对于导航应用

00:05:41.108 --> 00:05:43.777
让我们了解一下如何配置
导航提示

00:05:44.378 --> 00:05:46.680
你应使用
PlaybackCategory

00:05:47.447 --> 00:05:48.749
以及DefaultMode

00:05:49.183 --> 00:05:51.285
这里有几个
相关的选项

00:05:51.485 --> 00:05:54.087
你应同时使用
InterruptSpokenAudio

00:05:54.154 --> 00:05:56.990
AndMixWithOthers
以及duckOthers

00:05:57.758 --> 00:06:00.127
所以 如果你正在收听
播客 同时进行导航

00:06:00.194 --> 00:06:02.329
就会出现导航提示
表明

00:06:02.396 --> 00:06:03.997
500英尺后左转

00:06:04.064 --> 00:06:06.600
提示实际上会中断播客应用

00:06:07.367 --> 00:06:08.836
如果你在听音乐

00:06:08.936 --> 00:06:12.039
提示会降低音乐音量
并混杂在音乐中

00:06:13.740 --> 00:06:17.144
对于这种应用 你也应
使用后台音频键

00:06:20.714 --> 00:06:24.051
接下来 让我们看看如何
对会话激活进行管理

00:06:25.786 --> 00:06:27.554
所以 激活意味着什么？

00:06:27.754 --> 00:06:29.890
激活你的会话 会通知系统

00:06:29.957 --> 00:06:32.759
配置硬件
以适应应用的需求

00:06:33.794 --> 00:06:35.896
比如
我有一个应用

00:06:35.963 --> 00:06:37.831
类别为PlayAndRecord

00:06:38.465 --> 00:06:41.235
当我激活我的会话
系统会配置硬件

00:06:41.301 --> 00:06:43.470
使用输入和输出

00:06:46.907 --> 00:06:49.510
现在 如果我
在使用音乐应用听音乐时

00:06:49.576 --> 00:06:51.178
激活会话 会怎么样？

00:06:51.645 --> 00:06:55.048
这里 我们可以看到
系统当前状态设置为仅播放

00:06:56.083 --> 00:06:57.718
所以 当我激活会话时

00:06:58.252 --> 00:07:02.689
我通知系统 针对输入
和输出进行硬件配置

00:07:03.457 --> 00:07:05.826
而且 既然我
处在不可混杂的应用位置

00:07:05.893 --> 00:07:07.427
我中断了音乐应用

00:07:10.264 --> 00:07:12.799
所以 比如我的应用
进行了快速录音

00:07:12.866 --> 00:07:15.135
一旦完成 我就停用会话

00:07:16.136 --> 00:07:19.206
如果我选择通知其它应用
我已经停用会话

00:07:19.273 --> 00:07:21.775
我们将看到
音乐应用恢复播放

00:07:25.279 --> 00:07:28.849
接下来 让我们看下如何
处理我们注册接收的通知

00:07:31.084 --> 00:07:33.420
我们首先看一下
中断通知

00:07:33.487 --> 00:07:35.422
我们会研究一个案例
案例中 你的应用

00:07:35.489 --> 00:07:37.291
没有播放UI

00:07:37.858 --> 00:07:40.194
首先获取
interruptionType

00:07:40.761 --> 00:07:42.763
如果这是
中断的开始

00:07:43.197 --> 00:07:44.932
你的会话已经停用

00:07:45.799 --> 00:07:47.935
所以播放器已经暂停

00:07:48.001 --> 00:07:51.171
你将利用这段时间
更新你的任何内部状态

00:07:52.940 --> 00:07:54.741
如果你收到结束中断

00:07:55.342 --> 00:07:57.244
你会去激活会话

00:07:57.511 --> 00:08:00.514
启动播放器
同时更新内部状态

00:08:01.949 --> 00:08:05.419
我们看下这个过程在拥有
播放UI的应用中有什么不同

00:08:07.621 --> 00:08:09.690
你接收开始中断的
通知

00:08:09.857 --> 00:08:12.860
你的会话停用
你更新内部状态

00:08:13.293 --> 00:08:14.962
而且这次要同时更新UI

00:08:15.229 --> 00:08:17.331
如果你有播放/暂停按钮

00:08:17.397 --> 00:08:20.200
这种情况下 你应接着
将按钮设置为“播放”

00:08:22.369 --> 00:08:24.705
现在 当你接收到
结束中断通知

00:08:25.038 --> 00:08:27.941
你应该查看并了解
shouldResume选项是否提交进来

00:08:28.509 --> 00:08:31.812
如果已经提交进来 那么你
可以继续激活你的会话

00:08:32.011 --> 00:08:34.815
开始播放 同时更新
内部状态和UI

00:08:35.515 --> 00:08:36.517
如果没有提交进来

00:08:36.582 --> 00:08:39.686
你应等到用户
明确地恢复播放后

00:08:42.655 --> 00:08:45.792
应特别注意的是
你的中断不一定是配对的

00:08:45.859 --> 00:08:49.396
所以 不是每个开始中断
随后都匹配一个结束中断

00:08:49.963 --> 00:08:53.800
一个例子就是
彼此中断的媒体播放器应用

00:08:57.471 --> 00:08:59.740
现在 让我们看下
如何处理路径变更

00:09:00.674 --> 00:09:02.910
路径变更的
发生原因有很多：

00:09:03.277 --> 00:09:06.847
可能是连接设备变化了
可能是类别变化了

00:09:07.214 --> 00:09:09.850
可能是你选择了
不同的数据源或端口

00:09:10.651 --> 00:09:13.320
首先要获取
routeChangeReason

00:09:15.389 --> 00:09:18.859
如果你得到的原因是
媒体播放器应用中

00:09:18.926 --> 00:09:20.427
原有设备不可用

00:09:20.494 --> 00:09:22.563
此时你应停止播放

00:09:22.629 --> 00:09:26.600
这种情况的一个例子是
如果你的用户使用耳机

00:09:26.667 --> 00:09:28.001
收听音乐然后拔下耳机

00:09:28.068 --> 00:09:30.504
他们不会想
让音乐立即通过

00:09:30.804 --> 00:09:32.272
扬声器恢复播放

00:09:34.675 --> 00:09:37.978
对于更高级的用例 若你
收到oldDeviceUnavailable

00:09:38.045 --> 00:09:40.681
或newDeviceAvailable
routeChangeReason

00:09:40.747 --> 00:09:43.450
你可能需要在特定会话属性
应用到你的应用时

00:09:43.517 --> 00:09:45.185
重新评估这些属性

00:09:48.388 --> 00:09:50.958
最后 让我们看下
如何处理设置了通知的

00:09:51.024 --> 00:09:52.693
媒体服务

00:09:53.393 --> 00:09:56.029
这种通知很少发生
但也确实会收到

00:09:56.096 --> 00:09:58.332
因为我们不能确保
demon程序永远运行

00:09:59.766 --> 00:10:01.201
这里需要特别注意的是

00:10:01.268 --> 00:10:04.605
你的AVAudioSession
sharedInstance仍有效

00:10:06.006 --> 00:10:08.976
你将需要重置
类别模式和其它选项

00:10:11.011 --> 00:10:13.413
你也需要破坏和重建
你的播放器对象

00:10:13.480 --> 00:10:15.082
如AVAudioEngine

00:10:15.616 --> 00:10:18.085
远程I/O
以及其它播放器对象

00:10:19.653 --> 00:10:22.856
我们提供在设备上
进行此测试的途径

00:10:22.923 --> 00:10:25.726
路径是设置——开发者
——重设媒体服务

00:10:29.830 --> 00:10:32.633
好 大致重述下
使用AVAudioSession的

00:10:32.699 --> 00:10:34.868
四大步骤
基本步骤

00:10:34.935 --> 00:10:36.603
你注册以接收通知

00:10:36.670 --> 00:10:39.306
你设置适当的
类别模式和选项

00:10:39.373 --> 00:10:41.208
你对会话激活进行管理

00:10:41.408 --> 00:10:43.110
并且处理各种通知

00:10:43.477 --> 00:10:45.312
让我们了解下今年的
一些新内容

00:10:46.713 --> 00:10:49.416
今年的新内容中 我们添加了
两个新的类别选项：

00:10:49.483 --> 00:10:53.487
将allowAirPlay和allowBluetoothA2DP
添加到PlayAndRecord类别

00:10:55.122 --> 00:10:58.425
所以 这意味着你现在可以
在使用蓝牙或AirPlay终端

00:10:58.492 --> 00:11:00.360
播放时 同时使用麦克风

00:11:02.095 --> 00:11:03.830
如果这是你应用的用例

00:11:03.897 --> 00:11:06.733
继续操作 设置
类别和选项

00:11:06.800 --> 00:11:08.235
然后允许用户从

00:11:08.302 --> 00:11:11.672
MPVolumeView或
 “控制中心”中选择路径

00:11:15.209 --> 00:11:17.344
我们同时为
AVAudioSessionPortDescription

00:11:17.411 --> 00:11:19.446
上的VoIP应用添加了新属性

00:11:19.513 --> 00:11:21.782
可以决定当前路径
是否已经激活

00:11:21.849 --> 00:11:23.851
硬件语音处理

00:11:24.751 --> 00:11:27.487
所以 如果你的用户
连接到拥有硬件语音处理的

00:11:27.721 --> 00:11:30.991
CarPlay系统或
蓝牙免提耳机

00:11:31.391 --> 00:11:34.795
你可以使用该属性禁用
你的软件语音处理功能

00:11:34.862 --> 00:11:36.830
这样你就不会对音频
重复处理了

00:11:39.066 --> 00:11:42.503
如果你已经使用Apple的
内置语音处理输入/输出设备

00:11:42.569 --> 00:11:44.238
你无需担心这一点

00:11:45.205 --> 00:11:47.908
今年新内容中 我们也引进了
CallKit框架

00:11:48.175 --> 00:11:51.211
为使你了解如何使用
CallKit增强你的VoIP应用

00:11:51.278 --> 00:11:52.679
本周早些时候
安排了场演讲

00:11:52.746 --> 00:11:55.349
如果你错过了
可以到网上收看

00:11:58.018 --> 00:12:00.220
所以 这只是
AVAudioSession的概况

00:12:00.287 --> 00:12:02.823
在之前的演讲中 我们
对此话题进行了许多深入介绍

00:12:02.890 --> 00:12:06.727
所以 我们鼓励你到网上查看
之前的视频和编程指南

00:12:09.763 --> 00:12:10.697
好 我们继续

00:12:11.098 --> 00:12:14.034
AVAudioSession适用于
你平台的情况下 你完成设置

00:12:14.234 --> 00:12:17.771
现在 我们看下如何在应用中
进行简单的音频播放和录制

00:12:19.873 --> 00:12:21.942
我们先看一下
AVFoundation框架

00:12:22.476 --> 00:12:24.978
这里有很多级别
可以处理这种任务

00:12:25.045 --> 00:12:26.647
我们有AVAudioPlayer

00:12:26.813 --> 00:12:29.650
AVAudioRecorder
以及AVPlayer等级别

00:12:32.352 --> 00:12:35.455
AVAudioPlayer是文件中
播放音频的最简单方法

00:12:36.056 --> 00:12:38.325
我们支持各种格式

00:12:39.359 --> 00:12:41.762
我们提供所有
基本的播放操作

00:12:42.462 --> 00:12:44.264
我们同时支持
一些高级的操作

00:12:44.331 --> 00:12:45.866
比如 设置音量

00:12:46.166 --> 00:12:48.202
你可以按照声道获得计量

00:12:48.268 --> 00:12:51.038
你可以循环播放
调整播放速度

00:12:51.405 --> 00:12:53.173
进行立体声调制

00:12:54.575 --> 00:12:57.778
如果你使用iOS或tvOS
你可以进行声道分配

00:13:00.747 --> 00:13:03.050
如果你有多个文件
要进行播放

00:13:03.116 --> 00:13:05.652
你可以使用多个
AVAudioPlayer对象

00:13:05.719 --> 00:13:07.788
也可以同步你的播放

00:13:09.957 --> 00:13:12.426
今年新内容中
加入了一种方法 可以允许你

00:13:12.492 --> 00:13:14.962
在特定时间内
逐渐降到某个音量

00:13:18.298 --> 00:13:22.035
看下代码示例 了解你在应用中
如何使用AVAudioPlayer

00:13:22.970 --> 00:13:26.373
比如 我还是在开发和构建
一个简单的提高效率的应用

00:13:26.440 --> 00:13:27.908
我想要
在用户保存文档时

00:13:27.975 --> 00:13:29.643
播放确认音频

00:13:30.410 --> 00:13:35.616
这种情况下 我有AVAudioPlayer
和链接到我级别中资源的URL

00:13:37.117 --> 00:13:41.054
在设置功能中 我继续操作
使用我URL的内容

00:13:41.388 --> 00:13:45.392
创建AVAudioPlayer对象
同时我准备好播放器进行播放

00:13:47.528 --> 00:13:50.697
在saveDocument功能中
我可能进行一些工作

00:13:50.764 --> 00:13:52.566
了解下文档是否
保存成功

00:13:52.633 --> 00:13:54.868
如果已保存 我只需播放文件

00:13:55.068 --> 00:13:56.069
非常简单

00:13:58.605 --> 00:14:00.340
现在 让我们看下
AVAudioRecorder

00:14:01.742 --> 00:14:04.111
这是将音频录制到文件的
最简单方法

00:14:04.745 --> 00:14:06.713
你可以录制指定的时长

00:14:06.780 --> 00:14:09.616
或者录制到
用户明确要求停止的时候

00:14:09.816 --> 00:14:12.186
你基于声道
获得计量

00:14:12.452 --> 00:14:14.922
我们支持各种编码格式

00:14:16.256 --> 00:14:19.960
所以 要设置格式 我们使用
Recorder Settings Dictionary

00:14:20.093 --> 00:14:21.628
这是由键组成的字典

00:14:21.695 --> 00:14:25.465
包含的键列表可使你
设置各种格式参数

00:14:25.532 --> 00:14:28.268
例如采样率和声道数

00:14:28.569 --> 00:14:30.137
若你使用Linear PCM数据

00:14:30.204 --> 00:14:32.773
你可以调整位深度
和字节顺序等

00:14:32.840 --> 00:14:34.441
如果你使用编码格式

00:14:34.508 --> 00:14:36.710
你可以调整质量
和比特率等

00:14:37.244 --> 00:14:40.314
让我们看下代码示例 了解如何使用
AVAudioRecorder

00:14:42.683 --> 00:14:45.719
所以 我首先做的是
创建格式设置

00:14:46.119 --> 00:14:49.356
这里 我创建了一个
比特率相当高的AAC文件

00:14:50.557 --> 00:14:54.494
然后 我要做的是创建
AVAudioRecorder对象

00:14:54.995 --> 00:14:56.997
包含指向文件位置的URL

00:14:57.564 --> 00:14:59.499
以及我刚刚定义的
格式设置

00:15:01.935 --> 00:15:04.538
在这个例子中
有一个简单的按钮

00:15:04.605 --> 00:15:06.306
我可以用它来切换
录音机的状态

00:15:06.473 --> 00:15:09.343
所以我按下这个按钮时
如果录音机正在录制

00:15:09.476 --> 00:15:11.111
我接着操作 停止录制

00:15:11.478 --> 00:15:13.080
我开始录制

00:15:13.146 --> 00:15:16.617
我可以使用录音机的
内置仪表向UI提供反馈

00:15:19.253 --> 00:15:20.988
最后让我们看下AVPlayer

00:15:22.389 --> 00:15:26.260
AVPlayer不仅适用于本地文件
而且适用于流媒体内容

00:15:26.994 --> 00:15:29.363
你拥有所有的标准控件

00:15:30.531 --> 00:15:32.399
我们同时提供你可以直接

00:15:32.466 --> 00:15:35.102
使用的内置用户界面
比如AVPlayerView

00:15:35.169 --> 00:15:36.870
以及AVPlayerViewController

00:15:38.372 --> 00:15:40.707
AVPlayer也适用于
视频内容

00:15:40.774 --> 00:15:43.510
今年 我们在AVPlayer中
添加了若干新功能

00:15:43.577 --> 00:15:45.512
如果想了解我们做出的改进

00:15:45.579 --> 00:15:48.415
你可查看AVFoundation
Playback的新进展

00:15:48.482 --> 00:15:50.851
如果你错过了那部分
你可以到网上进行观看

00:15:53.787 --> 00:15:54.888
高级播放和录制

00:15:54.955 --> 00:15:58.258
好 目前我们已经了解了
一些非常简单的

00:15:58.325 --> 00:15:59.826
播放和录制案例

00:16:00.427 --> 00:16:02.663
现在 让我们看一下
一些更高级的用例

00:16:04.364 --> 00:16:07.968
高级用例不仅包括
从文件中播放音频

00:16:08.035 --> 00:16:10.237
而且包括处理
缓冲音频数据

00:16:12.773 --> 00:16:15.275
你可能感兴趣的是
音频处理

00:16:15.342 --> 00:16:18.312
应用特定的音效
以及将多个来源的音频混合

00:16:20.147 --> 00:16:22.416
或者你可能对
实施3D音效感兴趣

00:16:23.917 --> 00:16:27.521
这方面的应用案例包括
开发经典的卡拉OK应用

00:16:28.488 --> 00:16:31.225
开发具有超高音效的
DJ应用

00:16:31.558 --> 00:16:34.261
或者开发一款让用户
完全沉浸其中的游戏

00:16:36.196 --> 00:16:37.664
对于这种高级用例

00:16:37.731 --> 00:16:41.134
我们在AVFoundation中有
叫AVAudioEngine的级别

00:16:43.036 --> 00:16:45.038
AVAudioEngine
是一款强大

00:16:45.105 --> 00:16:47.674
功能丰富的Objective-C
和Swift API

00:16:49.810 --> 00:16:51.378
它是一种实时音频系统

00:16:51.912 --> 00:16:53.914
可以通过向你提供
非实时界面

00:16:53.981 --> 00:16:56.350
简化实时音频的处理工作

00:16:57.484 --> 00:17:00.721
所以 处理实时音频
涉及很多复杂的操作

00:17:00.787 --> 00:17:02.856
而AVAudioEngine可以
使你的代码更加简单

00:17:04.992 --> 00:17:07.094
AVAudioEngine管理
一个节点图表

00:17:07.327 --> 00:17:09.663
这些节点使你
得以播放和录制音频

00:17:10.329 --> 00:17:12.031
你可以以各种方式
连接这些节点

00:17:12.098 --> 00:17:14.800
从而形成多个不同的
处理链条

00:17:15.769 --> 00:17:16.837
并进行混音

00:17:17.804 --> 00:17:21.407
你也可以在处理链条的
任意一点捕获音频

00:17:22.108 --> 00:17:25.045
我们提供一个专门的节点
可以使你实现音频的空间化

00:17:27.414 --> 00:17:30.684
那么 让我们看一下根本的
组成部分——AVAudioNode

00:17:31.985 --> 00:17:33.453
我们有三类节点

00:17:34.354 --> 00:17:36.924
我们有源节点
可以提供用于呈现的数据

00:17:37.724 --> 00:17:39.459
例如你的PlayerNode

00:17:39.526 --> 00:17:42.095
InputNode或者抽样单位

00:17:43.764 --> 00:17:46.466
我们有处理节点
可以使你处理音频数据

00:17:46.700 --> 00:17:50.704
所以 你客户处理的效果包括
延迟、失真以及混音

00:17:52.773 --> 00:17:55.642
我们有目标节点

00:17:55.709 --> 00:17:57.744
即你图表中的
终端节点

00:17:57.811 --> 00:18:00.247
它与输出硬件
直接连接

00:18:02.716 --> 00:18:04.251
让我们看一下设置示例

00:18:05.452 --> 00:18:07.821
比如 我正在构建
一款经典的卡拉OK应用

00:18:09.690 --> 00:18:11.692
在这个例子中
我有三个源节点

00:18:11.758 --> 00:18:14.361
我使用InputNode
捕获用户声音

00:18:14.895 --> 00:18:17.297
使用PlayerNode
播放伴奏曲

00:18:18.332 --> 00:18:20.767
使用另一个PlayerNode
播放其它音效

00:18:20.834 --> 00:18:22.736
和对用户使用的反馈

00:18:24.304 --> 00:18:25.739
对于处理节点

00:18:25.806 --> 00:18:28.742
我可能会对用户声音
应用特定的EQ

00:18:30.077 --> 00:18:31.879
然后我会使用混音器

00:18:31.945 --> 00:18:34.281
将三个源合成为
单个输出内容

00:18:35.148 --> 00:18:37.951
然后这单个输出内容
将通过OutputNode播放

00:18:38.018 --> 00:18:39.620
然后传递到输出硬件

00:18:41.522 --> 00:18:44.391
我也可以捕获用户的声音
并进行一定的分析

00:18:44.491 --> 00:18:47.461
从而了解安装TapBlock后
他们的表现情况

00:18:48.362 --> 00:18:51.231
然后基于此
我可以无条件地安排

00:18:51.298 --> 00:18:53.934
播放出这些反馈队列

00:18:56.170 --> 00:18:58.572
现在 让我们看一下
游戏设置示例

00:19:00.274 --> 00:19:03.043
这里主要相关节点是
EnvironmentNode

00:19:03.110 --> 00:19:04.845
它可以模拟3D空间

00:19:05.078 --> 00:19:07.347
并将相连的源空间化

00:19:07.447 --> 00:19:09.283
引擎设置示例
游戏

00:19:09.349 --> 00:19:13.153
在这个例子中 我使用InputNode
以及PlayerNode作为源

00:19:14.855 --> 00:19:17.057
你也可以调整你源上的
各种3D混音属性

00:19:17.124 --> 00:19:20.627
比如位置和闭塞

00:19:21.395 --> 00:19:24.064
而对于EnvironmentNode
你也可以在那里调整属性

00:19:24.131 --> 00:19:28.001
如listenerPosition
以及其它混响参数

00:19:30.571 --> 00:19:33.674
所以 该3D空间然后
可以与伴奏曲混合

00:19:33.740 --> 00:19:35.375
然后通过输出设备播放

00:19:38.946 --> 00:19:39.847
核心级别

00:19:39.913 --> 00:19:42.182
在进一步
介绍AVAudioEngine前

00:19:42.249 --> 00:19:44.484
我想再介绍下
Engine广泛使用的

00:19:44.551 --> 00:19:46.353
一些根本的核心级别

00:19:47.387 --> 00:19:49.323
我从AVAudioFormat开始

00:19:50.958 --> 00:19:53.560
AVAudioFormat
描述音频文件或音频流中的

00:19:53.627 --> 00:19:55.429
数据格式

00:19:56.096 --> 00:19:59.199
所以我们有标准格式
通用格式

00:19:59.266 --> 00:20:00.868
以及压缩格式

00:20:01.735 --> 00:20:04.404
该级别也包含
AVAudioChannelLayout

00:20:04.571 --> 00:20:07.341
你在处理多声道音频时
可能会用到

00:20:07.474 --> 00:20:11.144
它是我们的现代界面 连接到
AudioStreamBasicDescription结构

00:20:11.211 --> 00:20:13.013
以及AudioChannelLayout结构

00:20:15.349 --> 00:20:16.917
现在 让我们看下
AVAudioBuffer

00:20:16.984 --> 00:20:18.719
AVAudioBuffer
核心级别

00:20:18.852 --> 00:20:20.587
该级别有两个子级别

00:20:20.654 --> 00:20:24.291
AVAudioPCMBuffer
可用于缓冲PCM数据

00:20:24.625 --> 00:20:26.727
包括AVAudioCompressBuffer

00:20:26.793 --> 00:20:29.162
可用来缓冲压缩音频数据

00:20:30.163 --> 00:20:32.499
这两个级别均提供
现代界面 连接到我们的

00:20:32.566 --> 00:20:35.769
AudioBufferList
以及AudioStreamPacketDescription

00:20:38.005 --> 00:20:39.706
让我们看一下AVAudioFile

00:20:40.641 --> 00:20:43.710
该级别允许你
从任何支持的格式进行读写

00:20:44.678 --> 00:20:47.447
允许你将数据读入
PCM缓存并从PCM缓存

00:20:47.514 --> 00:20:49.716
将数据写入文件

00:20:49.850 --> 00:20:53.453
这样 它可以透明化地
处理任何编码和解码

00:20:55.322 --> 00:20:59.426
它现在取代我们的AudioFile
和ExtAudioFile API

00:21:00.260 --> 00:21:02.563
最后 让我们看下
AVAudioConverter

00:21:03.163 --> 00:21:05.566
AVAUDIO转换器
核心级别

00:21:05.632 --> 00:21:07.801
该级别处理音频格式转换

00:21:08.335 --> 00:21:12.606
所以 你可以在两种
PCM数据格式间转换

00:21:14.575 --> 00:21:17.978
也可以在PCM以及
压缩音频格式间转换

00:21:18.912 --> 00:21:21.281
其中 转换器帮你
进行编码和解码

00:21:23.317 --> 00:21:26.220
这一级别取代我们的
AudioConverter API

00:21:28.455 --> 00:21:29.990
今年新内容中 我们也添加了

00:21:30.057 --> 00:21:32.593
最小相位
采样速率转换器算法

00:21:35.095 --> 00:21:38.498
所以 你可以看到
当与音频数据相连时

00:21:38.565 --> 00:21:40.300
所有核心级别能很好地协作

00:21:42.536 --> 00:21:46.373
让我们看下这些级别然后怎样与
AVAudioEngine交互

00:21:48.809 --> 00:21:53.413
若你观察AVAudioNode发现
它有输入和输出AVAudio格式

00:21:55.382 --> 00:21:58.852
如果你观察PlayerNode
它可以通过AVAudioFile

00:21:58.919 --> 00:22:01.989
或AVAudioPCMBuffer
使连接到Engine

00:22:05.092 --> 00:22:08.762
如果你安装NodeTap
该部分以PCM缓存的形式

00:22:08.829 --> 00:22:10.831
向你提供音频数据

00:22:11.064 --> 00:22:12.366
你可以使用它进行分析

00:22:12.432 --> 00:22:15.736
或者你可以使用AVAudio文件
将它保存在文件中

00:22:17.804 --> 00:22:19.339
如果你处理的是
压缩流

00:22:19.406 --> 00:22:21.275
你可以将它分解为
压缩缓存

00:22:21.341 --> 00:22:24.845
用AVAudioConverter
将它转换为PCM缓存

00:22:24.912 --> 00:22:27.447
然后通过PlayerNode
将它提供给Engine

00:22:32.486 --> 00:22:36.356
今年新内容中我们为Watch带来了
AVAudioEngine子集

00:22:37.090 --> 00:22:40.093
与此同时 我们也添加了
AVAudioSession子集

00:22:40.160 --> 00:22:42.262
以及你刚刚看到的
所有核心级别

00:22:43.864 --> 00:22:45.866
我相信你一定想
看一下演示

00:22:46.633 --> 00:22:47.835
我们为你准备了演示

00:22:48.769 --> 00:22:52.372
我们直接使用SceneKit
和AVAudioEngine开发了简单的游戏

00:22:53.407 --> 00:22:56.677
在这个游戏中 我的举动是
将小行星发射到太空

00:22:56.910 --> 00:22:58.912
在屏幕底端
有一团火焰

00:22:58.979 --> 00:23:02.082
我可以使用Watch的
数码表冠控制火焰

00:23:02.783 --> 00:23:04.618
现在 如果行星
接触到火焰

00:23:04.685 --> 00:23:06.587
就会播放特别大的
爆炸声

00:23:07.221 --> 00:23:08.388
所以 让我们来看看

00:23:09.056 --> 00:23:11.625
演示WATCHOS上的
AVAUDIOENGINE

00:23:27.875 --> 00:23:30.177
我肯定这个游戏
违背了基本的物理定律

00:23:30.244 --> 00:23:33.514
因为它在太空中播放音频
对吧？这是不可能的

00:23:36.817 --> 00:23:40.320
好 那让我快速看一下游戏中的
AVAudioEngine代码

00:23:42.322 --> 00:23:44.625
在我的级别中
我有AVAudioEngine

00:23:44.892 --> 00:23:46.360
我有两个PlayerNode

00:23:46.493 --> 00:23:48.195
一个播放爆炸声

00:23:48.328 --> 00:23:50.030
一个播放发射声

00:23:51.698 --> 00:23:54.368
我也有连接到
我音频资源的URL

00:23:56.637 --> 00:24:00.207
在这个例子中 我使用
缓存向引擎提供数据

00:24:03.744 --> 00:24:05.145
让我们看下如何
设置引擎

00:24:06.480 --> 00:24:09.383
首先要做的是
附加我的PlayerNode

00:24:09.449 --> 00:24:12.352
所以 我触摸explosionPlayer
和launchPlayer

00:24:13.854 --> 00:24:15.722
接下来 我将使用核心级别

00:24:15.789 --> 00:24:19.193
我将从我资产的URL
创建一个AVAudio文件

00:24:19.793 --> 00:24:21.695
然后
我将创建一个PCM缓存

00:24:21.762 --> 00:24:24.965
我将把文件中的数据
读入PCM缓存

00:24:25.532 --> 00:24:28.535
之所以能这样做是
因为我的音频文件非常短

00:24:31.205 --> 00:24:33.240
接下来 我继续操作
连接源节点

00:24:33.307 --> 00:24:36.243
以及引擎的主要混音器

00:24:39.479 --> 00:24:43.250
所以 当游戏即将开始时
我接着开启引擎

00:24:43.317 --> 00:24:44.751
并开启播放器

00:24:45.786 --> 00:24:49.790
当发射小行星时
我只是安排launchBuffer

00:24:49.857 --> 00:24:51.491
在launchPlayer上播放

00:24:52.693 --> 00:24:54.595
当小行星接触到火焰时

00:24:54.661 --> 00:24:58.465
只需安排explosionBuffer
在explosionPlayer上播放

00:24:59.633 --> 00:25:00.968
这样 只需几行代码

00:25:01.034 --> 00:25:03.270
我就能为
watchOS上的游戏

00:25:03.337 --> 00:25:05.072
创造非常丰富的音频体验

00:25:06.106 --> 00:25:07.474
这只是个简单的例子

00:25:07.541 --> 00:25:09.710
我们非常期待能看到
你制造的效果

00:25:12.079 --> 00:25:13.247
多声道音频

00:25:13.313 --> 00:25:17.317
结束AVAudioEngine介绍
之前 我要谈论下多声道音频

00:25:18.218 --> 00:25:20.621
具体的是 它如何与
tvOS关联的

00:25:22.322 --> 00:25:24.725
去年十月 我们发布了tvOS

00:25:24.791 --> 00:25:26.860
以及第四代Apple TV

00:25:27.261 --> 00:25:30.497
所以这是在全球开发者大会上
我们首次可以谈论该话题

00:25:30.931 --> 00:25:33.834
有关Apple TV上音频
有趣的一点是

00:25:33.901 --> 00:25:37.271
很多用户已经连接到
多声道硬件

00:25:37.471 --> 00:25:39.840
这是因为很多家庭影院系统
已经支持

00:25:39.907 --> 00:25:42.910
5.1或7.1环绕立体声系统

00:25:43.243 --> 00:25:46.880
今天 我只是想略微展示下
你怎样使用AVAudioEngine

00:25:47.247 --> 00:25:48.615
来呈现多声道音频

00:25:50.651 --> 00:25:53.153
首先 让我们回顾下
AVAudioSession的设置

00:25:54.588 --> 00:25:57.558
我首先设置我的类别
和其他选项

00:25:57.624 --> 00:26:00.460
然后激活会话
以便配置硬件

00:26:00.527 --> 00:26:02.362
满足我的应用需求

00:26:03.964 --> 00:26:06.800
现在 按照我想使用的
呈现格式

00:26:06.900 --> 00:26:09.369
我首先需要查看
当前路径是否支持该格式

00:26:09.503 --> 00:26:12.739
要查看这一点
我需要查看我想要的声道数

00:26:12.806 --> 00:26:15.876
是否小于或等于
最大输出声道数

00:26:16.176 --> 00:26:19.847
如果是 那么我可以继续
设置我想要的输出声道数

00:26:22.049 --> 00:26:25.252
接着 我可以从会话中
查询得到实际的声道数

00:26:25.319 --> 00:26:26.987
然后使用它继续操作

00:26:29.189 --> 00:26:33.193
或者 我可以查看当前端口上
的ChannelDescription阵列

00:26:34.161 --> 00:26:37.064
每个ChannelDescription
向我提供一个channelLabel

00:26:37.464 --> 00:26:38.498
和一个channelNumber

00:26:39.366 --> 00:26:42.269
所以 我可以使用该信息
了解确切的格式

00:26:42.336 --> 00:26:45.539
以及如何将内容映射到
连接的硬件上

00:26:47.441 --> 00:26:49.776
现在我们换回
AVAudioEngine设置话题

00:26:51.178 --> 00:26:52.446
这里有两个用例

00:26:52.513 --> 00:26:56.149
第一个用例是
如果你已经拥有多声道内容

00:26:57.684 --> 00:26:59.953
第二个用例是
如果你拥有单声道内容

00:27:00.020 --> 00:27:01.188
并且想对它空间化

00:27:01.255 --> 00:27:03.223
这通常是为游戏准备的

00:27:04.992 --> 00:27:06.426
所以 在第一个用例中

00:27:07.895 --> 00:27:10.864
我拥有多声道内容
以及多声道硬件

00:27:11.532 --> 00:27:13.367
我只需获得硬件格式

00:27:13.433 --> 00:27:16.570
我将它设置为我的混音器
和我的OutputNode间的连接

00:27:16.970 --> 00:27:19.540
在源端
我获得了内容格式

00:27:19.606 --> 00:27:22.743
并将它设置为我的
SourceNode和混音器间连接

00:27:23.243 --> 00:27:26.113
这里混音器为你
处理声道映射

00:27:29.349 --> 00:27:32.119
现在 在第二个用例中
我们有一堆单声道源

00:27:32.452 --> 00:27:35.022
我们将使用EnvironmentNode
对其空间化

00:27:36.456 --> 00:27:38.659
跟之前一样
我们获取硬件格式

00:27:38.825 --> 00:27:42.162
但在设置兼容格式前
我们必须将其映射到

00:27:42.229 --> 00:27:44.231
EnvironmentNode
支持的格式

00:27:45.265 --> 00:27:48.802
要了解支持的格式列表
你可以查询我们的网上文件

00:27:49.436 --> 00:27:51.672
所以 我设置好兼容格式

00:27:51.905 --> 00:27:55.209
现在 在源端
像之前一样 我获得内容格式

00:27:55.309 --> 00:27:59.046
并将其设置为我的播放器和
EnvironmentNode之间的连接

00:28:00.113 --> 00:28:05.018
最后 我也必须将
多声道呈现算法设置为

00:28:05.085 --> 00:28:08.288
SoundField 它目前受
EnvironmentNode支持

00:28:09.756 --> 00:28:13.026
此时 我可以启动引擎
开始播放

00:28:13.360 --> 00:28:16.663
然后调整我们支持的
所有各种3D混音属性

00:28:19.967 --> 00:28:20.868
好 简单回顾下

00:28:21.268 --> 00:28:25.005
AVAudioEngine是功能
丰富强大的API

00:28:26.840 --> 00:28:28.976
它简化了实时音频的
处理工作

00:28:30.844 --> 00:28:34.114
它使你能够处理
多声道音频和3D音频

00:28:35.015 --> 00:28:36.250
现在 你可以在Watch上

00:28:36.316 --> 00:28:38.552
开发具有丰富音频体验的游戏

00:28:40.120 --> 00:28:44.157
它取代了我们的
AUGraph和OpenAL API

00:28:44.758 --> 00:28:47.127
我们在之前演讲中
简要介绍了Engine

00:28:47.194 --> 00:28:50.597
我们鼓励你尽量
了解与此相关的内容

00:28:51.365 --> 00:28:53.600
现在 我要将舞台
交给我的同事Doug

00:28:53.667 --> 00:28:54.768
让他接着介绍

00:28:55.035 --> 00:28:55.869
Doug？

00:29:01.175 --> 00:29:02.276
谢谢 Saleem

00:29:02.843 --> 00:29:07.181
好 我想在此继续介绍
音频API

00:29:07.681 --> 00:29:12.486
我们介绍AVAudioEngine
时顺便说到了实时音频

00:29:13.353 --> 00:29:14.922
Saleem强调

00:29:15.656 --> 00:29:19.259
尽管音频处理
在实时环境中发生

00:29:19.493 --> 00:29:22.262
我们却是在非实时
环境中进行控制

00:29:22.329 --> 00:29:24.331
这就是操作简化的本质

00:29:24.698 --> 00:29:26.733
但有的时候
你实际想要

00:29:26.800 --> 00:29:30.337
在实时过程或环境下工作

00:29:30.604 --> 00:29:32.272
所以 我想进一步介绍下这点

00:29:32.606 --> 00:29:34.608
那么 什么是实时音频

00:29:34.741 --> 00:29:37.511
有的用例中
我们需要实时操作

00:29:37.578 --> 00:29:40.080
这种用例的特点是
低延迟

00:29:42.216 --> 00:29:44.718
可能我所熟悉的
我们平台上

00:29:44.785 --> 00:29:47.321
最早的应用例子是
音乐应用

00:29:47.888 --> 00:29:51.525
比如
当用户按下MIDI键盘上的

00:29:51.592 --> 00:29:54.127
一个键时
你可能正在合成声音

00:29:54.795 --> 00:29:56.563
我们想要尽量减少

00:29:56.630 --> 00:30:00.067
从按下MIDI音符到
播放音符的时间

00:30:00.534 --> 00:30:04.338
我们有像吉他踏板
一样的实时音频效果

00:30:05.272 --> 00:30:09.009
我们想要尽量减少
从吉他音频

00:30:09.076 --> 00:30:11.144
输入进电脑

00:30:12.012 --> 00:30:15.782
到我们在电脑中处理音频
应用延迟、变形

00:30:15.849 --> 00:30:17.818
然后将音频发回到扩音器
所花费的时间

00:30:18.218 --> 00:30:21.989
所以这种情况下我们需要
低延迟以实现乐器的快速响应

00:30:22.623 --> 00:30:26.226
电话也具有
要求低延迟的特征

00:30:26.894 --> 00:30:29.963
我们都曾经跟其他国家的
人打电话

00:30:30.030 --> 00:30:31.932
而且经历过高延迟的情况

00:30:31.999 --> 00:30:33.800
高延迟在电话中是不好的

00:30:34.134 --> 00:30:36.003
我们进行很多信号处理

00:30:36.103 --> 00:30:37.704
我们需要降低延迟

00:30:38.438 --> 00:30:41.675
同样 在游戏引擎中
我们也希望降低延迟

00:30:42.209 --> 00:30:45.946
用户在进行操作
与控制杆等交互

00:30:46.480 --> 00:30:48.982
我们想要尽快产生相应声音

00:30:49.049 --> 00:30:51.318
有时候我们想要
在声音呈现时

00:30:51.385 --> 00:30:52.653
控制这些声音

00:30:53.053 --> 00:30:55.756
或者 也许我们就
已经有了游戏引擎

00:30:56.256 --> 00:31:00.093
在所有这些案例中
我们都需要写出能够

00:31:00.327 --> 00:31:01.562
在实时环境中运行的代码

00:31:02.596 --> 00:31:06.366
在这种实时环境中

00:31:07.768 --> 00:31:10.437
我们受到约束的

00:31:10.504 --> 00:31:13.173
一个主要特征是
我们的操作是有时限的

00:31:14.174 --> 00:31:16.410
对吧？每隔几毫秒

00:31:16.476 --> 00:31:20.080
系统都会叫醒我们
要求我们发出

00:31:20.147 --> 00:31:22.216
持续同样短暂时间的声音

00:31:22.716 --> 00:31:26.353
也许 我们能够完成任务
产生无缝对接的音频

00:31:26.854 --> 00:31:30.257
也许 我们任务失败
花费过长时间产生音频

00:31:30.824 --> 00:31:32.893
因而输出内容产生缺陷

00:31:32.960 --> 00:31:35.395
用户听到的是故障的声音

00:31:36.029 --> 00:31:40.234
我们制造音频所能使用的
时间间隔很短

00:31:40.300 --> 00:31:43.203
我们的期限通常
短至3毫秒

00:31:43.270 --> 00:31:46.707
而iOS中默认的
20毫秒

00:31:46.773 --> 00:31:50.544
也仍然是非常紧张的期限

00:31:51.545 --> 00:31:55.182
所以 在这样的环境中
我们必须特别小心自己的操作

00:31:56.083 --> 00:31:59.653
我们不能停滞
我们不能分配内存

00:31:59.753 --> 00:32:01.522
我们不能使用互斥体

00:32:01.588 --> 00:32:04.258
我们不能访问文件系统
或者套接字

00:32:04.658 --> 00:32:05.659
我们不能记录

00:32:05.993 --> 00:32:10.130
我们甚至不能调用分派
“async”因为它会分配续延

00:32:10.898 --> 00:32:14.067
我们必须小心不要
与Objective-C

00:32:14.134 --> 00:32:18.539
Swift运行时交互 因为
它们二者并不完全实时安全

00:32:18.605 --> 00:32:21.808
有些情况下 它们也会
采取互斥体

00:32:22.776 --> 00:32:25.846
这是部分列表
还有其它操作我们不能做

00:32:25.913 --> 00:32:27.814
你要问自己
最重要的事情是

00:32:28.148 --> 00:32:32.119
我进行的操作
分配内存或使用互斥体吗？

00:32:32.186 --> 00:32:35.289
如果答案是“是”
那操作就不是实时安全的

00:32:36.056 --> 00:32:37.424
那么 我们能做什么呢

00:32:37.491 --> 00:32:39.927
过会儿 我会
向大家展示这方面的例子

00:32:41.428 --> 00:32:47.167
不过 首先 我想只是
讨论下如何管理

00:32:47.234 --> 00:32:50.337
打包实时音频组件的问题

00:32:50.704 --> 00:32:53.774
我们通过叫做Audio Unit的
API集实现打包

00:32:54.474 --> 00:32:58.545
所以 这是我们打包的方式

00:32:58.612 --> 00:33:00.948
而对于你 关于此问题
作为其他开发者

00:33:01.014 --> 00:33:03.383
你可以通过它打包你
在其它应用中会再次使用的

00:33:03.450 --> 00:33:06.386
信号处理和模块

00:33:06.753 --> 00:33:11.358
而且它也提供一个API
可以管理

00:33:11.425 --> 00:33:15.629
你非实时环境
和实时呈现环境之间的

00:33:15.696 --> 00:33:17.631
转变和交互

00:33:19.333 --> 00:33:22.269
所以 作为应用开发者
你可以托管Audio Unit

00:33:23.270 --> 00:33:25.706
这意味着你可以允许
用户选择一个单元

00:33:25.772 --> 00:33:30.043
或者你可以简单的使用指向
系统内置单元的硬编码引用

00:33:31.044 --> 00:33:33.514
你也可以构建
自己的Audio Unit

00:33:34.147 --> 00:33:37.017
可以将它们构建为
应用扩展或插件

00:33:37.651 --> 00:33:41.755
你也可以简单地
私下对你的应用

00:33:41.822 --> 00:33:42.856
注册一个Audio Unit

00:33:42.923 --> 00:33:46.593
这样很有用 比如
如果你有一些小块的

00:33:46.660 --> 00:33:48.495
信号处理想要在

00:33:48.562 --> 00:33:51.064
AVAudioEngine
环境中使用

00:33:54.301 --> 00:33:56.136
所以 在Audio Unit下

00:33:56.203 --> 00:33:59.039
我们有更根本的API

00:33:59.273 --> 00:34:00.874
叫做音频组件

00:34:02.075 --> 00:34:06.380
这是AudioToolbox
框架内的一组API

00:34:07.114 --> 00:34:11.585
框架维护了系统上
所有组件的记录

00:34:11.652 --> 00:34:13.053
AUDIO UNITS：组件

00:34:13.120 --> 00:34:16.822
每个组件都有一种类型
子类型以及制造商

00:34:16.889 --> 00:34:18.292
这些是包含4个字符的代码

00:34:18.725 --> 00:34:22.295
它们作为发现并注册
组件的键

00:34:24.063 --> 00:34:27.568
有很多种不同的
音频组件类型

00:34:28.168 --> 00:34:33.739
两种主要的类型是Audio
Units和Audio Codecs

00:34:34.373 --> 00:34:37.077
但在Audio Unit中
我们又有输入/输出单元

00:34:37.143 --> 00:34:38.846
生成器、效果、乐器

00:34:39.279 --> 00:34:41.949
转换器以及混音器

00:34:42.315 --> 00:34:45.319
在codecs编码解码器中
我们又有编码器和解码器

00:34:45.585 --> 00:34:48.255
在macOS上
我们还有音频文件组件

00:34:51.725 --> 00:34:55.161
关于组件的实施

00:34:56.029 --> 00:34:59.299
组件的实施
有很多不同的方法

00:34:59.366 --> 00:35:02.069
有一些是如果你用它
写代码时需要了解的

00:35:02.135 --> 00:35:03.837
而另外一些 不过是背景知识

00:35:04.738 --> 00:35:08.942
现在创建组件
最好的方法

00:35:09.009 --> 00:35:12.646
若是Audio Unit 最好是
创建Audio Unit应用扩展

00:35:13.280 --> 00:35:19.152
通过10.11和9.0版本
我们去年对此进行了介绍

00:35:20.153 --> 00:35:21.488
所以 那些是应用扩展

00:35:21.555 --> 00:35:25.526
而那之前 Audio Units是
打包在组件捆绑包里的

00:35:25.592 --> 00:35:27.294
audio codecs等也是如此

00:35:28.862 --> 00:35:31.064
那大概要回溯到
Mac OS 10.1了

00:35:33.367 --> 00:35:38.939
有趣的是 音频组件也包括
iOS上应用间的音频节点

00:35:39.373 --> 00:35:41.775
节点应用使用

00:35:42.109 --> 00:35:45.779
组件子类型和制造商密钥
进行注册

00:35:46.446 --> 00:35:49.683
主应用程序通过Audio
Component Manager

00:35:50.250 --> 00:35:51.952
发现
节点应用程序

00:35:53.720 --> 00:35:56.390
最终 你能够注册
——像我之前提到的——

00:35:56.456 --> 00:35:59.860
你能够注册自己的组件
以便用于你自己的应用程序

00:36:00.527 --> 00:36:03.897
只是补充下
有一些Apple内置组件

00:36:04.331 --> 00:36:07.000
在iOS上 它们连接到
AudioToolbox

00:36:09.002 --> 00:36:12.639
所以 以上就是
组件实施的情况

00:36:12.840 --> 00:36:16.510
现在 这里 我要将焦点
仅仅集中到一种组件——

00:36:16.743 --> 00:36:18.545
音频输入/输出单元

00:36:18.712 --> 00:36:19.913
这是Audio Unit

00:36:19.980 --> 00:36:21.849
音频输入/输出单元
最常用

00:36:21.915 --> 00:36:25.752
如果你只使用一种组件
这很可能就是

00:36:25.819 --> 00:36:27.254
你会使用的组件

00:36:28.121 --> 00:36:31.425
其中的原因是
这是连接到系统基本

00:36:31.491 --> 00:36:34.528
音频输入/输出路径的
首选界面

00:36:35.329 --> 00:36:39.867
现在 在macOS上 该基本
路径位于Core Audio框架

00:36:40.300 --> 00:36:41.602
我们称之为Audio HAL

00:36:42.402 --> 00:36:44.204
这是非常低级别的界面

00:36:44.638 --> 00:36:48.942
比如 它能使客户处理
在多声道设备上

00:36:49.009 --> 00:36:51.011
有趣的流媒体类型

00:36:52.045 --> 00:36:56.283
所以通过音频
输入/输出单元

00:36:56.650 --> 00:36:58.585
能够非常轻松地
处理Audio HAL界面

00:37:00.087 --> 00:37:04.491
在iOS上 你甚至不需要
Core Audio框架的访问权限

00:37:04.558 --> 00:37:05.792
在那里 它不是公共的

00:37:05.959 --> 00:37:08.262
你必须使用
音频输入/输出单元

00:37:08.695 --> 00:37:13.267
作为你将音频输入
和输出系统的低级别方式

00:37:15.369 --> 00:37:17.538
我们现在音频输入/输出

00:37:18.405 --> 00:37:21.608
单元的首选界面是
AUAudioUnit

00:37:21.675 --> 00:37:23.443
及AudioToolbox框架

00:37:24.178 --> 00:37:26.980
如果你使用
我们的API已经有一段时间

00:37:27.347 --> 00:37:31.218
你熟悉第2版Audio Units
它是macOS上AUHAL系统

00:37:31.285 --> 00:37:36.423
以及iOS和Watch上
AURemoteIO系统的

00:37:36.490 --> 00:37:38.492
一部分——

00:37:39.059 --> 00:37:41.328
实际上 我不确定
Watch上有没有

00:37:41.395 --> 00:37:46.333
不过不论如何
AUAudioUnit是你连接到

00:37:46.567 --> 00:37:48.936
低级别I/O机制的全新现代界面

00:37:50.604 --> 00:37:53.473
所以 我要向你展示使用

00:37:53.540 --> 00:37:58.912
AUAudioUnit
进行AudioIO操作的情况

00:37:59.379 --> 00:38:02.049
所以 这里
我用Swift写好了

00:38:02.850 --> 00:38:04.551
产生方波的简单程序

00:38:06.220 --> 00:38:08.622
这是我的信号处理

00:38:08.689 --> 00:38:12.226
像之前提到的 我要
展示你在这儿可以做什么

00:38:12.893 --> 00:38:16.363
所以 这个波形信号发生器
向你展示

00:38:16.697 --> 00:38:21.168
你基本上可以读取内存
写入内容并进行数学运算

00:38:21.902 --> 00:38:24.238
这是这里进行的
所有操作

00:38:24.304 --> 00:38:27.975
即产生最简单的
波形 ——方波——

00:38:28.208 --> 00:38:30.911
至少从计算机的
角度来说最简单

00:38:31.879 --> 00:38:34.414
所以 这种级别叫做
SquareWaveGenerator

00:38:35.549 --> 00:38:39.853
让我们看看如何使用AUAudioUnit
播放SqaureWaveGenerator

00:38:41.755 --> 00:38:45.125
首先 我们创建
一条音频组件描述

00:38:46.093 --> 00:38:49.363
这条描述告诉我们寻找
哪个组件

00:38:50.130 --> 00:38:51.331
类型是输出

00:38:51.465 --> 00:38:55.135
子类型是我根据
平台在这里做出的选择——

00:38:55.602 --> 00:38:57.471
RemoteIO或
HalOutput

00:38:58.172 --> 00:39:01.842
这里有Apple制造商
以及一些未使用的标记

00:39:02.910 --> 00:39:06.947
然后我可以使用组件描述
创建AUAudioUnit

00:39:08.081 --> 00:39:09.816
这样我就能得到想要的单元

00:39:11.418 --> 00:39:15.722
现在 打开了
我可以开始配置

00:39:16.557 --> 00:39:19.626
这里我要做的
第一件事是搞清楚

00:39:19.693 --> 00:39:23.197
系统上有多少音频声道

00:39:23.263 --> 00:39:27.801
这可以使用多种方法通过iOS上的
AVAudioSession实现

00:39:28.368 --> 00:39:32.372
不过 最简单和便捷的是

00:39:32.439 --> 00:39:36.376
你可以简单地查询

00:39:36.810 --> 00:39:39.346
输入/输出单元的
outputBusses

00:39:39.746 --> 00:39:45.052
而outputBus[0]是
输出指向的流

00:39:45.652 --> 00:39:48.488
所以我将获取它的格式
那是我的硬件格式

00:39:48.956 --> 00:39:52.693
那么 这个硬件格式
可能是比较奇异的东西

00:39:52.759 --> 00:39:55.329
比如 它可能显示惰性

00:39:56.830 --> 00:39:59.633
我不知道
是不是要处理它

00:39:59.700 --> 00:40:01.802
所以我只是创建
一个renderFormat

00:40:01.869 --> 00:40:04.905
这是具有相同采样率的
标准格式

00:40:05.405 --> 00:40:07.074
以及一些声道

00:40:08.242 --> 00:40:13.347
为快速简单起见
我只呈现两个波段

00:40:13.413 --> 00:40:15.482
而不论
硬件声道数是多少

00:40:16.316 --> 00:40:18.118
好 那就是我的
renderFormat

00:40:18.352 --> 00:40:20.954
现在 我可以告诉I/O单元

00:40:21.321 --> 00:40:25.058
这是我想要在
inputBus[0]上给你的格式

00:40:25.559 --> 00:40:29.997
完成该操作后 该单元
现会把我的renderFormat

00:40:30.163 --> 00:40:31.365
转换成hardwareFormat

00:40:31.965 --> 00:40:33.967
在该例中 在我的MacBook上

00:40:34.034 --> 00:40:37.971
该单元会获取
该去交错的浮点

00:40:38.372 --> 00:40:41.775
并将其转换成
交错浮点缓冲器

00:40:43.577 --> 00:40:47.481
好 接下来 我将
构建我的方波生成器

00:40:48.248 --> 00:40:51.051
如果你是像我一样的
音乐和数学迷

00:40:51.585 --> 00:40:54.788
你知道代码中有A440
该数值乘以

00:40:54.855 --> 00:40:58.225
1.5后增长20%

00:40:59.693 --> 00:41:02.062
所以 我将在
左声道呈现A

00:41:02.129 --> 00:41:04.231
右声道呈现E

00:41:05.365 --> 00:41:08.836
这里是
会在实时环境中运行的代码

00:41:12.039 --> 00:41:13.774
其中有很多参数

00:41:13.941 --> 00:41:16.143
而实际上我只需要
其中的几个

00:41:16.210 --> 00:41:20.113
我只需要frameCount
和rawBufferList

00:41:20.914 --> 00:41:25.452
rawBufferList是一种
高难度的低级别C结构

00:41:25.886 --> 00:41:32.893
我可以使用SDK上的覆盖
在Swift语言中对其重包装

00:41:32.993 --> 00:41:35.329
这样拿走了
音频bufferList

00:41:35.896 --> 00:41:39.333
让它看起来像是
矢量或数组/阵列

00:41:40.767 --> 00:41:42.603
将rawBufferList转换成

00:41:42.669 --> 00:41:46.039
不错的Swift包装后
我可以查询它的数量

00:41:46.540 --> 00:41:50.344
如果我得到至少一个缓冲器
那么 我就能呈现左声道

00:41:50.844 --> 00:41:53.614
如果我得到至少两个缓冲器
我就能够呈现右声道

00:41:54.248 --> 00:41:56.850
这就是我现在
要做的所有工作

00:41:56.917 --> 00:41:59.453
当然 波形信号发生器内
还有更多的工作要做

00:41:59.520 --> 00:42:01.522
不过上述就是
实时环境下的所有工作

00:42:02.656 --> 00:42:05.626
所以 现在 我都设置好了
准备好呈现了

00:42:06.026 --> 00:42:07.861
我会告诉I/O单元

00:42:08.629 --> 00:42:11.565
进行所有必要的分配
以便开始呈现

00:42:12.099 --> 00:42:14.201
然后I/O单元
实际会让硬件

00:42:14.735 --> 00:42:16.603
运行3秒 然后停止

00:42:16.670 --> 00:42:18.539
这个简单的程序到此结束

00:42:23.243 --> 00:42:24.912
这就是AUAudioUnit

00:42:26.180 --> 00:42:30.450
接下来 我要简单讲一下
其它一些Audio Unit

00:42:30.984 --> 00:42:35.022
我们有效果 可以获取
音频输入 产生音频输出

00:42:35.455 --> 00:42:38.659
有乐器 可以获取
类似MIDI的东西作为输入

00:42:39.059 --> 00:42:40.727
同时也能产生音频输出

00:42:41.195 --> 00:42:44.531
有生成器 能够产生
音频输出

00:42:44.665 --> 00:42:48.602
而不输入任何东西
除了一些可能的参数控制

00:42:48.902 --> 00:42:52.906
如果我要将我的方波生成器
重新打包为Audio Unit

00:42:53.006 --> 00:42:54.508
我会做成生成器

00:42:57.644 --> 00:43:00.314
要托管这些
种类的Audio Unit

00:43:00.380 --> 00:43:02.482
你也可以使用AUAudioUnit

00:43:03.584 --> 00:43:07.354
你可以使用单独的部分
向它提供输入

00:43:07.588 --> 00:43:10.157
这跟你在I/O单元上
看到的

00:43:10.224 --> 00:43:12.826
输出供应块非常相似

00:43:13.660 --> 00:43:16.163
你可以将这些单元
呈现部分连接起来

00:43:16.230 --> 00:43:18.265
创建你自己的
定制化类型

00:43:18.966 --> 00:43:21.902
你可以使用参数
控制这些单元

00:43:23.203 --> 00:43:26.306
而且 很多单元
尤其是第三方单元

00:43:26.874 --> 00:43:28.542
都有很好的用户界面

00:43:28.609 --> 00:43:31.011
作为主应用程序
你可以获取

00:43:31.078 --> 00:43:34.815
audio unit视图
在你的应用程序中显示

00:43:34.882 --> 00:43:36.450
并让用户与其交互

00:43:39.786 --> 00:43:41.889
若你想
编写自己的Audio Unit

00:43:43.991 --> 00:43:46.627
我首先的做法很简单
就是在应用的环境中

00:43:46.693 --> 00:43:48.428
构建Audio Unit

00:43:48.695 --> 00:43:53.467
这样你可以进行调试
而无需担心流程间的通信问题

00:43:53.534 --> 00:43:54.668
全部在一个过程中完成

00:43:55.068 --> 00:43:57.504
你首先
将AUAudioUnit划入子级别

00:43:58.071 --> 00:44:02.276
使用AUAudioUnit的
这一级别方法将其注册为组件

00:44:02.976 --> 00:44:04.244
然后你可以对其进行调试

00:44:05.279 --> 00:44:06.780
一旦完成——

00:44:06.914 --> 00:44:09.116
如果你确定了
要将其作为

00:44:09.683 --> 00:44:11.285
Audio Unit扩展分布

00:44:11.652 --> 00:44:14.755
你就可以采取同样的
AUAudioUnit子级别

00:44:15.422 --> 00:44:17.591
你可以对其微调
和进一步修饰

00:44:18.325 --> 00:44:21.028
不过然后你将需要
多花一点功夫

00:44:21.361 --> 00:44:23.764
将其打包为
Audio Unit扩展

00:44:24.398 --> 00:44:27.434
所以 你就获得一个扩展程序
你可以把它嵌入某个应用程序

00:44:27.501 --> 00:44:29.803
也可以在App Store
出售该应用程序

00:44:33.707 --> 00:44:35.776
好 我想邀请
我的同事Torrey

00:44:35.843 --> 00:44:39.346
向你展示下Audio Unit扩展
的一些威力

00:44:39.680 --> 00:44:41.682
过去一年
我们一些开发者使用它

00:44:41.748 --> 00:44:42.883
做了不少很酷的事情

00:44:43.684 --> 00:44:44.751
大家可好？ 

00:44:45.552 --> 00:44:46.753
参加WWDC可开心？

00:44:48.188 --> 00:44:49.056
好

00:44:50.724 --> 00:44:51.959
让我们制造些声响吧

00:44:52.693 --> 00:44:54.695
我会从这儿开始 启动——

00:44:54.761 --> 00:44:56.630
首先
我的乐器在这儿

00:44:56.697 --> 00:45:00.567
这是我的iPad Pro
我首先启动Arturia iSEM

00:45:01.268 --> 00:45:03.170
这是非常强大的合成器应用

00:45:03.237 --> 00:45:06.006
这里是我喜欢的
合成喇叭声音

00:45:11.845 --> 00:45:15.349
我很喜欢这个声音 我想把它
放到我正在编辑的曲目中

00:45:15.449 --> 00:45:19.019
这个将作为我们的Audio
Unit插件应用

00:45:19.520 --> 00:45:21.688
现在 我要启动GarageBand

00:45:21.755 --> 00:45:24.591
它将作为我们的Audio Unit
主应用程序

00:45:25.192 --> 00:45:28.595
现在GarageBand中
有个我正编辑的sick beat

00:45:28.662 --> 00:45:31.565
我将它命名为WWDC Demo

00:45:32.366 --> 00:45:33.333
让我们听一下

00:45:43.577 --> 00:45:46.780
好 接下来我们看一下
辞句部分

00:45:55.088 --> 00:45:57.925
接着 我们将处理
和声部分

00:45:57.991 --> 00:45:59.960
这应该是歌曲的
高潮部分

00:46:00.027 --> 00:46:02.262
我希望多一点动感
多一点张力

00:46:02.696 --> 00:46:05.265
让我们通过Audio Unit
制造这种效果

00:46:06.800 --> 00:46:08.235
我将在这里添加一个新曲目

00:46:09.069 --> 00:46:12.105
添加新乐器 我会看到
这里有Audio Unit选项

00:46:12.973 --> 00:46:15.309
如果我选择它 接下来我会
在这里看到系统上

00:46:15.375 --> 00:46:16.910
寄存
所有的Audio Unit

00:46:17.244 --> 00:46:21.648
我看到的是Arturia iSEM
因为我在家里练习这个

00:46:22.983 --> 00:46:25.185
选择iSEM
GarageBand现在将

00:46:25.252 --> 00:46:28.555
在这里显示屏幕上的
MIDI控制器以供我使用

00:46:28.922 --> 00:46:32.693
它有完整的尺度变化
以及琶音器 就在这里

00:46:32.759 --> 00:46:35.462
我会充分利用这些工具
因为我很喜欢动感的音乐

00:46:35.863 --> 00:46:39.366
在这里的左边
你可以看到音调/修正滚轮

00:46:39.433 --> 00:46:41.001
你甚至可以修改速度

00:46:41.335 --> 00:46:44.104
Audio Unit在这里
向我提供的视图

00:46:44.171 --> 00:46:45.339
其实我可做小的调整

00:46:45.839 --> 00:46:48.442
而现在 我要在这里
录制一小段音频

00:46:48.509 --> 00:46:50.544
然后看一下它
在整个曲子中的效果

00:46:50.611 --> 00:46:51.478
那么——

00:47:04.825 --> 00:47:06.093
好了 不错

00:47:08.262 --> 00:47:10.063
让我们听一下它
在整个曲子中的效果

00:47:14.201 --> 00:47:16.270
好了
这就是我想要的张力

00:47:16.970 --> 00:47:20.374
现在 让我进行更深入的介绍
向大家展示我进行的操作

00:47:22.576 --> 00:47:23.977
我会在这里进行编辑

00:47:25.379 --> 00:47:28.182
我会更仔细地
观察循环曲目

00:47:29.082 --> 00:47:31.084
这里 我希望大家
注意两点

00:47:31.185 --> 00:47:33.887
第一点是
这些是MIDI事件

00:47:33.987 --> 00:47:36.456
使用跨应用音频与将
Audio Unit作为插件使用

00:47:36.523 --> 00:47:40.527
的不同点是
你实际可以在这里看到

00:47:40.594 --> 00:47:42.663
MIDI音符 
这就使事后的编辑更简单

00:47:43.063 --> 00:47:45.799
我希望大家在这里
注意的另外一点是

00:47:45.866 --> 00:47:47.968
你可以在这里
看到单个MIDI音符

00:47:48.035 --> 00:47:50.971
但是之前你看到的是
我弹奏巨大粗厚的和弦

00:47:51.371 --> 00:47:53.340
这是因为我利用了

00:47:53.407 --> 00:47:55.709
GarageBand内置的
琶音器

00:47:55.776 --> 00:47:57.244
所以我才得到了这些单个音符

00:47:57.311 --> 00:47:59.112
如果愿意
我可以随意更改

00:47:59.179 --> 00:48:00.981
使音符听起来
更人性化

00:48:01.315 --> 00:48:03.450
不过我对曲子现在的效果
已经很满意

00:48:04.751 --> 00:48:08.021
这里 我最后要向大家显示的
实际是 首先

00:48:08.088 --> 00:48:12.092
我会将这个复制到
临近的单元格

00:48:13.727 --> 00:48:18.265
我之前跟你提过
这里提供的Audio Unit视图

00:48:18.532 --> 00:48:20.300
实际是交互式的

00:48:20.367 --> 00:48:21.835
它不仅是外观漂亮的图片

00:48:21.935 --> 00:48:24.505
所以 如果你喜欢探索
你甚至可以尝试

00:48:24.571 --> 00:48:26.874
为朋友演奏一曲

00:48:32.012 --> 00:48:33.180
略微提高音量

00:49:32.840 --> 00:49:33.707
让我们收尾

00:50:01.335 --> 00:50:02.503
我的演示就到这里

00:50:05.305 --> 00:50:07.774
我想感激大家所付出的
时间和精力

00:50:07.841 --> 00:50:10.043
始终感谢大家写出炫酷的应用

00:50:11.178 --> 00:50:13.146
演示
Audio Unit扩展

00:50:14.982 --> 00:50:15.883
谢谢Torrey

00:50:16.250 --> 00:50:19.653
好 这里简单回顾下

00:50:20.854 --> 00:50:24.124
你能看到我们去年
关于Audio Unit扩展的介绍

00:50:24.191 --> 00:50:28.028
其中更详细地介绍了
API的构造

00:50:28.095 --> 00:50:29.429
这里我们只是想向你展示

00:50:29.496 --> 00:50:31.431
由于Audio Unit炫酷的功能
人们利用它都做了什么

00:50:33.667 --> 00:50:37.871
好 说到MIDI
我们看到GarageBand怎样

00:50:37.938 --> 00:50:39.673
将Torrey的演奏录制成MIDI

00:50:40.707 --> 00:50:42.910
我们的系统中
有很多API是

00:50:42.976 --> 00:50:46.246
使用MIDI通信的
而要在什么时候使用

00:50:46.313 --> 00:50:48.282
哪些API并不总是很清楚

00:50:48.982 --> 00:50:51.952
所以我希望能够
帮助大家稍稍澄清这一点

00:50:53.754 --> 00:50:56.723
现在 你可能就有
一个标准的MIDI文件

00:50:57.591 --> 00:51:00.294
比如 难听的手机铃声

00:51:00.427 --> 00:51:03.630
不过MIDI文件
在音乐教学中十分有用

00:51:03.830 --> 00:51:07.768
我可以获得我想学习
乐曲的MIDI文件

00:51:07.835 --> 00:51:09.336
我可以看到所有的音符

00:51:10.003 --> 00:51:12.105
若你有一个MIDI文件 你可用
AVAudioSequencer

00:51:12.172 --> 00:51:13.707
播放该文件

00:51:14.007 --> 00:51:17.244
这样会在AVAudioEngine
环境中播放文件

00:51:19.246 --> 00:51:21.815
如果你想要控制
软件合成器

00:51:22.282 --> 00:51:24.818
如我们看到GarageBand
控制iSEM的情形

00:51:25.419 --> 00:51:28.555
能使用的最好的API是
AUAudioUnit

00:51:29.590 --> 00:51:31.892
而且如果你想要
AUAudioUnit回放到

00:51:31.959 --> 00:51:35.863
AVAudioEngine
你可以使用AVAudioMIDIInstrument

00:51:39.032 --> 00:51:40.667
现在 有MIDI核心框架

00:51:40.734 --> 00:51:42.769
人们经常认为
该框架会做一些

00:51:43.036 --> 00:51:44.505
其它较高级别的任务

00:51:44.571 --> 00:51:48.475
但实际上 它是非常
底层的API

00:51:48.542 --> 00:51:50.744
基本上只是用于
与MIDI硬件通信

00:51:50.878 --> 00:51:53.747
比如 外部USB的
MIDI接口

00:51:54.181 --> 00:51:55.749
或者蓝牙MIDI键盘

00:51:56.283 --> 00:51:58.218
我们也提供MIDI网络驱动

00:51:59.019 --> 00:52:03.190
你可以使用它发送原始
MIDI消息 比如在iPad

00:52:03.257 --> 00:52:04.758
和MacBook之间发送

00:52:06.360 --> 00:52:09.029
你也可以使用核心
MIDI框架

00:52:09.096 --> 00:52:10.964
在流程之间实时发送MIDI

00:52:12.065 --> 00:52:15.769
这有时会涉及一个灰色地带

00:52:15.836 --> 00:52:19.039
人们会问：“好吧 我该使用
核心MIDI在我的

00:52:19.106 --> 00:52:23.110
排序器
以及正在收听MIDI和

00:52:23.177 --> 00:52:25.245
合成的应用之间通信吗？”

00:52:25.746 --> 00:52:29.082
我会说那可能不是
适合于这种情况的API

00:52:29.149 --> 00:52:31.318
如果你正在同时
使用MIDI和音频

00:52:31.618 --> 00:52:33.520
我会使用AUAudioUnit

00:52:33.887 --> 00:52:36.089
情况应该是
当你在两个应用中

00:52:36.156 --> 00:52:39.560
或者一个应用的两个实体中

00:52:39.626 --> 00:52:42.629
操作纯MIDI时——
或许其中一个是来自

00:52:42.696 --> 00:52:43.797
另一开发者的静态库

00:52:44.665 --> 00:52:48.702
在上述情况下 你可以
将核心MIDI用于流程间

00:52:48.802 --> 00:52:50.871
或实体间的实时MIDI

00:52:52.539 --> 00:52:56.510
这里就到了我们
音频API长篇介绍的尾声

00:52:57.277 --> 00:53:00.047
我们从应用程序开始
——在底端是

00:53:00.113 --> 00:53:03.584
CoreAudio框架
和驱动

00:53:04.418 --> 00:53:07.721
介绍了AVAudioEngine
如何用AVAudioSession

00:53:07.788 --> 00:53:11.358
在我们除了macOS之外的
所有平台上完成设置

00:53:11.992 --> 00:53:14.127
我们介绍了你可以怎样
使用AVAudioPlayer

00:53:14.194 --> 00:53:16.630
及AVAudioRecorder
从文件中

00:53:16.697 --> 00:53:18.098
进行简单的播放和录制操作

00:53:18.732 --> 00:53:21.735
或者如果你的文件
或网络流媒体涉及视频

00:53:21.802 --> 00:53:23.103
你可以使用AVPlayer

00:53:23.971 --> 00:53:27.074
AVAudioEngine是
构建复杂处理图表的

00:53:27.374 --> 00:53:30.210
优质高级别界面

00:53:30.444 --> 00:53:32.579
可以处理很多问题

00:53:32.646 --> 00:53:36.884
你通常无需使用
任何较低级别的API

00:53:37.251 --> 00:53:41.788
不过如果使用了 我们介绍了
AudioToolbox中的

00:53:42.256 --> 00:53:45.192
AUAudioUnit 它可以让你
直接与I/O循环

00:53:46.193 --> 00:53:50.964
与第三方或与你自己的乐器
效果和生成器通信

00:53:51.598 --> 00:53:54.401
最后 我们简要介绍了
核心MIDI框架

00:53:56.570 --> 00:53:58.639
我今天在此的介绍结束了

00:53:59.773 --> 00:54:02.009
你可以访问此链接
了解更多信息

00:54:02.676 --> 00:54:04.811
我们在此提供了
很多相关介绍

00:54:05.245 --> 00:54:06.113
非常感谢