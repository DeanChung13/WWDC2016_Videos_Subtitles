00:00:19.653 --> 00:00:22.055
神经网络和加速

00:00:23.624 --> 00:00:26.627
下午好 欢迎来到“加速”演讲

00:00:27.394 --> 00:00:29.363
我是Eric Bainville...

00:00:29.863 --> 00:00:32.698
我是核心OS
向量和数值团队的一员

00:00:34.735 --> 00:00:38.105
我们组提供对CPU性能优化的库

00:00:38.972 --> 00:00:42.409
优化性能的库通常意味着
我们要与底层的东西打交道

00:00:42.476 --> 00:00:46.380
能提供大计算量的函数
比如 求矩阵积

00:00:46.647 --> 00:00:48.482
傅立叶变换 之类的

00:00:49.516 --> 00:00:52.653
大多数这些函数被包括在
Accelerate框架里

00:00:52.819 --> 00:00:56.990
我们有 像vImage
一个用于图像处理的库

00:00:57.691 --> 00:00:59.893
它能被用于类型转换

00:00:59.960 --> 00:01:02.930
也能用于对图像的几何变换

00:01:04.298 --> 00:01:06.300
挨着vImage
你们会看到vDSP

00:01:06.366 --> 00:01:09.169
它主要被用于信号处理
像傅立叶变换

00:01:09.436 --> 00:01:11.605
和其它信号处理的用途

00:01:13.340 --> 00:01:18.979
然后 我们有BLAS
一个用于线性代数的库

00:01:19.179 --> 00:01:21.381
它已经很老了
它创建于70年代

00:01:21.648 --> 00:01:24.484
几年前
我们添加了SparseBLAS

00:01:24.551 --> 00:01:27.221
用于向量和矩阵的稀疏计算

00:01:27.521 --> 00:01:30.390
我们也在LinearAlgebra里
提供了LAPACK

00:01:30.457 --> 00:01:33.060
一个用于线性代数的高级库

00:01:34.127 --> 00:01:38.131
在Accelerate之外
我们还有一些库

00:01:38.465 --> 00:01:40.567
比如simd 它包含了一组标头

00:01:40.901 --> 00:01:45.305
能让你们对向量指令和类型
直接进行读写

00:01:45.372 --> 00:01:48.609
但它们不会操控CPU的向量单元

00:01:48.675 --> 00:01:53.280
它们介于中层和外层
不会改写汇编代码

00:01:54.248 --> 00:01:56.783
我们还在去年添加了
compression

00:01:56.850 --> 00:01:58.385
用于无损压缩

00:01:59.419 --> 00:02:03.557
对所支持的CPU
我们为所提供的技术进行了优化

00:02:03.690 --> 00:02:06.293
所以 当你们拿到新手机
我们为它的代码进行优化

00:02:06.860 --> 00:02:08.294
这样你们就不用为此担心了

00:02:08.996 --> 00:02:10.264
好 那今天...

00:02:11.198 --> 00:02:13.834
首先 我们来简单地回顾下
compression

00:02:15.302 --> 00:02:18.639
然后 我们将介绍两个
在Accelerate里新的库

00:02:19.039 --> 00:02:23.777
BNNS 它是一组用于神经网络
低级计算的函数

00:02:25.612 --> 00:02:27.214
还有Quadrature

00:02:27.381 --> 00:02:31.752
它是一个用于求
函数数值积分的小型的库

00:02:32.019 --> 00:02:34.154
之后 我的同事Steve会上台

00:02:34.221 --> 00:02:36.657
介绍simd的新添项

00:02:37.658 --> 00:02:39.359
好 首先 在我们开始之前

00:02:39.493 --> 00:02:42.262
让我向你们简单介绍下
Accelerate的使用

00:02:42.896 --> 00:02:45.599
基于你们对语言的选择

00:02:45.766 --> 00:02:50.003
你们要用import或
include导入函数的声明

00:02:50.537 --> 00:02:53.941
之后 你们要链接
Accelerate框架

00:02:54.074 --> 00:02:57.644
那从Xcode的你们的项目设置里
你们要浏览至

00:02:57.744 --> 00:03:02.049
target
然后点击build phases

00:03:02.816 --> 00:03:04.051
出现一个窗口

00:03:04.218 --> 00:03:06.753
点击Link Binary With Libraries

00:03:06.820 --> 00:03:07.821
打开它

00:03:08.655 --> 00:03:09.489
好的

00:03:09.756 --> 00:03:12.426
点开这里有个小加号的地方

00:03:13.427 --> 00:03:16.964
你们会看到一个
所有能被链接的库和框架的列表

00:03:17.030 --> 00:03:18.832
Accelerate在第一个

00:03:24.938 --> 00:03:27.441
好的

00:03:27.508 --> 00:03:30.444
那如果它不在第一个
在上面有个搜索栏

00:03:30.511 --> 00:03:32.779
若要找compression
输入compression

00:03:32.846 --> 00:03:34.114
我知道compression
一定会在里面

00:03:34.481 --> 00:03:36.683
好的 现你们就在使用
Accelerate了

00:03:36.750 --> 00:03:38.886
好

00:03:39.052 --> 00:03:40.220
那compression...

00:03:40.287 --> 00:03:43.090
记得当去年Sebastian

00:03:43.156 --> 00:03:46.493
在平台详情咨文介绍LZFSE时

00:03:46.560 --> 00:03:48.562
我们都不知道他们是谁

00:03:48.729 --> 00:03:53.400
但今天我们要宣布对LZFSE开源

00:03:53.867 --> 00:03:55.669
你们可以在GitHub上找到它

00:03:55.769 --> 00:03:58.305
我们以BSD许可的形式发布它

00:03:59.940 --> 00:04:03.277
让我提一下 你们会想用它的理由

00:04:03.710 --> 00:04:06.947
这些是平台比较
在LZFSE

00:04:07.014 --> 00:04:09.616
和zlib之间 使用相同的选项

00:04:10.284 --> 00:04:14.621
我们的编码速度要快1.4倍
解码速度要快2.6倍

00:04:16.023 --> 00:04:17.891
好的
这就是我们的compression

00:04:18.257 --> 00:04:19.793
现在让我们来看下BNNS

00:04:20.194 --> 00:04:22.262
“基础神经网络子程序”

00:04:22.829 --> 00:04:24.598
这个名字看起来很像BLAS

00:04:24.665 --> 00:04:26.900
BLAS是指“基础线性代数子程序”

00:04:27.100 --> 00:04:29.903
如我之前所提
它起源于70年代

00:04:30.671 --> 00:04:35.943
BNNS提供了一组低级计算例程

00:04:36.109 --> 00:04:38.912
我稍后细说

00:04:40.581 --> 00:04:42.082
我们只做低级计算

00:04:42.149 --> 00:04:44.718
像求矩阵积 但针对于神经网络

00:04:45.986 --> 00:04:48.822
在我细讲它的作用

00:04:49.022 --> 00:04:50.257
和相关的API之前

00:04:50.324 --> 00:04:54.728
让我们来回顾下神经网络

00:04:55.395 --> 00:04:57.598
假设我们有这样一个网络

00:04:57.965 --> 00:05:00.701
我们训练了它去识别动物

00:05:00.767 --> 00:05:02.536
那作为输入 你们有一个图像

00:05:02.603 --> 00:05:04.571
然后 你们有这个橘色的大框

00:05:04.805 --> 00:05:08.709
在橘色的框里
这个红色的框代表了权值

00:05:09.142 --> 00:05:11.545
这些是这个网络的参数

00:05:11.612 --> 00:05:14.448
作为输出 我们有四个值

00:05:14.615 --> 00:05:17.017
这些是相应的概率
对于是一只猫 一只狗

00:05:17.084 --> 00:05:18.685
一只长颈鹿或一条蛇

00:05:19.386 --> 00:05:21.255
好的　那首先你们要训练它

00:05:21.321 --> 00:05:22.823
假设你们有个猫的图像

00:05:23.657 --> 00:05:27.761
你们通过网络处理这猫的图像
并得到一个答案

00:05:28.428 --> 00:05:30.764
这是最高的概率
它说是只狗

00:05:31.465 --> 00:05:33.467
呵呵 这就是你们需要训练它的原因

00:05:33.800 --> 00:05:37.004
事实上是只猫 那你们要做的是

00:05:37.471 --> 00:05:39.473
反向传播正确答案

00:05:39.540 --> 00:05:41.842
如果我稍许改动下权值 会怎么样

00:05:42.543 --> 00:05:47.314
那现在这个网络会稍偏向
猫的方向

00:05:47.781 --> 00:05:53.587
你们要使用大量的图像
做这个成千上万次

00:05:53.820 --> 00:05:55.122
在某一刻

00:05:56.023 --> 00:05:59.159
你们会有一个训练好的网络
能正确回答

00:05:59.226 --> 00:06:00.961
每一个请求

00:06:01.028 --> 00:06:03.463
如果是只长颈鹿

00:06:05.032 --> 00:06:07.334
它会说是只长颈鹿
因为你们正确地训练了它

00:06:08.735 --> 00:06:10.938
好的　这就是神经网络所能做的

00:06:11.004 --> 00:06:13.574
注意训练和推测的区别

00:06:13.640 --> 00:06:15.843
在推测时 我们不改变权值

00:06:16.076 --> 00:06:18.312
那一般来说 假设你们有这样一个应用

00:06:18.912 --> 00:06:21.748
你们要在线下做这些训练

00:06:21.949 --> 00:06:23.817
当你们创建应用时
做你们的训练

00:06:23.884 --> 00:06:26.253
那当你们改动应用时
你们要改动权值

00:06:26.320 --> 00:06:28.222
和网络拓扑

00:06:28.322 --> 00:06:31.592
最后能让它在设备上进行推测

00:06:32.526 --> 00:06:35.495
好的
那在这个橘色的框里有些什么？

00:06:35.562 --> 00:06:36.797
让我给你们个例子

00:06:36.864 --> 00:06:39.600
若你们去了“Metal的新特性
第二部分”演讲

00:06:39.933 --> 00:06:42.936
一个昨天的讲座
你们已经见过了个更大型的例子

00:06:43.270 --> 00:06:45.572
一个场景识别网络

00:06:45.672 --> 00:06:48.008
和一个对笑脸识别网络的展示

00:06:48.108 --> 00:06:51.011
这都是些进阶的网络
它们有成百上千的层面

00:06:51.178 --> 00:06:54.281
这个是五年前最前沿的技术

00:06:54.348 --> 00:06:58.986
它描述了一个百数位识别网络

00:06:59.620 --> 00:07:01.288
那作为输入
你们有个小型的图像

00:07:01.455 --> 00:07:04.758
一个对手写的捕捉

00:07:05.225 --> 00:07:07.127
然后它被递入各个层面

00:07:07.461 --> 00:07:09.763
这里你们有个5x5的卷积

00:07:10.063 --> 00:07:12.566
输出会是一个含五个图像的堆栈

00:07:13.367 --> 00:07:16.703
这个输出是五个有着不同权值的卷积

00:07:17.104 --> 00:07:19.239
然后 你们添加另一个层面

00:07:19.773 --> 00:07:23.710
你们对这五个图像应用更多的卷积

00:07:23.777 --> 00:07:25.779
你们会得到一个更大的堆栈

00:07:26.146 --> 00:07:29.149
包含五十个5x5像素的图像

00:07:29.349 --> 00:07:33.854
那这样 你们从图像空间

00:07:33.921 --> 00:07:37.090
一层层地来到了特征空间

00:07:37.758 --> 00:07:41.028
这些小型图像的内容变得
越来越抽象

00:07:41.094 --> 00:07:43.096
最后就只有特征

00:07:43.197 --> 00:07:45.399
那会告诉你们那是个零或那是个一

00:07:45.465 --> 00:07:47.100
这是你们想要的输出

00:07:47.501 --> 00:07:48.335
好的

00:07:48.735 --> 00:07:51.104
那通过使用少量的层面

00:07:51.238 --> 00:07:54.174
你们可以达到目的
并且效果还不错

00:07:54.641 --> 00:07:59.079
那在这些卷积之后
我们把这些5x5x50的值

00:07:59.880 --> 00:08:01.949
作为一个大型的向量

00:08:02.449 --> 00:08:05.085
对其应用一个全面连接层面

00:08:05.152 --> 00:08:07.054
其实就是求个大型的矩阵积

00:08:07.120 --> 00:08:11.658
它会将所有值混合
然后输出一组100个值

00:08:12.392 --> 00:08:15.362
在这个模型里 被称为隐藏层面

00:08:16.396 --> 00:08:21.635
之后你们需要最后一步
使这100个值

00:08:21.935 --> 00:08:24.771
混合在一起
然后产生10个你们你们想要的输出

00:08:24.905 --> 00:08:27.040
这里 你们在计算未来空间

00:08:27.474 --> 00:08:31.211
这里的每个数值对应着
成为一个具体数字的概率

00:08:31.945 --> 00:08:32.779
好的

00:08:32.846 --> 00:08:34.581
这就是这个网络的结构

00:08:34.648 --> 00:08:38.452
如你们所见
我们有两个不同类别的层面

00:08:38.519 --> 00:08:40.153
这正是我们在BNNS所实现的

00:08:40.220 --> 00:08:42.623
我们提供对这些层面的计算部分

00:08:44.258 --> 00:08:47.227
好　在我们开始讨论计算

00:08:47.294 --> 00:08:49.396
和相关API之前
让我向你们展示些数字

00:08:49.463 --> 00:08:52.533
这里我们将用Caffe作对比

00:08:52.933 --> 00:08:56.770
它是一个知名的
神经网络计算程序包

00:08:57.337 --> 00:08:59.473
这是Caffe有关卷积的部分

00:08:59.573 --> 00:09:02.042
我们有14个不同卷积的大小

00:09:02.509 --> 00:09:03.810
在这里 你们可以看下

00:09:04.545 --> 00:09:08.649
这是Caffe的处理时间...

00:09:09.616 --> 00:09:11.652
这是速度
所以值越高越好

00:09:11.718 --> 00:09:13.720
通过Caffe处理这些卷积

00:09:13.987 --> 00:09:15.923
这是你们用BNNS所得的结果

00:09:16.790 --> 00:09:18.892
从平均来看 BNNS要快2.1倍

00:09:18.959 --> 00:09:21.028
如果你们有更大的卷积

00:09:21.094 --> 00:09:23.397
你们可以几乎达到快4倍的速度

00:09:25.365 --> 00:09:27.968
好的　这就是所有的数字

00:09:28.035 --> 00:09:31.038
现在让我来介绍下BNNS的构架

00:09:32.039 --> 00:09:34.074
它是一个低级计算函数的集合

00:09:34.141 --> 00:09:37.010
与BLAS十分相似
这也是我们将其取名为BNNS的原因

00:09:37.678 --> 00:09:41.048
它并不知道
什么是神经网络

00:09:41.248 --> 00:09:43.650
这意味着
那是你们要知道的事

00:09:43.784 --> 00:09:46.954
它只提供计算的部分

00:09:48.689 --> 00:09:51.058
并且它只执行推测

00:09:51.792 --> 00:09:52.793
事实上

00:09:52.860 --> 00:09:55.629
我觉得 在设备上运行训练不合理

00:09:55.696 --> 00:09:56.730
成本太高

00:09:56.797 --> 00:09:59.333
你们会要有数以万计的图像和计算

00:09:59.600 --> 00:10:00.701
这不会合适

00:10:00.968 --> 00:10:04.104
那一般来说 推测会在线下完成
如我所述

00:10:04.404 --> 00:10:07.774
你们会在应用上执行推测

00:10:08.041 --> 00:10:10.143
我们提供三个不同类别的层面

00:10:10.377 --> 00:10:12.212
卷积层 池化层

00:10:12.279 --> 00:10:14.081
和全面连接层

00:10:14.348 --> 00:10:15.549
为什么？ 因为...

00:10:16.116 --> 00:10:20.554
实际上 在现代的网络
你们会花费百分之七十五的时间

00:10:20.621 --> 00:10:22.022
于计算卷积

00:10:22.389 --> 00:10:24.625
接下来是池化层

00:10:24.691 --> 00:10:26.627
使用约百分之十五

00:10:27.094 --> 00:10:29.496
全面连接层也会花费许多时间

00:10:29.563 --> 00:10:32.733
但你们通常在网络的末端看见它

00:10:33.233 --> 00:10:35.435
像在例子里见到的 只有两个

00:10:35.802 --> 00:10:37.838
在末端的全面连接层

00:10:38.205 --> 00:10:40.140
但这还是要花费许多时间

00:10:40.741 --> 00:10:44.278
好的　现在我们了解了构架

00:10:44.344 --> 00:10:47.281
我将细讲这三个不同类别的层面

00:10:47.447 --> 00:10:51.585
和我们计算些什么
还有如何通过API来创建它们

00:10:52.252 --> 00:10:54.488
让我们从卷积层开始

00:10:55.322 --> 00:10:56.523
这是一个卷积

00:10:56.590 --> 00:10:58.158
它使用一个输入图像

00:10:58.692 --> 00:11:01.662
一组权值 中间橘色的矩阵

00:11:01.728 --> 00:11:03.797
然后输出图像里的每一个像素

00:11:04.531 --> 00:11:08.335
是通过计算对每一组输入像素

00:11:08.502 --> 00:11:10.470
与权值的的积

00:11:10.604 --> 00:11:13.373
之后将结果相加
得到你们上方的像素

00:11:13.774 --> 00:11:16.510
你们要对每一个输出像素
执行上述步骤

00:11:16.877 --> 00:11:19.179
那如果你数下
这是个四维的循环

00:11:19.246 --> 00:11:21.181
因为你们要循环x和y

00:11:21.415 --> 00:11:23.250
还有内核的维数

00:11:24.084 --> 00:11:26.520
现实里 要比上述更复杂些

00:11:26.587 --> 00:11:29.323
因为我们的输入不仅是一个图像

00:11:29.389 --> 00:11:30.858
我们有一堆图像

00:11:31.191 --> 00:11:33.227
那我们要复制权值

00:11:33.927 --> 00:11:37.998
并知道在每一层
我们在计算此卷积

00:11:38.298 --> 00:11:40.133
然后再将它们相加

00:11:40.200 --> 00:11:42.336
获取我们的输出像素

00:11:42.836 --> 00:11:45.239
那现在循环就是五维的了

00:11:45.706 --> 00:11:48.275
我在公式里添加了IC参数

00:11:48.909 --> 00:11:51.044
这其实不是我们要计算的

00:11:51.278 --> 00:11:53.380
因为我们还要有个输出堆栈

00:11:53.780 --> 00:11:56.550
那实际上 我们在卷积里是在
做这样的计算

00:11:56.750 --> 00:12:00.721
我们重复这个多次
每一次为一个输出层

00:12:01.288 --> 00:12:03.557
那现在我们有个六维的循环

00:12:04.024 --> 00:12:06.827
这意味着 即使每个维度都很小

00:12:06.894 --> 00:12:10.731
像在这个例子里
我们没有大于264的

00:12:11.098 --> 00:12:13.800
这的确很小 但你们将它们相乘

00:12:13.867 --> 00:12:15.969
你们会有几十亿的操作

00:12:16.036 --> 00:12:18.672
这相当于几十毫秒的计算量

00:12:19.373 --> 00:12:21.975
那对大很多的整个网络来讲

00:12:22.543 --> 00:12:25.245
你们会有数以兆计的浮点运算操作

00:12:25.312 --> 00:12:27.814
这相当于几秒的CPU时间

00:12:28.682 --> 00:12:30.851
好的　一个在卷积层的计算

00:12:30.918 --> 00:12:33.120
怎样通过BNNS来实现？

00:12:33.320 --> 00:12:36.723
那首先 你们要描述你们的输入堆栈

00:12:37.591 --> 00:12:41.094
你们要指定图像的尺寸

00:12:41.361 --> 00:12:42.863
通道数

00:12:43.096 --> 00:12:46.200
还有在内存里的分层

00:12:46.300 --> 00:12:51.104
包括两行之间的增量和
两层面间的增量

00:12:51.305 --> 00:12:53.273
还有很重要的是

00:12:53.440 --> 00:12:55.976
他们的储存类型

00:12:57.444 --> 00:13:01.915
举例 我们使用32位浮点数
或甚至64位浮点数

00:13:02.482 --> 00:13:04.885
在神经网络里
我们无需这样的精确度

00:13:04.952 --> 00:13:07.554
一般人们会用16位浮点数

00:13:08.188 --> 00:13:10.390
那很好 因为这会削减一半的储存空间

00:13:11.024 --> 00:13:13.493
那本来20兆字节 我们只需10

00:13:13.660 --> 00:13:16.129
如果你们能用整数
8位的整数

00:13:16.196 --> 00:13:17.998
那你们只需5兆字节

00:13:18.298 --> 00:13:21.502
同样 一般你们的输出也无需
任何精确度

00:13:22.836 --> 00:13:26.006
所以 你们可以使用
与输入相同的类型

00:13:26.673 --> 00:13:28.675
你们需要对输出堆栈作相同的设定

00:13:29.076 --> 00:13:31.512
然后 你们要描述卷积自身

00:13:31.712 --> 00:13:33.313
这包括内核的尺寸

00:13:33.747 --> 00:13:37.417
对输入的0填充

00:13:38.185 --> 00:13:41.421
x和y在循环里的增幅

00:13:42.122 --> 00:13:44.157
还有 你们要重复

00:13:44.224 --> 00:13:47.794
输入和输出的通道数
还有权值

00:13:47.995 --> 00:13:50.731
那是之前中间橘色的部分

00:13:51.131 --> 00:13:53.667
列出权值 同样
你们可以设置不同的

00:13:53.734 --> 00:13:55.602
储存类型给权值

00:13:55.869 --> 00:14:00.274
一般你们将其设定为16位或8位

00:14:00.741 --> 00:14:06.513
因为那可以降低内存使用和
储存空间

00:14:08.348 --> 00:14:09.650
当你们完成了这些

00:14:09.716 --> 00:14:12.653
你们能用这个函数来创建
卷积筛选器

00:14:13.220 --> 00:14:14.988
你们告诉它 这是我的输入堆栈

00:14:15.055 --> 00:14:17.991
那是我的输出堆栈
那是我的卷积 创建一个筛选器

00:14:18.458 --> 00:14:20.894
你会获取一个筛选器对象
然后用它

00:14:20.994 --> 00:14:23.263
对你们的数据应用卷积

00:14:23.864 --> 00:14:25.165
在你们使用完它之后

00:14:25.232 --> 00:14:26.834
你们调用销毁筛选器

00:14:27.201 --> 00:14:29.937
来移除它并释放资源

00:14:30.804 --> 00:14:32.372
以上就是关于卷积层的内容

00:14:32.439 --> 00:14:35.075
现在 让我们来看下池化层

00:14:35.342 --> 00:14:37.544
池化要比卷积简单些

00:14:38.011 --> 00:14:39.646
要计算一个输出像素

00:14:39.713 --> 00:14:42.783
你们要使用一组输入像素

00:14:42.983 --> 00:14:45.152
然后取最大的平均值

00:14:45.385 --> 00:14:46.553
这就是你们的结果

00:14:46.620 --> 00:14:49.690
你们要对所有通道的所有像素
重复这样的计算

00:14:50.724 --> 00:14:52.226
这就是这公式所形容的

00:14:52.893 --> 00:14:55.929
同样 为池化层创建一个筛选器

00:14:56.029 --> 00:14:58.932
你们要描述输入和输出堆栈

00:14:59.600 --> 00:15:02.669
与之前一样
你们也要描述

00:15:03.103 --> 00:15:04.638
池化层自身

00:15:04.705 --> 00:15:07.508
同样 包括
内核尺寸 填充 增幅

00:15:07.574 --> 00:15:09.176
这里没有权值

00:15:09.243 --> 00:15:12.145
那要使用哪个函数来计算输出

00:15:12.212 --> 00:15:14.014
使用最大平均

00:15:15.549 --> 00:15:18.185
在你们完成这些后
你们就可以创建筛选器

00:15:18.252 --> 00:15:21.121
获得一个和之前相似的
筛选器对象

00:15:21.722 --> 00:15:25.058
最后我们支持的层面是
全面连接层

00:15:26.426 --> 00:15:29.997
它尽管被称为全面连接层
这里有个隐藏的矩阵积

00:15:30.063 --> 00:15:35.169
作为输入你们有一个向量
然后你们要将它与一个矩阵相乘

00:15:35.235 --> 00:15:38.372
加入向量偏量
然后获取你们的输出

00:15:39.173 --> 00:15:40.908
就是求个矩阵的积

00:15:41.842 --> 00:15:44.244
这里 你们的向量里没有图像

00:15:44.311 --> 00:15:47.381
所以 你们要描述向量 它的大小

00:15:47.848 --> 00:15:50.083
与数据对应并且
你们要指定使用的类型

00:15:50.150 --> 00:15:56.390
用于储存这些值 你们可以使用
32或16位浮点数或整数

00:15:59.593 --> 00:16:04.498
然后你们要通过矩阵的尺寸
来描述这个层面自身

00:16:04.798 --> 00:16:06.500
和矩阵的系数

00:16:07.768 --> 00:16:10.771
偏量不在演示稿里
但你们有偏量

00:16:11.505 --> 00:16:13.874
之后 你们可以创建一个卷积筛选器

00:16:15.676 --> 00:16:17.945
同样与之前的筛选器相似

00:16:18.011 --> 00:16:20.848
接下来是怎样应用筛选器

00:16:21.281 --> 00:16:23.750
你们将输入数据当作输出数据

00:16:24.151 --> 00:16:27.788
和你们的筛选器
你们有两个应用它们的函数

00:16:29.556 --> 00:16:33.327
叫作筛选器应用
如果你们只有一对输入和输出

00:16:33.393 --> 00:16:35.229
如果你们有很多对

00:16:35.295 --> 00:16:37.431
你们要调用
筛选器批量应用

00:16:38.532 --> 00:16:41.568
你们告诉它对数

00:16:41.635 --> 00:16:43.737
并且怎样从一对到另一对

00:16:43.804 --> 00:16:45.339
就是怎样在内存里迈进

00:16:47.107 --> 00:16:50.177
好的 这些就是关于BNNS的内容
让我们总结下

00:16:50.677 --> 00:16:55.415
BNNS是一组针对神经网络计算的
低级函数

00:16:56.683 --> 00:16:59.219
很低　我们着重于计算
我们完善它

00:16:59.286 --> 00:17:00.254
我们提高它的处理速度

00:17:00.988 --> 00:17:03.624
但它不知道什么是神经网络

00:17:03.824 --> 00:17:05.592
它只针对于计算

00:17:07.661 --> 00:17:10.364
我们优化它
让它变得更快 更省能源

00:17:11.898 --> 00:17:15.636
最主要的是
他支持各种数据类型

00:17:18.405 --> 00:17:19.839
以上就是BNNS的内容

00:17:19.940 --> 00:17:21.308
接下来 Quadrature

00:17:21.441 --> 00:17:23.109
我们收到请求...

00:17:23.810 --> 00:17:29.183
许多人要我们开发一个
用于求数值积分的库

00:17:29.316 --> 00:17:30.417
那 这就是

00:17:30.817 --> 00:17:33.887
好 那还记得你们在学校里学的

00:17:34.154 --> 00:17:37.491
它能计算一个函数在区间a b
上的积分

00:17:37.858 --> 00:17:40.694
也就是在曲线和轴之间绿色的部分

00:17:42.496 --> 00:17:45.499
那要使用这个
你们首先要描述函数

00:17:45.933 --> 00:17:47.434
你们要提供一个回调

00:17:47.501 --> 00:17:50.237
我们做的改动之一
与之前的

00:17:50.404 --> 00:17:52.139
旧的库里不一样的是

00:17:52.406 --> 00:17:56.210
回调接收一组点并求值

00:17:56.910 --> 00:17:58.846
通常当你们计算积分

00:17:58.912 --> 00:18:01.281
你们要在许多点上计算函数值

00:18:01.348 --> 00:18:05.452
如果你们有一个向量化的回调
能提高速度 那很好

00:18:05.519 --> 00:18:10.257
你们可以使其更快
通过使用这个多x的回调

00:18:10.324 --> 00:18:13.694
它会通过x递给你们多个值

00:18:13.760 --> 00:18:18.131
你们填入每一个对应的y的值
通过计算f(xi)

00:18:19.399 --> 00:18:22.803
这就是你们的函数
然后要告诉它如何计算积分

00:18:22.870 --> 00:18:25.639
那我们提供了三个
计算积分的方法

00:18:26.173 --> 00:18:28.375
它们有不同的的复杂度和运行时间

00:18:29.076 --> 00:18:32.045
有些还可以积分至无限

00:18:32.179 --> 00:18:35.249
你们可以在Quadrature标头
找到更多的细节

00:18:36.450 --> 00:18:40.254
你们也要指定输出的误差

00:18:40.954 --> 00:18:43.223
和细分区间的最大数量

00:18:43.290 --> 00:18:45.259
用于计算结果

00:18:45.459 --> 00:18:47.895
然后你们将它递入
integrate函数

00:18:49.363 --> 00:18:51.465
你们还要告诉函数 a和b

00:18:51.532 --> 00:18:54.868
你们也要递入一个点
用于接收误差

00:18:55.135 --> 00:18:59.239
它被称为估计误差

00:18:59.706 --> 00:19:01.942
它会在结果里返回估计误差

00:19:02.009 --> 00:19:04.745
和状态
我们接受计算的状态

00:19:04.811 --> 00:19:07.147
因为如果你要求一个很低的误差

00:19:07.214 --> 00:19:09.116
有时无法被转换

00:19:09.183 --> 00:19:11.418
那我们可以在状态里看到

00:19:11.718 --> 00:19:13.387
这就是Quadrature所有内容

00:19:14.555 --> 00:19:16.456
现在让我请Steve上台

00:19:16.557 --> 00:19:18.992
他会来讲下关于simd的新添项

00:19:19.860 --> 00:19:20.928
十分感谢 Eric

00:19:21.228 --> 00:19:22.196
我是Steve Canon

00:19:22.262 --> 00:19:24.431
我与Eric一起在
向量与数值团队工作

00:19:24.598 --> 00:19:27.734
Eric刚才将你们带回了
学微积分的日子里

00:19:27.801 --> 00:19:29.770
我现在将带你们前进些

00:19:29.837 --> 00:19:31.505
来到线性代数

00:19:33.674 --> 00:19:35.309
我们有这样一个很有用的模块
叫simd

00:19:35.609 --> 00:19:39.513
它能提供几何操作和向量操作

00:19:39.980 --> 00:19:43.517
针对C、Objective-C、
C++和Swift

00:19:44.518 --> 00:19:47.654
它很好地对应了Metal着色语言

00:19:48.488 --> 00:19:51.892
它能与SceneKit和
Model I/O紧密结合

00:19:51.959 --> 00:19:53.660
还有各种图形的库

00:19:53.794 --> 00:19:57.130
如果你们在写向量相关的代码来执行

00:19:57.197 --> 00:20:01.535
小型的3x3、4x4之类的
线性代数的操作

00:20:01.802 --> 00:20:04.538
这个库就是你们想要的
你们就不用去自己写了

00:20:04.605 --> 00:20:06.607
我们有大部分你们想要的

00:20:06.673 --> 00:20:08.742
如果没有 可以请求我们添加它

00:20:08.809 --> 00:20:10.644
它十分的快 让我们来细看

00:20:10.777 --> 00:20:11.945
那有些什么？

00:20:13.080 --> 00:20:14.348
我们有一大堆类型

00:20:14.515 --> 00:20:17.684
有浮点数的向量和双精确度的向量

00:20:18.018 --> 00:20:21.054
有带符号和不带符号的整数
像2、3和4

00:20:22.222 --> 00:20:25.425
我们还有相同尺寸的
浮点数和双精确度的矩阵

00:20:26.560 --> 00:20:29.396
这些只是在所有语言里都有的

00:20:30.163 --> 00:20:31.899
在C、C++
和Objective-C里

00:20:31.965 --> 00:20:33.233
还有其它许多类型

00:20:33.300 --> 00:20:36.236
那些会对你们写自己泛型的
向量代码很有用

00:20:36.303 --> 00:20:39.306
但我将着重于共有的子集

00:20:39.373 --> 00:20:42.242
在所有的语言里和平台上
在今天的讲座里

00:20:43.143 --> 00:20:45.112
显然 我们还有类型相关的操作

00:20:45.179 --> 00:20:48.815
有一般的算术操作

00:20:48.882 --> 00:20:50.717
用于向量和矩阵

00:20:51.585 --> 00:20:54.121
还有我们所熟悉的
几何和着色函数

00:20:54.188 --> 00:20:55.756
若你们有过任何着色编程的经验

00:20:55.822 --> 00:20:58.659
大多数你们想用的 这里都有

00:20:58.892 --> 00:21:00.861
我现在来展示个小型的例子

00:21:01.762 --> 00:21:05.732
这是一个相同的函数
被用三种语言编写

00:21:06.300 --> 00:21:09.837
有Objective-C在最上面
有C++在中间

00:21:09.903 --> 00:21:11.672
Swift在底部

00:21:12.072 --> 00:21:13.674
你们可以看到模版

00:21:13.740 --> 00:21:15.409
在各个语言之间有些不同

00:21:15.475 --> 00:21:18.345
只是因为函数声明在
这些语言之间有所不同

00:21:18.512 --> 00:21:21.448
但如果我们注意
实际计算的部分

00:21:21.748 --> 00:21:23.851
在各语言里 基本上都一样

00:21:23.917 --> 00:21:26.386
同时 它也很对应

00:21:26.587 --> 00:21:29.122
你们在数学里表达的方式

00:21:29.456 --> 00:21:30.991
不会有许多奇怪的函数调用

00:21:31.058 --> 00:21:33.427
你们也不用写for循环之类的

00:21:33.527 --> 00:21:35.963
你们能自然流畅地写
你们的代码

00:21:36.230 --> 00:21:38.732
我们替你们翻译

00:21:38.999 --> 00:21:40.467
编写变得友好和简单

00:21:40.534 --> 00:21:43.770
这用Metal代码写
看起来也一样

00:21:43.837 --> 00:21:46.573
那这里凑巧已经有了
reflect函数

00:21:46.640 --> 00:21:47.875
在库里面

00:21:47.941 --> 00:21:49.743
那你们就不用自己编写了

00:21:50.811 --> 00:21:54.615
在各种语言之间调用函数
像很多在model I/O里的

00:21:54.681 --> 00:21:57.584
能通过使用接受这些类型的
Objective-C API

00:21:58.018 --> 00:21:59.553
很不错

00:21:59.620 --> 00:22:01.788
向量类型是编译器的扩展

00:22:01.855 --> 00:22:04.291
在C、Objective-C
和C++里

00:22:05.125 --> 00:22:07.561
在Swift里
它们被定义为structs

00:22:07.628 --> 00:22:10.898
但编译器知道如何为你们
映射它们

00:22:11.598 --> 00:22:13.367
所以 你们根本不用做任何事

00:22:13.834 --> 00:22:15.202
这里有个简单的例子

00:22:15.302 --> 00:22:16.904
若我有个Objective-C的函数

00:22:16.970 --> 00:22:19.606
我在这里调用某个对向量类型
执行操作的函数

00:22:20.307 --> 00:22:21.808
并且我想调用那个函数

00:22:21.942 --> 00:22:23.944
通过Swift
使用Swift向量类型

00:22:24.011 --> 00:22:25.746
我可以成功的这么做

00:22:25.812 --> 00:22:27.414
我无需做任何进阶的事

00:22:27.548 --> 00:22:28.782
这些类型都有相同的布局

00:22:28.849 --> 00:22:31.418
所以 没有转换开销之类的

00:22:32.252 --> 00:22:33.987
相似的 对于矩阵

00:22:34.188 --> 00:22:36.823
Swift的矩阵类型布局和

00:22:36.890 --> 00:22:39.126
C、Objective-C
和C++类型相匹配

00:22:39.660 --> 00:22:42.529
那如果我要使用它们
这里我有Swift

00:22:42.796 --> 00:22:45.666
我来创建一个Swift的类型
通过C的类型

00:22:46.300 --> 00:22:48.168
我所要做的就是使用init函数

00:22:48.235 --> 00:22:49.069
很好用

00:22:49.136 --> 00:22:50.637
没有任何的计算开销

00:22:50.704 --> 00:22:53.106
就好像 不知不觉地改变了类型

00:22:53.173 --> 00:22:55.742
相似的 我可以使用C的
矩阵属性

00:22:56.109 --> 00:23:00.848
如果我要通过C的类型调用C或
Objective-C或C++的函数

00:23:01.415 --> 00:23:04.318
我们今年有些新的东西
我想向你们展示

00:23:05.619 --> 00:23:07.020
我们有三个新的函数

00:23:07.087 --> 00:23:09.656
simd orient和simd incircle
还有simd insphere

00:23:09.723 --> 00:23:12.693
它们已被重载
为支持许多不一样的类型

00:23:12.759 --> 00:23:14.628
和不同的长度 之类的

00:23:14.695 --> 00:23:16.797
基本上所有在simd库里的都这样

00:23:16.864 --> 00:23:18.565
所以 仅管我们只有三个新函数

00:23:18.632 --> 00:23:20.567
实际上 有许多新东西

00:23:21.768 --> 00:23:23.103
我会从orient开始讲

00:23:23.637 --> 00:23:25.672
orient让我们回答这样的问题：

00:23:25.739 --> 00:23:27.641
一组向量是否都朝向正面？

00:23:28.108 --> 00:23:31.044
如果你们不记得线性代数
意思是

00:23:31.445 --> 00:23:33.046
它们是否遵循右手螺旋法则？

00:23:33.313 --> 00:23:35.015
你们可能记得在物理里见过它

00:23:35.082 --> 00:23:37.384
或 相等同的
是否有正值的行列式？

00:23:38.018 --> 00:23:40.621
如果在座的有数学专业的
你们现在会抗议

00:23:40.687 --> 00:23:43.657
一组向量是没有行列式的

00:23:43.757 --> 00:23:45.726
我的意思是你们把它们

00:23:45.792 --> 00:23:47.794
放到一个矩阵里

00:23:48.095 --> 00:23:49.730
计算矩阵的行列式

00:23:49.796 --> 00:23:51.098
是不是正的？

00:23:51.798 --> 00:23:53.567
那我们为什么关心这个？

00:23:53.667 --> 00:23:55.502
这很明显

00:23:56.103 --> 00:24:00.240
你们能用这回答许多
计算几何的问题

00:24:00.307 --> 00:24:01.308
会很有用

00:24:01.542 --> 00:24:04.211
比如 这个三角形是
面朝我还是背朝我？

00:24:04.278 --> 00:24:06.079
如果你们想象个四面体

00:24:06.146 --> 00:24:08.515
有两个面朝着你们

00:24:08.582 --> 00:24:11.251
也有两个面背着你们

00:24:11.318 --> 00:24:13.020
如果你们在进行图形操作

00:24:13.086 --> 00:24:15.756
知道面朝你们的面
会是很有用的

00:24:15.822 --> 00:24:17.791
因为那些是你们要处理的面

00:24:18.192 --> 00:24:21.628
相似的 如果我有一个点和一条线
我想回答这样个问题

00:24:21.695 --> 00:24:24.965
点在不在线上
或 如果不在 那它在线的哪侧？

00:24:25.632 --> 00:24:28.101
我能用orient判断
去回答那个问题

00:24:28.335 --> 00:24:31.038
那 这看起来很简单的样子
的确很简单

00:24:31.104 --> 00:24:33.941
除了实际回答这个问题
可能会很难

00:24:34.007 --> 00:24:37.110
当点离线很近时
我们会在下面细说

00:24:38.045 --> 00:24:39.913
这里有个这样的例子

00:24:40.447 --> 00:24:44.051
在显示的右侧 我有个平面

00:24:44.117 --> 00:24:46.320
我会在平面上加些点

00:24:47.020 --> 00:24:50.190
我有三个点
a和b还有c

00:24:50.257 --> 00:24:53.861
我将使用的simd orient
查询它们的朝向

00:24:54.194 --> 00:24:56.396
由于我们是通过
逆时针的方向

00:24:56.663 --> 00:24:59.233
从a到b到c

00:24:59.766 --> 00:25:01.768
我们说它们是
正朝向

00:25:01.835 --> 00:25:04.505
这是在平面里对
正朝向的定义

00:25:04.571 --> 00:25:09.142
如果我们移动其中一点
变成顺时针方向

00:25:09.343 --> 00:25:11.144
现在就是负朝向了

00:25:12.412 --> 00:25:16.550
那如果我移动点c
让它正好在a和b之间的线上

00:25:16.817 --> 00:25:19.653
那它们共线 朝向是0

00:25:19.720 --> 00:25:21.355
或许 你们会说它是虚的

00:25:21.555 --> 00:25:25.492
判定点是否正好在线上
一般是件很难的事

00:25:25.559 --> 00:25:27.594
特别是利用浮点数的坐标

00:25:27.661 --> 00:25:30.931
因为朝向数值的不稳定性

00:25:31.532 --> 00:25:33.567
由于浮点数的取舍

00:25:33.634 --> 00:25:36.203
如果行列式的结果接近0

00:25:36.336 --> 00:25:38.138
你们很有可能得到一个错误的符号

00:25:38.205 --> 00:25:40.574
对于一些算法来说
这无关紧要

00:25:40.641 --> 00:25:43.143
但对于其它算法
你们可能会遇到无法收敛的情况

00:25:43.210 --> 00:25:45.779
或 当使用它时
你们也许会获得错误的的结果

00:25:45.846 --> 00:25:47.381
像在碰撞检测之类的情况里

00:25:47.447 --> 00:25:50.017
能回答这个问题变得很重要

00:25:50.083 --> 00:25:53.420
还有像使用三角网格建立模型
之类的

00:25:53.487 --> 00:25:56.123
这会是个重要的问题
要求有准确的答案

00:25:57.691 --> 00:26:01.028
让我们来看个难回答的例子

00:26:02.563 --> 00:26:04.865
我在平面里建立两个向量
u和v

00:26:04.932 --> 00:26:07.501
它们几乎相同

00:26:07.568 --> 00:26:10.771
它们只有一点点的不同

00:26:11.705 --> 00:26:15.375
我在右侧将它们放大了很多倍

00:26:15.442 --> 00:26:16.810
那样你们能看见它们的不同

00:26:16.877 --> 00:26:20.080
如果我将它们按真实比例来画
它们会全部重叠

00:26:20.547 --> 00:26:25.219
如果我们用通常的方式来
计算朝向

00:26:25.285 --> 00:26:28.021
我们会得到结果0
因为浮点数的取舍

00:26:28.088 --> 00:26:30.157
这是个简单的
结果为0的例子

00:26:30.324 --> 00:26:32.426
如果维度大于2x2

00:26:32.559 --> 00:26:34.995
我们会得到一个完全错误的符号

00:26:35.062 --> 00:26:37.164
不只是结果为0
当它不应该是0时

00:26:37.464 --> 00:26:39.333
但若我们使用
simd orient函数

00:26:39.600 --> 00:26:41.335
我们会得到一个很小的正数

00:26:41.401 --> 00:26:44.371
是正确的结果
这些是正朝向的

00:26:44.838 --> 00:26:48.442
我要提醒的是
不要诠释

00:26:48.509 --> 00:26:50.544
这个极小的正数
对任何情况都有意义

00:26:50.611 --> 00:26:52.012
这不是一个行列式的值

00:26:52.513 --> 00:26:54.948
有时候是行列式的值

00:26:55.015 --> 00:26:57.251
但有时只是有个准确的符号

00:26:57.317 --> 00:27:00.187
所以 我们这里真正关心的是
这个数字的符号

00:27:00.387 --> 00:27:01.622
那我们是怎么做到的？

00:27:01.722 --> 00:27:04.024
这些我今天像你们展示的
几何判定

00:27:04.091 --> 00:27:06.059
都是使用自适应精度

00:27:06.159 --> 00:27:09.263
我们计算至我们需要的位

00:27:09.363 --> 00:27:10.497
来获取正确的结果

00:27:10.564 --> 00:27:14.034
这让我们在大部分的时候
能很快返回正确的结果

00:27:14.401 --> 00:27:16.403
但如果我们要进一步

00:27:16.470 --> 00:27:18.739
进行精确的计算
为你们取得正确的结果

00:27:18.906 --> 00:27:20.007
我们也可以这么做

00:27:20.073 --> 00:27:22.209
你们可以相信这在你们代码里会给出正确答案

00:27:22.276 --> 00:27:24.344
你们不用担心

00:27:25.445 --> 00:27:27.247
Incircle很相似

00:27:27.414 --> 00:27:28.916
我们在平面里取三点

00:27:29.016 --> 00:27:30.150
那决定一个圆

00:27:30.217 --> 00:27:32.486
你们会注意到
它们是 正朝向的

00:27:32.553 --> 00:27:34.555
围着圆　这很重要

00:27:34.922 --> 00:27:37.257
如果我在圆里加个点 x

00:27:37.424 --> 00:27:39.826
然后simd incircle
能告诉我点是否在圆内

00:27:40.027 --> 00:27:42.162
如在圆内 我得到个正值

00:27:42.462 --> 00:27:45.032
如在圆上 我得到0

00:27:45.599 --> 00:27:48.035
如在圆外 我得到个负值

00:27:48.535 --> 00:27:51.972
insphere也是相同的

00:27:54.241 --> 00:27:55.576
只是现在是三维的了

00:27:55.642 --> 00:27:57.444
我需要四个维度来定义球体

00:27:57.511 --> 00:27:59.246
我设定点x
然后得到相应的结果

00:28:00.647 --> 00:28:02.416
我向你们展示
一个之前提过的例子

00:28:02.482 --> 00:28:05.519
判断一个三角形的面是
正对还是背对着你们

00:28:06.153 --> 00:28:09.456
这里我有个简单的struct
用来在Swift里代表三角形

00:28:09.890 --> 00:28:13.660
三角形由三个点定义
我把它们放一个集合里

00:28:14.428 --> 00:28:17.464
我用这个判定
IsFacing来告诉我

00:28:17.831 --> 00:28:20.501
三角形是否面对相机

00:28:21.201 --> 00:28:23.237
那通常你们的计算方式是

00:28:23.303 --> 00:28:26.773
运用叉乘积来计算
一个对三角形面的法向量

00:28:27.241 --> 00:28:30.811
然后计算它与
对着相机的向量的点积

00:28:30.878 --> 00:28:33.413
如果值为正
那三角形正对着相机

00:28:33.480 --> 00:28:36.884
我们可以简化这些代码
并准确计算结果

00:28:38.318 --> 00:28:41.121
通过使用simd orient判定

00:28:41.321 --> 00:28:42.389
那我的代码变简单了

00:28:42.789 --> 00:28:44.758
它很快 还能给我正确的答案

00:28:44.825 --> 00:28:46.426
这都是我想要的

00:28:46.493 --> 00:28:48.829
这就是我们尝试着
在Accelerate实现的

00:28:48.896 --> 00:28:50.264
给予你们简单的东西

00:28:50.330 --> 00:28:52.332
用于复杂的数学计算

00:28:53.967 --> 00:28:55.969
那我们今天向你们展示了
许多新的东西

00:28:58.438 --> 00:29:00.474
我们有些全新的库

00:29:00.607 --> 00:29:02.743
我们有BNNS用于神经网络

00:29:03.277 --> 00:29:04.678
我们有Quadrature

00:29:04.745 --> 00:29:06.947
我们还有些新的功能

00:29:07.614 --> 00:29:09.716
simd里的
orientation和incircle

00:29:09.783 --> 00:29:12.286
这每一个新功能和库

00:29:12.686 --> 00:29:16.757
都是为回应开发者的需求
所添加的

00:29:16.857 --> 00:29:19.660
所以 我们很想知道你们所想要的

00:29:19.927 --> 00:29:22.663
通过我们能添加的东西
能简化你们的计算工作

00:29:22.729 --> 00:29:24.498
我们想给予你们简单的接口

00:29:24.698 --> 00:29:27.067
它能让你们有效率地
完成你们要做的事

00:29:27.634 --> 00:29:29.636
我们今年还做了许多其它的事

00:29:30.137 --> 00:29:33.207
在vImage里
Eric在简介里带过的

00:29:33.907 --> 00:29:37.277
我们有一组全套的几何操作用于
交叉存取的色度平面

00:29:37.344 --> 00:29:39.613
这绝对是最频繁的请求

00:29:39.680 --> 00:29:41.114
我们在近年里所收到的

00:29:41.281 --> 00:29:42.883
所以 我们很乐意地添加了它

00:29:42.950 --> 00:29:44.685
如果你们不知道那是什么
无需担心

00:29:44.751 --> 00:29:47.321
但如果你们知道
那你们会明白它的有用之处

00:29:47.588 --> 00:29:49.656
我们还扩展了

00:29:49.723 --> 00:29:52.025
vImage里的转换例程
用于新的格式

00:29:52.092 --> 00:29:54.795
这为许多你们或许听说过的关于
深色的东西奠定了基础

00:29:54.862 --> 00:29:57.030
所以这个对那来说很重要

00:29:58.565 --> 00:30:00.434
我们提高了性能

00:30:00.501 --> 00:30:02.536
针对vDSP里的交织复杂格式

00:30:02.603 --> 00:30:06.707
通过FFT 我们支持交织和截面布局

00:30:06.773 --> 00:30:08.108
复杂和虚的部分

00:30:08.175 --> 00:30:09.977
要么被分开 要么放在一起

00:30:11.745 --> 00:30:14.281
我们一般使用截面布局
进行操作

00:30:14.348 --> 00:30:18.218
我们推荐这么做
但如果你们只有交织的数据

00:30:18.285 --> 00:30:21.021
你们现在可以使用FFT
它们很快

00:30:22.022 --> 00:30:24.858
我们也提高了所有
Level II BLAS操作性能

00:30:24.925 --> 00:30:27.861
有些是由你们所见到的
BNNS员工发起的

00:30:27.928 --> 00:30:30.497
有些是我们所预见并跟进的机会

00:30:30.564 --> 00:30:33.133
Accelerate里
还有许多新的东西

00:30:33.200 --> 00:30:34.535
许多改进了的东西

00:30:34.868 --> 00:30:38.205
每当有新处理器发布
我们一定会针对它们进行优化

00:30:38.272 --> 00:30:41.508
我们想解决所有的那些低级计算细节

00:30:41.575 --> 00:30:44.378
让你们能注重于
编写高级算法

00:30:44.578 --> 00:30:46.146
基于低级细节层面

00:30:46.213 --> 00:30:48.081
让你们能达成你们想做的

00:30:49.183 --> 00:30:52.019
总结下
我们想成为你们一站式购物的地方

00:30:52.085 --> 00:30:53.820
为计算的算法

00:30:54.288 --> 00:30:56.657
我们能提供给你们的实现是准确

00:30:56.857 --> 00:30:59.193
快速和节省能源的

00:30:59.493 --> 00:31:01.662
并且我们会针对新硬件
进行优化

00:31:01.728 --> 00:31:04.097
当它们发布时
这样你们就不用为此担心

00:31:04.164 --> 00:31:08.035
如果你们想自己优化
那我们有了新的芯片

00:31:08.101 --> 00:31:10.504
你们就需要对其更新

00:31:10.571 --> 00:31:12.739
如果你们交给我们来处理

00:31:12.806 --> 00:31:14.274
那你们就不用担心了

00:31:15.309 --> 00:31:18.212
继续提交你们的请求
我们很高兴能收到它们

00:31:18.278 --> 00:31:20.247
我们今天在实验室和
你们许多人交谈了

00:31:20.314 --> 00:31:22.549
我们已经得到了许多将来的请求

00:31:22.616 --> 00:31:24.985
能将雷达归档
我们想要这个功能

00:31:25.686 --> 00:31:30.224
如果你们想见到更多相关信息
这个讲座的连接在这里

00:31:30.757 --> 00:31:33.493
我也推荐你们去看下
前几年的讲座

00:31:33.560 --> 00:31:37.464
有关于这些库的其它方面
有用的细节

00:31:38.232 --> 00:31:40.267
有两个很好的关于
Metal的演讲

00:31:40.334 --> 00:31:43.437
我高度推荐你们去看下
昨天的演讲

00:31:43.504 --> 00:31:45.906
特别是如果
你们对这些感兴趣的话

00:31:45.973 --> 00:31:47.808
十分感谢你们的到来