00:00:19.520 --> 00:00:24.992
高级Metal着色器优化

00:00:31.532 --> 00:00:32.866
大家好

00:00:32.966 --> 00:00:35.602
我叫Fiona
这是我的同事Alex

00:00:36.069 --> 00:00:39.806
我任职于iOS GPU处理器团队

00:00:39.873 --> 00:00:43.277
我们的工作就是让大家的着色器
运行于最新的iOS设备上

00:00:43.377 --> 00:00:46.180
而且让它们尽可能高效地运行

00:00:46.647 --> 00:00:48.982
这里我要谈一下我们的演讲

00:00:49.116 --> 00:00:50.517
高级Metal着色器优化

00:00:50.584 --> 00:00:53.954
锻造和打磨你的Metal着色器

00:00:54.721 --> 00:00:56.757
我们的编译器是基于LVM的

00:00:56.823 --> 00:00:58.492
而且我们和开源社区合作

00:00:58.559 --> 00:01:01.862
让LVM更加适用于GPU

00:01:03.730 --> 00:01:07.034
这是其它几个Metal相关的演讲
万一你错过了的话

00:01:07.100 --> 00:01:08.969
不用担心 你可以上网看录像

00:01:09.336 --> 00:01:11.738
昨天讲了Metal应用的
第一部分和第二部分

00:01:12.239 --> 00:01:14.975
今天早些时候讲了Metal新特性
的第一和第二部分

00:01:15.042 --> 00:01:16.743
因为Metal有太多新的东西了

00:01:17.311 --> 00:01:18.946
当然 现在这个是最后一部分

00:01:19.513 --> 00:01:20.781
就是你们现在看的东西

00:01:22.115 --> 00:01:24.918
所以在这个演讲中
我们将讨论一些东西

00:01:24.985 --> 00:01:28.889
你们可以利用这些编辑器相关的东西
来让你们的代码运行地更快

00:01:29.489 --> 00:01:33.760
这些中的一部分是针对A8处理器
和更新的图像处理器

00:01:33.827 --> 00:01:36.763
包括一些从未被公布过的信息

00:01:37.598 --> 00:01:39.399
其中一些也将比较通俗

00:01:39.466 --> 00:01:42.302
我们会谈到大家看到A8的图标

00:01:42.503 --> 00:01:45.372
在演示文稿中 是针对A8处理器的

00:01:45.973 --> 00:01:50.010
另外 我们会谈一些潜在的陷阱

00:01:50.377 --> 00:01:53.981
这些东西一般不会出现 就像微优化

00:01:54.047 --> 00:01:55.482
你们经常发现的那样

00:01:55.749 --> 00:01:59.319
但是一旦你们碰到了
很有可能会降低很多性能

00:01:59.386 --> 00:02:01.488
相比之下 其他东西都不重要了

00:02:01.688 --> 00:02:04.424
所以始终要确保你们不会掉入这些陷阱

00:02:04.491 --> 00:02:07.427
这些会被标记上三角符号
正如你们看到的那样

00:02:08.127 --> 00:02:10.597
在我们继续之前 这不是第一步

00:02:10.931 --> 00:02:12.132
这是最后一步

00:02:12.799 --> 00:02:15.369
进行低级别的着色器优化是没有意义的

00:02:15.435 --> 00:02:17.771
除非之前你已经做了高级别的优化

00:02:17.838 --> 00:02:19.406
比如观看其他的Metal演讲

00:02:19.473 --> 00:02:22.976
优化你的绘制调用 你的引擎结构等等

00:02:23.577 --> 00:02:26.813
优化你的着色器差不多是
你要做的最后一件事情

00:02:27.481 --> 00:02:31.952
而且 这个演讲主要是给
经验丰富的着色器程序员

00:02:32.419 --> 00:02:34.188
也许你在Metal方面经验丰富

00:02:34.254 --> 00:02:36.356
而且你想要更深入的学习优化着色器

00:02:36.423 --> 00:02:40.227
又或许你刚开始接触Metal
但你已在着色器优化方面做了很多工作

00:02:40.294 --> 00:02:42.896
在其他平台
而且你想知道如何更好地优化

00:02:42.963 --> 00:02:46.600
A8处理器和更新的图像处理器
这个演讲就是为你们准备的

00:02:48.302 --> 00:02:51.905
你可能已经看过这个管线图了
若你看过任意一个之前Metal演讲

00:02:52.339 --> 00:02:56.376
当然 我们也将聚焦在
这个管线图的编码阶段

00:02:56.443 --> 00:02:58.312
正如你们所见的 着色器课程

00:02:59.213 --> 00:03:02.449
首先 Alex将会讲一下
一些着色器性能的基本知识

00:03:02.516 --> 00:03:03.784
和一些高级一点的问题

00:03:03.851 --> 00:03:09.456
然后 我会回来讲一些低级别的
底层的 繁琐的着色器优化

00:03:10.624 --> 00:03:12.459
着色器性能基础

00:03:17.731 --> 00:03:19.900
谢谢Fiona 首先让我解释一下

00:03:19.967 --> 00:03:21.268
着色器性能基础

00:03:21.702 --> 00:03:22.903
这些是你想要确保

00:03:22.970 --> 00:03:26.106
你们是对的
在你们深入了解源代码级别的优化

00:03:26.473 --> 00:03:29.643
通常你们在此所做改变的影响可能弱化

00:03:29.710 --> 00:03:33.013
或者潜在地掩盖你在其它地方
做的更加有针对性的改变

00:03:33.347 --> 00:03:34.815
所有今天我打算谈四个方面

00:03:34.882 --> 00:03:37.084
缓冲参数的地址空间选择

00:03:37.150 --> 00:03:38.619
缓冲预加载

00:03:38.685 --> 00:03:40.354
碎片函数资源的处理

00:03:40.420 --> 00:03:42.422
和如何优化电脑内核

00:03:44.324 --> 00:03:45.692
好 让我们从地址空间开始

00:03:46.159 --> 00:03:48.762
因为这个功能不存在于

00:03:48.829 --> 00:03:50.597
所有着色语言
我给大家简单的入门

00:03:51.231 --> 00:03:53.734
所以 图像处理器有很多的途径
从内存中拿到数据

00:03:53.800 --> 00:03:56.937
而对于不同的应用场景
这些途径都是被优化过的

00:03:57.070 --> 00:03:59.840
所以它们有着不同的性能特征

00:04:00.641 --> 00:04:04.511
在Metal中 我们给了开发者
使用路径的控制权

00:04:04.578 --> 00:04:08.348
通过要求它们符合所有的缓存器
参数和指针

00:04:08.415 --> 00:04:11.385
在着色语言中 用它们要用的地址空间

00:04:11.652 --> 00:04:14.655
所以一部分地址空间专门用于

00:04:14.721 --> 00:04:16.790
从内存中提取信息

00:04:18.358 --> 00:04:20.427
其中的第一个就是设备地址空间

00:04:20.994 --> 00:04:23.163
这是一个限制相对较少的地址空间

00:04:23.230 --> 00:04:24.965
你可以通过地址空间来读写数据

00:04:25.032 --> 00:04:26.900
你可以传任意多的数据

00:04:26.967 --> 00:04:29.369
你在API级别指定的寄存器

00:04:29.436 --> 00:04:31.605
有着相对灵活的参数要求

00:04:33.574 --> 00:04:35.876
另一方面 你有固定的地址空间

00:04:36.076 --> 00:04:38.111
如名字中所写
这是一个只读的地址空间

00:04:38.178 --> 00:04:39.847
但是有另外一些约束

00:04:40.247 --> 00:04:42.115
你能传输的数据量是有限制的

00:04:42.182 --> 00:04:44.284
通过地址空间 另外 缓存区偏移量

00:04:44.351 --> 00:04:47.788
你在API级别指定的
有更加严格的对齐要求

00:04:48.222 --> 00:04:49.823
但是 这就是地址空间

00:04:49.890 --> 00:04:51.959
被优化 为了大量数据重用的情况

00:04:52.025 --> 00:04:54.761
所以 每当它有理的时候
你就会利用这个地址空间

00:04:56.063 --> 00:04:57.965
找出是否这个连续地址空间

00:04:58.031 --> 00:04:59.266
对你的缓冲器参数有意义

00:04:59.333 --> 00:05:01.835
通常在于两个问题

00:05:02.636 --> 00:05:05.105
第一个问题是
我是否知道我有多少数据

00:05:05.539 --> 00:05:07.708
如果你的数据量是变化的

00:05:07.774 --> 00:05:10.711
这通常就是你需要使用
设备地址空间的一个信号

00:05:11.378 --> 00:05:16.450
另外 你要看一下缓冲器中的
每一个有多少被读取

00:05:16.517 --> 00:05:20.621
如果这些可能被读取多次

00:05:20.988 --> 00:05:23.857
这通常表示你需要
把他们放下连续地址空间

00:05:24.825 --> 00:05:26.960
让我们用几个例子把这付诸实践

00:05:27.027 --> 00:05:28.395
例子源于一些顶点着色器

00:05:29.830 --> 00:05:31.899
首先 你有规则的原始顶点数据

00:05:32.900 --> 00:05:36.370
可以看出 每个顶点有自己的数据块

00:05:36.803 --> 00:05:38.972
而且每个数据块只被自己的顶点读

00:05:39.039 --> 00:05:40.474
因此基本上没有重用

00:05:40.541 --> 00:05:45.412
这是在设备地址空间
真正需要满足的条件

00:05:46.747 --> 00:05:51.618
接着 你有投影矩阵以及其它的矩阵

00:05:52.186 --> 00:05:54.087
现在 属于你的

00:05:54.421 --> 00:05:59.927
是你有一个对象
这些对象被单一的顶点读

00:06:00.594 --> 00:06:02.396
在完全的数据重用情况下

00:06:02.462 --> 00:06:04.631
你想这个对象在常量地址空间里

00:06:07.935 --> 00:06:10.737
把东西混合一点后 分析常量矩阵

00:06:11.171 --> 00:06:14.741
在这种情况下 很大可能你能得到最大

00:06:14.808 --> 00:06:16.009
bone数
这些对象是你正在处理的

00:06:16.643 --> 00:06:18.278
但是你单个看每个bone时

00:06:19.079 --> 00:06:21.882
矩阵可以被每一个和
那个bone相关的顶点读取

00:06:21.949 --> 00:06:24.985
这也是潜在的大量重用

00:06:25.052 --> 00:06:27.688
所以这也该在常量地址空间里

00:06:29.223 --> 00:06:31.191
最后，让我们来看看每一个实例数据

00:06:33.861 --> 00:06:35.996
如你所见，例子中的所有顶点

00:06:36.063 --> 00:06:37.898
将会读取这个特定的数据

00:06:38.332 --> 00:06:41.401
但是另一方面
你有一些潜在的可变实例

00:06:41.468 --> 00:06:44.238
所以这也应该在设备地址空间里

00:06:45.839 --> 00:06:48.842
为何地址空间的选择对于性能那么重要

00:06:48.909 --> 00:06:51.211
我们进入到下一个话题 缓冲器预加载

00:06:53.113 --> 00:06:54.815
Fiona将会花些时间讲一下

00:06:54.882 --> 00:06:57.251
如何真正地在着色器中优化加载和存储

00:06:57.317 --> 00:06:59.720
但在很多情况下
你能做的最好的事就是

00:06:59.786 --> 00:07:02.623
把这个工作交给专门的硬件去做

00:07:03.257 --> 00:07:04.892
以下两种情况
我们能做优化

00:07:05.392 --> 00:07:07.160
背景缓存和顶点缓存

00:07:07.528 --> 00:07:12.032
但是这基于 你知道着色器中访问模式

00:07:12.099 --> 00:07:13.934
和你把它们放在了什么地址空间

00:07:15.402 --> 00:07:17.070
让我们以常量缓存预加载

00:07:17.704 --> 00:07:19.039
所以这里想说的是

00:07:19.106 --> 00:07:21.008
不同于通过常量地址空间来加载

00:07:21.074 --> 00:07:22.643
我们其实要做的是拿到你的数据

00:07:22.709 --> 00:07:25.379
然后将它们置于特殊的常量寄存器
这些寄存器是更快的

00:07:25.445 --> 00:07:26.547
对于ALU的读写

00:07:27.214 --> 00:07:29.816
所以只要我们知道什么数据会被读取
我们就可这么做

00:07:30.651 --> 00:07:33.787
如果你的偏移量是已知的编译时间
这就很直接明了了

00:07:33.954 --> 00:07:36.056
但是如果你的偏移量在运行前是未知的

00:07:36.123 --> 00:07:37.824
那么我们就需要一些额外的信息

00:07:37.891 --> 00:07:39.426
关于你正在读取多少数据量

00:07:41.495 --> 00:07:44.865
所以给编译器表明
这个通常需要两个步骤

00:07:44.965 --> 00:07:47.668
第一 你需要确保这个数据
是在常量地址空间

00:07:48.936 --> 00:07:51.972
另外你需要表明
你的访问时是静态绑定的

00:07:53.207 --> 00:07:55.442
做这个最好的方式是通过传参数时

00:07:55.609 --> 00:07:57.978
尽量使用引用而不是指针

00:07:58.212 --> 00:08:00.614
若你只是传递一个参数或者一个结构体

00:08:00.681 --> 00:08:03.650
这是很直接的
你可以只改变指向引用的指针

00:08:03.717 --> 00:08:05.219
和对应地改变你的访问

00:08:06.253 --> 00:08:09.022
如果你传递一个绑定的数组
这就会有所不同

00:08:09.590 --> 00:08:12.593
所以你在这个例子中要做的是
你可以嵌入那个大小的数组

00:08:12.659 --> 00:08:16.163
并将那个结构体通过引用来传递
而不是传递原来的指针

00:08:16.864 --> 00:08:18.966
我们通过一个例子来实践一下

00:08:19.633 --> 00:08:21.435
在前灯碎片着色器

00:08:22.202 --> 00:08:24.705
如你在原始版本中看到的那样

00:08:24.771 --> 00:08:26.106
我们有的是一些参数

00:08:26.173 --> 00:08:27.574
作为普通设备指针进行传递

00:08:27.641 --> 00:08:29.810
而且这并没有给出我们想要的信息

00:08:30.544 --> 00:08:31.712
所以我们能比这个做得更好

00:08:32.212 --> 00:08:34.114
相反 若我们注意到灯的数量相互关联

00:08:34.181 --> 00:08:36.817
我们能做的就是将灯的数据

00:08:36.884 --> 00:08:39.219
和数量一起放在这么一个结构体中

00:08:40.587 --> 00:08:42.990
然后将这个结构体传给常量地址空间

00:08:43.056 --> 00:08:44.157
作为像这样一个引用

00:08:44.725 --> 00:08:46.727
这样 我们就实现了常量缓存预加载

00:08:48.295 --> 00:08:51.198
让我们在看一个例子
看看它实际中是如何影响你的

00:08:52.165 --> 00:08:55.135
实现延迟渲染有很多种方式

00:08:55.202 --> 00:08:57.638
但是我们发现实际上
你选择的实现方式

00:08:57.704 --> 00:09:00.040
会对实践中你实现的性能

00:09:00.107 --> 00:09:01.408
有很大的影响

00:09:02.843 --> 00:09:05.379
现在一种常用的模式是使用单一着色器

00:09:05.445 --> 00:09:07.814
来积累出所有灯光的结果

00:09:08.382 --> 00:09:11.018
正如你在函数的声明中看到的那样

00:09:11.084 --> 00:09:13.287
它可能在这个场景中
读取任意或者所有的光

00:09:13.353 --> 00:09:15.255
这意味着你的输入大小是无关联的

00:09:17.224 --> 00:09:19.960
另一方面 如果你能结构化你的渲染

00:09:20.027 --> 00:09:22.763
使得每一个光在它自己的
绘制调用中被处理

00:09:22.829 --> 00:09:27.134
那么每一个光就只需要读那个光的数据

00:09:27.201 --> 00:09:29.970
它是着色器 那意味着你可以传递

00:09:30.037 --> 00:09:33.473
在常量地址空间和充分利用缓存预加载

00:09:34.274 --> 00:09:38.111
其实我们发现在A8后的图像处理器上
这有一个很大的性能提升

00:09:40.614 --> 00:09:42.716
现在让我们谈一下顶点缓存预加载

00:09:42.783 --> 00:09:45.786
顶点缓存预加载的目的是
重用相同的专用硬件

00:09:45.853 --> 00:09:47.921
我们会在固定的函数顶点获取中使用

00:09:48.889 --> 00:09:51.525
我们可在常规缓存加载中做这个 就像

00:09:51.592 --> 00:09:54.461
你在读取缓存
看上去就像固定函数顶点获取

00:09:54.862 --> 00:09:55.829
它意味着你需要

00:09:55.896 --> 00:09:58.098
使用顶点或者实例的ID来进行索引

00:09:58.832 --> 00:10:01.235
现在我们可以处理一些额外的改变

00:10:01.301 --> 00:10:04.071
为顶点或者实例ID
比如应用一个发生器

00:10:04.137 --> 00:10:06.840
使用或者不使用基本顶点

00:10:06.907 --> 00:10:08.976
或实例偏移量
你可能在API级别的应用

00:10:10.077 --> 00:10:12.145
当然最简单的方式是充分利用

00:10:12.212 --> 00:10:15.849
尽量使用Metal顶点描述功能

00:10:16.450 --> 00:10:18.151
但是如果你写你自己的索引代码

00:10:18.752 --> 00:10:20.287
我们强烈建议设计你的数据

00:10:20.354 --> 00:10:23.123
使得顶点线性到达而简化缓冲区索引

00:10:23.824 --> 00:10:26.059
意识到这并不妨碍你做自己喜欢的事情

00:10:26.126 --> 00:10:28.996
比如你在画矩形 你想赋值

00:10:29.429 --> 00:10:33.133
给矩形的所有顶点
你仍然可以做其它事情

00:10:33.200 --> 00:10:36.937
像用顶点ID除以4建立索引
因为这看起来就像个分配器

00:10:38.672 --> 00:10:42.276
让我们继续着色器阶段的一些具体问题

00:10:43.911 --> 00:10:46.947
在iOS 10里
我们介绍了记录资源的功能

00:10:47.014 --> 00:10:48.448
在片段功能里

00:10:48.782 --> 00:10:51.151
对于隐藏的表面去除有着有趣的含义

00:10:52.252 --> 00:10:54.321
在这之前你也许已经习惯这种行为

00:10:54.388 --> 00:10:56.423
片段不需要被着色

00:10:56.823 --> 00:10:59.293
只要一个不透明的片段过来遮挡它

00:11:00.160 --> 00:11:02.095
所以这不再是正确的尤其

00:11:02.162 --> 00:11:03.797
当你的片段功能正在写资源

00:11:03.864 --> 00:11:05.866
因为这些资源记录仍需要发生

00:11:06.767 --> 00:11:10.270
相反你的行为仅仅取决于
前面所发生的事情

00:11:10.904 --> 00:11:12.472
确切地说 发生什么取决于

00:11:12.539 --> 00:11:15.676
在你的片段功能里
你是否能进行早期的片段测试

00:11:16.443 --> 00:11:20.681
如果你通过 了早期的片段测试
一旦被栅格化

00:11:20.747 --> 00:11:23.650
只要它通过早期的深度和模块测试

00:11:24.418 --> 00:11:26.353
如果你没有指定早期的片段测试

00:11:26.420 --> 00:11:29.323
那么只要它被栅格化了
你的片段就会被着色

00:11:30.057 --> 00:11:32.159
所以从最小化你的着色器的角度看

00:11:32.226 --> 00:11:35.062
你要做的是尽量早地使用早期片段测试

00:11:35.128 --> 00:11:36.330
但是有一些其它事情

00:11:36.396 --> 00:11:38.732
你可以做的 来提高你得到的拒绝

00:11:40.167 --> 00:11:41.768
且这其中大部分归结于绘制顺序

00:11:41.835 --> 00:11:44.304
你想要绘制这些图案

00:11:44.371 --> 00:11:47.040
片段函数进行资源写的图案

00:11:47.307 --> 00:11:48.509
在不透明的图案的后面

00:11:48.775 --> 00:11:51.678
而且如果你使用这些图案
来更新的你的深度和画笔缓存

00:11:51.745 --> 00:11:54.781
我们强烈建议
你把这些缓存按照从前到后进行排序

00:11:55.582 --> 00:11:57.751
注意这个指导应该听上去相当的熟悉

00:11:57.818 --> 00:11:59.453
如果你曾经处理过片段函数

00:11:59.520 --> 00:12:01.622
丢弃或者修改你每一像素点的深度

00:12:04.091 --> 00:12:05.659
现在让我谈一谈计算机内核

00:12:05.726 --> 00:12:08.395
因为计算机内核的决定性特征

00:12:08.462 --> 00:12:10.531
决定了计算能力

00:12:10.964 --> 00:12:15.636
我们来说说什么因素影响了
你在iOS中是怎么做的

00:12:17.070 --> 00:12:19.239
首先 我们有计算机线程启动的限制

00:12:20.574 --> 00:12:24.711
所以在A8及以后的图像处理器上
有一定量的时间

00:12:24.778 --> 00:12:27.481
被花在了启动一些计算机线程

00:12:27.548 --> 00:12:30.551
所以如果你的在一个计算机线程中
没有做足够多的工作

00:12:30.617 --> 00:12:32.953
这就会使硬件没有被充分利用

00:12:33.020 --> 00:12:34.488
这就降低了性能

00:12:35.956 --> 00:12:38.592
一个处理这个问题
比较好的方式和一个好的模式

00:12:38.659 --> 00:12:40.794
对于在iOS上写计算机内核

00:12:40.861 --> 00:12:44.665
是在一个计算线程上
处理多个概念的工作条目

00:12:45.465 --> 00:12:48.101
尤其我们找到一种工作得很好的模式是

00:12:48.168 --> 00:12:51.805
重用数值 不是通过线程组内存传递

00:12:51.872 --> 00:12:55.209
而是通过重用加载的数据
为下一个工作条目

00:12:55.275 --> 00:12:58.345
当你在同一个计算线程中
处理下一个工作条目

00:12:59.213 --> 00:13:01.114
最好通过一个例子来阐述这点

00:13:02.115 --> 00:13:03.650
这是一个音节过滤内核

00:13:03.717 --> 00:13:06.153
这是一种最直接的版本了

00:13:06.220 --> 00:13:08.288
它读取三个不发音的区域

00:13:08.722 --> 00:13:10.791
并产生一个输出像素点

00:13:12.092 --> 00:13:17.431
所以如果应用处理多工作条目的模式

00:13:17.798 --> 00:13:20.467
在单一计算线程中
我们就得到类似于这样的东西

00:13:21.034 --> 00:13:24.238
注意现在我们是在以
一次两个像素点向前迈进

00:13:24.838 --> 00:13:27.074
所以处理第一个像素点
和它以前做的没区别

00:13:27.140 --> 00:13:28.542
我们读取这个3乘3的区域

00:13:29.042 --> 00:13:31.245
我们应用了这个过滤器
且写上去了这个数值

00:13:32.946 --> 00:13:34.948
但让我们看看
第二个像素点是如何被处理

00:13:35.482 --> 00:13:38.218
支架是以一次两个像素点迈进的

00:13:38.285 --> 00:13:40.654
我们需要确保有第二个像素点被处理

00:13:41.421 --> 00:13:42.689
现在我们读取了它的数据

00:13:43.323 --> 00:13:46.560
注意到这个像素点
所需要的三分之二的区域

00:13:46.627 --> 00:13:48.295
已经被之前的像素点加载

00:13:48.362 --> 00:13:50.764
所以我们不需要重新加载
我们可重用这些原有值

00:13:51.031 --> 00:13:54.635
现在我们所需要加载是
这个像素点的新的三分之一

00:13:55.702 --> 00:13:58.172
之后 我们就能应用过滤器完成任务

00:13:59.273 --> 00:14:02.442
注意 最后我们不是做12个纹理读取

00:14:02.509 --> 00:14:05.212
不是原有的9个
而是我们在创建2个像素点

00:14:05.612 --> 00:14:09.116
在大量的单个像素点的纹理获取中
这是个有意义的缩减

00:14:09.783 --> 00:14:13.453
当然这个模式并不适用于
所有的计算使用案例

00:14:13.954 --> 00:14:16.924
有时你仍然要通过线程组内存传递数据

00:14:17.824 --> 00:14:19.326
这种情况下 当你同步

00:14:19.393 --> 00:14:21.595
一个线程组中的线程的时候

00:14:22.462 --> 00:14:24.031
需要记住一个重要的事情是

00:14:24.097 --> 00:14:26.834
你想要使用栅栏在尽量小的范围内

00:14:26.900 --> 00:14:28.669
为你需要同步的线程

00:14:29.236 --> 00:14:33.440
尤其若你的线程组在一个SIMD里面

00:14:34.041 --> 00:14:37.144
在Metal中
通常的线程组闸函数是不需要的

00:14:37.511 --> 00:14:39.179
你可以使用的

00:14:39.246 --> 00:14:42.549
是新的SIMD组闸函数
这是在iOS 10中引入的

00:14:43.617 --> 00:14:46.954
我们发现的实际上是线程组

00:14:47.020 --> 00:14:51.792
符合单一SIMD和
使用SIMD组闸通常要快于

00:14:51.859 --> 00:14:55.128
使用一个更大的线程组
为了挤压另外的重用

00:14:55.195 --> 00:14:57.331
但是不得不使用线程组闸作为结果

00:14:59.032 --> 00:15:01.335
总的来说

00:15:02.736 --> 00:15:04.471
确保你使用正确的地址空间

00:15:04.538 --> 00:15:05.739
为每一个缓存参数

00:15:05.806 --> 00:15:07.641
根据我们说的规则

00:15:08.775 --> 00:15:11.645
机构化你的数据和渲染
最大程度地利用常量

00:15:11.712 --> 00:15:13.146
和顶点缓存预加载

00:15:14.448 --> 00:15:16.250
确保使用早期片段测试来过滤

00:15:16.316 --> 00:15:19.786
尽量多的片段
当你在做资源写操作的时候

00:15:21.388 --> 00:15:24.324
给每一个计算给予线程足够的工作量
这样你就不会被限制

00:15:24.391 --> 00:15:26.360
在计算线程启动

00:15:27.294 --> 00:15:29.196
给任务使用最小的栏栅当你需要

00:15:29.263 --> 00:15:31.365
同步线程池中的线程的时候

00:15:31.632 --> 00:15:35.002
那么 我想让Fiona详细地
讲一下调制着色器代码

00:15:41.408 --> 00:15:42.276
谢谢Alex

00:15:43.243 --> 00:15:45.979
在进入这些细节之前

00:15:46.046 --> 00:15:48.615
我想要讲一下
一些图像处理器的普通特性

00:15:48.682 --> 00:15:50.551
和一些你们可能会遇到的瓶颈

00:15:50.617 --> 00:15:52.352
可能你们中所有的人都熟悉它

00:15:52.452 --> 00:15:54.454
但是我觉得还是有必要快速的过一下

00:15:54.755 --> 00:15:58.525
对于图像处理器
通常来讲你有一组资源

00:15:58.625 --> 00:16:02.329
经常会发生的事情是着色器
被其中的一个资源给卡住了

00:16:02.596 --> 00:16:04.031
举个例子 你卡在了

00:16:04.097 --> 00:16:07.067
内存带宽
提高你的着色器中的其它东西

00:16:07.134 --> 00:16:09.970
通常不会带来明显的性能提升

00:16:10.537 --> 00:16:12.973
识别出这些瓶颈

00:16:13.040 --> 00:16:16.276
和聚焦在这些瓶颈上
以提高性能是很重要的

00:16:16.343 --> 00:16:19.746
这实际上对于非瓶颈的东西也是有益的

00:16:19.813 --> 00:16:23.483
比如 在那个例子当中
如果内存使用成为了瓶颈

00:16:23.550 --> 00:16:26.520
你通过提高算法变得更加高效

00:16:26.587 --> 00:16:30.557
你仍然节约了电量
即使你没有提高帧速率

00:16:30.724 --> 00:16:34.027
当然在移动设备上
节约电量始终是是重要的

00:16:34.294 --> 00:16:35.963
所以这不是一个能忽略的东西

00:16:36.029 --> 00:16:38.565
只是因为帧速率在那个例子中没有上升

00:16:38.632 --> 00:16:43.504
所以在着色器这里
你需要记住四个典型的瓶颈

00:16:43.704 --> 00:16:45.706
第一个是非常直接的ALU带宽

00:16:45.772 --> 00:16:47.708
图像处理器能处理的数学计算量

00:16:48.542 --> 00:16:50.844
第二是内存带宽 同样也是非常直接的

00:16:50.911 --> 00:16:53.747
图像处理器能从系统内存中
加载的数据量

00:16:54.481 --> 00:16:55.916
另外两个相对就没那么明显

00:16:55.983 --> 00:16:57.951
第一是内存问题率

00:16:58.018 --> 00:17:01.488
它表示能执行的内存处理量

00:17:01.855 --> 00:17:06.026
这会出现在以下的场景中
当你的内存处理比较小的时候

00:17:06.093 --> 00:17:08.529
或者你使用很多线程组内存等等

00:17:09.029 --> 00:17:11.964
最后一个
也是我等会儿会深入讲的一个

00:17:12.031 --> 00:17:14.034
是延迟占用寄存器使用

00:17:14.101 --> 00:17:16.936
也许你已经同说过它来
但是我会把它留在最后

00:17:18.605 --> 00:17:20.507
所以为了缓解其中的一些瓶颈

00:17:20.574 --> 00:17:23.310
和提高着色器的性能和效率

00:17:23.377 --> 00:17:27.013
我们将一起看一下四类优化机会

00:17:27.580 --> 00:17:28.982
第一类是数据类型

00:17:29.550 --> 00:17:31.285
首先要想到

00:17:31.351 --> 00:17:34.354
当你优化着色器时 是选择数据类型

00:17:34.755 --> 00:17:38.659
当你选择数据类型时
最重要的一件事是A8

00:17:38.725 --> 00:17:42.196
及更新的图像器有16位的寄存器单元

00:17:42.763 --> 00:17:45.766
这意味着当你使用32位数据类型时

00:17:45.866 --> 00:17:49.236
那就是两倍的寄存器空间 两倍的带宽

00:17:49.703 --> 00:17:53.841
可能是两倍的电量等等
总之所有东西都是翻倍的

00:17:54.641 --> 00:17:56.977
所以 对应的 需要节约寄存器

00:17:57.044 --> 00:18:00.013
这样会得到更快的性能 更低的能耗

00:18:00.214 --> 00:18:01.715
通过使用更小的数据类型

00:18:01.949 --> 00:18:04.785
在运算中尽可能地使用
半字节和短字节的变量

00:18:05.185 --> 00:18:07.221
从能耗看
半字节比浮点型变量节能多了

00:18:07.688 --> 00:18:09.523
浮点型比整型又要节能

00:18:09.823 --> 00:18:13.493
甚至在整型当中
短整型又要比长整型节能

00:18:13.794 --> 00:18:16.797
你节省寄存器最有效的方式

00:18:16.864 --> 00:18:20.167
是给纹理和插值使用半字节型

00:18:20.234 --> 00:18:23.303
因为通常情况下你并不需要浮点型

00:18:23.370 --> 00:18:26.073
注意我不是指纹理格式

00:18:26.139 --> 00:18:28.942
我指的是数据类型
这数据类型是你用来存储

00:18:29.009 --> 00:18:30.811
纹理样本或者插值的结果

00:18:32.045 --> 00:18:36.650
A8及更新的图像处理器中
是相当方便的

00:18:37.050 --> 00:18:40.654
使得比在其它图像处理器上
使用更小的数据类更加的简单

00:18:40.921 --> 00:18:43.991
是因为数据类型转换一般是免费的

00:18:44.124 --> 00:18:46.527
甚至在浮点型和半字节型之间

00:18:46.593 --> 00:18:48.462
这意味着你不需要担心

00:18:48.529 --> 00:18:53.133
我会不会在使用半字节类型的过程中
引入了太多的类型转化

00:18:53.200 --> 00:18:55.335
这会导致消耗太多吗
这是否值得

00:18:55.736 --> 00:18:58.272
不 因为类型转换是自由的
所以很可能是更快了

00:18:58.539 --> 00:19:01.375
无论何时你都可以使用半字节类型
不需要担心这个部分

00:19:01.675 --> 00:19:05.279
需要记住的一点是半字节精度的数值

00:19:05.345 --> 00:19:08.115
和限制与浮点型数据是不同的

00:19:08.916 --> 00:19:11.418
经常出现的一个错误

00:19:11.485 --> 00:19:16.957
如写65,535这样一个半字节类型

00:19:17.424 --> 00:19:19.760
但它实际上是无穷大

00:19:20.160 --> 00:19:22.362
因为这比最大的半字节类型还要大

00:19:22.429 --> 00:19:24.998
所以要注意有哪些限制条件

00:19:25.065 --> 00:19:28.302
最好能知道哪里应该用
半字节类型 哪里不应该用

00:19:28.368 --> 00:19:31.104
降低在着色器中发生意外错误的可能性

00:19:32.072 --> 00:19:34.141
一个例子应用

00:19:34.208 --> 00:19:37.878
对于使用短整型数据类型 是线程ID

00:19:38.178 --> 00:19:41.915
你们中与计算机内核打过交道的
应该知道

00:19:41.982 --> 00:19:44.518
线程ID在程序中是广泛被使用的

00:19:44.985 --> 00:19:47.654
所以把它们弄得小一点
能很大程度地提高

00:19:47.721 --> 00:19:51.792
运算的性能 可以节省寄存器等等

00:19:52.626 --> 00:19:58.632
对于本地线程ID 在这个例子中
没有理由去使用无符号整型

00:19:58.866 --> 00:20:01.435
因为本地线程ID
不能用那么多的线程ID

00:20:01.869 --> 00:20:05.172
对于全局线程ID
通常你可以使用无符号短整型

00:20:05.239 --> 00:20:08.242
因为大多数情况下
你不会有那么多的线程ID

00:20:08.308 --> 00:20:09.643
当然这要取决于你的程序

00:20:09.977 --> 00:20:14.114
但是在绝大多数的情况下
你不会超过2的16次方减1

00:20:14.181 --> 00:20:15.516
所以你可使用无符号短整型

00:20:16.116 --> 00:20:19.253
这会降低功耗 也会更快

00:20:19.319 --> 00:20:23.290
因为所有线性ID相关的运算都变快了

00:20:23.590 --> 00:20:26.026
所以我强烈建议你尽可能的这么做

00:20:28.562 --> 00:20:31.565
另外 记住在类C的语言中

00:20:31.632 --> 00:20:33.100
当然这也包括Metal

00:20:33.166 --> 00:20:37.137
运算的精度是通过
输入类型的大小来定义的

00:20:37.804 --> 00:20:40.140
比如 一个浮点型乘以一个半字节型

00:20:40.207 --> 00:20:43.577
这是一个浮点型运算而非半字节型运算
它会向上提升

00:20:44.011 --> 00:20:48.782
所以对应的 确保尽量不要使用浮点型

00:20:48.849 --> 00:20:52.419
因为这会把一个半字节运算

00:20:52.486 --> 00:20:55.455
输入半字节型 返回半字节型
变成一个浮点型运算

00:20:55.522 --> 00:20:57.291
因为根据语法

00:20:57.357 --> 00:21:01.061
这实际上是一个浮点型运算
因为输入值中至少有一个是浮点型

00:21:01.762 --> 00:21:03.764
所有你可能想要做么做

00:21:04.565 --> 00:21:06.433
事实上 这就会是一个半字节型运算

00:21:06.500 --> 00:21:08.101
而且会变得更快

00:21:08.602 --> 00:21:10.204
这可能就是你所说的

00:21:10.504 --> 00:21:14.007
所以要注意 不要在不经意间
引入浮点型精度的运算

00:21:14.074 --> 00:21:15.909
在你的代码中
当你其实并不想要它时

00:21:19.079 --> 00:21:21.715
虽然我刚才说了数据类型越小越好

00:21:21.782 --> 00:21:24.551
有一个例外是字符型

00:21:25.085 --> 00:21:27.554
在A8及更新的处理器上
原生的数据类型大小

00:21:27.621 --> 00:21:31.058
是16位的 而不是8位的

00:21:31.391 --> 00:21:35.529
所以字符型并不会节省空间
或者能耗或者其它一些东西

00:21:35.596 --> 00:21:38.365
进一步说 没有原生的8位运算

00:21:38.432 --> 00:21:40.100
所以它似乎要被仿真

00:21:40.167 --> 00:21:43.470
如果你需要的话
它不会过度的耗资源 随便用

00:21:43.537 --> 00:21:45.606
但是它可能会导致额外的指令

00:21:45.839 --> 00:21:48.675
所以不要把变量压缩为字符型

00:21:48.742 --> 00:21:50.544
在没有必要的时候

00:21:53.981 --> 00:21:57.217
所以接下来我们会有计算优化

00:21:57.451 --> 00:22:01.288
在这个类别中
几乎所有的都会影响ALU带宽

00:22:01.989 --> 00:22:05.926
你能做的第一件事情始终
是尽量使用Metal内置

00:22:06.293 --> 00:22:09.096
它们是给各种不同的函数优化实现的

00:22:09.162 --> 00:22:11.164
它们已经为硬件进行了优化

00:22:11.231 --> 00:22:13.700
通常来讲 会比你自己实现的要好

00:22:14.334 --> 00:22:16.170
特别的

00:22:16.470 --> 00:22:20.574
实际上 他们中的一些通常是免费的

00:22:21.375 --> 00:22:24.344
这是因为图形处理器通常都有修改工具

00:22:24.444 --> 00:22:28.849
运算可以通过输入输出指令免费地执行

00:22:28.916 --> 00:22:32.085
对于A8及以后的图形处理器
通常包括非门

00:22:32.152 --> 00:22:36.690
绝对值和饱和值 像你们看到的一样
这三种绿色的运算符

00:22:37.090 --> 00:22:41.962
所以 没有必要尝试着
让你的代码更加聪明或者加速它

00:22:42.029 --> 00:22:43.297
通过避免这些

00:22:43.363 --> 00:22:45.399
同样是因为他们几乎总是免费的

00:22:45.632 --> 00:22:48.302
因为他们是免费的
你不可能比免费更加好

00:22:48.368 --> 00:22:50.304
无法在免费的基础上再进行优化了

00:22:52.706 --> 00:22:56.944
A8及更新的图形处理器
和很多其它处理器一样 是标量机器

00:22:57.277 --> 00:22:59.513
而着色器通常是用向量表示的

00:22:59.580 --> 00:23:02.382
编译器会把它们在内部分离开来

00:23:02.716 --> 00:23:05.552
当然 写向量代码并没有什么坏处

00:23:05.819 --> 00:23:08.889
它经常更加清晰 也更容易维护

00:23:08.956 --> 00:23:10.724
而且它符合你想要的东西

00:23:11.158 --> 00:23:14.995
但是它也不会比写标量代码更加好
从编译器的角度

00:23:15.062 --> 00:23:16.163
和你要得到的代码

00:23:16.530 --> 00:23:19.399
所以没有必要去向量化代码

00:23:19.466 --> 00:23:21.902
那并不符合向量格式

00:23:21.969 --> 00:23:24.771
因为最后它只会导致一样的东西

00:23:24.872 --> 00:23:26.507
而你浪费了你的时间

00:23:27.241 --> 00:23:30.777
但是 从一个侧面说明
我等会儿会深入说一下

00:23:30.844 --> 00:23:32.179
在A8及更新图像处理器上

00:23:32.246 --> 00:23:36.149
确实有向量加载在存储里
尽管他们没有向量运算

00:23:36.850 --> 00:23:39.119
所以这只是应用于算术

00:23:40.921 --> 00:23:42.556
指令级别并行

00:23:42.623 --> 00:23:45.259
你们中有些人可能已经优化过了

00:23:45.325 --> 00:23:47.327
特别是若你做过中央处理器相关的工作

00:23:47.794 --> 00:23:51.765
但是在A8及更新的图形处理器上
这通常不是一个好事情

00:23:51.832 --> 00:23:55.202
去尝试优化它
因为通常它要与寄存器使用竞争

00:23:55.269 --> 00:23:57.371
而寄存器使用通常更重要

00:23:57.905 --> 00:24:00.974
所以你可能见过的一种普通模式是一种

00:24:01.041 --> 00:24:03.243
你有多个有序的加法器

00:24:03.310 --> 00:24:07.181
在图形处理器上更好地处理延迟

00:24:07.748 --> 00:24:11.385
但是在A8及更新的图形处理器上
这可能是降低效率的

00:24:11.685 --> 00:24:13.921
你最好只使用一个累加器

00:24:14.087 --> 00:24:16.523
当然 这会导致更多的复杂例子

00:24:16.590 --> 00:24:18.692
比人工的简单例子

00:24:19.159 --> 00:24:20.127
简而言之

00:24:20.194 --> 00:24:23.263
不要尝试去重新结构化你的代码
从中得到更多的ILP

00:24:23.330 --> 00:24:25.499
这可能并不会对你有所帮助

00:24:25.566 --> 00:24:27.801
最糟糕的是 你的代码可能变得更差

00:24:29.603 --> 00:24:33.240
所以在A8及更新的图形处理器上
有个相当好的功能

00:24:33.307 --> 00:24:37.744
就是它们有着非常快速的选择指令集
它们是三元运算符

00:24:38.412 --> 00:24:43.483
过去 使用一些小聪明是非常普遍的
就像这个

00:24:43.550 --> 00:24:49.056
在三元运算符中执行选择操作
为了避免那些分支等等

00:24:49.523 --> 00:24:52.860
但是在现代图形处理器上
这些通常会是起相反的效果

00:24:52.926 --> 00:24:55.262
特别是对于A8及更新的图形处理器

00:24:55.329 --> 00:24:57.731
因为编译器不会考虑这些小聪明

00:24:57.798 --> 00:25:00.100
它不会明白你的真实意图

00:25:00.567 --> 00:25:02.769
真的 这是非常糟糕的

00:25:03.504 --> 00:25:04.771
你可能刚刚写了这个

00:25:04.838 --> 00:25:06.940
而且它会更快 更短

00:25:07.007 --> 00:25:08.442
它会展示你的意图

00:25:08.909 --> 00:25:12.412
像以前一样 太过聪明反而会变得复杂

00:25:12.479 --> 00:25:14.648
你所做的会使编译器困惑

00:25:16.783 --> 00:25:20.120
现在 它就是一个潜在的陷阱
希望这不会经常发生

00:25:20.988 --> 00:25:26.026
对于相对的图形处理器
它们中的大部分都没有整数除法运算

00:25:26.093 --> 00:25:29.029
或者取余数指令集
整数型而不是浮点型

00:25:29.530 --> 00:25:33.767
所以避免除法运算

00:25:33.834 --> 00:25:36.603
不是字面的或者函数常量

00:25:36.670 --> 00:25:39.106
这个新特性在前面当然演讲中提到过

00:25:39.506 --> 00:25:42.209
所以在这个例子中 我们想说的是

00:25:42.276 --> 00:25:45.679
分母是一个变量

00:25:45.746 --> 00:25:47.681
那就会非常非常得慢

00:25:47.748 --> 00:25:49.650
想象一下成百上千的时钟秒针

00:25:50.284 --> 00:25:52.619
但是这另外两个例子 它们会非常得快

00:25:52.686 --> 00:25:53.554
它们是好的

00:25:53.620 --> 00:25:55.489
不要觉得你必须要避免它

00:25:57.558 --> 00:26:00.661
最后 快速数学运算的主题

00:26:00.994 --> 00:26:04.264
在Metal中 快速运算是默认的

00:26:04.331 --> 00:26:07.234
这是因为编译器是经过
快速运算优化过的

00:26:07.301 --> 00:26:09.903
这对Metal着色器的性能来说
至关重要

00:26:09.970 --> 00:26:14.875
这能提供50%或者更多的性能提升
相较于没有快速运算

00:26:14.942 --> 00:26:16.476
这也是为什么它是默认开启的

00:26:17.177 --> 00:26:20.214
那么在快速运算模式下
我们到底做了什么事情呢

00:26:20.781 --> 00:26:23.951
第一 一部分Metal中内置的函数

00:26:24.017 --> 00:26:27.454
对于有没有快速运算
有着不用的精度保证

00:26:27.521 --> 00:26:30.290
所以在某些函数中
它们会有稍微低一点的精度

00:26:30.357 --> 00:26:33.227
在快速运算模式中会有更好的性能

00:26:34.494 --> 00:26:37.497
编译器会提高中间件的精度

00:26:37.564 --> 00:26:40.734
对于你的运算
比如通过组成一个多个加法指令集

00:26:41.235 --> 00:26:44.171
这不会降低中间件的精度

00:26:44.605 --> 00:26:46.740
所以举个例子
如果你写了一个浮点型的运算

00:26:46.807 --> 00:26:50.310
你的这个运算至少是浮点型的运算

00:26:50.377 --> 00:26:51.578
不是一个数学运算

00:26:52.012 --> 00:26:53.647
若你想要写一个半字节型的运算

00:26:53.714 --> 00:26:56.450
你最好就自己写
编译器是不会帮你做的

00:26:56.517 --> 00:26:57.551
因为这是不被允许的

00:26:57.618 --> 00:27:00.053
它不会让你的精度达到那样

00:27:00.921 --> 00:27:03.824
我们确实会忽略
如果不是一个数字 无穷量

00:27:03.891 --> 00:27:06.527
和符号零 这是很重要的

00:27:06.593 --> 00:27:08.862
如果不那样的话 你不能真正证明

00:27:08.929 --> 00:27:11.198
x乘以0等于0

00:27:11.965 --> 00:27:16.503
但是我们不会引进一个新的NaN
不是一个数字

00:27:16.570 --> 00:27:20.240
因为现实中 那是一个非常好的方式

00:27:20.307 --> 00:27:22.442
来激怒开发者 毁坏他们的代码

00:27:22.509 --> 00:27:23.977
我们不想要这么做

00:27:24.845 --> 00:27:28.582
编译器会执行算术重整合

00:27:28.749 --> 00:27:30.617
但是不会做算术分配

00:27:30.684 --> 00:27:33.987
而且实际上 这不会毁坏代码

00:27:34.054 --> 00:27:36.456
而且会使得它更快

00:27:36.523 --> 00:27:38.192
我们不想毁坏代码

00:27:40.661 --> 00:27:43.997
所以无论什么原因
如果绝对不能使用快速运算

00:27:44.364 --> 00:27:47.434
还是有方法恢复一部分性能

00:27:48.168 --> 00:27:52.105
Metal有一个内置的
融合的乘法加法

00:27:52.172 --> 00:27:55.509
它允许你直接请求
融合的乘法加法指令集

00:27:55.809 --> 00:27:57.077
当然如果快速运算被停用

00:27:57.144 --> 00:27:59.246
编译器就不会被允许编译它们

00:27:59.313 --> 00:28:02.850
它不会改变你的四舍五入的一位
这是被禁止的

00:28:03.350 --> 00:28:06.854
所以如果你想要使用融合的乘法加法
而且快速运算是停用的

00:28:06.920 --> 00:28:08.422
你需要使用内置的

00:28:09.122 --> 00:28:11.091
而且那会重新增加一部分的性能

00:28:11.425 --> 00:28:13.393
不是所有的性能 但至少有一部分

00:28:15.028 --> 00:28:17.598
所以 我们的第三个话题 控制流程

00:28:18.365 --> 00:28:20.667
预测的GP控制流程不是一个新的话题

00:28:20.734 --> 00:28:22.769
你们中的一些人
可能对此已经非常熟悉了

00:28:22.836 --> 00:28:25.038
但我快速回顾一下
这对你来说有什么意义

00:28:25.539 --> 00:28:27.875
控制流程在SIMD中是一致的

00:28:27.941 --> 00:28:31.345
每一个线程都在做同一件事情
相当的快速

00:28:31.979 --> 00:28:35.048
就算编译器看不到它 这也是真的

00:28:35.482 --> 00:28:38.919
所以如果你的程序看上去不一致

00:28:38.986 --> 00:28:41.355
但是只有当运行的时候它才一致

00:28:41.421 --> 00:28:43.357
那仍然是很快的

00:28:44.024 --> 00:28:46.793
类似的 这个分歧的另一面

00:28:46.860 --> 00:28:49.296
不同的道路做不同的事情

00:28:49.363 --> 00:28:51.932
在那个例子中 它可能不得不运行

00:28:51.999 --> 00:28:54.334
于所有的路径 同时地

00:28:54.401 --> 00:28:57.738
不同于中央处理器在一个时间点
只会选择一个路径

00:28:58.372 --> 00:29:00.841
因为它会做更多的工作

00:29:00.908 --> 00:29:03.076
当然也就意味着不高效的控制流程

00:29:03.143 --> 00:29:04.878
会影响任意一个瓶颈

00:29:04.945 --> 00:29:07.681
因为它只是直接地表明
图像处理器做了更多事情

00:29:07.748 --> 00:29:09.383
无论是什么事情

00:29:11.151 --> 00:29:15.622
所以 在控制流程这个话题上
我给大家的一个建议

00:29:15.889 --> 00:29:18.392
是避免切换fall-through

00:29:18.659 --> 00:29:20.961
这在中央处理器的代码中非常的普遍

00:29:21.028 --> 00:29:23.997
但是对于图像处理器
它们可能会成为低效

00:29:24.264 --> 00:29:28.302
因为编译器不得不做相当严重的转型

00:29:28.368 --> 00:29:31.038
为了让它们符合
图像处理器的控制流程模型

00:29:31.104 --> 00:29:34.541
而且经常的 这会导致冗余的代码
和各种各样的麻烦的东西

00:29:34.608 --> 00:29:36.643
你可能不希望发生这样的事情

00:29:37.144 --> 00:29:40.280
若你能找到好方法来避免
代码中fall-through切换

00:29:40.347 --> 00:29:42.049
你可能会变的更好

00:29:43.550 --> 00:29:45.285
现在到了我们最后一个话题

00:29:45.352 --> 00:29:46.186
内存访问

00:29:46.453 --> 00:29:50.557
我们现在先从大家最可能碰到
的陷阱开始说

00:29:50.624 --> 00:29:54.962
那是动态地索引非常量堆数组

00:29:55.128 --> 00:29:56.463
这是非常有争议的

00:29:56.530 --> 00:30:00.467
但你们中很多人可能已熟悉这些代码了
大致上看上去着这样的

00:30:00.968 --> 00:30:05.472
你有一个包含数值的数组
在运行时被定义

00:30:05.539 --> 00:30:08.509
在每一个线程或者
每一个函数调用中变化

00:30:08.575 --> 00:30:12.079
而且你索引这个数字
通过另外一个也是变量的值

00:30:12.346 --> 00:30:15.315
这就是动态索引非常量堆

00:30:15.782 --> 00:30:17.284
在我们继续之前

00:30:17.351 --> 00:30:19.520
我不会想当然的认为

00:30:19.586 --> 00:30:21.455
对于图形处理器 堆栈是慢的

00:30:21.522 --> 00:30:22.723
我会解释为什么

00:30:23.223 --> 00:30:27.628
所以 对于中央处理器
通常你有多个线程 或者几十个线程

00:30:27.694 --> 00:30:30.330
且你有几MB的缓存分配在这些线程中

00:30:30.898 --> 00:30:33.767
所以每一个线程可能有
成千上百KB的堆栈空间

00:30:33.834 --> 00:30:36.503
在它们变慢和不得不去处理主内存之前

00:30:37.271 --> 00:30:40.941
对于图形处理器
通常会有成千上万的线程在同时跑

00:30:41.441 --> 00:30:43.977
而且它们都在分享一个小得多的缓存

00:30:44.244 --> 00:30:45.812
所以平均下来

00:30:45.879 --> 00:30:48.448
每一个线程只有非常小的空间
给数据和堆栈

00:30:49.116 --> 00:30:52.085
这不单单意味着那个这不是很高效

00:30:52.152 --> 00:30:54.821
作为一个惯例
对于绝大多数的图形处理器程序

00:30:54.888 --> 00:30:57.191
如果你使用堆栈 你已经输了

00:30:57.257 --> 00:31:01.628
这会非常慢
使得几乎其他任何东西都本有可能更好

00:31:02.596 --> 00:31:05.265
一个真实世界的应用

00:31:05.332 --> 00:31:10.571
程序开始时 它需给向量
从两个浮点型数据中选择一个

00:31:10.637 --> 00:31:13.941
它用了32字节的数组
一组两个浮点型数据

00:31:14.007 --> 00:31:16.844
在他它们中选择 使用这个堆栈数组

00:31:16.910 --> 00:31:18.946
这会导致30%的性能损失

00:31:19.012 --> 00:31:21.081
在这个程序中 尽管只在开始时做一次

00:31:22.449 --> 00:31:24.051
这也会是相当的重要

00:31:24.651 --> 00:31:27.554
当然每次我们提高编译器的时候

00:31:27.621 --> 00:31:29.923
我们要尽量避免

00:31:29.990 --> 00:31:31.425
尽量

00:31:31.491 --> 00:31:35.195
避免产生这些堆栈访问
因为这是不好的

00:31:35.729 --> 00:31:38.699
现在我要给大家展示两个好的例子

00:31:39.566 --> 00:31:43.804
另外一个 哪些是常量 不是变量

00:31:43.937 --> 00:31:46.707
那不是一个非常量堆栈数组 没关系

00:31:47.174 --> 00:31:50.177
因为每一个线程的值不会变化

00:31:50.244 --> 00:31:51.845
它们不需要在每个线程中被复制

00:31:52.412 --> 00:31:53.480
所以这是可以的

00:31:54.781 --> 00:31:56.416
这个也是可以的

00:31:56.550 --> 00:31:59.820
等等 为什么？
这仍然是一个动态索引非常量堆栈数组

00:32:00.120 --> 00:32:02.656
但是它只是做动态索引 因为这个回路

00:32:03.257 --> 00:32:06.126
而且编译器会展开这个回路

00:32:06.393 --> 00:32:09.463
实际上 你的编译器展开任意的回路

00:32:09.530 --> 00:32:12.432
那会访问这个堆栈
为了让它停止这么做

00:32:13.166 --> 00:32:16.370
所以在这个例子中
它被展开后 就不再被动态索引了

00:32:16.436 --> 00:32:18.739
它会变得很快 值得提出来的是

00:32:18.805 --> 00:32:21.375
因为在大量的图形学代码中
这是非常普通的模式

00:32:21.441 --> 00:32:24.678
而且我不想吓唬你不要这么做
当它可能还行的时候

00:32:26.146 --> 00:32:27.481
既然我们已经讲了这个主题

00:32:27.548 --> 00:32:30.250
关于如何不要做加载和存储这些类型

00:32:30.450 --> 00:32:34.555
让我们继续讲加载和存储
我们会讲得快一些

00:32:35.355 --> 00:32:37.925
当A8及更新的图像处理器
都是用标量算法

00:32:37.991 --> 00:32:41.228
正如我前面说过的那样
它们确实有向量内存单元

00:32:41.995 --> 00:32:45.432
一个大的向量加载资源自然比

00:32:45.499 --> 00:32:48.602
多个小向量要快
当小向量相加大小和这一个大向量一样

00:32:49.536 --> 00:32:52.206
这通常会影响内存处理速率瓶颈

00:32:52.272 --> 00:32:55.509
因为你通过负载来运行 那没多少负载

00:32:56.176 --> 00:33:00.013
对于iOS 10
我们新的编译器优化中的一点

00:33:00.080 --> 00:33:02.749
是我们会去向量化一些负载和存储

00:33:02.816 --> 00:33:05.385
会去尽可能地邻接内存位置

00:33:05.719 --> 00:33:08.055
同样是因为它可以给出好的性能提升

00:33:08.889 --> 00:33:13.227
虽然如此
这是一个处理编译器时的例子

00:33:13.293 --> 00:33:15.429
可能会很有帮助 我给大家举个例子

00:33:16.263 --> 00:33:18.265
正如你们看到的这样
这是一个简单的回路

00:33:18.365 --> 00:33:21.268
它做了一些计算和
读取了一个结构体数组

00:33:21.869 --> 00:33:25.072
但是在每一步循环 它只读取两个加载

00:33:25.439 --> 00:33:27.574
现在如果可以 我们想要它变成一个

00:33:27.641 --> 00:33:29.009
因为一个比两个要好

00:33:29.276 --> 00:33:31.979
而且编译器也想这样

00:33:32.045 --> 00:33:34.348
它想要向量化这个 但是它做不到

00:33:34.414 --> 00:33:36.817
因为A和C在内存中不是紧挨着的

00:33:36.884 --> 00:33:37.818
所以它什么都做不了

00:33:37.885 --> 00:33:39.987
编译器是不被允许重新安排结构体的

00:33:40.153 --> 00:33:41.355
所以我们有两个负载

00:33:42.089 --> 00:33:43.590
对此有两个解决办法

00:33:43.924 --> 00:33:46.460
第一 当然是把它变成一个浮点型

00:33:46.527 --> 00:33:47.961
它就是向量负载了 结束了

00:33:48.629 --> 00:33:50.330
一个负载 两个一组 什么都好了

00:33:51.098 --> 00:33:54.935
而且 对于iOS 10
这也一个相同的快速

00:33:55.202 --> 00:33:58.472
因为在这里 我们重拍了我们的结构体
让值一个接一个

00:33:58.705 --> 00:34:01.942
那样编译器可以向量化负载
当它做这个的时候

00:34:02.176 --> 00:34:05.279
这同样是一个处理编译器的例子

00:34:05.579 --> 00:34:08.549
编译器被允许做一些
它以前做不了的事情

00:34:08.649 --> 00:34:11.217
因为你知道到底发生了什么

00:34:11.284 --> 00:34:15.255
你知道如何选择模式 使得编译器开心

00:34:15.422 --> 00:34:17.357
让它可以做

00:34:19.826 --> 00:34:22.929
所以 另外一个要记住的
关于负载和存储的事情

00:34:22.996 --> 00:34:26.166
是A8和更新的图像处理器
有专门的硬件

00:34:26.233 --> 00:34:28.135
给设备内存地址分配

00:34:28.467 --> 00:34:31.737
但是这个硬件是有限制的

00:34:32.406 --> 00:34:36.409
访问设备内存的偏移量
必须在有符号整型的范围内

00:34:36.777 --> 00:34:39.213
小一点的数据类型
比如短整型和无符号短整型也是可以的

00:34:39.279 --> 00:34:40.981
实际上 它们是被强烈推荐的

00:34:41.348 --> 00:34:43.717
因为那些也是在有符号整型的范围的

00:34:44.284 --> 00:34:46.786
但是 无符号整型当然不是的

00:34:46.853 --> 00:34:49.089
因为他可能有值超出了
有符号整型的范围

00:34:49.623 --> 00:34:53.994
所以如果编译器发生一种情况

00:34:54.061 --> 00:34:56.630
当偏移量是一个无符号整型
就不能保证

00:34:56.697 --> 00:34:58.899
它会很好的待在有符号整型的范围内

00:34:59.199 --> 00:35:01.602
必须手动地计算地址

00:35:02.069 --> 00:35:04.071
而不是让专用硬件来做这个

00:35:04.371 --> 00:35:05.639
那样会浪费电量

00:35:05.706 --> 00:35:08.876
它会浪费ALU性能等等

00:35:08.942 --> 00:35:10.077
这是不好的

00:35:10.544 --> 00:35:15.249
所以 把你的偏移量转为整型
这样问题就解决了

00:35:15.315 --> 00:35:18.619
当然利用这个通常会节省ALU带宽

00:35:21.421 --> 00:35:24.124
所以在我们的最后一个话题上
我前面有所掩盖

00:35:24.191 --> 00:35:25.492
延迟和占用

00:35:26.193 --> 00:35:30.197
现代图像处理器的核心设计之一
是隐藏延迟

00:35:30.264 --> 00:35:32.132
通过使用大规模的多线程

00:35:32.566 --> 00:35:34.701
所以当它们等待一些慢的东西结束

00:35:34.768 --> 00:35:37.604
比如纹理读取
它们只是运行另一个线程

00:35:37.671 --> 00:35:39.273
而不是坐着什么都不干
只是等待

00:35:39.339 --> 00:35:40.407
这是相当重要的

00:35:40.474 --> 00:35:43.343
因为纹理读取通常要花好几百个循环

00:35:43.410 --> 00:35:44.645
才能结束 平均下来

00:35:47.214 --> 00:35:49.483
所以你在着色器中延迟越多

00:35:49.550 --> 00:35:52.052
你就需要更多的线程来隐藏延迟

00:35:52.519 --> 00:35:54.154
你有多少线程呢？

00:35:54.221 --> 00:35:57.191
这限制于你有一定数量的资源

00:35:57.257 --> 00:35:59.693
它们被一个线程组中的线程共享

00:36:00.027 --> 00:36:02.629
所以显然基于每一个线程的使用量

00:36:02.696 --> 00:36:04.598
你需要限制线程的数量

00:36:04.831 --> 00:36:06.934
相冲突的两件事情是

00:36:07.000 --> 00:36:08.769
寄存器和线程组存储器的数量

00:36:09.303 --> 00:36:11.138
所以在每个线程中你使用寄存器越多

00:36:11.305 --> 00:36:12.606
你就不能使用这么多线程

00:36:12.706 --> 00:36:13.540
太简单了

00:36:13.707 --> 00:36:15.976
如果你在每个线程中使用的线程组越多

00:36:16.043 --> 00:36:18.645
你又会遭遇同样的问题

00:36:18.812 --> 00:36:20.948
每一个线程对于你的线程

00:36:21.648 --> 00:36:25.152
你可以检查着色器的实际占用率

00:36:25.552 --> 00:36:31.291
用MTLComputePipeLineState
导致maxTotalThreadsPerThreadgroup

00:36:31.558 --> 00:36:35.195
这将告诉你着色器的实际占有率是多少

00:36:35.262 --> 00:36:39.533
基于寄存器的使用率
和线程组存储器的使用率

00:36:39.833 --> 00:36:42.336
所以当我们说着色器延迟限制

00:36:42.536 --> 00:36:45.739
这意味着用来
隐藏着色器延迟的线程太少

00:36:45.806 --> 00:36:47.441
这时 你可以做两件事情

00:36:47.608 --> 00:36:49.610
你可以减少着色器的延迟

00:36:50.010 --> 00:36:52.412
保存寄存器 另外一件事是

00:36:52.479 --> 00:36:54.882
避免使用更多的线程

00:36:56.984 --> 00:37:03.857
所以 对于一个非常大而复杂的着色器
克服延迟是有点困难的

00:37:04.157 --> 00:37:06.226
我将会重温一些伪代码实例

00:37:06.293 --> 00:37:08.195
可能会给你强烈的直觉

00:37:08.262 --> 00:37:12.933
在你的着色器中
如何考虑延迟和怎样略微理智地建模

00:37:14.001 --> 00:37:16.670
所以 这儿有一个REAL的依赖案例

00:37:17.004 --> 00:37:19.606
有一个纹理样本
然后我们使该纹理样本

00:37:19.673 --> 00:37:21.708
执行if语句

00:37:21.775 --> 00:37:24.311
然后我们在x语句里
创建另一个纹理样本

00:37:24.912 --> 00:37:25.979
我们必须等两次

00:37:26.046 --> 00:37:28.715
因为我们在执行if语句前必须等一次

00:37:29.016 --> 00:37:31.485
在使用值之前又必须等一次

00:37:31.552 --> 00:37:32.753
第二个纹理样本的

00:37:33.086 --> 00:37:38.725
两次连续的纹理访问造成总共两次延迟

00:37:40.260 --> 00:37:42.229
这儿有一个错误的依赖案例

00:37:42.296 --> 00:37:43.397
该依赖看来很像另个

00:37:43.463 --> 00:37:45.999
除非我们在if语句中不使用它

00:37:46.900 --> 00:37:51.071
但是通常我们不能等待跨控制流程

00:37:51.271 --> 00:37:54.374
这种情况下if语句
成为了一个严重的障碍

00:37:54.641 --> 00:37:58.345
所以我们不得不等

00:37:58.412 --> 00:37:59.780
即使没有数据依赖

00:38:00.047 --> 00:38:01.648
所以我们仍然有两次延迟

00:38:01.915 --> 00:38:05.652
当你意识到GPU并不在乎数据依赖

00:38:05.986 --> 00:38:09.389
它只在乎出现什么依赖

00:38:09.890 --> 00:38:13.861
这样第二个依赖的
延迟时间和第一个是一样的

00:38:13.927 --> 00:38:16.029
即使那儿没有数据依赖

00:38:17.431 --> 00:38:19.366
最后有个简单的依赖

00:38:19.433 --> 00:38:21.335
在顶端你仅仅获取两个纹理

00:38:21.869 --> 00:38:26.640
它们都被并行获取
这样我们就只等一次

00:38:26.740 --> 00:38:29.176
所以就是1 x延迟而不是2 x延迟

00:38:30.110 --> 00:38:32.613
所以 运用这个知识你将会干什么呢？

00:38:32.679 --> 00:38:36.016
在很多实际着色器中 你有机会

00:38:36.083 --> 00:38:38.452
在延迟和吞吐量之间权衡

00:38:39.019 --> 00:38:41.788
一个常见的案例是

00:38:41.855 --> 00:38:45.125
你能决定代码以一个纹理获取为依据

00:38:45.192 --> 00:38:48.095
在这个着色器中我们不必做任何事
还是早点放弃

00:38:48.495 --> 00:38:50.364
而且这是非常有意义的

00:38:50.430 --> 00:38:53.300
因为在这种情况下你要做的事情

00:38:53.367 --> 00:38:56.069
将不必做 你正在保存所有的工作

00:38:56.270 --> 00:38:57.171
太棒了

00:38:57.671 --> 00:39:01.808
但是当你增加吞吐量

00:39:02.509 --> 00:39:04.378
通过减少你需要干的工作

00:39:05.012 --> 00:39:07.948
但是你也增加了延迟

00:39:08.015 --> 00:39:12.853
因为现在必须获取第一个纹理
然后等待纹理获取

00:39:13.320 --> 00:39:14.955
接着做早期的终止检查

00:39:15.255 --> 00:39:17.758
接着做其它的纹理获取

00:39:18.192 --> 00:39:21.295
呃 会更快吗？难道不是吗？

00:39:21.361 --> 00:39:23.964
时常你只需要测试一下

00:39:24.298 --> 00:39:27.534
因为哪个更快真正依赖的是着色器

00:39:27.601 --> 00:39:31.038
但是值得考虑的事时常是真正的权衡

00:39:31.104 --> 00:39:33.440
你时常要测试来明确什么是正确的

00:39:34.174 --> 00:39:35.876
虽然没有通用规则

00:39:35.943 --> 00:39:40.447
我可以针对A8和后期的GPUs
给你一个独特的的指南

00:39:40.514 --> 00:39:45.485
那就是同一时刻
硬件至少需要两个纹理获取

00:39:45.552 --> 00:39:47.955
来获得足够的性能来避免延迟

00:39:48.222 --> 00:39:49.456
一个是不够的

00:39:49.823 --> 00:39:51.558
如果你只能做一次 没有问题

00:39:51.625 --> 00:39:53.760
但是如果你有一些选择

00:39:53.827 --> 00:39:55.829
来分配着色器中的纹理获取

00:39:55.896 --> 00:39:58.131
如果你同一时刻允许它做两次

00:39:58.198 --> 00:39:59.833
你会获得更好的性能

00:40:01.235 --> 00:40:02.569
所以 总结就是

00:40:03.504 --> 00:40:04.371
确保你选择了

00:40:04.438 --> 00:40:07.708
正确的地址空间 数据结构 布局等等

00:40:07.774 --> 00:40:10.344
因为把这个弄错会导致

00:40:10.410 --> 00:40:13.080
这个演讲中的其它东西都不重要了

00:40:14.314 --> 00:40:15.516
用编译器工作

00:40:15.582 --> 00:40:16.950
写下你想的

00:40:17.017 --> 00:40:18.452
不要尝试着太聪明

00:40:18.519 --> 00:40:21.188
否则编译器不知道你想什么而迷失

00:40:21.421 --> 00:40:22.789
且不能做好它自己的任务

00:40:23.590 --> 00:40:25.459
另外 写下你想的是很简单的

00:40:26.894 --> 00:40:30.163
注意大陷阱而不仅仅是极小的优化

00:40:30.297 --> 00:40:33.800
它们时常不明显而且它们也不时常发生

00:40:33.867 --> 00:40:35.302
但当它们发生时 会导致严重的问题

00:40:35.369 --> 00:40:39.339
它们导致的问题如此严重
以至于再多的小优化都无法弥补

00:40:40.908 --> 00:40:42.576
随意试验

00:40:42.643 --> 00:40:44.845
会发生很多定律权衡

00:40:44.912 --> 00:40:47.648
根本就没有单一的定律

00:40:47.981 --> 00:40:49.950
全部都试一下 看哪种更快

00:40:51.818 --> 00:40:54.354
如果你想要更多的信息 上网查询

00:40:54.421 --> 00:40:55.822
演讲视频就在网上

00:40:57.724 --> 00:40:58.825
还有其它的演讲

00:40:58.892 --> 00:41:01.695
如果你又错过了 视频在网上都会有的

00:41:02.863 --> 00:41:03.697
谢谢