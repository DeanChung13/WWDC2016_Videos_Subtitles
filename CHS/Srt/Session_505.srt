00:00:20.087 --> 00:00:22.956
使用Core Image编辑
Live Photo和RAW处理

00:00:29.396 --> 00:00:30.831
非常感谢各位 早上好

00:00:30.898 --> 00:00:34.168
我叫David Hayward
今天我要讲的是

00:00:34.234 --> 00:00:37.671
关于使用Core Image编辑
Live Photos和Raw图片

00:00:37.738 --> 00:00:40.307
我们今天要讲很多不错的东西

00:00:40.741 --> 00:00:42.910
首先我简单介绍一下
Core Image

00:00:42.976 --> 00:00:44.878
如果你对它一无所知的话

00:00:45.145 --> 00:00:48.015
接下来我们会谈下
我们今早的三个主要话题

00:00:48.081 --> 00:00:50.918
第一 在iOS上调整RAW图片

00:00:51.485 --> 00:00:53.921
第二 编辑Live Photos

00:00:54.154 --> 00:00:56.557
第三 如何扩展Core Image

00:00:56.623 --> 00:00:59.426
通过全新的方式 即利用
CIImageProcessor节点

00:01:01.195 --> 00:01:03.664
首先 是对于Core Image的
简单介绍

00:01:04.697 --> 00:01:07.701
选择Core Image的原因是
它提供了一个非常简单

00:01:07.768 --> 00:01:10.871
高性能的API来将滤镜应用到图片上

00:01:11.371 --> 00:01:14.041
基本的想法就是你开始有一张图片

00:01:14.107 --> 00:01:16.844
其来自于JPEG或某个文件或内存
你可以选择

00:01:16.910 --> 00:01:19.646
对其应用一个滤镜 结果就是输出图片

00:01:20.013 --> 00:01:22.349
在你的代码中实现是非常非常简单的

00:01:22.716 --> 00:01:26.553
你只需要调取你的图片
调用applyingFilter

00:01:26.620 --> 00:01:28.188
并声明滤镜的名字

00:01:28.488 --> 00:01:31.058
以及其他适用于该滤镜的参数

00:01:31.458 --> 00:01:32.359
这非常简单

00:01:32.659 --> 00:01:34.728
当然了你可以完成更复杂的事情

00:01:34.795 --> 00:01:36.897
你可以将多个滤镜链在一起使用...

00:01:37.297 --> 00:01:41.168
应用到序列或是图片上
并获得非常复杂的效果

00:01:42.269 --> 00:01:46.106
Core Image的一个非常棒
的特性就是它提供了自动颜色管理

00:01:46.373 --> 00:01:48.375
这对于现如今很重要

00:01:48.542 --> 00:01:50.477
我们现在有很多设备

00:01:50.677 --> 00:01:53.647
支持宽色域的输入和输出

00:01:54.114 --> 00:01:56.550
Core Image所做的就是
它会自动插入

00:01:56.617 --> 00:01:58.785
恰当的节点到渲染图中去

00:01:58.986 --> 00:02:01.355
以便它与你的输入图像匹配

00:02:01.421 --> 00:02:03.123
到Core Image的工作域

00:02:03.190 --> 00:02:04.825
而到了要显示的时候

00:02:04.892 --> 00:02:07.561
它会从工作域匹配到显示域

00:02:08.562 --> 00:02:10.830
这是你应该特别注意的

00:02:10.898 --> 00:02:14.801
因为宽色域图片和宽色域显示
现在都很常见了

00:02:15.636 --> 00:02:18.605
而很多做图像处理的开源库

00:02:19.106 --> 00:02:20.440
不会自动处理它

00:02:20.507 --> 00:02:23.143
这是Core Image很棒的特性
因为它处理了所有这些

00:02:23.210 --> 00:02:24.878
让你很容易的使用

00:02:27.114 --> 00:02:29.416
另一个要注意的是每个滤镜

00:02:29.950 --> 00:02:32.119
实际上是附带着一小段代码的

00:02:32.186 --> 00:02:33.921
叫做kernel的小小子程序

00:02:34.621 --> 00:02:37.591
我们所有内置滤镜
都有这些kernel

00:02:37.791 --> 00:02:41.595
一个不错的特性是
如果你将一个序列的滤镜链在一起

00:02:41.895 --> 00:02:44.264
Core Image会自动连接这些

00:02:44.331 --> 00:02:46.333
子程序成单个程序

00:02:46.700 --> 00:02:49.069
这么做是为了提高性能

00:02:49.136 --> 00:02:51.505
通过减少

00:02:51.572 --> 00:02:53.774
通过减少中间缓存的数量

00:02:56.677 --> 00:02:58.979
Core Image
有逾180个内置滤镜

00:02:59.046 --> 00:03:01.748
它们在我们的所有平台上都是一样的

00:03:02.115 --> 00:03:05.219
不管是macOS tvOS
还是iOS

00:03:05.519 --> 00:03:08.155
我想谈下今年我们新发布的一些滤镜

00:03:08.488 --> 00:03:12.392
其中一个是用来生成色彩饱和度和梯度

00:03:12.860 --> 00:03:15.362
它会生成色彩和饱和度的梯度

00:03:15.596 --> 00:03:17.698
然后你可以声明一个参数

00:03:17.998 --> 00:03:19.266
关于图片的亮度

00:03:19.333 --> 00:03:21.835
也声明了颜色轮内的色域

00:03:22.302 --> 00:03:26.273
如你所料
此滤镜目前在用在macOS上

00:03:26.340 --> 00:03:28.775
作为颜色选择器的基础

00:03:29.343 --> 00:03:32.880
目前可以识别几个不同类型的显示色域

00:03:35.249 --> 00:03:40.821
另一个新滤镜是
CINinePartStretched and NinePartTiled

00:03:40.888 --> 00:03:43.423
你可能有一个小的资源

00:03:43.490 --> 00:03:44.958
像是这个画框

00:03:45.025 --> 00:03:48.262
而你想要拉伸它使其适应一个特定尺寸

00:03:48.328 --> 00:03:49.863
这个滤镜非常容易使用

00:03:49.930 --> 00:03:55.002
你需要提供一个输入图片和四个断点

00:03:55.068 --> 00:03:56.570
水平的两个 垂直的两个

00:03:56.637 --> 00:03:59.306
一旦你声明了这些点之后 你可以声明

00:03:59.373 --> 00:04:00.908
你想让其拉伸到多大的尺寸

00:04:01.375 --> 00:04:02.442
它非常容易用

00:04:05.546 --> 00:04:07.881
第三个新滤镜很有意思

00:04:07.948 --> 00:04:11.652
开始时我们有个很小的输入图片

00:04:11.952 --> 00:04:13.754
在这里有一个包含有颜色数据的图片

00:04:13.820 --> 00:04:16.089
但它也可以包含参数数据

00:04:16.356 --> 00:04:19.560
假设你有一个小的颜色或者参数集合

00:04:19.826 --> 00:04:21.894
可能只有6乘7个像素

00:04:22.162 --> 00:04:25.299
你想要扩展到全尺寸的图片上

00:04:26.233 --> 00:04:30.304
我们要做的是扩展颜色图像
这个小的颜色图像

00:04:30.838 --> 00:04:34.041
但是维护底图图形的边

00:04:34.441 --> 00:04:37.578
如果你不维护底图图形
而只是拉伸

00:04:37.644 --> 00:04:40.647
小的图片和全尺寸的图像一边大

00:04:40.714 --> 00:04:43.283
你只会得到一张混合颜色的图片

00:04:43.350 --> 00:04:45.152
但利用这个滤镜你可得到更多东西

00:04:45.219 --> 00:04:46.553
你可以得到

00:04:46.620 --> 00:04:49.623
维护边和颜色的图片

00:04:49.823 --> 00:04:53.060
这对于很多其他类型的算法来说
也是个有用的特性

00:04:53.126 --> 00:04:56.864
事实上
我们在新版本的照片应用里就用到了它

00:04:56.930 --> 00:05:00.334
来提高调光滑条的表现

00:05:01.535 --> 00:05:04.137
我期待看到你在你的应用里会怎么用

00:05:04.638 --> 00:05:07.040
我们今年也做了一些新的性能控制

00:05:07.608 --> 00:05:10.410
今年还对Core Image性能
做了改善

00:05:10.677 --> 00:05:13.447
其中一个就是
我们默认打开了Metal功能

00:05:13.514 --> 00:05:16.950
所以如果你用了
任何一个我们内置的180个滤镜

00:05:17.017 --> 00:05:18.552
或者你自定义的kernel

00:05:18.619 --> 00:05:23.123
所有的kernel都会被
快速转换为Metal的供你使用

00:05:23.190 --> 00:05:24.658
这是个不错的方式来利用

00:05:24.725 --> 00:05:27.861
Metal的作用
而你几乎不用做什么

00:05:29.429 --> 00:05:32.533
我们还对一个重要的API
做了很大的改进

00:05:32.599 --> 00:05:35.169
从CIImage中
创造了UIImage

00:05:35.469 --> 00:05:38.438
相比原来它的性能提高很多

00:05:38.505 --> 00:05:43.777
因此你可用它高效地在UIImage
视图中使一个图片动画化

00:05:45.812 --> 00:05:47.581
另一个新特性是

00:05:47.648 --> 00:05:50.284
Core Image现支持了一个
新Core Graphics特性

00:05:50.350 --> 00:05:52.920
就是Core Graphics
现支持半浮点数了

00:05:53.587 --> 00:05:56.890
让我们谈谈像素格式
因为这会引出一个很有意思的点

00:05:58.225 --> 00:06:02.930
我们对于传统的
像素格式RGBA8都很熟悉

00:06:03.263 --> 00:06:09.102
它仅需要花费每像素4字节来存储
拥有8比特的深度

00:06:09.169 --> 00:06:11.538
并且可以在0到1范围内编码

00:06:12.439 --> 00:06:16.543
然而 这个格式不利于呈现宽色域数据

00:06:16.743 --> 00:06:20.948
因为它只有8比特
而且值被限定在0到1的范围内

00:06:21.615 --> 00:06:25.252
过去的替代方案是
使用RGBAfloat

00:06:25.619 --> 00:06:28.755
它每像素有16字节 需要四倍的内存

00:06:28.956 --> 00:06:32.125
但会带给你想要的深度和范围

00:06:33.160 --> 00:06:35.362
另一个特性是它使用了浮点数

00:06:35.429 --> 00:06:38.398
也就是会分层 它是呈对数分布的

00:06:38.465 --> 00:06:41.468
这很好地适应了人眼感应颜色的方式

00:06:43.270 --> 00:06:45.405
还有个Core Image
支持的新特性

00:06:45.472 --> 00:06:47.608
Core Graphics现也支持

00:06:47.674 --> 00:06:52.279
我将其成为Goldilocks
像素格式 即RGBAh

00:06:52.479 --> 00:06:55.616
这会让你在每像素8字节的情况下

00:06:55.682 --> 00:06:58.619
存储10比特深度的数据

00:06:58.852 --> 00:07:03.223
允许的值区间是
负65000到正65000

00:07:03.524 --> 00:07:05.726
这些值是对数性量化的

00:07:05.792 --> 00:07:07.995
它对于存储线性数据很好

00:07:08.061 --> 00:07:09.930
这些数据是不会被识别为量子化的

00:07:10.531 --> 00:07:12.966
因此我高度推荐这个像素格式

00:07:13.367 --> 00:07:16.236
另一个我要提到的新格式是

00:07:16.336 --> 00:07:18.338
Core Video支持新像素格式

00:07:18.405 --> 00:07:23.744
它名字很长 叫做30RGBLE
PackedWideGamut

00:07:24.211 --> 00:07:26.980
它也支持10比特的深度

00:07:27.047 --> 00:07:31.752
但通过牺牲alpha信道
它只需要每像素4字节就能存储

00:07:31.885 --> 00:07:34.454
它对于很多情况都很有用

00:07:34.688 --> 00:07:37.524
Core Image支持或是渲染自

00:07:37.591 --> 00:07:40.127
或者渲染到CV像素缓存
利用这个格式

00:07:42.863 --> 00:07:45.699
接下来我想谈下一个主要的话题

00:07:45.766 --> 00:07:49.303
关于利用Core Image
调整RAW图片

00:07:49.369 --> 00:07:51.605
我很高兴今天能讲下这个

00:07:51.672 --> 00:07:53.240
我们致力于此已经很长时间了

00:07:53.307 --> 00:07:55.709
它包含了我们大量的辛苦工作
我很兴奋

00:07:55.776 --> 00:07:58.011
我们将其引入了iOS中

00:07:58.979 --> 00:08:01.882
我要先说下什么是RAW文件

00:08:02.115 --> 00:08:04.484
如何使用
CIRAWFilter API

00:08:04.551 --> 00:08:06.987
一些关于支持宽色域输出的说明

00:08:07.054 --> 00:08:09.423
还有关于管理内存的技巧

00:08:11.391 --> 00:08:13.093
那么首先 什么是RAW文件呢

00:08:13.260 --> 00:08:17.831
大部分相机的运作方式都包括
两个关键的部件

00:08:18.065 --> 00:08:20.667
颜色过滤阵列和传感器阵列

00:08:20.801 --> 00:08:24.104
其工作原理就是光线从场景内进入

00:08:24.171 --> 00:08:27.975
通过颜色过滤阵列
并被传感器阵列所计数

00:08:28.575 --> 00:08:31.879
当然了
该数据实际上是一个更大图像的一部分

00:08:32.179 --> 00:08:34.948
但是为了将其转换为可用的图像

00:08:35.414 --> 00:08:38.085
需要进行大量的图像处理

00:08:38.150 --> 00:08:40.687
以便为用户生成一张不错的图片

00:08:41.554 --> 00:08:45.192
我想谈一下这个 其主要思路就是

00:08:45.259 --> 00:08:49.530
如果你获取由传感器所捕捉的数据
那就是RAW文件

00:08:49.596 --> 00:08:51.398
如果你获取的数据是捕获于

00:08:51.465 --> 00:08:54.668
图像处理之后
那就是一张TIFF或者JPEG图片

00:08:55.769 --> 00:08:58.705
RAW存储着未处理的场景数据

00:08:58.772 --> 00:09:02.509
而JPEG文件存储处理过的输出图像

00:09:03.510 --> 00:09:04.711
换句话说

00:09:04.778 --> 00:09:08.348
RAW存储的是
你要生成一张图片的原料

00:09:08.649 --> 00:09:12.386
而JPEG存储的是原料的结果

00:09:12.452 --> 00:09:14.788
将这些原料烤成漂亮的蛋糕后

00:09:17.558 --> 00:09:19.259
为了从原料

00:09:19.326 --> 00:09:22.196
做成最终的蛋糕是需要很多阶段的

00:09:22.262 --> 00:09:24.264
让我大概说下其中的几个

00:09:24.731 --> 00:09:27.000
首先 我们要提取文件中的元数据

00:09:27.067 --> 00:09:30.237
其会告诉我们要花多久来做蛋糕
接着刚才的比喻来说

00:09:31.071 --> 00:09:33.740
我们还需要将从传感器中
获得的RAW数据解码

00:09:34.474 --> 00:09:39.479
我们需要将图像去马赛克
以重构整张有色图

00:09:39.546 --> 00:09:41.315
从所获取的数据中

00:09:41.381 --> 00:09:44.284
每个像素位置只有一个RGB值

00:09:45.152 --> 00:09:48.789
我们需要应用几何畸变来进行镜头矫正

00:09:49.890 --> 00:09:53.794
减少噪点 也是处理中的一个重要点

00:09:54.361 --> 00:09:57.264
我们需要从场景数据中做颜色匹配

00:09:57.331 --> 00:10:01.001
这些由传感器捕获的数据
会传到输出数据用以显示图像

00:10:02.169 --> 00:10:04.371
接下来我们要做的事就是诸如调整曝光

00:10:04.438 --> 00:10:05.672
色温 还有色调

00:10:05.739 --> 00:10:08.675
最后 非常重要的是 增强锐度

00:10:08.742 --> 00:10:11.912
对比度和饱和度来使图片看起来更漂亮

00:10:12.045 --> 00:10:13.347
这么多阶段可真不少

00:10:15.382 --> 00:10:16.884
RAW的优点有哪些呢？

00:10:16.950 --> 00:10:18.519
最大的优点就是

00:10:18.585 --> 00:10:21.622
RAW文件包含了线性的深度像素数据

00:10:21.688 --> 00:10:24.224
这使得可编辑性很好

00:10:25.859 --> 00:10:29.596
RAW的另一个特性是
它的图像处理每年都变得更好

00:10:29.663 --> 00:10:33.534
因此也就保证了利用RAW
你昨天所拍的照片

00:10:33.600 --> 00:10:37.271
可能在你来年处理它时效果更好

00:10:39.406 --> 00:10:42.042
RAW文件还有色彩空间的不可知性

00:10:42.109 --> 00:10:44.578
它们可以被渲染到任何目标的输出空间

00:10:44.645 --> 00:10:48.282
这对于我们如今诸多的显示标准来说
是个不错的特性

00:10:49.583 --> 00:10:51.985
用户可以选择使用不同的软件

00:10:52.052 --> 00:10:53.620
来解释RAW文件

00:10:53.687 --> 00:10:56.056
就像是把相同原料交给两个不同的厨师

00:10:56.123 --> 00:10:57.491
你会得到两个不同的结果

00:10:57.558 --> 00:11:00.327
有些用户可能更喜欢另一个厨师

00:11:02.596 --> 00:11:05.465
JPEG也是有很多优点的

00:11:06.200 --> 00:11:08.435
首先就是由于已经处理过了

00:11:08.502 --> 00:11:10.204
它们加载和显示非常快

00:11:11.071 --> 00:11:15.108
它们包含针对特定输出的颜色和调整

00:11:15.175 --> 00:11:16.310
这可能很有用

00:11:17.277 --> 00:11:19.346
它也会给你可预见的结果

00:11:20.414 --> 00:11:24.051
还有值得一提的是如今的相机表现出色

00:11:24.117 --> 00:11:25.819
对于拍摄JPEG照片来说

00:11:25.886 --> 00:11:29.022
并且我们的iOS相机
尤其是一个好例子

00:11:31.925 --> 00:11:34.528
说到RAW 让我再说一点

00:11:34.595 --> 00:11:36.630
关于我们的平台是如何支持RAW的吧

00:11:37.431 --> 00:11:41.735
好消息是我们现在在iOS上
完全支持了RAW

00:11:41.802 --> 00:11:44.638
即将到来的tvOS推送也是

00:11:45.772 --> 00:11:48.509
这意味着我们支持超过400个
独特的相机型号

00:11:48.575 --> 00:11:50.344
来自于16个不同的厂商

00:11:50.410 --> 00:11:53.547
我们也支持被捕获的DNG文件

00:11:53.614 --> 00:11:55.382
用我们自己的iOS设备

00:11:55.782 --> 00:12:00.854
iOS设备包括
iPhone 6S、6S Plus

00:12:00.921 --> 00:12:04.157
SE 还有iPad Pro 9.7

00:12:05.325 --> 00:12:06.593
这真让人兴奋

00:12:06.894 --> 00:12:09.162
我推荐如果你们还没有看
回去看看

00:12:09.229 --> 00:12:11.331
iOS摄影进阶

00:12:11.398 --> 00:12:13.800
那个演讲是关于

00:12:13.867 --> 00:12:15.802
可在这些设备上捕捉RAW照片的API

00:12:17.871 --> 00:12:21.775
另一个很棒的东西是我们现在拥有了
同样同性能的RAW管道

00:12:22.309 --> 00:12:27.114
iOS平台 如我们在macOS
完成的一样 可算是一个成就了

00:12:27.181 --> 00:12:29.750
我那天计算了一下我们的管道

00:12:29.816 --> 00:12:34.354
它包含了超过4500行的
CIKernel代码

00:12:34.555 --> 00:12:36.390
而且运行的很高效

00:12:36.456 --> 00:12:39.526
它是我们能力的确切证明 也是

00:12:39.593 --> 00:12:43.330
Core Image可以处理
复杂渲染场景的证明

00:12:45.632 --> 00:12:49.603
我们iOS上的管道需要
A8或以上的设备

00:12:49.670 --> 00:12:51.972
你可以通过你的应用来测试

00:12:52.039 --> 00:12:54.474
通过检查iOS
GPU Family 2

00:12:57.711 --> 00:12:59.580
另一个关于平台支持的说明是

00:12:59.646 --> 00:13:02.983
我们一直在增加对新相机的支持
从它一上市就开始

00:13:03.050 --> 00:13:06.653
而且也在改进对已支持相机的支持质量

00:13:07.187 --> 00:13:10.157
新相机被加到未来的软件更新中

00:13:10.390 --> 00:13:13.360
我们也在周期性的改进
我们的管道

00:13:13.427 --> 00:13:16.830
我们的管道有不同的版本
你既可以用我们的最新版本

00:13:16.897 --> 00:13:19.333
也可以倒回使用你想要的旧版本

00:13:21.902 --> 00:13:24.471
为了避免后面的麻烦 我想做个演示

00:13:24.538 --> 00:13:25.806
它看起来是怎么样的

00:13:32.045 --> 00:13:35.549
我这里有些示例代码
有一个早前版本的

00:13:35.616 --> 00:13:38.352
可供下载 它叫RAWExposed

00:13:38.418 --> 00:13:41.455
它是个应用 同时最新版本也是

00:13:41.522 --> 00:13:42.856
相片编辑扩展

00:13:43.423 --> 00:13:46.894
我们可以进入Photos程序
并实际运用这段示例代码

00:13:47.394 --> 00:13:50.397
我们有三张24兆像素的RAW照片

00:13:50.464 --> 00:13:53.033
是用Canon 5D
Mark III拍的

00:13:53.100 --> 00:13:56.470
你可以看出来这张照片有点过曝了

00:13:56.670 --> 00:14:00.073
RAW的一个很棒的特性就是
你可以修补这样的照片

00:14:00.340 --> 00:14:02.643
我们来这里 点“编辑” 然后...

00:14:02.976 --> 00:14:07.414
用我们的照片编辑扩展程序
来编辑这个RAW文件

00:14:07.881 --> 00:14:12.052
那么现在既然我们是在将其当做
RAW文件来编辑 就可以做些调整

00:14:12.953 --> 00:14:14.087
［听不清］

00:14:15.489 --> 00:14:17.491
我们可以上下调整曝光量

00:14:18.559 --> 00:14:21.762
我们可以在这24兆像素上浏览

00:14:22.095 --> 00:14:23.730
而且得到了不错的结果

00:14:24.531 --> 00:14:28.268
我现在对这张照片很满意
看上去比之前强多了

00:14:28.335 --> 00:14:30.204
我会点击“完成” 之后它会生成

00:14:30.637 --> 00:14:34.608
一张新的全分辨率照片 它会显示在

00:14:34.675 --> 00:14:36.043
Photos应用中

00:14:43.684 --> 00:14:46.887
另一个关于RAW文件不错的特性是
你可以做出不错的调整

00:14:46.954 --> 00:14:49.256
对于一张照片的白平衡

00:14:49.323 --> 00:14:52.826
这张照片不错 但是有点不正
而且白平衡也是关闭的

00:14:53.327 --> 00:14:54.761
我要进到这里

00:14:54.828 --> 00:14:57.130
稍微调整下白平衡

00:14:58.198 --> 00:15:01.902
以此得到一张好看得多的照片
我们可以放大来看看成果

00:15:02.269 --> 00:15:04.505
我们可以实时地调整这些结果

00:15:06.473 --> 00:15:07.908
然后点击“完成”以保存

00:15:10.110 --> 00:15:11.311
另一张我想展示的照片

00:15:11.378 --> 00:15:13.680
是张噪点很多的

00:15:13.747 --> 00:15:17.084
我想向你们展示一下
我们的噪点减少算法

00:15:17.150 --> 00:15:21.722
我们的4500行kernel代码有
超过一半是涉及到噪点减少的

00:15:22.289 --> 00:15:23.924
我要进到这里 编辑下这张照片

00:15:24.858 --> 00:15:27.427
你们可以看到 至少在前排的人可以

00:15:27.494 --> 00:15:29.029
照片上的颗粒

00:15:29.963 --> 00:15:32.299
我们API中的一个特性就是可以

00:15:32.366 --> 00:15:34.434
关掉我们的噪点减少算法

00:15:34.735 --> 00:15:39.173
然后你就可以看到RAW文件中
噪点的自然呈现

00:15:39.873 --> 00:15:42.109
这是个挺有挑战性的任务

00:15:42.943 --> 00:15:45.012
既要对照片实施噪点减少

00:15:45.078 --> 00:15:49.449
使其没有这些带颜色的点
还要保留颜色边缘

00:15:49.516 --> 00:15:51.084
照片所倾向于保留的

00:15:52.286 --> 00:15:53.453
我保存下照片

00:15:55.422 --> 00:15:57.624
最后 我想演示一下

00:15:57.691 --> 00:15:59.860
我们这周早些时候拍的一张照片

00:16:00.093 --> 00:16:02.362
在大堂里 用这个iPad拍的

00:16:02.429 --> 00:16:04.898
我就是那些拿iPad拍照的人
其中之一

00:16:06.567 --> 00:16:09.269
在此我想展示给你

00:16:09.336 --> 00:16:11.338
一张本身就带有挑战性的照片

00:16:11.405 --> 00:16:14.441
因为它有些地方太暗
而有些地方过曝了

00:16:15.509 --> 00:16:17.544
我有个能做的事情就是

00:16:17.678 --> 00:16:19.046
降低曝光量

00:16:19.112 --> 00:16:22.216
我有个高光的滑动条
可让我把高光调高一点

00:16:25.652 --> 00:16:27.688
我也可以降低曝光量

00:16:27.754 --> 00:16:30.357
现在我能看到窗外发生了什么

00:16:30.724 --> 00:16:33.794
但是现在影子太暗了
我可以调高一下那块

00:16:34.261 --> 00:16:37.431
这里展现了你可以对RAW文件
做些什么调整

00:16:37.497 --> 00:16:41.702
这是你像素数据拥有更深精确度的优势

00:16:41.768 --> 00:16:43.170
这是RAW文件所带来的

00:16:43.904 --> 00:16:45.005
我要点击下“完成”

00:16:48.041 --> 00:16:51.445
这就是我们关于iOS上RAW的演示

00:16:55.983 --> 00:16:58.619
非常感谢我们的团队使这一切成真

00:16:59.119 --> 00:17:02.022
让我谈下API 因为它仅仅是

00:17:02.089 --> 00:17:03.891
提供一个演示程序是不够的

00:17:03.957 --> 00:17:07.426
我们想要使你们的应用也能用到它

00:17:07.961 --> 00:17:11.765
我们有一个相关的API
叫CIRAWFilter API

00:17:11.832 --> 00:17:14.434
它为你的应用提供了一些关键性的东西

00:17:14.501 --> 00:17:17.704
它为你的应用提供一个CIImage
拥有宽色域

00:17:17.771 --> 00:17:20.907
扩展的区间 半浮点精度运算

00:17:21.742 --> 00:17:24.344
它也赋予你对于很多个阶段的控制权

00:17:24.411 --> 00:17:27.548
就比如我刚才演示过的
RAW演示管道

00:17:28.715 --> 00:17:31.852
它也利用GPU提供快速交互表现

00:17:31.919 --> 00:17:33.187
在我们的所有设备上

00:17:34.454 --> 00:17:37.324
这是怎么实现的呢 API其实很简单

00:17:37.391 --> 00:17:41.295
你开始有一个输入
可以使文件URL或者数据

00:17:41.361 --> 00:17:45.599
甚至是利用我们下次推送中
会带来的CVPixelBuffer API

00:17:46.166 --> 00:17:47.367
这是我们的输入

00:17:47.434 --> 00:17:50.971
我们会通过输入来创建一个
CIRAWFilter的实例

00:17:53.006 --> 00:17:55.242
过滤器被实例化的时候它将会

00:17:55.309 --> 00:17:58.779
给所有用户可调整的参数赋上默认值

00:17:58.846 --> 00:18:01.348
而这些是你应该想呈现给用户的

00:18:02.816 --> 00:18:05.219
你有了CIRAWFilter以后
你可以

00:18:05.285 --> 00:18:07.988
向它请求一个CIImage
你可在这里开始做很多事

00:18:08.055 --> 00:18:11.091
让我给你展示一下代码
看看它多简单就能实现

00:18:12.092 --> 00:18:14.394
我们只需要给它一个URL

00:18:14.962 --> 00:18:17.865
我们要创建一个接受
该URL的CIFilter实例

00:18:18.632 --> 00:18:21.068
接下来 如果我们想获得值

00:18:21.134 --> 00:18:24.404
该值是关于当前的噪点减少量
我们可以获取该值

00:18:24.471 --> 00:18:27.708
forKey: kCIInputImageNoiseReductionAmount

00:18:28.642 --> 00:18:30.544
如果我们想改变它
非常的简单

00:18:30.611 --> 00:18:32.246
我们只需给该键设一个新值

00:18:32.813 --> 00:18:36.416
做完这些改变后
请求outputImage就完成了

00:18:36.483 --> 00:18:37.684
我们就需要做这些

00:18:38.619 --> 00:18:40.554
你可能想要显示这张照片

00:18:40.621 --> 00:18:44.057
通常你会获取这张照片 并将其显示在

00:18:44.124 --> 00:18:48.962
UIImage或MetalKit
视图或其他类型的显示系统中

00:18:49.496 --> 00:18:51.398
用户可能会提出

00:18:51.465 --> 00:18:53.500
可能这张照片有点过曝了

00:18:53.567 --> 00:18:57.538
所以在你的UI中
应该有调整曝光的滑条

00:18:58.005 --> 00:19:00.107
以便用户可以做出调整

00:19:00.174 --> 00:19:03.377
你可将其作为一个新值
传给CIRAWFilter

00:19:03.677 --> 00:19:06.246
然后你可以请求一个CIImage

00:19:06.780 --> 00:19:11.218
然后你就可以显示这张曝光
调整稍微亮一些的新照片

00:19:12.252 --> 00:19:13.854
这也非常容易

00:19:15.889 --> 00:19:17.991
你还可能想获得
你的CIImage——

00:19:18.425 --> 00:19:21.395
有些时候
可能你想将你的照片导出到背景

00:19:21.461 --> 00:19:22.863
来生成一张全尺寸的照片

00:19:23.063 --> 00:19:25.632
或者你可能要导出几张照片到背景

00:19:25.899 --> 00:19:27.801
在这些情况下 你应该

00:19:28.035 --> 00:19:31.738
或是创建一个CGImage
用来将其传到其他API

00:19:32.506 --> 00:19:37.177
或直接用JPEG或TIFF
我们现有很容易用的API来实现这个

00:19:38.612 --> 00:19:41.982
如果你要实现诸如RAW这类
大文件的后台处理

00:19:42.049 --> 00:19:46.520
我们推荐创建一个CIContext
来明确用于此目的

00:19:46.920 --> 00:19:49.756
你要声明一个上下文

00:19:49.823 --> 00:19:51.959
被保存在一个单例变量中

00:19:52.025 --> 00:19:54.761
不需要给每张照片都创建
一个新的上下文

00:19:55.128 --> 00:19:59.867
这使得CI可以缓存所有涉及到
的kernel的编译文件

00:20:01.401 --> 00:20:03.437
不过因为我们只需要渲染一张照片一次

00:20:03.504 --> 00:20:06.373
我们不需要Core Image
来缓存中间文件

00:20:06.440 --> 00:20:07.808
所以你可以在这声明为假

00:20:07.875 --> 00:20:11.211
这会帮助减少此场景下的内存需求

00:20:12.312 --> 00:20:16.517
还有一个设置是关于你想要使用
低优先级的GPU渲染

00:20:16.817 --> 00:20:18.986
如果你是要做一个后台保存

00:20:19.052 --> 00:20:21.088
你不会想让所需的GPU使用度

00:20:21.154 --> 00:20:24.091
对于该后台操作会拖慢性能

00:20:24.157 --> 00:20:25.559
对于你的前台UI

00:20:25.859 --> 00:20:28.262
不管在Core Image或
Core Animation中被完成的

00:20:29.263 --> 00:20:30.898
这对于后台处理很棒

00:20:30.964 --> 00:20:33.800
我们今年要发布的一个很棒的东西就是

00:20:33.867 --> 00:20:36.603
该选项对于macOS也可用

00:20:39.406 --> 00:20:42.242
一旦你有了上下文
就很简单了

00:20:42.309 --> 00:20:44.745
你要决定你要渲染的颜色空间是什么

00:20:44.811 --> 00:20:47.047
例如 DisplayP3颜色空间

00:20:47.581 --> 00:20:49.650
我们有个新的很方便的API

00:20:49.716 --> 00:20:52.085
用来生成CIImage然后将其
写成JPEG

00:20:52.152 --> 00:20:55.122
非常容易 你要声明CIImage

00:20:55.189 --> 00:20:57.791
目标URL和颜色空间

00:20:58.725 --> 00:21:03.630
在此你也正好可以决定要给JPEG
用什么样的压缩质量

00:21:04.798 --> 00:21:07.201
在这里会生成一个JPEG图片

00:21:07.267 --> 00:21:09.436
其已经被标记于P3空间

00:21:09.503 --> 00:21:12.272
这是个不错的方式来生成宽色域图片

00:21:12.339 --> 00:21:13.907
它会正确显示

00:21:13.974 --> 00:21:18.812
在任何支持基于ICC颜色管理的平台

00:21:19.513 --> 00:21:21.748
如果你觉得你的照片会出现在一个平台

00:21:21.815 --> 00:21:23.550
其并不支持颜色管理

00:21:23.617 --> 00:21:25.652
我们还有一个新选项供你选择

00:21:25.919 --> 00:21:29.690
该选择是作为
CGImageDestination API的一部分

00:21:30.290 --> 00:21:33.961
并且它是CGImageDestination
OptimizeForSharing

00:21:34.661 --> 00:21:37.130
它会存储所有的颜色

00:21:37.197 --> 00:21:39.032
这些颜色都在P3颜色空间内

00:21:39.499 --> 00:21:41.869
但是将它们这样存储
并有一个定制的档案

00:21:41.935 --> 00:21:44.137
以便该照片仍然会被正确显示

00:21:44.204 --> 00:21:48.275
若这张照片的接收者不支持颜色管理

00:21:48.809 --> 00:21:50.344
所以这也是个不错的特性

00:21:53.180 --> 00:21:55.682
还有若你想要创建一个CGImage

00:21:55.749 --> 00:21:59.419
从CIImage 我们有一个
新API和一些新选项

00:22:00.120 --> 00:22:02.089
我们的这个方便的API可以使你

00:22:02.155 --> 00:22:04.658
声明什么颜色空间和像素格式

00:22:04.725 --> 00:22:06.159
你想要渲染

00:22:07.561 --> 00:22:10.397
你可以选择创建一个CGImage

00:22:10.464 --> 00:22:12.599
其格式为RGBAh

00:22:12.666 --> 00:22:15.269
也就是我之前谈到的
Goldilocks像素格式

00:22:15.536 --> 00:22:18.672
在这种情况下你也可以选择使用
一个特殊的颜色空间

00:22:18.739 --> 00:22:21.041
也就是
extendedLinearSRGB空间

00:22:21.341 --> 00:22:24.611
因为像素格式支持0到1区间之外的值

00:22:24.878 --> 00:22:26.680
你要让颜色空间也是如此

00:22:28.549 --> 00:22:31.218
另一个新选项是可以声明

00:22:31.285 --> 00:22:33.387
创建CGImage的行动

00:22:33.453 --> 00:22:36.023
是要延迟还是立即进行

00:22:36.323 --> 00:22:39.826
如果你声明要延迟 则相关的工作

00:22:39.893 --> 00:22:42.763
用来渲染CIImage
到CGImage

00:22:42.829 --> 00:22:45.098
会在CGImage绘制完成后进行

00:22:45.165 --> 00:22:47.167
这样会很好的减少内存占用

00:22:47.234 --> 00:22:50.504
特别是如果你之后只会画
CGImage的一部分

00:22:50.571 --> 00:22:53.273
或者只画一次

00:22:53.473 --> 00:22:56.710
然而
如果你要渲染那张照片很多次的话

00:22:56.777 --> 00:22:59.079
你可以把延迟设为假

00:22:59.146 --> 00:23:01.715
在此情况下
Core Image会完成

00:23:01.782 --> 00:23:04.885
将其渲染到CGImage的工作
当此方法被调用时

00:23:04.952 --> 00:23:08.956
这是个我们给你们的应用配备的
很棒且灵活的新API

00:23:11.491 --> 00:23:15.429
另一个关于Core Image
过滤器API的高级特性

00:23:15.495 --> 00:23:18.131
我今天想谈下的就是 这个

00:23:18.198 --> 00:23:20.701
如我之前所说的管道
有很长的阶段

00:23:20.767 --> 00:23:24.104
用来处理RAW文件 有很多人问我

00:23:24.171 --> 00:23:27.574
我如何将我自己的处理
加入到管道上

00:23:27.741 --> 00:23:31.678
一个常见的开发者想要加入

00:23:31.745 --> 00:23:34.515
处理到RAW管道上
中间某处

00:23:34.581 --> 00:23:36.250
在去马赛克完成后

00:23:36.316 --> 00:23:39.686
但是在所有非线性操作之前 像是锐化

00:23:39.753 --> 00:23:42.756
还有对比度和颜色加速完成后

00:23:42.856 --> 00:23:44.691
对此我们有个API

00:23:44.758 --> 00:23:46.927
它是CIRAWFilter一个属性

00:23:46.994 --> 00:23:49.563
可以允许你声明一个可插入的过滤器

00:23:49.630 --> 00:23:50.964
其被插入到图表的中间

00:23:51.398 --> 00:23:53.767
我希望看到你们可以想象

00:23:53.834 --> 00:23:56.837
并思考什么被带到了该位置

00:23:58.906 --> 00:24:02.209
一些我之前提过的
关于宽色域输出的说明

00:24:02.743 --> 00:24:06.313
CIKernel语言将浮点精度
作为一门语言来支持

00:24:06.813 --> 00:24:09.917
不过
当CIFilter需要被渲染到

00:24:09.983 --> 00:24:13.687
中间过滤器时 我们会用能用的格式

00:24:13.754 --> 00:24:15.556
基于当前的CIContext

00:24:16.623 --> 00:24:20.093
macOS上
默认可用的格式是RGBA

00:24:20.160 --> 00:24:21.428
我们的Goldilocks格式

00:24:22.329 --> 00:24:26.834
在iOS和tvOS上
我们的默认格式还是BGRA8

00:24:27.234 --> 00:24:28.702
其性能良好

00:24:28.769 --> 00:24:30.938
但是如果你要渲染扩展区间数据

00:24:31.004 --> 00:24:33.507
这可能不是你想要做的

00:24:34.875 --> 00:24:36.944
记住我们的RAW管道

00:24:37.377 --> 00:24:39.513
我们管道的
所有kernel

00:24:39.880 --> 00:24:43.450
强制使用RGBA半浮点精度

00:24:43.517 --> 00:24:45.419
这对于RAW文件很关键

00:24:46.119 --> 00:24:48.622
但如果你担心

00:24:48.689 --> 00:24:50.657
宽色域输入和输出

00:24:50.724 --> 00:24:53.527
要在渲染图上保留该数据

00:24:53.694 --> 00:24:57.664
那么你应该修改CIContext
当你创建它来声明

00:24:57.731 --> 00:25:00.901
你想要一个可用的格式
也就是RGBAh时

00:25:03.303 --> 00:25:06.640
我想再提一下
Core Image支持很广泛的

00:25:06.707 --> 00:25:08.375
宽色域输出空间

00:25:08.442 --> 00:25:10.077
例如 你可以渲染到

00:25:10.143 --> 00:25:14.748
extendedLinearSRGB或Adobe RGB
或DisplayP3 无论哪种都行

00:25:17.451 --> 00:25:21.021
如我之前提到的
我要演示一张24兆像素的照片

00:25:21.088 --> 00:25:23.323
RAW文件可以比你想象的大得多

00:25:23.790 --> 00:25:25.959
RAW文件除了大也需要

00:25:26.026 --> 00:25:29.329
一些中间缓存来渲染
管道的所有阶段

00:25:29.930 --> 00:25:31.331
这很重要

00:25:31.398 --> 00:25:34.568
以便减少你程序中的
高度占用内存的水印

00:25:34.635 --> 00:25:37.337
通过使用我今天谈到的这些API

00:25:37.404 --> 00:25:41.041
比如当你不需要的时候关掉中间缓存

00:25:41.108 --> 00:25:45.512
或者使用新的JPEG写入形式
其非常高效

00:25:45.579 --> 00:25:48.515
或是当创建CGImage时
声明延迟渲染

00:25:50.384 --> 00:25:53.787
这是些关于RAW文件限制的说明

00:25:54.688 --> 00:25:58.325
其支持内存大于2GB的iOS设备

00:25:58.392 --> 00:26:00.928
我们支持最大120万像素的RAW文件

00:26:00.994 --> 00:26:03.230
我们很骄傲能将其实现

00:26:08.569 --> 00:26:13.207
对于运行在1GB内存设备的应用
我们支持

00:26:13.273 --> 00:26:16.743
处理最大60兆像素的照片
这也很惊人了

00:26:16.810 --> 00:26:19.513
这对于照片编辑扩展也适用

00:26:19.580 --> 00:26:21.782
会使其花费更少的内容就可以运行

00:26:24.852 --> 00:26:26.687
这就是关于RAW的讨论

00:26:26.753 --> 00:26:28.822
我很容易今天可以为你们做演示

00:26:28.889 --> 00:26:30.791
接下来我要把讲台交给Etienne

00:26:30.858 --> 00:26:33.293
和你们讲下另一个很棒的新图片格式

00:26:33.360 --> 00:26:36.930
以及你们如何在程序中
编辑Live Photos 谢谢

00:26:43.237 --> 00:26:44.171
谢谢你 David

00:26:44.271 --> 00:26:45.272
大家好

00:26:45.906 --> 00:26:47.474
我很高兴今天站在这里

00:26:47.541 --> 00:26:50.577
跟你们谈谈如何在程序中
编辑Live Photos

00:26:52.312 --> 00:26:55.082
首先我们要进行一个简要的介绍

00:26:55.148 --> 00:26:58.151
什么是Live Photos
然后看看你都可以编辑什么

00:27:00.020 --> 00:27:03.056
接下来我们会一步步的看看代码

00:27:03.123 --> 00:27:06.493
看看你如何得到一张
Live Photo以供编辑

00:27:06.860 --> 00:27:10.631
你如何设置Live Photo
编辑环境

00:27:11.498 --> 00:27:14.535
你如何将Core Image
滤镜应用到Live Photo上

00:27:15.135 --> 00:27:19.506
以及你如何在你的程序中
预览Live Photo

00:27:19.673 --> 00:27:24.077
最后就是你如何将编辑好的
Live Photo保存到照片库

00:27:24.478 --> 00:27:26.046
我们最后会做个快速的演示

00:27:26.747 --> 00:27:28.282
那么让我们开始吧

00:27:28.482 --> 00:27:31.752
正如你所知 Live Photos

00:27:31.818 --> 00:27:34.588
就是包含动作和声音的照片

00:27:34.655 --> 00:27:37.824
从拍摄前到拍摄后

00:27:39.026 --> 00:27:42.629
Live Photos
可以用新的设备拍摄

00:27:42.896 --> 00:27:47.968
如iPhone 6S、6S Plus
iPhone SE和iPad Pro

00:27:48.902 --> 00:27:53.440
事实上 Live Photo是
这些设备上的默认拍摄模式

00:27:53.507 --> 00:27:55.142
因此你可以预期你的用户

00:27:55.209 --> 00:27:57.945
已在他们的照片库
有大量的Live Photos了

00:27:59.613 --> 00:28:01.815
今年Live Photos
有何新特性？

00:28:02.349 --> 00:28:07.287
首先是用户可以在Photos
中完全编辑Live Photos了

00:28:07.354 --> 00:28:09.756
他们可以做出所有的调整

00:28:09.823 --> 00:28:12.226
如普通照片那样
应用到Live Photo上

00:28:13.293 --> 00:28:17.798
我们有新API用以在
你应用中拍摄Live Photos

00:28:17.965 --> 00:28:20.834
更多关于此的信息

00:28:20.901 --> 00:28:23.570
我强烈推荐你们去看下进阶

00:28:23.637 --> 00:28:26.673
本周早些时候举行的iOS摄影演讲

00:28:26.740 --> 00:28:29.510
它也包含了关于
Live Photos的许多信息

00:28:29.743 --> 00:28:31.512
基于拍摄者的角度

00:28:32.079 --> 00:28:34.481
最后我们有新API
编辑Live Photos

00:28:34.548 --> 00:28:36.617
这也是我为什么今天要站在这讲的原因

00:28:37.518 --> 00:28:38.418
好了

00:28:38.652 --> 00:28:40.654
到底什么能被编辑呢

00:28:40.721 --> 00:28:44.892
首先就是你可以编辑照片的内容

00:28:45.526 --> 00:28:48.695
而且你还可以编辑视频的所有帧

00:28:49.863 --> 00:28:51.932
你也可以调整音频的音量

00:28:53.667 --> 00:28:56.670
你可改变Live Photo的大小

00:28:57.171 --> 00:28:58.805
你不能实现的就是

00:28:58.872 --> 00:29:02.342
你不能改变Live Photo
的持续时间

00:29:04.711 --> 00:29:08.148
为了获得可供编辑的
Live Photo

00:29:08.882 --> 00:29:12.019
首先就是要从照片库中
获得一张Live Photo

00:29:12.085 --> 00:29:13.253
有两种方法可以实现

00:29:13.320 --> 00:29:16.690
取决于你是要创建一个照片编辑扩展

00:29:16.757 --> 00:29:18.592
还是一个PhotoKit应用

00:29:18.659 --> 00:29:20.827
如果是照片编辑扩展的话

00:29:21.628 --> 00:29:25.098
你若要实现Live Photo编辑
首先需要

00:29:25.165 --> 00:29:27.568
添加LivePhoto字符串

00:29:27.634 --> 00:29:31.071
为你的扩展将其加入
支持的媒体类型数组

00:29:31.872 --> 00:29:36.510
然后
在startContentEditing实现中

00:29:38.478 --> 00:29:39.880
它会被自动调用

00:29:39.947 --> 00:29:44.017
你会得到你收到的编辑输入的内容

00:29:44.084 --> 00:29:47.020
你还可以检查媒体类型以及媒体子类型

00:29:47.087 --> 00:29:49.089
以确保它是张Live Photo

00:29:49.890 --> 00:29:50.824
好的

00:29:51.158 --> 00:29:54.328
另一方面
如果你创建一个PhotoKit应用

00:29:55.963 --> 00:29:59.499
你已从PHAsset
请求了contentEditingInput

00:29:59.566 --> 00:30:03.203
那么你就可以以同样方式来
检查媒体类型和媒体子类型

00:30:04.705 --> 00:30:08.842
接下来要设置一个
LivePhotoEditingContext

00:30:08.976 --> 00:30:11.945
一个LivePhotoEditingContext
包含所有资源

00:30:12.012 --> 00:30:13.680
即编辑
Live Photos所需的

00:30:14.181 --> 00:30:16.116
它包含有关Live Photo信息

00:30:16.183 --> 00:30:19.319
诸如照片的持续时间

00:30:19.386 --> 00:30:22.756
Live Photo的尺寸
还有方向性

00:30:24.525 --> 00:30:27.127
它也有帧处理器属性

00:30:27.194 --> 00:30:29.930
你可以用来编辑
Live Photo的内容

00:30:29.997 --> 00:30:31.899
我会后面再跟你们多介绍一些

00:30:33.467 --> 00:30:36.203
你也可以调整音频的音量

00:30:36.670 --> 00:30:41.275
你可请求LivePhotoEditingContext
来为Live Photo准备回放

00:30:42.409 --> 00:30:45.412
你可以请求
LivePhotoEditingContext

00:30:45.479 --> 00:30:49.116
来保存和处理Live Photo
用来保存到照片库

00:30:50.717 --> 00:30:53.420
创建一个LivePhotoEditingContext
非常简单

00:30:53.487 --> 00:30:55.489
你只需要创建一个新的

00:30:55.556 --> 00:30:58.425
从LivePhotoEditingInput
为了Live Photo

00:31:00.260 --> 00:31:01.094
好了

00:31:01.161 --> 00:31:02.796
现在让我们来看下如何

00:31:02.863 --> 00:31:05.098
使用我之前提到的帧处理器

00:31:05.832 --> 00:31:09.937
我会通过描述一个PHLivePhotoFrame对象
来介绍Live Photo的帧

00:31:10.003 --> 00:31:14.107
其包含了输入图像
也就是该帧的CIImage

00:31:14.875 --> 00:31:18.612
类型 即它是一个视频帧还是相片帧

00:31:19.446 --> 00:31:22.449
和Live Photo中的时间帧

00:31:23.083 --> 00:31:26.220
还有该帧被渲染时的分辨率

00:31:28.555 --> 00:31:30.757
为了实现一个帧处理器

00:31:30.991 --> 00:31:35.629
你要在LivePhotoEditingContext
中设置帧处理器属性

00:31:35.696 --> 00:31:40.667
使其成为一个块来以参数形式接收一帧

00:31:40.734 --> 00:31:43.070
并返回一张图片或者报错

00:31:44.071 --> 00:31:47.474
我们刚返回了帧的输入图片

00:31:47.541 --> 00:31:50.711
它其实就是节点帧处理器

00:31:51.578 --> 00:31:53.714
现在让我们看看真实的例子

00:31:53.847 --> 00:31:58.118
这是张Live Photo
就像你在Photos中看到的

00:31:58.185 --> 00:31:59.686
我可以播放一下

00:32:00.387 --> 00:32:01.388
就是这

00:32:02.289 --> 00:32:03.257
还有

00:32:03.457 --> 00:32:07.060
假如我们想要对Live Photo
做个简单的调整

00:32:07.127 --> 00:32:09.663
就从一个简单的矩形剪切功能开始吧

00:32:10.397 --> 00:32:11.431
这里是如何实现

00:32:12.299 --> 00:32:14.935
对于你帧处理器的实现

00:32:15.002 --> 00:32:17.738
你要从帧的输入图像开始入手

00:32:17.804 --> 00:32:19.773
然后你需要计算剪切矩形的数据

00:32:20.874 --> 00:32:25.045
然后你可以用这里的方法来剪切图片

00:32:25.412 --> 00:32:28.882
即对rect调用剪切
然后返回剪切完成的图片

00:32:28.949 --> 00:32:32.486
这样就可以完成编辑和剪切
Live Photo

00:32:32.920 --> 00:32:34.021
这里是得到的结果

00:32:34.788 --> 00:32:37.424
我可以放侧面图
你可以看出照片是被剪切过的

00:32:37.491 --> 00:32:39.626
而我播放的视频也是被剪切过的

00:32:40.994 --> 00:32:41.828
好了

00:32:41.895 --> 00:32:45.799
这就是关于非常基本的静态调整的例子

00:32:45.866 --> 00:32:49.803
如果我们想要做个更动态的调整

00:32:49.870 --> 00:32:52.973
这张照片依时间而改变

00:32:53.040 --> 00:32:55.642
Live Photo播放时随之改变

00:32:55.709 --> 00:32:56.977
你也可以实现这个

00:32:57.044 --> 00:33:01.281
让我们做个剪切的例子来实现动态剪切

00:33:02.349 --> 00:33:03.684
这里是我们要如何实现

00:33:04.551 --> 00:33:08.488
首先我们需要获得一些信息

00:33:08.555 --> 00:33:12.259
关于Live Photo的时间选择
像是照片的确切时间

00:33:12.326 --> 00:33:14.995
因为我们想保持相同的效果

00:33:15.229 --> 00:33:18.332
让你的剪切矩形位于
Live Photo中心位置

00:33:18.966 --> 00:33:23.504
接下来是我们捕获
Live Photo的时长

00:33:24.371 --> 00:33:27.975
你会注意到我们是在帧处理器
代码块之外完成它的

00:33:28.041 --> 00:33:31.245
以此来避免循环依赖

00:33:33.046 --> 00:33:37.851
在这代码块里我们可以请求
关于该帧确切的时间

00:33:37.918 --> 00:33:40.053
然后我们可以写一个时间的方法

00:33:40.120 --> 00:33:43.156
使用所有这些信息来帮助运行矩形剪切

00:33:44.358 --> 00:33:45.759
这里是——

00:33:45.826 --> 00:33:48.695
结果 看得出来Live Photo
以相同方式被剪切

00:33:48.762 --> 00:33:51.064
就如照片一样 但当我播放它时

00:33:51.265 --> 00:33:54.301
你可以看到矩形剪切
现在从底部移动到了顶部

00:33:56.537 --> 00:33:59.740
这里是一个基于时间调整的例子

00:34:00.474 --> 00:34:02.342
现在让我们看点别的

00:34:02.943 --> 00:34:05.112
这个效果很有意思

00:34:05.179 --> 00:34:08.181
因为它是一个依赖于分辨率的效果

00:34:08.248 --> 00:34:13.887
意思就是滤镜的参数是怎么声明的

00:34:15.222 --> 00:34:16.623
它们在像素中被声明

00:34:16.690 --> 00:34:19.293
也就意味着你需要额外的仔细

00:34:19.359 --> 00:34:21.460
当你应用这类效果时要确保

00:34:21.527 --> 00:34:23.964
此效果是视觉上一致的

00:34:24.031 --> 00:34:27.534
无论Live Photo
所渲染的分辨率是多少

00:34:27.601 --> 00:34:30.904
在此我播放它 你可以看见视频

00:34:31.205 --> 00:34:33.674
特效被如应用到照片那样应用到视频上

00:34:33.739 --> 00:34:34.574
真不错

00:34:35.442 --> 00:34:37.143
让我们看看怎么能正确实现

00:34:38.110 --> 00:34:41.047
在你的帧处理器中你要注意

00:34:41.114 --> 00:34:43.717
帧上的renderScale属性

00:34:43.784 --> 00:34:47.955
它会给你当前帧的分辨率

00:34:48.021 --> 00:34:51.725
与Live Photo中的一比一
全尺寸的静态图片相比

00:34:53.360 --> 00:34:54.928
所以请记住

00:34:55.996 --> 00:34:59.733
视频帧和图片也是不同的尺寸

00:34:59.800 --> 00:35:02.302
通常视频会比照片小得多

00:35:02.803 --> 00:35:04.972
因此你要确保能正确的实现它

00:35:05.038 --> 00:35:06.106
为了实现这个目的

00:35:07.140 --> 00:35:09.543
你可以使用这的比例尺

00:35:09.610 --> 00:35:12.813
来案例比缩小宽度参数以便一比一

00:35:12.880 --> 00:35:15.282
的全尺寸照片的参数将会是50

00:35:15.349 --> 00:35:17.784
但它会在小分辨率下变得更小

00:35:19.186 --> 00:35:24.091
另一个可以用来做出
依赖分辨率的调整的方法就是

00:35:24.358 --> 00:35:25.259
使用

00:35:26.026 --> 00:35:30.597
利用图片的范围
就如我现在这里做的那样——

00:35:30.731 --> 00:35:32.366
对inputCenter参数

00:35:32.432 --> 00:35:35.936
我实际上使用了图片的中点 这也成功

00:35:36.003 --> 00:35:37.738
正确的缩放了

00:35:39.139 --> 00:35:40.040
好的

00:35:40.107 --> 00:35:42.910
对于这张图片还有一个编辑的地方

00:35:43.710 --> 00:35:47.347
你们可以注意到我在这边做了一个标识

00:35:47.714 --> 00:35:50.584
可能看上去很熟悉 当我播放它时

00:35:51.685 --> 00:35:54.154
你会看到标识从视频中消失了

00:35:54.221 --> 00:35:58.992
就是关于如何将一个调整
只应用到照片上

00:35:59.059 --> 00:36:00.160
而不是视频中

00:36:00.527 --> 00:36:01.962
这里是如何实现的

00:36:02.763 --> 00:36:05.499
在你帧处理器的实现中

00:36:06.200 --> 00:36:10.571
你要看一下帧类型
在此我们要检查下它是不是一张图片

00:36:10.637 --> 00:36:15.642
然后我们将静态标识整合到图片中去
而不是视频中

00:36:15.709 --> 00:36:17.177
就是这么容易

00:36:17.244 --> 00:36:19.947
你们或许知道 有一些调整

00:36:20.013 --> 00:36:22.182
可能是一个本地广告或是单个广告

00:36:22.249 --> 00:36:24.685
你不想或者不能应用到视频中

00:36:24.751 --> 00:36:26.720
而这么做就能很好的实现这一功能

00:36:28.255 --> 00:36:29.089
好了

00:36:29.156 --> 00:36:31.325
我们现有了一张
编辑过的Live Photo

00:36:32.259 --> 00:36:35.495
让我们看看如何在应用中预览它吧

00:36:36.063 --> 00:36:41.201
你用PHLivePhotoView
来预览一张Live Photo

00:36:41.268 --> 00:36:46.874
这个视图在iOS中早就可用了
而今年引入了macOS中

00:36:48.342 --> 00:36:53.380
为了预览Live Photo
你需请求LivePhotoEditingContext

00:36:53.447 --> 00:36:57.217
以准备回放一张Live Photo
你要传入

00:36:57.284 --> 00:37:03.056
目标尺寸
也就是你视图的像素尺寸

00:37:03.123 --> 00:37:05.826
然后你要异步地回调

00:37:05.893 --> 00:37:09.363
附着一张渲染过的
Live Photo在主线程上

00:37:10.297 --> 00:37:11.865
接下来你要做的就是设置

00:37:11.932 --> 00:37:14.301
LivePhotoView
的Live Photo属性

00:37:14.368 --> 00:37:19.673
以便你的用户可与其
Live Photo交互且获得

00:37:19.740 --> 00:37:22.209
编辑过的Live Photo
看起来如何的印象

00:37:23.810 --> 00:37:24.845
现在

00:37:24.912 --> 00:37:27.648
最后一步就是将其保存到照片库中

00:37:27.714 --> 00:37:32.452
这取决于你开发的是一个照片编辑

00:37:32.519 --> 00:37:34.922
扩展或PhotoKit应用

00:37:35.923 --> 00:37:40.661
若是照片编辑扩展 你就要实现
finishContentEditing

00:37:40.961 --> 00:37:45.599
第一步 创建一个新的
contentEditingOutput

00:37:45.666 --> 00:37:48.802
从你早先接收到
contentEditingInput中

00:37:49.703 --> 00:37:53.240
接下来你要请求
LivePhotoEditingContext

00:37:53.307 --> 00:37:55.509
以保存Live Photo
到该输出中

00:37:55.576 --> 00:37:59.379
这会处理全分辨率的
Live Photo

00:37:59.446 --> 00:38:03.517
以异步的方式 并且在主线程上回调

00:38:04.017 --> 00:38:05.319
成功还是报错

00:38:05.385 --> 00:38:07.921
如果所有都顺利的话

00:38:08.355 --> 00:38:12.259
你还要确保你除了编辑的内容
还保存了调整的数据

00:38:12.893 --> 00:38:15.162
这将会允许你的用户回到

00:38:15.229 --> 00:38:18.899
接下来在你的应用或者扩展中
并继续在那编辑

00:38:21.768 --> 00:38:24.238
最后要调用
completionHandler

00:38:24.304 --> 00:38:25.973
对于该扩展 然后你就完成了

00:38:27.174 --> 00:38:32.012
若你开发的是PhotoKit应用
步骤就很类似的

00:38:32.246 --> 00:38:35.883
唯一的区别就在于你要

00:38:35.949 --> 00:38:38.185
它们是来自于你本身的变化

00:38:38.252 --> 00:38:40.387
使用PHAssetChangeRequest

00:38:41.688 --> 00:38:44.424
现在我要给你们展示一个快速的演示

00:38:52.499 --> 00:38:53.333
好了

00:38:54.034 --> 00:38:57.704
我创建了一个Live Photo
扩展的简单演示

00:38:57.771 --> 00:38:59.139
我今天想要展示给你们看

00:38:59.940 --> 00:39:03.977
我现在Photos应用里
可以看到一些Live Photos

00:39:04.044 --> 00:39:05.746
可以来挑选看看这些内容

00:39:07.481 --> 00:39:09.816
我可以滑动来看它们活动起来

00:39:10.150 --> 00:39:12.219
这就是我今天要编辑的照片

00:39:12.653 --> 00:39:15.088
现在我要开始编辑了
正如我之前提到的

00:39:15.155 --> 00:39:18.425
我在Photos里就能
编辑Live Photo

00:39:18.492 --> 00:39:19.526
让我来编辑看看

00:39:19.593 --> 00:39:24.097
我想要应用下David之前
提到的这个新的亮度滑动条

00:39:24.831 --> 00:39:25.666
好了

00:39:26.400 --> 00:39:28.569
我可以在Photos应用中播放它

00:39:32.673 --> 00:39:33.807
当然了 我可以

00:39:33.874 --> 00:39:39.613
在这就停下
但我想也应用下我的示例编辑

00:39:40.013 --> 00:39:41.915
我要在这选择我的扩展

00:39:45.686 --> 00:39:51.992
我们应用的是贯穿幻灯片
所提的相同的调整

00:39:52.326 --> 00:39:56.029
你们能看出来这是个挺简单的扩展

00:39:56.096 --> 00:39:59.032
它显示LivePhotoView
因此我可与之交互

00:39:59.099 --> 00:40:03.170
我可以点按来播放它
就像在我的扩展这样

00:40:04.071 --> 00:40:04.972
这很简单

00:40:05.038 --> 00:40:08.575
下面一步就是要点击“完成”来保存

00:40:09.476 --> 00:40:13.013
而且要处理一个全分辨率
的Live Photo

00:40:13.847 --> 00:40:15.082
并将其发送回照片库

00:40:16.316 --> 00:40:18.552
就是在Photos那儿

00:40:19.987 --> 00:40:20.821
好了

00:40:21.555 --> 00:40:23.257
这就是这个演示

00:40:23.757 --> 00:40:25.025
现在回到幻灯片上

00:40:30.330 --> 00:40:31.164
谢谢

00:40:31.932 --> 00:40:32.933
好的

00:40:33.166 --> 00:40:35.969
这里是我们今天目前为止
所介绍的一个简要总结

00:40:36.436 --> 00:40:39.439
我们已经学到如何
获得一张Live Photo

00:40:39.506 --> 00:40:42.442
从照片库中

00:40:42.743 --> 00:40:46.046
如何使用和设置一个
LivePhotoEditingContext

00:40:46.113 --> 00:40:50.517
如何使用帧处理器来
编辑Live Photo的内容

00:40:50.984 --> 00:40:56.356
我们介绍了如何在你的应用中
利用LivePhotoView来预览Live Photo

00:40:57.124 --> 00:41:01.495
我们看到了如何将
Live Photo保存到照片库中

00:41:03.230 --> 00:41:06.266
我现在迫不及待地想看到
你们会用这个新API做出些什么

00:41:07.134 --> 00:41:08.402
有几点是需要记住的

00:41:09.903 --> 00:41:12.239
首先
如果你是要开发一个照片编辑扩展

00:41:12.306 --> 00:41:15.509
别忘记...
将LivePhotoEditing加到

00:41:15.576 --> 00:41:17.311
你info.plist中来扩展

00:41:17.377 --> 00:41:20.180
否则你得到的是一张静态图片
而非Live Photo

00:41:20.881 --> 00:41:24.852
就如我所说的
你要确保保存了调整数据

00:41:24.918 --> 00:41:28.455
以便你的用户们可以回到你的应用中

00:41:28.522 --> 00:41:30.624
继续无损的编辑

00:41:31.892 --> 00:41:37.064
最后 我觉得如果你已经
有了一个照片编辑应用

00:41:39.333 --> 00:41:43.070
采用Live Photo及添加对于
LivePhotoEditing的支持

00:41:43.136 --> 00:41:44.771
使用这新API实现就该非常容易

00:41:45.072 --> 00:41:48.308
特别是如果你的应用已经使用了
Core Image的情况下

00:41:48.375 --> 00:41:51.912
如果没有
Core Image里有个新API

00:41:51.979 --> 00:41:56.016
可以让你将自定义的处理
集成到Core Image里

00:41:56.083 --> 00:42:00.087
我会请Alex上台给你们详细介绍

00:42:00.153 --> 00:42:00.988
谢谢

00:42:06.793 --> 00:42:07.794
谢谢 Etienne

00:42:08.095 --> 00:42:09.296
我叫Alexandre Naaman

00:42:09.363 --> 00:42:11.331
我今天要讲的是关于一些新功能

00:42:11.398 --> 00:42:15.102
关于Core Image之前
所没有的额外特效

00:42:15.169 --> 00:42:18.639
这会用到一个叫
CIImageProcessor的新API

00:42:19.940 --> 00:42:22.943
就如David之前提到
在Core Image中 你可实现很多东西

00:42:23.010 --> 00:42:26.213
使用我们内置的180个滤镜

00:42:26.280 --> 00:42:30.217
你还可通过编写自定义的
kernel来做进一步的扩展

00:42:30.751 --> 00:42:33.954
有CIImageProcessor
我们能实现的就更多

00:42:34.388 --> 00:42:38.225
我们可以在渲染图中插入一个新的节点

00:42:38.926 --> 00:42:41.195
它能实现我们想要的一切

00:42:41.461 --> 00:42:43.597
还与现存的图完美融合

00:42:43.664 --> 00:42:47.501
我们可编写自定义的CPU代码...
或是Metal代码

00:42:49.870 --> 00:42:52.773
使用CIImageProcessor时

00:42:53.073 --> 00:42:54.775
与编写通用kernel有类似

00:42:54.842 --> 00:42:59.279
过去你写通用kernel
要声明某些字符串

00:43:00.080 --> 00:43:03.784
然后重写你CIFilter中
的输出图像方法

00:43:05.652 --> 00:43:07.821
并且提供范围 也就是

00:43:07.888 --> 00:43:09.790
你要创建的输出图片尺寸

00:43:10.791 --> 00:43:12.559
还有roiCallback函数

00:43:13.727 --> 00:43:15.062
最后

00:43:15.562 --> 00:43:18.465
无论你要将何参数传入kernel中

00:43:19.499 --> 00:43:24.037
这与创建CIImageProcessors
有许多的相似性

00:43:24.104 --> 00:43:27.374
所以我们今天不会再深入讨论它们了

00:43:27.441 --> 00:43:32.980
我们建议你去看看2014 WWDC
的演讲515

00:43:33.113 --> 00:43:35.249
若你想创建一个
CIImageProcessors

00:43:35.315 --> 00:43:37.918
我们强烈推荐你回去看下那个讲座

00:43:37.985 --> 00:43:40.254
因为我们讨论了如何处理范围

00:43:40.320 --> 00:43:43.524
和ROI参数

00:43:45.425 --> 00:43:47.060
现在让我们看下这个API

00:43:47.127 --> 00:43:49.162
用来创建CIImage处理器
的是什么样的

00:43:50.130 --> 00:43:51.899
这可能在将来更新中会有些许变化

00:43:51.965 --> 00:43:54.201
但是它现在的样子

00:43:54.935 --> 00:43:56.637
相似性是这些

00:43:56.703 --> 00:43:57.804
我们需要提供范围

00:43:57.871 --> 00:43:59.840
也就是我们要生成的输出图片的尺寸

00:43:59.907 --> 00:44:01.175
给它一个输入图像

00:44:02.142 --> 00:44:03.210
还有ROI

00:44:03.844 --> 00:44:06.880
我们需要提供很多额外的参数

00:44:06.947 --> 00:44:10.350
例如我们要创建的节点的描述

00:44:11.351 --> 00:44:14.488
我们需要提供一个摘要
有着某种哈希值

00:44:14.555 --> 00:44:16.056
对于我们所有的输入参数

00:44:16.123 --> 00:44:18.025
这对于Core Image很重要

00:44:18.091 --> 00:44:19.993
因为这是Core Image
如何决定

00:44:20.060 --> 00:44:22.129
我们是否要缓存那些值

00:44:22.196 --> 00:44:23.997
还有我们是否需要重渲染

00:44:24.198 --> 00:44:27.234
你需要确保每次你的参数改变的时候

00:44:27.668 --> 00:44:29.203
你要更新哈希值

00:44:30.304 --> 00:44:34.808
接下来我们可以声明是输入格式

00:44:34.875 --> 00:44:37.544
在这个例子中我们用了BGRA8

00:44:38.712 --> 00:44:40.314
但你也可以声明为0

00:44:40.380 --> 00:44:43.750
这意味着你会获得对于
该上下文可用的格式——

00:44:44.351 --> 00:44:46.553
作为一个输入图像格式

00:44:46.954 --> 00:44:48.989
你也可以声明输出格式

00:44:49.056 --> 00:44:51.325
在此我们用的是RGBAf
因为我们详细介绍

00:44:51.391 --> 00:44:53.093
的例子

00:44:53.160 --> 00:44:55.362
需要精度很高
因此我们需要在此使用全流量

00:44:56.597 --> 00:44:58.432
最后我们要看下处理器代码块

00:44:58.498 --> 00:45:00.767
在这我们有两个参数

00:45:00.834 --> 00:45:05.806
CIImageProcessorInput
和CIImageProcessorOutput

00:45:06.874 --> 00:45:09.877
它们在这里面以便我们
可以完成所需的所有工作

00:45:10.277 --> 00:45:12.779
让我们看看如何来实现它

00:45:12.946 --> 00:45:14.548
还有你为什么要实现它

00:45:17.117 --> 00:45:19.486
CIImageProcessor
特别有用

00:45:19.553 --> 00:45:22.990
对于你有某个算法的时候
或者你想用一个库

00:45:23.056 --> 00:45:25.192
其实现了Core Image外
某些东西

00:45:26.326 --> 00:45:28.729
且还是对于CIKernel语言
不合适的东西

00:45:28.795 --> 00:45:32.065
一个好例子就是积分图像

00:45:32.633 --> 00:45:35.469
积分图像就是凭借输出像素的图像

00:45:35.536 --> 00:45:37.804
它包含了其上所有像素的总和

00:45:37.871 --> 00:45:39.606
还有它左边的像素 包括它自身

00:45:40.841 --> 00:45:43.677
这是个好例子 对于不能完成的事情

00:45:43.744 --> 00:45:45.946
在数据平行类的着色器

00:45:46.013 --> 00:45:48.815
也就是当你编写CIKernel时
所写那种着色器

00:45:50.984 --> 00:45:52.653
让我们来看下

00:45:53.187 --> 00:45:55.022
关于积分图像的更多细节

00:45:55.088 --> 00:45:57.558
如果我们从左边的输入图像开始

00:45:57.624 --> 00:46:01.428
也就是说
与某些单信道 8比特数据相对应

00:46:02.629 --> 00:46:04.631
我们的积分图像会成为右边的图像

00:46:04.698 --> 00:46:06.667
如果我们看下这边的像素的话

00:46:06.733 --> 00:46:07.701
7

00:46:07.768 --> 00:46:11.705
它实际上对应着左边所有像素的和

00:46:11.772 --> 00:46:14.474
也就是1加4加0加2

00:46:15.475 --> 00:46:19.346
对于另外的像素也是如此
45对应的是和

00:46:19.413 --> 00:46:22.382
也就是那些像素的上边 左边
再加上它自己

00:46:26.286 --> 00:46:29.056
让我们来看看你会做些什么

00:46:29.122 --> 00:46:33.527
如果你要写CPU代码
到图像处理器代码块的话

00:46:33.861 --> 00:46:35.596
你也可以使用V Image

00:46:35.662 --> 00:46:37.965
或是我们系统里有的其他任何库

00:46:38.832 --> 00:46:40.000
首先重中之重的就是

00:46:40.334 --> 00:46:42.836
我们要获取一些指针返回到输入数据

00:46:42.903 --> 00:46:46.406
从CIImageProcessorInput
我们会得到基地址

00:46:47.241 --> 00:46:50.844
而且我们要确保使用8比特数据
也就是UInt8

00:46:51.512 --> 00:46:52.713
接着我们会得到
outputPointer

00:46:52.779 --> 00:46:54.615
也就是我们写入所有结果的地方

00:46:54.681 --> 00:46:58.118
要作为浮点类型写入
因为我们声明要写到RGBAf

00:47:00.287 --> 00:47:03.524
接下来我们要确保考虑到

00:47:04.024 --> 00:47:07.160
输入输出图像相关的偏移量

00:47:07.694 --> 00:47:10.330
Core Image很可能提供给你

00:47:10.397 --> 00:47:13.300
更大的输入图像

00:47:13.367 --> 00:47:15.936
至少和你的输出图像不一样大

00:47:16.003 --> 00:47:19.173
所以你要小心处理所有可能的偏移量

00:47:19.506 --> 00:47:22.342
当你创建输出图像
还有写for循环的时候

00:47:23.544 --> 00:47:26.246
在这种情况下
一旦我们弄清楚所需要的偏移量

00:47:26.480 --> 00:47:30.117
就可以执行我们的for循环
来计算输出值

00:47:30.184 --> 00:47:33.820
通过使用i-j位置的输入

00:47:33.887 --> 00:47:35.455
加上我们得到的偏移量

00:47:38.625 --> 00:47:41.228
现在我们已经看到如何利用
定制CPU循环来实现它

00:47:41.295 --> 00:47:44.198
也看看如何利用Metal来实现

00:47:44.264 --> 00:47:45.699
在这个例子中我们会使用

00:47:46.567 --> 00:47:48.168
Metal性能着色器

00:47:49.102 --> 00:47:51.038
在Metal性能着色器中
有个很不错的初始点

00:47:51.104 --> 00:47:54.074
来计算积分图像 叫做
MPSImageIntegral

00:47:55.142 --> 00:47:59.413
从CIImageProcessorOutput中
我们可以得到commandBuffer

00:47:59.646 --> 00:48:02.449
Metal command buffer 所以我们创建了一个
MPSImageIntegral

00:48:02.516 --> 00:48:04.051
利用那个commandBuffer

00:48:05.152 --> 00:48:08.422
我们要小心留意需要处理的偏移量

00:48:10.090 --> 00:48:13.060
然后对该commandBuffer
编写相应kernel即可

00:48:13.427 --> 00:48:16.096
还要提供我们得到的输入纹理作为输入

00:48:16.163 --> 00:48:17.798
其是从
CIImageProcessorInput得到的

00:48:17.865 --> 00:48:20.934
还要将
output.MetalTexture作为目的地

00:48:21.535 --> 00:48:24.171
这就是我们如何使用Metal

00:48:24.238 --> 00:48:26.240
在现存CIFilter图之内

00:48:27.341 --> 00:48:29.243
现在让我们看看我们能完成什么

00:48:29.309 --> 00:48:31.044
通过目前得到的积分图像

00:48:31.712 --> 00:48:33.647
我们从像是这么一张图片开始

00:48:33.714 --> 00:48:36.583
我们的目标是生成一张新的图片

00:48:37.684 --> 00:48:41.054
其每像素变量都有盒装模糊

00:48:41.121 --> 00:48:45.025
该张图片的每个像素都有不同的模糊量

00:48:45.092 --> 00:48:48.595
我们利用积分图像很快就可以实现

00:48:50.864 --> 00:48:53.834
我要说的是 盒状模糊是很有用的

00:48:54.768 --> 00:48:56.837
对于实现快速盒状相加

00:48:56.904 --> 00:48:58.805
如果我们就从这张输入图片开始 想要

00:48:58.872 --> 00:49:02.643
得到这九个像素点的和 通常来讲

00:49:02.709 --> 00:49:06.313
这需要进行九次读取
也就意味着这是个n平方复杂度的问题

00:49:06.747 --> 00:49:10.017
这可不会太快

00:49:11.718 --> 00:49:13.854
这不完全对 如果你稍微聪明点的话

00:49:13.921 --> 00:49:16.023
你可以通过多通道方法来实现它

00:49:16.089 --> 00:49:19.459
通过两个n次读取来实现
但你仍然要进行六次读取

00:49:20.160 --> 00:49:22.196
也没有明显缩小多少

00:49:23.463 --> 00:49:25.933
不过利用积分图像的话 我们就可以

00:49:25.999 --> 00:49:29.002
如果想得到这九个像素点的和

00:49:29.069 --> 00:49:30.637
我们只需要读取几个位置

00:49:30.704 --> 00:49:32.539
我们要读取右下角的位置

00:49:34.107 --> 00:49:35.509
然后再读取

00:49:35.576 --> 00:49:39.346
从一个到最左边 所有值的和

00:49:39.780 --> 00:49:42.816
然后再从中减去我们读取的头一个值

00:49:43.884 --> 00:49:46.987
然后我们要读取一个像素点
它就在我们所需的上面

00:49:47.054 --> 00:49:48.856
并减去目前为止

00:49:48.922 --> 00:49:50.490
所有像素相加所对应的行

00:49:50.557 --> 00:49:52.392
你们现可看到我们将左上角设为高亮

00:49:52.459 --> 00:49:55.028
设为1 因为我们已经减了两次那个值

00:49:55.095 --> 00:49:56.463
所以我们要再把它加回来

00:49:59.066 --> 00:50:03.637
这意味着我们可以创建
一个任意尺寸的盒状模糊

00:50:04.204 --> 00:50:05.672
就通过四次读取

00:50:09.276 --> 00:50:10.944
如果我们要 谢谢你们

00:50:13.313 --> 00:50:14.481
如果我们要手动做计算

00:50:14.548 --> 00:50:16.350
你可以看出来这些数加起来是对的

00:50:16.416 --> 00:50:19.753
也就是2加4加6等等 完全相同

00:50:19.820 --> 00:50:23.090
和66减10减13加1

00:50:26.727 --> 00:50:30.297
让我们回到Core Image
kernel语言

00:50:30.364 --> 00:50:34.334
看看我们如何使用积分图像
该图像或是我们利用CPU代码计算的

00:50:34.768 --> 00:50:37.171
或使用Metal性能着色器
基类型得到的

00:50:38.305 --> 00:50:40.974
并继续实现创建盒状模糊特效

00:50:41.508 --> 00:50:44.511
我们要做的第一件事就是计算左下角

00:50:44.578 --> 00:50:46.880
和右上角 从我们的图片中

00:50:46.947 --> 00:50:50.617
这会告诉我们需要要从哪进行加减

00:50:51.785 --> 00:50:54.354
然后我们要计算一些其他的值

00:50:54.421 --> 00:50:58.058
它们会帮助我们决定所需alpha值

00:50:58.125 --> 00:51:00.994
也就是我们当前要生成的像素的透明度

00:51:03.263 --> 00:51:05.832
我们取得四个角的样值

00:51:07.167 --> 00:51:10.737
做了所需的加法和减法

00:51:10.804 --> 00:51:13.373
再乘上所决定的合适的

00:51:13.440 --> 00:51:15.742
对于该输出像素的透明度

00:51:18.278 --> 00:51:21.915
该kernel接收单个参数

00:51:21.982 --> 00:51:24.318
作为输入半径 也就是

00:51:24.384 --> 00:51:25.919
如果你要在图片上调用它

00:51:25.986 --> 00:51:28.655
你会在整个图片上应用相同的半径

00:51:28.956 --> 00:51:31.325
不过我们可以简单

00:51:32.392 --> 00:51:33.894
去创建一个盒装模糊变量

00:51:33.961 --> 00:51:37.297
通过传入一个掩膜图像
我们可以利用该掩膜图像

00:51:37.364 --> 00:51:39.099
来决定多大

00:51:40.067 --> 00:51:43.036
的半径对于每像素为基础合适

00:51:44.505 --> 00:51:46.740
我们要传入一个额外的参数
也就是掩膜图像

00:51:46.807 --> 00:51:47.741
我们从中进行读取

00:51:49.309 --> 00:51:51.078
我们来看下红信道中有什么

00:51:51.144 --> 00:51:52.679
也可能从任何一个信道而来

00:51:52.746 --> 00:51:55.415
然后我们要把它乘上半径

00:51:55.482 --> 00:51:59.386
如果我们的半径是15
而在当前像素位置的值是0.5

00:51:59.453 --> 00:52:01.755
那么最终的半径是7.5

00:52:02.389 --> 00:52:04.658
我们可以得到这些值后 传到

00:52:04.725 --> 00:52:06.727
我们刚写好的盒状模糊kernel中

00:52:06.894 --> 00:52:10.097
这就是我们如何创建一个盒状模糊变量

00:52:10.464 --> 00:52:15.068
利用Metal性能着色器
和CIImageProcessor节点

00:52:18.205 --> 00:52:21.441
还有个我们今天没有提到的事情是

00:52:21.508 --> 00:52:24.211
我们现在有了可以声明的属性

00:52:24.511 --> 00:52:26.847
它们在你所写的CIKernels中

00:52:27.681 --> 00:52:31.652
实际上
我们现在就有一个 也就是输出格式

00:52:31.718 --> 00:52:37.624
在这里我们要请求RGBAf
不需要真的有用

00:52:37.691 --> 00:52:42.229
关键是说你想要写

00:52:42.296 --> 00:52:44.798
单信道还是双信道数据

00:52:44.865 --> 00:52:46.466
所以如果你想要

00:52:48.836 --> 00:52:50.437
如有些人所注意到
有个好方法

00:52:50.504 --> 00:52:56.376
来减少你的内存占用 也可以来声明

00:52:56.443 --> 00:53:00.180
对于某个特定kernel
你想要个确切的精度

00:53:00.247 --> 00:53:03.083
在可能和图剩余部分
不相对应的kernel

00:53:03.150 --> 00:53:06.186
就如我们在iOS上
处理RAW图片那样

00:53:06.253 --> 00:53:09.256
我们的所有kernel
都标记着RGBAh

00:53:12.993 --> 00:53:16.029
另外 我们要创建此特效还得

00:53:16.096 --> 00:53:17.598
提供某种掩膜图像

00:53:17.664 --> 00:53:21.168
调用CIFilter(name,
就可轻松实现

00:53:21.235 --> 00:53:24.271
然后附带参数请求一个
CIRadialGradient

00:53:24.338 --> 00:53:26.673
也就是要决定有多大

00:53:27.241 --> 00:53:30.244
的掩膜 还有它位于哪里

00:53:30.310 --> 00:53:33.080
然后我们要在0和1间插入

00:53:33.146 --> 00:53:34.648
非黑即白

00:53:35.315 --> 00:53:37.718
然后我们要从CIFilter中
请求输出图像

00:53:37.985 --> 00:53:40.153
之后我们就有了一个完美可用的掩膜

00:53:42.356 --> 00:53:45.025
现在让我们看看它实际看起来

00:53:45.092 --> 00:53:46.660
运行在设备上时是什么样的

00:53:46.727 --> 00:53:50.063
这是从iPhone 6S上录制的

00:53:50.130 --> 00:53:52.833
如果我们从输入图像开始
并看看掩膜的话

00:53:52.900 --> 00:53:54.168
我们可以移动它

00:53:54.368 --> 00:53:55.702
它非常具有可交互性

00:53:56.336 --> 00:53:59.573
可以改变半径 甚至将其设为负数

00:54:01.341 --> 00:54:05.078
如果我们使用此掩膜图像 并使用它在

00:54:05.145 --> 00:54:07.281
我们的盒状模糊变量
kernel代码中

00:54:08.549 --> 00:54:12.419
就可以得到这个类型的结果
它是非常可交互的

00:54:12.986 --> 00:54:15.422
因为积分图像也需要计算一次

00:54:15.489 --> 00:54:17.524
Core Image
为你缓存这些结果

00:54:17.591 --> 00:54:20.093
它几乎就是你现在所看到的这些东西

00:54:20.160 --> 00:54:22.930
就包括四次读取 所以它非常的快

00:54:32.472 --> 00:54:35.876
有些要你们记住的
当你使用CIImageProcessor时

00:54:37.044 --> 00:54:40.314
如果你要使用的在图像处理器中的数据

00:54:40.380 --> 00:54:44.985
不是在当前workingColorSpace
的上下文中

00:54:45.052 --> 00:54:47.654
你就要调用
CIImage.byColorMatching

00:54:47.721 --> 00:54:50.023
WorkingSpace(to,
来提供一个颜色空间

00:54:52.025 --> 00:54:55.429
类似的 在出口处如果你想要数据

00:54:55.495 --> 00:54:56.763
位于不同的颜色空间

00:54:56.830 --> 00:54:59.333
你就要调取
CIImage.byColorMatching

00:54:59.399 --> 00:55:02.135
ColorSpace(toWorking,
并给它一个颜色空间

00:55:05.639 --> 00:55:09.776
现在我们已经看到
如何创建CIImageProcessor

00:55:09.843 --> 00:55:10.844
并使用它

00:55:11.678 --> 00:55:13.247
让我们来看看会发生什么

00:55:13.313 --> 00:55:15.382
当我们使用环境变量
CI PRINT TREE时

00:55:15.449 --> 00:55:18.785
我们用它来得到实际的图

00:55:18.852 --> 00:55:20.754
我们渲染完会是什么样

00:55:23.056 --> 00:55:24.658
它看起来就会是这样的

00:55:24.725 --> 00:55:26.693
当你使用环境变量
CI PRINT TREE时

00:55:26.760 --> 00:55:28.028
而且将其值设为1

00:55:28.228 --> 00:55:31.732
是自底向上读取 而且它可以很冗长

00:55:32.432 --> 00:55:36.236
它从我们创建的
radialGradient输入开始

00:55:36.904 --> 00:55:41.408
接下来我们得到与工作空间
相匹配的输入图像

00:55:42.776 --> 00:55:45.812
然后就是我们的处理器节点被调用

00:55:45.879 --> 00:55:49.449
此十六进制值就是我们已经计算过的摘要

00:55:50.851 --> 00:55:53.420
处理器和颜色kernel结果

00:55:53.487 --> 00:55:56.790
来自radialGradient的
被传入variableBoxBlur中

00:55:57.691 --> 00:56:02.362
最后我们对于输出显示做颜色匹配

00:56:03.664 --> 00:56:07.301
这是我们的原始菜单

00:56:07.367 --> 00:56:11.305
用来声明才特效
但它不是实际被渲染的那个

00:56:12.439 --> 00:56:15.642
如果我们将环境变量
CI PRINT TREE设为8

00:56:15.709 --> 00:56:18.846
就可以看到很多东西都已经被压塌了

00:56:19.146 --> 00:56:22.683
并且处理看来参与的少了

00:56:23.750 --> 00:56:26.286
我们还是有处理器节点

00:56:26.353 --> 00:56:27.855
单独位于一行

00:56:27.921 --> 00:56:32.426
也就意味着它需要一个中间缓存

00:56:32.492 --> 00:56:35.495
这就是CIImageProcessors
非常好的原因

00:56:35.562 --> 00:56:38.098
不过你只应该在特定情况下才使用

00:56:38.165 --> 00:56:40.701
当你要生成的特效 你所有的算法

00:56:40.767 --> 00:56:43.604
不能在CIKernel语言内
被表达时

00:56:44.671 --> 00:56:47.941
如你所见
处理的剩余部分都会被连接到一起

00:56:48.008 --> 00:56:51.411
因此我们有variableBoxBlur
来处理剩余的颜色匹配

00:56:51.478 --> 00:56:54.314
还有clamptoalpha
都在一次传值中完成

00:56:54.515 --> 00:56:57.684
这也是为什么总要
在这些API中有所取舍的原因

00:56:57.751 --> 00:57:00.721
如果你可以的话就应该
写在CIKernel语言内

00:57:04.291 --> 00:57:06.159
这可能会有点难读

00:57:07.261 --> 00:57:09.730
所以你也可以声明

00:57:09.796 --> 00:57:12.266
使用了CI PRINT
TREE 即graphviz

00:57:12.799 --> 00:57:16.303
在这里我们使用了
CI PRINT TREE=8

00:57:17.104 --> 00:57:18.772
通过利用graphviz选项

00:57:19.339 --> 00:57:22.009
我们可以看到处理器节点 还有其与

00:57:22.075 --> 00:57:23.410
图的其他部分完全融合

00:57:23.877 --> 00:57:27.080
我们还可以看到
所请求的RGBAf输出

00:57:30.684 --> 00:57:33.754
我们复习下今天都学了些什么吧

00:57:34.221 --> 00:57:37.424
David给我们展示了
如何在iOS上编辑RAW图像

00:57:38.025 --> 00:57:39.159
然后Etienne跟我们讲了

00:57:39.226 --> 00:57:42.429
你如何利用Core Image
编辑Live Photos

00:57:42.496 --> 00:57:45.365
最后我们看到了如何使用

00:57:45.432 --> 00:57:47.734
CIImage上叫做
CIImageProcessor的新API

00:57:47.801 --> 00:57:51.104
还有如何在你的kernels上
声明一个输出格式

00:57:51.171 --> 00:57:53.207
借以减少内存占用

00:57:54.942 --> 00:57:56.310
为了获取更多信息

00:57:56.376 --> 00:57:58.745
请访问developer.apple.com

00:58:00.881 --> 00:58:03.116
有一些相关的演讲
你们可能会感兴趣

00:58:03.183 --> 00:58:06.353
特别是如果你打算
在iOS上做RAW处理的话

00:58:06.420 --> 00:58:09.156
还有Etienne提到的
“iOS摄影进阶”

00:58:09.790 --> 00:58:13.794
今天晚些时候还有个讲座叫
“用广色域来工作”

00:58:14.161 --> 00:58:15.529
还是在这进行

00:58:16.930 --> 00:58:18.665
非常感谢大家的到来

00:58:18.732 --> 00:58:20.567
我希望你们在接下来的
WWDC过得愉快