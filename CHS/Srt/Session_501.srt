00:00:19.553 --> 00:00:23.757 
IOS PHOTOGRAPHY的新特性

00:00:23.824 --> 00:00:24.725 
早上好

00:00:25.592 --> 00:00:27.895 
早上好各位
欢迎来到501会话

00:00:28.462 --> 00:00:29.530 
我是Brad Ford

00:00:29.596 --> 00:00:33.300 
我在Apple的Core Media和
AV Foundation Capture团队工作

00:00:34.835 --> 00:00:37.271 
本次会议全是关于iOS相机的

00:00:37.337 --> 00:00:38.872 
希望你们现在都已经知道了

00:00:38.939 --> 00:00:41.475 
这是世界上最流行的相机

00:00:41.575 --> 00:00:43.610 
本次会议也是关于摄影的

00:00:44.244 --> 00:00:46.079 
如果你开发一个摄影的应用

00:00:46.280 --> 00:00:49.016 
或是正考虑开发一个摄影应用

00:00:49.216 --> 00:00:51.351 
那么这对你来说是个不错的OS

00:00:51.418 --> 00:00:54.655 
我觉得你和iOS 10
很快就能交上朋友

00:00:55.589 --> 00:00:58.158 
今天我们将把注意力集中到
AV Foundation框架

00:00:58.225 --> 00:01:02.529 
它是我们最底层
并且最强大的访问相机的框架

00:01:02.996 --> 00:01:05.098 
AV Foundation
有着广度和深度

00:01:05.532 --> 00:01:07.367 
如果你是iOS拍照的新手

00:01:07.434 --> 00:01:12.472 
我邀请你看下列过去
WWDC 的相机主题演讲视频

00:01:13.073 --> 00:01:15.342 
它们会给你听今天的
演讲打下良好的基础

00:01:15.409 --> 00:01:17.644 
另外 你可以看到我优雅地老去

00:01:19.880 --> 00:01:22.349 
在接下来的58分钟里
我们将要进行这些

00:01:22.883 --> 00:01:26.086 
我会展示全新的
AVCaptureOutput

00:01:26.153 --> 00:01:28.155 
用来捕捉拍摄内容

00:01:28.655 --> 00:01:30.924 
然后我们会关注四个特性

00:01:31.558 --> 00:01:34.094 
我们会关注Live Photos

00:01:34.161 --> 00:01:36.263 
你们将学会如何用
你的应用拍摄Live Photos

00:01:36.330 --> 00:01:38.232 
就如Apple的相机应用一样

00:01:38.832 --> 00:01:41.168 
你们将学会如何拍摄
原生RAW格式图片

00:01:41.235 --> 00:01:45.239 
并将它们保存为DNG文件
其在iOS上首次出现

00:01:46.073 --> 00:01:48.742 
你们将学到如何获得预览或者缩略图

00:01:48.809 --> 00:01:52.613 
为你的常规图片拍摄
以获得一个更具响应性的UI

00:01:53.714 --> 00:01:58.218 
最后 你会学到如何用
宽色域拍摄漂亮的栩栩如生的照片

00:01:58.886 --> 00:01:59.786 
让我们现在开始吧

00:02:00.487 --> 00:02:03.924 
我们先快速回顾一下
AV Foundation的捕获类是怎么工作的

00:02:04.191 --> 00:02:07.628  
我们拍照的宇宙中心
是AVCaptureSession

00:02:08.027 --> 00:02:10.864  
你告诉这个对象开始或结束运行

00:02:11.398 --> 00:02:14.368  
它需要一些输入
来使其可以干些有用的事

00:02:14.701 --> 00:02:17.137  
像是相机或是麦克风这类输入

00:02:17.437 --> 00:02:19.606  
它们给会话提供了数据

00:02:19.673 --> 00:02:22.075  
它也需要输出来接收数据

00:02:22.409 --> 00:02:25.679  
比如一个StillImageOutput
可以捕捉静态的图像

00:02:25.979 --> 00:02:29.650  
或是一个QuickTimeMovieFileOutput
可以用来录制Quicktime影片

00:02:30.083 --> 00:02:31.351  
还有connections

00:02:31.418 --> 00:02:36.490  
它们被作为AVCaptureConnections
在API中所呈现

00:02:36.790 --> 00:02:38.592  
这是我们的对象概览图

00:02:38.659 --> 00:02:41.061  
你们该看出来我们如何
把所有东西整合到一起

00:02:41.995 --> 00:02:44.998  
所有我刚提到的这些特性
都与拍摄静态图片有关

00:02:45.065 --> 00:02:49.837  
所以你可能预计今天会花很长时间
在AVCaptureStillImageOutput上

00:02:50.737 --> 00:02:51.572  
但是你错了

00:02:53.440 --> 00:02:56.510  
今天介绍iOS 10中
全新的CaptureOutput

00:02:56.577 --> 00:02:58.979  
它叫做AVCapturePhotoOutput

00:02:59.279 --> 00:03:03.417 
值得强调的是现如今我们的照片
可不止是静态的图片

00:03:04.484 --> 00:03:10.157 
AVCapturePhotoOutput解决了
AVStillImageOutput的设计难题

00:03:10.224 --> 00:03:11.725 
从四个主要方面

00:03:12.392 --> 00:03:14.895 
它以一个函数式的编程模型为主要特色

00:03:15.095 --> 00:03:18.532 
它对于可变和不可变的
数据间有明确的划分

00:03:19.399 --> 00:03:23.637 
我们将照片设置信息封装到
一个特有的对象作用到其自身

00:03:24.571 --> 00:03:29.176 
PhotoOutput可追踪照片
从请求到完成的全过程

00:03:29.510 --> 00:03:32.212 
通过一个回调的代理式接口

00:03:32.779 --> 00:03:34.348 
最后 它解决了

00:03:34.414 --> 00:03:37.885 
你在早先拍摄阶段不确定的图片设置

00:03:38.151 --> 00:03:40.053 
因此你知道你会得到什么

00:03:40.320 --> 00:03:42.923  
让我们再多讲一些最后一个特性

00:03:44.224 --> 00:03:46.560  
AVCapturePhotoOutput
看起来是这样的

00:03:46.627 --> 00:03:49.730  
即便有着诸多的新特性
它仍是个简洁的接口

00:03:49.830 --> 00:03:52.900  
甚至比AVCaptureStill
ImageOutput还要小

00:03:52.966 --> 00:03:55.235  
它有一个只读属性的小集合

00:03:55.502 --> 00:03:58.138  
来告诉你是否支持一个特性

00:03:58.205 --> 00:04:00.974  
像是
isLivePhotoCaptureSupported

00:04:01.341 --> 00:04:04.945  
它有一个更小的可写属性的集合
让你可以参与进来

00:04:05.012 --> 00:04:07.581  
当某个特性被支持时

00:04:08.015 --> 00:04:11.418  
有些拍摄特性会
影响拍摄渲染管道的建立

00:04:11.485 --> 00:04:13.720  
所以你们要提前指明它们

00:04:14.054 --> 00:04:16.456  
其中一个是
isHighResolutionCapture

00:04:16.523 --> 00:04:18.926  
如果你想拍摄高分辨率的照片

00:04:18.992 --> 00:04:23.497  
像是在iPhone 6s上
五百万像素的自拍

00:04:23.997 --> 00:04:26.733  
你得先采用这个特性

00:04:26.800 --> 00:04:28.969 
在调用AVCapture session的
startRunning之前

00:04:29.469 --> 00:04:34.274  
最后 你可以调用一个简单的方法
来开始拍摄照片

00:04:34.975 --> 00:04:36.243  
仅仅一个动词

00:04:36.844 --> 00:04:40.747  
你可能会问
所有那些相片生成状态怎么办

00:04:41.615 --> 00:04:43.183  
我怎么请求闪光灯拍摄

00:04:43.250 --> 00:04:44.718  
我怎么获得BGRA

00:04:44.785 --> 00:04:46.587  
我怎么获得静态图片防抖

00:04:47.387 --> 00:04:49.223 
这些还有一些其他特性都被移动到

00:04:49.289 --> 00:04:52.459 
一个叫做AVCapturePhoto
Settings的新对象中

00:04:52.960 --> 00:04:54.695 
这个对象包含所有这些设置

00:04:54.761 --> 00:04:57.931 
关于拍摄一张照片的请求

00:04:58.498 --> 00:05:01.535 
把它想成是个列表项可供选择

00:05:01.602 --> 00:05:04.972 
像是当你在Apple线上
商店买Mac的时候

00:05:05.339 --> 00:05:07.975 
你在网上表格里填上所有你想要的特性

00:05:08.041 --> 00:05:10.110 
然后点击提交订单按钮

00:05:10.644 --> 00:05:13.480 
提交订单就像是调用
capturePhoto

00:05:13.747 --> 00:05:17.150 
将AVCapturePhotoSettings
作为你所传的第一个参数

00:05:17.784 --> 00:05:19.419 
当你在网上下单时

00:05:19.553 --> 00:05:23.323  
商店需要你的电邮地址
来和你沟通订单的信息

00:05:24.358 --> 00:05:30.163  
在AVCapturePhotoOutput世界
你所提供的电邮地址就是遵从

00:05:30.230 --> 00:05:33.834  
AVCapturePhotoCapture
Delegate协议的对象

00:05:34.001 --> 00:05:38.338  
这个delegate会被回调
作为和你的拍照发生相关的事件

00:05:38.972 --> 00:05:42.276  
这个对象是传给
CapturePhoto第二个参数

00:05:43.610 --> 00:05:46.446 
那么AVCapturePhotoSettings
有什么好处呢

00:05:46.513 --> 00:05:48.315 
首先 它们是原子性的

00:05:48.849 --> 00:05:51.752 
所有设置都被封装到一个单一对象

00:05:52.019 --> 00:05:54.988 
所有的设置都不可能会不同步

00:05:55.489 --> 00:05:58.458 
因为它们不是
AVCapturePhotoOutput的属性

00:05:58.659 --> 00:06:00.827 
而是每一设置相关的对象

00:06:01.361 --> 00:06:02.196 
它们是独一无二的

00:06:02.563 --> 00:06:05.966 
每个照片设置实例都有唯一的ID属性

00:06:06.300 --> 00:06:09.136 
你只允许使用一个照片设置一次

00:06:09.369 --> 00:06:10.337 
并且不能再用

00:06:10.404 --> 00:06:15.008 
因此你每次拍照请求
将收到正好一组结果

00:06:17.010 --> 00:06:21.014 
在附加一组设置请求拍照后
你可以坚持不变动

00:06:21.081 --> 00:06:23.684 
并验证它们返回给你的结果

00:06:23.750 --> 00:06:27.354 
就有点像做了一个
你在线订单表格的备份

00:06:28.655 --> 00:06:30.824 
那么相片委托有什么好处呢

00:06:31.725 --> 00:06:33.427 
它是一个单一的回调函数集合

00:06:33.493 --> 00:06:35.896 
而且又是随着每个照片设置而变

00:06:36.697 --> 00:06:38.065 
序列是被记录下来的

00:06:38.131 --> 00:06:40.067 
你可以明确知道你将获得哪个回调函数

00:06:40.133 --> 00:06:41.768 
何时 以什么顺序

00:06:42.402 --> 00:06:45.372 
并且它是个用来解决不确定设置的手段

00:06:45.772 --> 00:06:48.242 
我想这点我得再多解释一点

00:06:48.809 --> 00:06:52.913 
假如说你的应用在时间轴上的
这个位置请求照片

00:06:54.314 --> 00:06:56.950 
你指明照片设置是带有自动闪光灯

00:06:57.117 --> 00:06:59.453 
和自动静态图片防抖

00:06:59.553 --> 00:07:01.922 
我把“静止图像稳定”缩写成SIS

00:07:01.989 --> 00:07:03.490 
以便能在幻灯片上显示的更好

00:07:04.091 --> 00:07:07.861 
你告诉PhotoOutput
我想使用闪光灯或者SIS

00:07:07.928 --> 00:07:10.898 
但是只在你需要的时候
还有它们适合于当前场景的时候

00:07:11.865 --> 00:07:14.301 
很快你提出了请求

00:07:14.368 --> 00:07:17.037 
PhotoOutput
会调用你委托的第一个回调函数

00:07:17.104 --> 00:07:20.374 
也就是willBeginCapture
ForResolvedSettings

00:07:20.440 --> 00:07:23.310 
这个回调函数永远都是第一个被调用

00:07:23.644 --> 00:07:26.180 
它就有点像是
你从Apple收到的礼节性邮件

00:07:26.246 --> 00:07:28.081 
告诉你我们已经收到了你的订单

00:07:28.515 --> 00:07:29.983 
我们会发送给你什么

00:07:30.384 --> 00:07:32.286 
这个回调函数传给你一个实例

00:07:32.352 --> 00:07:36.890 
实例是一个新对象的 叫做
AVCapturePhotoResolvedSettings

00:07:37.491 --> 00:07:39.893 
它就像你填写的照片设置

00:07:39.960 --> 00:07:41.695 
不同的是所有问题都解决了

00:07:42.563 --> 00:07:44.298 
它们有着相同的唯一ID

00:07:44.598 --> 00:07:47.734 
你未确定和决定的版本
共享一个唯一ID

00:07:47.801 --> 00:07:49.169 
以便你将它们一起比较

00:07:49.469 --> 00:07:52.406 
它也告诉你照片的输出
为你挑出了什么特性

00:07:52.773 --> 00:07:55.809 
注意 在这个例子中
闪光灯被设定为开

00:07:56.176 --> 00:07:57.911 
SIS被设定为关

00:07:58.078 --> 00:08:01.281 
我们现在很明显是处在极度弱光环境
像是这个会议室

00:08:01.448 --> 00:08:04.852 
接下来的回调函数是
willCapturePhotoForResolvedSettings

00:08:04.918 --> 00:08:07.454 
它是正好在拍照片的时候被送到

00:08:07.654 --> 00:08:10.390 
或是当虚拟相机快门正在闭合

00:08:10.724 --> 00:08:12.459 
并且播放了快门声的时候

00:08:12.759 --> 00:08:15.229 
如果你想播放一个快门动画效果

00:08:15.295 --> 00:08:16.930 
那么这正是时候

00:08:17.865 --> 00:08:21.702 
接下来马上就是
didCapturePhotoForResolvedSettings

00:08:21.768 --> 00:08:24.571 
就在图像被完全曝光呈现出来

00:08:24.638 --> 00:08:26.340 
而且虚拟快门开启之后

00:08:27.474 --> 00:08:30.978 
然后你要等一下因为图像正在被处理

00:08:31.044 --> 00:08:33.080 
加上所有你要求的特性

00:08:33.413 --> 00:08:35.048 
当照片最后处理完成时

00:08:35.115 --> 00:08:38.150 
你获得didProcessing
PhotoSampleBuffer这个回调函数

00:08:38.217 --> 00:08:41.188 
还有你一直在等的
ImageSampleBuffer

00:08:41.255 --> 00:08:44.024 
耶 就像是崭新的
Mac送到了你的门口

00:08:44.725 --> 00:08:49.496 
最后 你获得的回调函数是
didFinishCaptureForResolvedSettings

00:08:49.563 --> 00:08:51.865 
它肯定是最后被送达的

00:08:52.332 --> 00:08:55.536 
它就像是你收到的
来自Apple的回访邮件

00:08:55.602 --> 00:08:57.171 
告诉你所有包裹已经送到了

00:08:57.237 --> 00:08:58.906 
与你打交道非常愉快 完毕

00:08:59.740 --> 00:09:02.876 
现在是你清理图片生成
中间阶段存储的好时机

00:09:04.478 --> 00:09:06.980 
让我们详细讨论下那些委托

00:09:07.514 --> 00:09:10.551 
回调函数会追踪一个单一拍照请求

00:09:11.451 --> 00:09:14.888 
照片输出会保留一个
对你委托的弱引用

00:09:14.955 --> 00:09:17.191 
所以它不会一直给你保留那个对象

00:09:17.691 --> 00:09:20.127 
记着在你的代码里给它保留一个强引用

00:09:20.794 --> 00:09:24.031 
所有在这个协议里的回调函数
都被标为可选的

00:09:24.331 --> 00:09:26.400 
但其中有些在runtime
会变为必需

00:09:26.466 --> 00:09:28.101 
这取决于你的照片设置

00:09:28.168 --> 00:09:31.438 
例如 当你正拍一个压缩的跑步图片时

00:09:31.505 --> 00:09:34.975 
你的委托需要在你获得
照片的时候就实现一个回调函数

00:09:35.242 --> 00:09:37.344 
否则 我们就会无处送达它

00:09:37.945 --> 00:09:42.082 
此规则在AVCapturePhotoOutput.h
头文件中就明确写出了

00:09:43.183 --> 00:09:46.854 
所有回调函数都会传一个
ResolvedPhotoSettings对象的实例

00:09:46.920 --> 00:09:49.523 
就是我告诉你们的那个
因此你总会知道你将要得到什么

00:09:49.590 --> 00:09:50.858 
或是你刚刚得到了什么

00:09:54.161 --> 00:09:55.062 
说到设置

00:09:55.128 --> 00:09:57.698 
我们来看段代码 它展示了
如何初始化照片拍摄

00:09:57.764 --> 00:10:00.767 
利用AVCapturePhotoSettings
的诸多特性

00:10:01.134 --> 00:10:03.904 
首先第一个
takeHighResolutionPhoto

00:10:04.204 --> 00:10:07.307 
如我前面所说
iPhone 6s的前置摄像头

00:10:07.374 --> 00:10:11.245 
支持五百万像素的高分辨率自拍

00:10:11.311 --> 00:10:13.514 
但是它不能支持
五百万像素的连续流畅拍照

00:10:13.580 --> 00:10:15.816 
它只支持单个高像素的定格照

00:10:16.416 --> 00:10:19.186 
所以你必须创建
一个PhotoSettings对象

00:10:19.386 --> 00:10:23.257 
并设置启用
HighResolutionPhotoCaptureEnabled

00:10:23.490 --> 00:10:29.062 
这样你就生成了带有参数的结构体
AVCapturePhotoSettings

00:10:29.563 --> 00:10:32.933 
它默认将输出格式设为JPEG

00:10:32.999 --> 00:10:35.536 
并启用了静态图像防抖

00:10:36.370 --> 00:10:39.173 
然后我将isHighResolution
PhotoEnabled设为真

00:10:39.239 --> 00:10:40.874 
并调用CapturePhoto

00:10:41.542 --> 00:10:44.711 
在第二个例子
takeFlashPhoto中

00:10:45.512 --> 00:10:48.882 
注意flashMode
现在是settings对象的一个属性了

00:10:48.949 --> 00:10:51.084 
如果你过去用过
StillImageOutput

00:10:51.151 --> 00:10:54.521 
你就会知道Flash原来是
AVCaptureDevice的一部分

00:10:54.588 --> 00:10:56.356 
所以这会产生问题
就是你需要访问

00:10:56.423 --> 00:10:58.859 
两个不同的对象来设置settings

00:10:58.992 --> 00:11:01.695 
现在它是单独一个对象的一部分了

00:11:02.062 --> 00:11:02.930 
太棒了

00:11:03.664 --> 00:11:08.135 
最后一个例子用了一个挺复杂的
AVCapturePhotoSettings的结构体

00:11:08.202 --> 00:11:11.905 
这回我们要传递我们想要的输出格式

00:11:11.972 --> 00:11:14.541 
在这里
我们想要非压缩的BGRA格式

00:11:14.908 --> 00:11:17.811 
我们要建立
一个CV像素缓存属性的字典

00:11:18.312 --> 00:11:22.683 
然后将其作为
AVCapturePhotoSettings的参数传递

00:11:23.083 --> 00:11:23.984 
这样就行了

00:11:24.418 --> 00:11:26.286 
当你调用capturePhoto时

00:11:26.520 --> 00:11:28.689 
AVCapturePhotoOutput
会验证你的设置

00:11:28.755 --> 00:11:30.924 
来确保你不是在请求一些荒唐的东西

00:11:30.991 --> 00:11:33.293 
它将保证自治性

00:11:33.360 --> 00:11:36.630 
也将确保你所请求的东西真的被支持

00:11:36.697 --> 00:11:38.599 
如果不被支持 它会抛出一个异常

00:11:40.400 --> 00:11:43.937 
Result设置
如你所想是完全不能变动的

00:11:44.304 --> 00:11:45.906 
所有属性都是只读的

00:11:46.006 --> 00:11:47.741 
它们仅供你参考用

00:11:47.808 --> 00:11:50.477 
而且这是函数式编程不可变的部分

00:11:51.011 --> 00:11:52.980 
它有一个唯一ID来让你和

00:11:53.046 --> 00:11:55.315 
你的未设置的
settings对象作比较

00:11:55.616 --> 00:11:56.617 
这是个不错的特性

00:11:56.683 --> 00:12:00.120 
它让你在没得到你的照片前
就知道照片的尺寸

00:12:00.521 --> 00:12:04.525 
所以你能提前计划 做一些分配
或是其他你需要做的事

00:12:05.659 --> 00:12:08.462 
它会告诉你flash
被设为on还是off

00:12:08.762 --> 00:12:10.898 
静态图片防抖是被设为on还是off

00:12:12.432 --> 00:12:14.501 
它也支持包围曝光拍摄

00:12:14.735 --> 00:12:18.272 
这是一种你请求
多张图片时的特殊拍摄手法

00:12:18.405 --> 00:12:20.474 
有时候伴随着不同的曝光值

00:12:20.807 --> 00:12:25.179 
例如 可能是这么来做的
如果你想将多张曝光图片合并在一起

00:12:25.245 --> 00:12:28.148 
来生成像是HDR这样的效果

00:12:28.615 --> 00:12:32.853 
我在2014年的508会议上
讲了很多关于这类拍摄的问题

00:12:33.554 --> 00:12:35.522 
去看下那个视频来回想一下

00:12:36.256 --> 00:12:43.030 
在AVCaptureStillImageOutput中
我们支持自动包围曝光和定制包围曝光

00:12:43.797 --> 00:12:46.400 
而请求包围曝光的新方法是

00:12:46.667 --> 00:12:50.871 
初始化一个
AVCapturePhotoBracketSettings

00:12:51.004 --> 00:12:53.073 
它像是照片设置但它是一个子类

00:12:53.140 --> 00:12:54.741 
它有你额外所需的东西

00:12:54.808 --> 00:12:56.410 
用来完成包围曝光拍摄

00:12:57.277 --> 00:13:01.215 
当你想创建一个包围曝光时
你要声明一个数组

00:13:01.281 --> 00:13:03.417 
数组是AVCaptureBracketed
StillImageSettings的

00:13:03.483 --> 00:13:07.554 
这是个从AVCaptureStillImageOutput
时代就有的对象

00:13:08.222 --> 00:13:10.224 
你给每个曝光表明其中一个值

00:13:10.290 --> 00:13:14.895 
例如 -2EV +2EV 0EV

00:13:15.495 --> 00:13:18.899 
如果你是用iPhone 6s
或者6s Plus

00:13:18.966 --> 00:13:21.702 
你可以选择启用镜头防抖

00:13:21.768 --> 00:13:24.538 
利用isLensStabilizationEnabled属性

00:13:25.339 --> 00:13:27.574 
请你回忆下我之前幻灯片
展示给你们的时间轴

00:13:27.641 --> 00:13:32.279 
照片被传到didFinishProcessing
PhotoSampleBuffer回调函数

00:13:32.412 --> 00:13:35.082 
当你请求三张图片的包围曝光时

00:13:35.315 --> 00:13:37.217 
该回调函数会被调用三次

00:13:37.284 --> 00:13:38.385 
每张图片一次

00:13:38.719 --> 00:13:42.856 
第五个参数告诉你是哪个包围曝光设置

00:13:42.923 --> 00:13:45.826 
在这个图片请求中与之协同的

00:13:46.860 --> 00:13:50.430 
我们很喜欢新的
AVCapturePhotoOutput

00:13:50.564 --> 00:13:52.633 
所以我们想让你马上就用它

00:13:52.900 --> 00:13:57.004 
因此我们在iOS10中不赞成使用
AVCaptureStillImageOutput

00:13:57.070 --> 00:14:00.440 
和其他所有AVCaptureDevice中
闪光灯相关的属性

00:14:00.741 --> 00:14:03.243 
这才是你应该用的

00:14:04.211 --> 00:14:07.748 
如我所说
闪光灯拍摄的一部分被打包到

00:14:07.814 --> 00:14:11.518 
相片设置中
它是一个更好的程序接口

00:14:11.885 --> 00:14:13.153 
尽快的使用它吧

00:14:14.655 --> 00:14:16.089 
最后一项是

00:14:16.957 --> 00:14:19.560 
在我们在说下面之前说下photo的好处

00:14:20.494 --> 00:14:22.196 
它们使书签功能更容易

00:14:22.863 --> 00:14:24.498 
即时的设置设定

00:14:25.265 --> 00:14:26.800 
有把握的请求追踪

00:14:27.267 --> 00:14:28.769 
它对Apple来说也有益处

00:14:28.836 --> 00:14:32.439 
因为它对我们来说
像是个可扩展的回调函数调色板

00:14:32.506 --> 00:14:35.209 
我们可以在将来加入
新的方法并回调给你

00:14:35.642 --> 00:14:38.846 
最后一点对于
接下来我要说的特性很重要

00:14:38.912 --> 00:14:40.981  
我要说的就是Live Photos

00:14:41.815 --> 00:14:46.820  
Apple.com上有关于何谓
Live Photos好的宣传广告

00:14:46.887 --> 00:14:50.457 
静态照片捕捉到的是瞬间凝结的记忆

00:14:50.924 --> 00:14:52.993 
而有了Live Photos
你能将这些瞬间变成

00:14:53.060 --> 00:14:55.529 
令人难忘 鲜活生动的回忆

00:14:56.730 --> 00:14:58.498 
Live Photos的美妙之处在于

00:14:58.565 --> 00:15:02.002 
它们会珍藏你留存于
记忆深处的美好瞬间

00:15:02.736 --> 00:15:06.240 
在这张照片里
这是张不错的静态照片

00:15:07.007 --> 00:15:10.544 
巨大恶心的沙蟹
这是我外甥从沙滩上挖出来的

00:15:10.611 --> 00:15:11.445 
一张不错的照片

00:15:11.512 --> 00:15:13.080 
如果我3D touch它

00:15:17.084 --> 00:15:19.520 
好了 现在我想起来了
那天太冷了

00:15:19.586 --> 00:15:21.989 
他从来没到过海边
他的嘴唇都冻青了

00:15:22.055 --> 00:15:24.091 
他在海水里时间太长
手都一直在发抖

00:15:24.324 --> 00:15:26.793 
我还在开始时候听到我哥哥的声音

00:15:26.994 --> 00:15:29.396 
所有这些都帮我进行了回忆

00:15:29.630 --> 00:15:32.999 
因为我更多的感官被唤醒了

00:15:33.901 --> 00:15:35.903 
人们发现了各种新的方式

00:15:35.969 --> 00:15:38.272 
把Live Photos
当做艺术创作的媒介使用

00:15:38.672 --> 00:15:40.941 
这张是一个旋转的自拍

00:15:41.441 --> 00:15:44.311  
我们的相机产品团队
把它叫做甜甜圈自拍

00:15:46.513 --> 00:15:48.415 
要完成它可是相当有难度的

00:15:48.916 --> 00:15:52.986 
有张用Live Photo拍的
正在旋转的转椅也很流行

00:15:53.253 --> 00:15:54.087 
看看那张吧

00:15:54.922 --> 00:15:57.791 
我是个展现惊喜的
live photo的大粉丝

00:15:58.158 --> 00:16:00.093 
不幸的是 我们孩子们也是

00:16:06.366 --> 00:16:08.535 
一个三秒的窗口实在太有诱惑力了

00:16:08.602 --> 00:16:10.704 
对于我这么一个天生的
吓人照片爱好者来说

00:16:11.471 --> 00:16:15.342 
Live Photos是从
Apple设计工作室思考体验中诞生

00:16:15.409 --> 00:16:16.410 
其诞生的前提是

00:16:16.810 --> 00:16:18.712 
即便我们现在有了这么多好的屏幕

00:16:18.779 --> 00:16:20.614 
来分享和观看内容

00:16:21.048 --> 00:16:25.118 
照片体验已经保持静态有150年了

00:16:25.652 --> 00:16:28.655 
我们划过屏幕浏览的那些JPEG文件
只不过就是数字版本的

00:16:28.722 --> 00:16:32.159 
那些我们留存在鞋盒中相纸的化学药剂

00:16:32.559 --> 00:16:35.229 
而它仍然是
人们保存他们回忆的主要方式

00:16:35.295 --> 00:16:37.531 
所以难道我们不能做得更好么

00:16:38.265 --> 00:16:40.434 
经过了很多的试验和原型体验

00:16:40.501 --> 00:16:43.136 
我们得出了这个新的媒体体验

00:16:43.704 --> 00:16:44.805 
一个时刻或是一个记忆

00:16:45.005 --> 00:16:48.075 
首先最重要的是它还是一张静态照片

00:16:48.442 --> 00:16:50.711 
它仍然和以前照片的质量一样好

00:16:50.777 --> 00:16:54.281 
它是一张1200万像素全分辨率的
静态JPEG图片

00:16:54.581 --> 00:16:57.751 
它与非LIve Photos
有着相同的质量

00:16:57.818 --> 00:16:59.386 
让我再强调一遍

00:16:59.920 --> 00:17:04.090 
Live Photos有Apple
非Live Photos的一切优点

00:17:04.223 --> 00:17:07.194 
所以你把它打开没有牺牲任何东西

00:17:08.962 --> 00:17:11.932 
另一个很棒的点子是平滑拍摄

00:17:12.398 --> 00:17:14.300 
这意味着你不需要学习任何新的东西

00:17:14.434 --> 00:17:16.569 
你就如你原来一样拍摄照片就可以

00:17:17.104 --> 00:17:20.273 
还是那样 定景 按快门

00:17:20.607 --> 00:17:22.209 
不用考虑别的

00:17:23.777 --> 00:17:25.679 
一张Live Photo
同样也是一段记忆

00:17:26.012 --> 00:17:28.615 
它能比静态图片调动更多感觉

00:17:28.682 --> 00:17:30.417 
它可以帮你唤起回忆

00:17:31.451 --> 00:17:34.588 
所以它就像是一部短电影 3秒的电影

00:17:34.655 --> 00:17:38.725 
1.5秒是静态图之前发生的事
1.5秒是之后的

00:17:39.326 --> 00:17:43.797 
我们能以
屏幕分辨率或者1080p拍摄它

00:17:45.566 --> 00:17:47.134 
而且它包含音频

00:17:48.468 --> 00:17:50.871 
我们还在持续改进它的设计

00:17:51.271 --> 00:17:55.876 
iOS9.1中我们加入挺棒的特性
自动裁剪Live Photos

00:17:55.943 --> 00:17:59.279 
以防你你冲着你的鞋子
或者口袋做出挥动的动作

00:17:59.513 --> 00:18:01.648 
我们会自动裁掉这些
去除掉

00:18:01.715 --> 00:18:03.317 
你不想在影片中看到的部分

00:18:03.851 --> 00:18:05.853 
在iOS 10中
我们加入新特性让它变得更好

00:18:05.953 --> 00:18:08.989 
现在所有的Live Photo
影片都是防抖的了

00:18:10.190 --> 00:18:13.493 
另一个iOS10的新特性是
拍摄时可以播放音乐

00:18:13.560 --> 00:18:14.995 
如果你正在放音乐

00:18:17.598 --> 00:18:19.233 
是啊 这个特性不错

00:18:19.299 --> 00:18:20.200 
我也挺喜欢的

00:18:21.902 --> 00:18:24.571 
为了让它成为一个时刻也是一段记忆

00:18:24.705 --> 00:18:27.040 
如你所料的
Live Photo有两部分组成

00:18:27.107 --> 00:18:29.142 
JPEG及
QuickTime电影文件

00:18:29.510 --> 00:18:33.380 
这两部分共享一个通用的
UUID以此来连系它们

00:18:33.780 --> 00:18:35.516 
JPEG文件的UUID被存储在

00:18:35.582 --> 00:18:37.684 
Apple Maker Note里

00:18:38.418 --> 00:18:40.354 
影片资源 也就是我说的

00:18:40.420 --> 00:18:43.223 
通常三秒长 有视频轨

00:18:43.290 --> 00:18:46.560 
大概是1080p
有着3比1的宽高比

00:18:47.194 --> 00:18:50.597 
它包含一个带有示例的定时元轨道

00:18:50.664 --> 00:18:53.667 
就相当于是对应静态图片的时间

00:18:53.901 --> 00:18:55.269 
在影片的时间轴上

00:18:55.636 --> 00:18:58.071 
它还包含了一些上层影片的元数据

00:18:58.138 --> 00:19:00.507 
可以用来与JPEG的元数据来配对

00:19:00.741 --> 00:19:03.677 
这叫做QuickTime内容识别器

00:19:04.077 --> 00:19:06.313 
它的值是一个UUID风格的流

00:19:08.248 --> 00:19:10.651 
需要怎样
才能拍摄Live Photos呢

00:19:11.418 --> 00:19:12.853 
在AVCapturePhotoOutput里

00:19:12.920 --> 00:19:17.224 
有一个属性叫
isLivePhotoCaptureSupported

00:19:17.291 --> 00:19:18.325 
你得确保它被支持

00:19:18.392 --> 00:19:19.993 
它不是在所有设备上都被支持的

00:19:20.494 --> 00:19:24.598 
目前它只支持
AVCaptureSessionPresetPhoto

00:19:25.666 --> 00:19:30.704 
你要使用AVCapturePhotoOutput
.isLivePhotoCaptureEnabled

00:19:30.771 --> 00:19:31.738 
将其设为真

00:19:32.239 --> 00:19:35.509 
你需要在你开始运行会话之前启用它

00:19:35.576 --> 00:19:38.812 
否则会造成会话破坏性的重新配置

00:19:38.879 --> 00:19:39.947 
你绝对想避免这麻烦

00:19:40.881 --> 00:19:44.618 
如果你在你的Live Photo
影片中播放音频

00:19:44.685 --> 00:19:47.721 
你要为麦克风添加一个
AVCaptureDeviceInput

00:19:48.121 --> 00:19:49.556 
这很重要 不要忘了

00:19:50.457 --> 00:19:53.560 
而且不支持同时录制

00:19:53.627 --> 00:19:56.997 
使用AVCaptureMovieOutput
录制的常规电影

00:19:57.064 --> 00:19:58.866 
和Live Photos

00:19:59.166 --> 00:20:02.903 
因此如果在会话的拓扑图上
有一个影片文件输出

00:20:02.970 --> 00:20:04.838 
它会使Live Photo拍摄禁用

00:20:06.139 --> 00:20:08.809 
可按通常方式配置
LivePhotoCapture

00:20:09.209 --> 00:20:11.712 
它有默认的结构体

00:20:12.112 --> 00:20:17.084 
不过你要额外声明一个
LivePhotoMovieFileURL

00:20:17.384 --> 00:20:20.220 
在这里我们会写入影片

00:20:20.287 --> 00:20:23.457 
并且它必须在你的沙盒内
你还得能访问它

00:20:24.324 --> 00:20:28.295 
你不需要声明任何的
livePhotoMovieMetadata

00:20:28.362 --> 00:20:29.630 
但是如果你想的话也可以

00:20:30.097 --> 00:20:33.867 
在此我举个使用
author元数据的例子

00:20:33.934 --> 00:20:35.636 
我把自己设为author

00:20:35.702 --> 00:20:37.804 
以便全世界都知道这是我的影片

00:20:37.871 --> 00:20:42.309 
你也可以加些有趣的东西
像是往你的影片里加入GPS标签

00:20:42.876 --> 00:20:45.612 
让我们谈谈跟
Live Photo有关的委托方法

00:20:45.879 --> 00:20:48.115 
如我之前所说的
我们有个可扩展的调色板

00:20:48.182 --> 00:20:50.117 
关于委托回调函数的
我们将会用到它

00:20:50.851 --> 00:20:54.021 
当拍摄Live Photo时
你的第一个回调函数让你知道

00:20:54.087 --> 00:20:55.989 
有一个Live Photo
将会被录制

00:20:56.056 --> 00:20:58.659 
借由告诉你影片定好的尺寸

00:20:58.725 --> 00:21:01.261 
看到了吗 你不仅调整了照片的尺寸

00:21:01.328 --> 00:21:03.931 
你还知道了Live Photo
的尺寸会是多大

00:21:04.331 --> 00:21:05.999 
你收到了预期的回调函数

00:21:06.066 --> 00:21:10.237 
还包含了一张和以前一样
会保存在内存中的JPEG文件

00:21:10.304 --> 00:21:11.905 
不过我们会给你一些新的东西

00:21:12.840 --> 00:21:15.776 
一个Live Photo影片
实际就是三秒的影片

00:21:15.843 --> 00:21:17.611 
在其正中间夹着一张静态图片

00:21:17.978 --> 00:21:22.216 
这意味着在你的拍摄请求
发出的最多1.5秒内

00:21:22.416 --> 00:21:24.151 
你将会收到一个新的回调函数

00:21:24.218 --> 00:21:25.619 
而该回调函数有个古怪名字

00:21:25.886 --> 00:21:31.458 
叫didFinishRecordingLivePhotoMovie
ForEventualFileAtURL.

00:21:31.692 --> 00:21:32.726 
试试分析下语法吧

00:21:33.427 --> 00:21:38.031 
它的意思是文件还没被写好
但是已经采好样了

00:21:38.098 --> 00:21:40.100 
为这部影片

00:21:40.234 --> 00:21:44.571 
换句话说
若UI中有Live Photo标记

00:21:44.805 --> 00:21:46.907 
现在最好把它去掉了

00:21:46.974 --> 00:21:48.942 
让人们知道不用再举着相机不动了

00:21:49.443 --> 00:21:52.346 
现在最好把
Live Photo标记去掉

00:21:53.113 --> 00:21:57.384 
很快地 影片文件就会被写入完成

00:21:57.551 --> 00:22:01.688 
然后你会得到didFinishProcessing
LivePhotoToMovieFileAtURL.

00:22:01.889 --> 00:22:04.424 
如果你制作Live Photos
那这是必需的回调函数

00:22:04.858 --> 00:22:06.760 
现在你可以欣赏影片了

00:22:07.895 --> 00:22:10.631 
最后你竖个大拇指吧 都完成了

00:22:11.265 --> 00:22:13.967 
我们所有该做的都做完了

00:22:14.501 --> 00:22:16.937 
要注意的是拍摄
Live Photo的JPEG部分

00:22:17.004 --> 00:22:19.940 
和拍摄静态照片是一样的

00:22:20.007 --> 00:22:22.709 
它作为样例缓存保存在内存中

00:22:23.043 --> 00:22:25.679 
利用didFinishProcessingPhoto
SampleBuffer这个回调函数

00:22:25.746 --> 00:22:26.747 
如我们已见过的方式

00:22:27.381 --> 00:22:30.851 
如果你想把它写到硬盘上
那可是个琐碎的活

00:22:31.652 --> 00:22:34.087 
我们在AVCapturePhotoOutput里
有一个类方法

00:22:34.154 --> 00:22:38.325 
用来把JPEG重写成Data文件
D是大写的

00:22:38.759 --> 00:22:41.929 
这个方法很适合将
JPEG文件写入硬盘中

00:22:42.296 --> 00:22:43.931 
你可以在这里的action看到

00:22:44.431 --> 00:22:49.002 
我先跳过第二个参数
也就是previewPhotoSampleBuffer

00:22:49.069 --> 00:22:50.604 
我们一会儿再讲它

00:22:52.105 --> 00:22:55.676 
在此我有个做
Live Photo的建议

00:22:56.076 --> 00:22:58.645 
拍摄Live Photo是
某一类拍摄的例子

00:22:58.712 --> 00:23:00.380 
也就是传递多种资源的拍摄

00:23:00.447 --> 00:23:03.450 
这有点像分单购物

00:23:03.517 --> 00:23:06.486 
比如你使用一个订单购买电脑
和使用另外一个订单购买适配器

00:23:07.554 --> 00:23:10.858 
所以我们发现当传递多种资源时
我们可以很便捷的

00:23:10.924 --> 00:23:12.793 
我们所写的测试应用中进行测试

00:23:13.126 --> 00:23:18.198 
来实例化一个新的
AVCapturePhotoDelegate对象

00:23:18.265 --> 00:23:21.301 
为当前场景的每个照片请求

00:23:21.869 --> 00:23:24.438 
接下来在这个对象里
你可以汇集

00:23:24.505 --> 00:23:25.506 
所有你得到的东西

00:23:25.572 --> 00:23:28.876 
面向这个请求的样本缓冲影片等等

00:23:28.942 --> 00:23:31.545 
然后有个方便的地方来处理这个对象

00:23:31.612 --> 00:23:34.081 
即thumbs up回调函数
标志着我们完成了

00:23:34.381 --> 00:23:35.816 
这是一个有用的小提示

00:23:37.251 --> 00:23:38.886 
在你的资源被写入硬盘时

00:23:38.952 --> 00:23:41.455 
你还需要做几个步骤

00:23:41.788 --> 00:23:43.857 
来获取完全的动态图片体验

00:23:43.924 --> 00:23:46.560 
尽管视频部分是
标准的QuickTime影片

00:23:46.827 --> 00:23:48.695 
但那并不意味着它可被从头到尾播放

00:23:48.762 --> 00:23:51.131 
像是用一个AVPlayer
播放普通电影那样

00:23:51.431 --> 00:23:53.534 
这里有一个可以回放它的小窍门

00:23:53.800 --> 00:23:58.372 
它应该可以在照片的
动态图像时间缓入缓出

00:23:58.438 --> 00:24:01.175 
当你在这些资源间滑动的时候

00:24:01.241 --> 00:24:03.744 
它们会在photos应用里
有些许移动

00:24:04.144 --> 00:24:06.446 
为获得完全的
Live Photo回放体验

00:24:06.513 --> 00:24:09.516 
你需要使用photos和
photos UI框架

00:24:09.883 --> 00:24:12.085 
还有与Live Photo相关的类

00:24:12.419 --> 00:24:15.656 
用来将你的RAW资源摄取到照片库中

00:24:15.889 --> 00:24:18.859 
并恰当的播放它们 例如
通过LivePhotoView

00:24:20.127 --> 00:24:21.461 
且iOS 10中新提供了

00:24:21.528 --> 00:24:26.366 
photos框架可以让你就像编辑
静态照片来编辑Live Photo

00:24:26.733 --> 00:24:27.768 
这是个很棒的消息

00:24:28.068 --> 00:24:29.102 
我想做一下演示

00:24:36.343 --> 00:24:40.113 
在此我们有一些示例代码
令人尊敬的AVCam

00:24:40.180 --> 00:24:41.815 
得有五年没有被用过了

00:24:42.449 --> 00:24:44.551 
但我们现在又重新装扮它

00:24:44.618 --> 00:24:47.521 
以便它有特定的照片模式和影片模式

00:24:47.855 --> 00:24:50.591 
这是因为只能在照片模式
使用Live Photos

00:24:50.991 --> 00:24:52.926 
你要注意的是在顶部有标记告诉你

00:24:52.993 --> 00:24:55.062 
Live Photo模式是开还是关

00:24:56.029 --> 00:24:57.531 
你还可以切换摄像头

00:24:57.798 --> 00:24:59.933 
我会试着做下那个很难的甜甜圈自拍

00:25:00.000 --> 00:25:01.502 
让我们来看看我做的成不成功

00:25:01.835 --> 00:25:07.574 
你要做的就是开始
在中间拍一下 然后结束

00:25:07.908 --> 00:25:10.844 
注意看当我在自拍的时候
是有一个live标记出现的

00:25:10.911 --> 00:25:13.881 
而这就是在运用
我之前跟你说的回调函数

00:25:15.282 --> 00:25:18.118 
好了 现在它被写入了照片库

00:25:18.685 --> 00:25:20.888 
然后 在中间的某处拍一下

00:25:21.221 --> 00:25:22.122 
不错吧

00:25:22.389 --> 00:25:24.258 
但这还不是我们所能做的全部

00:25:24.391 --> 00:25:26.760 
在iOS 9中
当你想编辑Live Photo时

00:25:26.827 --> 00:25:28.529 
你会丢失其中的影片部分

00:25:28.762 --> 00:25:32.533 
但是现在你既可以在photos应用
中本地编辑

00:25:32.866 --> 00:25:35.269  
也可以使用应用内你所提供的代码

00:25:35.536 --> 00:25:38.272  
比如这个叫做
LivePhotoEditor的小例子

00:25:38.872 --> 00:25:42.109  
它在我所包含的照片编辑扩展应用中

00:25:42.910 --> 00:25:45.879 
我可以加上简单的滤镜
或是裁剪这部影片

00:25:46.513 --> 00:25:49.616 
通过它来加上有色滤镜非常的简单

00:25:49.816 --> 00:25:51.451 
值得注意的是它并没有丢失影片

00:25:51.518 --> 00:25:52.519 
我还可以播放它

00:25:52.586 --> 00:25:54.721 
然后 在中间的某处拍一下

00:25:54.788 --> 00:25:56.757 
棒极了
你可以编辑Live Photos了

00:26:03.730 --> 00:26:05.966 
好的 现在说回AVCam

00:26:06.033 --> 00:26:09.169 
就如我所说的
它有单独的视频和照片录制模式

00:26:09.236 --> 00:26:10.804 
所以你能获得最棒的照片体验

00:26:10.871 --> 00:26:12.873 
你可以获得最棒的影片制作体验

00:26:13.273 --> 00:26:15.375 
而且它展示了恰当的live标记技术

00:26:15.442 --> 00:26:16.577 
就如我谈到的

00:26:16.643 --> 00:26:19.313 
它也向你展示了如何将其写入到资源库

00:26:19.613 --> 00:26:21.582 
该示例代码现在已经可见了

00:26:21.648 --> 00:26:24.284 
你会在我们会话的页面上找到它

00:26:25.252 --> 00:26:26.553 
它甚至都被Swift化了

00:26:26.920 --> 00:26:29.056 
如果你想了解更多关于
Live Photo编辑的内容

00:26:29.122 --> 00:26:32.092 
请在周四上午11点参加505会话

00:26:32.459 --> 00:26:33.527 
你会听到其内容

00:26:35.128 --> 00:26:39.132 
我们还支持了一个叫做
LivePhotoCaptureSuspension的特性

00:26:39.333 --> 00:26:42.603 
在这个小例子里展示了
它什么时候会有用

00:26:43.036 --> 00:26:45.038 
假如说你有一个拍照的app

00:26:45.105 --> 00:26:47.641 
能发出烦人的雾角的声音

00:26:48.842 --> 00:26:50.244 
就跟着我想象该例子的场景

00:26:51.178 --> 00:26:52.145 
它会拍照

00:26:52.379 --> 00:26:53.947 
发出烦人的雾角声

00:26:54.248 --> 00:26:55.682 
现在假如说在时间轴上

00:26:55.749 --> 00:26:57.718 
你的用户在此拍了张Live Photo

00:26:58.418 --> 00:27:01.922 
然后他们在这里发出了烦人的雾角声

00:27:02.756 --> 00:27:06.293 
接下来在声音放完后又在此
拍了另一张Live Photo

00:27:07.728 --> 00:27:09.329 
这就会产生一个问题

00:27:09.396 --> 00:27:14.168 
因为两张照片的影片部分与

00:27:14.334 --> 00:27:16.069 
烦人的雾角声重叠了

00:27:16.570 --> 00:27:19.106 
你这下同时毁了
两部Live Photos影片

00:27:19.473 --> 00:27:21.975 
你会在一张照片里听到雾角声的结尾

00:27:22.042 --> 00:27:24.011 
而在另一张听到雾角声的开头

00:27:25.012 --> 00:27:27.281 
这可不太好 因此为了应对这个问题

00:27:27.681 --> 00:27:31.585  
你可以将
isLivePhotoCaptureSuspended设为真

00:27:31.652 --> 00:27:33.520  
就在你要放烦人的雾角声之前

00:27:34.154 --> 00:27:37.090  
这会使得任何在处理过程中的
Live Photos

00:27:37.291 --> 00:27:39.893  
被强行裁减到该点

00:27:40.327 --> 00:27:41.395  
你可以同样如此处理

00:27:41.461 --> 00:27:44.298  
把isLivePhotoCaptureSuspended
设为假

00:27:44.364 --> 00:27:48.368  
这会使结尾处有一个清楚的中断

00:27:48.435 --> 00:27:51.104  
以便没有任何早于该点的内容

00:27:51.572 --> 00:27:53.740  
会在你取消暂停的时候
出现在你的影片中

00:27:53.841 --> 00:27:54.908 
一个不错的小特性

00:27:56.577 --> 00:27:57.678 
让我们谈谈设备支持

00:27:57.744 --> 00:28:00.013 
我们应该让什么设备
支持LivePhoto拍摄呢

00:28:00.414 --> 00:28:03.684 
我们在所有近年的iOS设备上支持它

00:28:03.750 --> 00:28:07.487 
有个简单的方法来记忆就是
所有具有1200万像素摄像头

00:28:07.654 --> 00:28:09.389 
设备都会支持Live Photos

00:28:11.825 --> 00:28:14.494 
接下来进入我们今天的下一个
重要特性介绍

00:28:14.561 --> 00:28:16.029 
那就是RAW相片拍摄

00:28:18.599 --> 00:28:20.934 
为了解释什么是RAW图像

00:28:21.001 --> 00:28:25.172 
我得先高度概述一下
CMOS传感器是如何工作的

00:28:26.006 --> 00:28:31.144  
CMOS传感器会采集光中的光子
通过二维阵列的传感器

00:28:32.079 --> 00:28:35.349  
数组的上层叫做颜色过滤阵列

00:28:36.049 --> 00:28:38.252  
当光线透过上层时

00:28:38.485 --> 00:28:40.587  
它只允许一种颜色通过

00:28:40.654 --> 00:28:43.690  
红 绿 蓝 其一
依照Bayer模式

00:28:44.358 --> 00:28:46.793  
绿色在这个小棋盘上
是其他两种颜色的两倍多

00:28:46.860 --> 00:28:49.863  
因为我们的眼睛
对于绿色光有着两倍的敏感度

00:28:49.930 --> 00:28:51.398  
相比于其他两种颜色来说

00:28:52.165 --> 00:28:54.768  
底层被称为传感器阵列

00:28:56.203 --> 00:29:02.976 
在RAW文件中实际存储的是强度
此强度即红 绿 蓝光的数量

00:29:03.043 --> 00:29:06.346 
穿过传感器
每个探测器

00:29:06.947 --> 00:29:09.616 
也需要被存储在Bayer模式中

00:29:09.683 --> 00:29:13.086 
换句话说 就是红 绿 蓝光的排列

00:29:13.453 --> 00:29:15.556 
以便之后将其去马赛克化

00:29:16.190 --> 00:29:18.625 
你还要存许多其他元数据

00:29:18.692 --> 00:29:20.994 
像是颜色信息 曝光信息

00:29:22.663 --> 00:29:24.998 
因此RAW转换器工作很繁重

00:29:25.265 --> 00:29:27.835 
RAW会提取所有这些东西

00:29:27.901 --> 00:29:29.636 
并将其转换为RGB图像

00:29:31.171 --> 00:29:33.207 
去马赛克化只不过是冰山一角

00:29:33.273 --> 00:29:37.211 
在其被最终呈现在屏幕上之前
有许多工作需要完成

00:29:38.412 --> 00:29:39.880  
如果做个类比的话

00:29:40.180 --> 00:29:45.118  
存储RAW文件很大程度上就像是
存储用来烤蛋糕的原料

00:29:45.552 --> 00:29:48.222  
然后你走到哪都得带着这些原料

00:29:49.056 --> 00:29:50.257  
这样可太重了

00:29:50.591 --> 00:29:51.525  
也太糟糕了

00:29:52.226 --> 00:29:54.761  
每次你都要花些时间来烘烤它

00:29:55.562 --> 00:29:56.997 
如果你让两个不同的烘焙师

00:29:57.130 --> 00:29:58.932 
用相同的原料来烤蛋糕

00:29:58.999 --> 00:30:01.268 
你或许会得到口味有些许不同的蛋糕

00:30:02.336 --> 00:30:04.771 
但是使用RAW也有一些很大的好处

00:30:05.973 --> 00:30:09.343 
首先最重要的是
你可以灵活掌握烘焙的时间

00:30:09.409 --> 00:30:14.248 
你是把原料都在身边
但你可以来年再做一个更好的蛋糕

00:30:15.716 --> 00:30:21.321 
这里不会有像是BGRA或者420
那样的压缩出现

00:30:21.388 --> 00:30:22.723 
你有更多的比特可供操作

00:30:22.923 --> 00:30:28.629 
有一个10比特的RAW传感器
包括在每像素14比特而不是8比特

00:30:30.163 --> 00:30:32.199 
另外你有很多的净空间可供编辑

00:30:33.200 --> 00:30:37.838 
而且还给予你
创作空间来做出不同的决定

00:30:37.905 --> 00:30:40.307 
其实你就是把烘焙时间往后拖

00:30:41.208 --> 00:30:42.709 
那么JPEG又是什么呢

00:30:43.310 --> 00:30:45.345 
RAW图像提供了很多优势

00:30:45.412 --> 00:30:47.714 
但它们不是最终的存在形式

00:30:48.048 --> 00:30:51.385 
重要的是你要清楚你选择RAW时
是要有所取舍的

00:30:51.852 --> 00:30:54.555 
JPEG仍然是一个有吸引力的选项

00:30:55.756 --> 00:31:00.861 
JPEG就像是
专为你烘焙的Apple蛋糕

00:31:01.995 --> 00:31:03.230 
这是个不错的蛋糕

00:31:03.297 --> 00:31:05.632 
它包含着Apple的所有善意

00:31:07.134 --> 00:31:08.135 
快得多的渲染速度

00:31:08.202 --> 00:31:10.437 
你就不必再带着这么多原料了

00:31:11.471 --> 00:31:15.475 
你还会获得像是防抖那样的好东西

00:31:15.676 --> 00:31:19.379 
就如我之前提到的
我们使用多张图片融合来进行防抖

00:31:19.746 --> 00:31:21.415 
你用一单张
RAW照片是得不到的

00:31:21.481 --> 00:31:23.984 
不管它质量多好也不行
因为我们是要拍

00:31:24.051 --> 00:31:25.986 
我觉得就有点像是多层的蛋糕

00:31:26.620 --> 00:31:29.256 
所以你用单张的图片是做不到的

00:31:30.123 --> 00:31:32.125 
而且你也获得了更小的文件尺寸

00:31:33.460 --> 00:31:36.663 
因此所有这些东西使得JPEG
变成非常有吸引力的替代方案

00:31:36.763 --> 00:31:39.199 
你得决定你想要用哪一个

00:31:39.266 --> 00:31:40.367 
才对你的应用来说更好

00:31:41.168 --> 00:31:44.071 
我们用四个字符的编码
来识别RAW格式

00:31:44.137 --> 00:31:47.941 
如我们在Core Video框架中
识别普通像素格式那样

00:31:48.342 --> 00:31:51.545 
在CVPixelBuffer.h中
加入了四个新的常量

00:31:51.612 --> 00:31:53.881 
用来描述四种不同的Bayer样式

00:31:54.214 --> 00:31:56.149 
你会在相机应用中遇到的

00:31:56.416 --> 00:31:57.284 
它们被列在这

00:31:57.417 --> 00:31:58.685 
它们基本上是描述了

00:31:58.752 --> 00:32:00.487 
红 绿 蓝光在棋盘上的顺序

00:32:02.489 --> 00:32:05.425 
你怎么用AVCapturePhotoOutput
来拍摄RAW呢

00:32:05.492 --> 00:32:06.293 
其实挺简单的

00:32:07.027 --> 00:32:10.464 
RAW仅在使用相片格式时才被支持

00:32:10.531 --> 00:32:13.100 
也就是预设的照片
跟Live Photo一样

00:32:14.034 --> 00:32:16.003 
而且它只支持后置摄像头

00:32:17.204 --> 00:32:21.475 
我们支持RAW的包围曝光
所以你可以拍摄包围曝光

00:32:21.542 --> 00:32:23.710 
例如 给三张RAW照片

00:32:24.745 --> 00:32:26.146 
为了请求一个RAW拍摄

00:32:26.213 --> 00:32:28.549 
你要创建一个
AVCapturePhotoSettings对象

00:32:28.615 --> 00:32:31.151 
但是神奇吧
这里有个不同的结构体

00:32:31.451 --> 00:32:33.687 
该结构体接收
rawPixelFormat

00:32:34.488 --> 00:32:38.725 
那你怎么决定应该
让它生成哪种RAW格式呢

00:32:38.992 --> 00:32:41.628 
你可以问下PhotoOutput

00:32:41.695 --> 00:32:45.499 
它会告诉你我有RAW相片像素格式

00:32:45.566 --> 00:32:48.101 
你可以从中选择一个

00:32:49.603 --> 00:32:52.606 
你声明的RAW格式
必须要被硬件所支持

00:32:53.440 --> 00:32:57.044 
还有一个重要的事
是在这些RAW设置当中

00:32:57.678 --> 00:33:03.851 
SIS是没有意义的
因为这不是一个多图片融合的场景

00:33:04.151 --> 00:33:07.020 
因此autoStillImage
StabilizationEnabled

00:33:07.087 --> 00:33:09.156 
需要被设为no
否则会抛出异常

00:33:09.656 --> 00:33:11.992 
highResolutionPhotoEnabled也是

00:33:12.059 --> 00:33:14.862 
毫无意义的
因为你只是要获得RAW的功能

00:33:15.362 --> 00:33:16.964 
所以它也要被设为false

00:33:18.532 --> 00:33:20.868 
有一个关于RAW照片的
单独委托回调函数

00:33:20.934 --> 00:33:25.472 
叫做didFinishProcessing
RAWPhotoSampleBuffer

00:33:25.873 --> 00:33:28.575 
你非常才思敏捷的话

00:33:28.675 --> 00:33:31.411 
你就会注意到它有着完全相同的参数

00:33:31.512 --> 00:33:35.649 
就和你之前获得
常规照片时的回调函数一样

00:33:35.716 --> 00:33:38.552 
didFinishProcessing
RAWPhotoSampleBuffer这个回调函数

00:33:38.619 --> 00:33:40.287 
现在你可能想问

00:33:40.354 --> 00:33:45.292 
我们为何还这么麻烦给RAW样本缓冲
弄一个新的委托回调函数呢

00:33:45.359 --> 00:33:48.328 
既然它和另一个有着完全相同的参数

00:33:48.862 --> 00:33:49.997 
其实有一个很好的理由

00:33:50.397 --> 00:33:51.965 
这个理由就是

00:33:53.400 --> 00:33:56.069 
为了支持RAW plus processed图片

00:33:56.236 --> 00:34:00.641 
我们支持该种照片
就像DSLR相机 无反光板相机那样

00:34:01.008 --> 00:34:04.878 
这是种能让你同时得到RAW和JPEG
的工作流

00:34:04.978 --> 00:34:06.713 
即processed图片的意思

00:34:07.214 --> 00:34:10.918 
能同时拍摄RAW和JPEG
可是相当专业的特性

00:34:12.286 --> 00:34:14.855 
你能获得RAW plus processed图片

00:34:14.922 --> 00:34:17.858 
它不是必须得是JPEG
它也能是BGRA 420

00:34:19.025 --> 00:34:21.929 
processed图像
被生成到另一个回调函数

00:34:21.995 --> 00:34:24.864 
叫做didFinishProcessingPhoto
SampleBuffer

00:34:24.965 --> 00:34:28.068 
RAW被生成到名字当中带有
RAW的那个回调函数

00:34:30.137 --> 00:34:33.172 
RAW plus processed brackets也被支持

00:34:33.239 --> 00:34:34.608 
看看你是不是能想明白

00:34:34.708 --> 00:34:36.243 
其实就是
我要做一个包围曝光

00:34:36.310 --> 00:34:38.178 
同时我请求RAW plus JPEG

00:34:38.344 --> 00:34:40.179 
所以我做了三次包围曝光

00:34:40.246 --> 00:34:42.583 
我会得到三张RAW
和三张JPEG图片

00:34:44.885 --> 00:34:47.721 
但是其并不支持RAW plus
静态照片防抖

00:34:49.822 --> 00:34:51.925 
为了拍摄RAW plus JPEG

00:34:52.292 --> 00:34:56.429 
你还得需要另一个叫
AVCapturePhotoSettings的结构体

00:34:56.830 --> 00:34:59.633 
在这个结构体中
你要声明RAW像素格式

00:34:59.700 --> 00:35:02.135 
还有你想要的processed格式

00:35:02.769 --> 00:35:07.774 
在此我选择了JPEG和
RAW作为输出格式

00:35:09.643 --> 00:35:13.914 
当你选择JPEGPlusRAW时
HighResolutionPhotoEnabled

00:35:13.981 --> 00:35:14.882 
是有用的

00:35:14.948 --> 00:35:17.150 
因为它现在被应用到JPEG上

00:35:19.353 --> 00:35:21.722  
让我们讨论下如何存储
RAW缓冲

00:35:22.189 --> 00:35:25.492  
如果你在内存层面跟它们打交道的话
那它们就不那么有用了

00:35:26.293 --> 00:35:29.763  
所以与其介绍
一个Apple专利的RAW文件格式

00:35:29.830 --> 00:35:31.798 
就像许多其他相机供应商做的那样

00:35:32.165 --> 00:35:36.236 
不如选使用Adobe的
数字式负格式来存储

00:35:37.070 --> 00:35:40.908 
DNG是一个标准化的方式来
储存比特和元数据

00:35:41.041 --> 00:35:43.577 
它并不是指一种文件格式

00:35:43.911 --> 00:35:47.114 
回到我们的烤蛋糕类比

00:35:47.447 --> 00:35:51.351 
DNG就像是存原料的盒子

00:35:51.985 --> 00:35:54.288  
还是取决于个体的RAW转换器

00:35:54.354 --> 00:35:56.557  
来决定怎么解释那些原料

00:35:56.857 --> 00:36:00.794  
因此由第三方应用所打开的DNG
可能看起来不太一样

00:36:00.861 --> 00:36:02.729  
与另一个应用打开的DNG相比

00:36:03.897 --> 00:36:05.732 
所以存储DNG是相当琐碎麻烦的

00:36:06.400 --> 00:36:10.337 
你要调用一个叫做
dngPhotoDataRepresentation的类函数

00:36:11.104 --> 00:36:14.074 
把你从委托回调函数中
获得的RAW缓冲传出去

00:36:14.641 --> 00:36:19.546 
这会在内存中生成
一个可被写入文件的Data

00:36:20.480 --> 00:36:24.852 
并且这个API会写入很多的
压缩DNG文件

00:36:24.918 --> 00:36:25.986 
来保存空间

00:36:28.689 --> 00:36:30.290 
这里该有个演示了

00:36:36.897 --> 00:36:38.465 
对于RAW拍摄

00:36:38.532 --> 00:36:42.769 
我们更新了另一部分的令人尊敬的代码
叫做AVCamManual

00:36:43.303 --> 00:36:45.372 
我们是2014年发布的

00:36:45.439 --> 00:36:48.575 
在我们展示手动控制API时

00:36:48.942 --> 00:36:53.981 
它让你选择对焦 曝光 白平衡

00:36:54.314 --> 00:36:57.551 
你可以手动或自动控制这些功能

00:36:58.051 --> 00:37:02.055 
在左边的HUD里有个新东西

00:37:02.256 --> 00:37:04.625 
可以让你选择开或者关RAW

00:37:05.292 --> 00:37:08.795 
你可以选择在该应用里拍摄RAW照片

00:37:09.429 --> 00:37:10.864 
让我们看看曝光吧

00:37:10.931 --> 00:37:14.101 
我看看能不能故意过曝一点

00:37:15.369 --> 00:37:16.603 
然后我再拍张照

00:37:18.272 --> 00:37:19.506 
现在我要退出这个应用

00:37:20.440 --> 00:37:24.111 
我要打开一个叫
RAWExpose的应用

00:37:24.178 --> 00:37:26.013 
这个应用不是
AV Foundation团队写的

00:37:26.079 --> 00:37:27.648 
而是Core Image团队写的

00:37:27.915 --> 00:37:30.651 
他们很有风度的把它借给我来做演示

00:37:31.785 --> 00:37:34.021 
我们来看下刚刚拍的照片

00:37:34.888 --> 00:37:37.524 
这是张RAW照片

00:37:37.591 --> 00:37:39.660 
它会读取DNG文件

00:37:40.160 --> 00:37:45.365 
我们可以做到用
JPEG永远都做不到的事

00:37:46.233 --> 00:37:51.638 
像是我们可以恢复EV值

00:37:52.072 --> 00:37:53.707 
还能调整色温和色调

00:37:53.774 --> 00:37:57.110 
所有这些都是在后期完成的
而且完全可逆

00:37:57.578 --> 00:38:01.782 
我也可以看看有或没有
减少噪点看着是什么样的

00:38:02.482 --> 00:38:06.119 
这就是编辑RAW的
新Core image API的部分特性

00:38:06.687 --> 00:38:07.988 
我们再回到幻灯片中

00:38:13.994 --> 00:38:17.531 
AVCamManual的
示例代码现在可见了

00:38:17.698 --> 00:38:18.765 
你可以找得到

00:38:18.832 --> 00:38:21.735 
它和这节课的幻灯片是有关联的

00:38:22.503 --> 00:38:25.706 
如果你想学到
更多关于RAW编辑的内容

00:38:25.772 --> 00:38:29.743 
你可以去我刚才提过的同个会话
505会话

00:38:30.110 --> 00:38:31.345 
他们会同时谈到这两点

00:38:31.578 --> 00:38:34.181 
第二个部分是通过
Core Image来处理RAW

00:38:34.248 --> 00:38:35.315 
这是个不错的部分

00:38:37.351 --> 00:38:39.419 
RAW照片拍摄都被什么设备支持呢

00:38:40.554 --> 00:38:41.722 
巧合的是

00:38:41.788 --> 00:38:46.360 
和我们Live Photos
支持的设备一样

00:38:46.827 --> 00:38:50.330 
所有具有1200万像素摄像头的设备
都支持RAW照片拍摄

00:38:51.498 --> 00:38:52.733 
我们的下一个话题是

00:38:53.467 --> 00:38:57.538 
拍摄预览图像 也就是缩略图

00:38:58.672 --> 00:39:00.641 
摄影app通常会拍照

00:39:00.707 --> 00:39:03.410 
然后想快速显示预览结果

00:39:03.777 --> 00:39:05.579 
像是Apple Zone相机应用

00:39:06.246 --> 00:39:08.715 
当照片播放时注意看下左底角

00:39:14.021 --> 00:39:17.090  
你一按下快门键

00:39:17.157 --> 00:39:21.495  
几乎同时就有一张照片预览
出现在左底角

00:39:22.062 --> 00:39:24.131  
这会令你的用户感到欣慰

00:39:24.198 --> 00:39:25.966  
知道他们拍的照片没问题

00:39:27.134 --> 00:39:28.635 
这会给他们即时反馈

00:39:29.636 --> 00:39:31.772 
有许多的图像处理算法

00:39:31.839 --> 00:39:37.044 
像是Core Images CIRectangleDetector
或是CIQRCodeDetector

00:39:37.110 --> 00:39:40.414 
能很好兼容小图像
或是未压缩的小图像

00:39:40.480 --> 00:39:43.984 
它们不需要整张1200万像素的
JPEG来找到人的脸

00:39:45.619 --> 00:39:50.190 
不幸的是 这里有个继承阻抗的不匹配

00:39:51.058 --> 00:39:52.993 
你请求一张高质量的JPEG图片

00:39:53.360 --> 00:39:55.729 
因为你想要将其保存在硬盘上

00:39:55.796 --> 00:39:57.531 
那是你想要留下来的

00:39:58.332 --> 00:40:01.635 
但是你也想要很快在屏幕上
显示一个预览图

00:40:02.169 --> 00:40:05.038 
所以如果你要自己实现的话
你要解压缩JPEG

00:40:05.105 --> 00:40:06.240 
你要缩减它的大小

00:40:06.373 --> 00:40:07.541 
并最终显示出来

00:40:08.175 --> 00:40:11.311 
这些都需要费时占空间
还增加了复杂度

00:40:12.045 --> 00:40:15.749 
最好是能同时得到
供保存的高质量JPEG图片

00:40:15.816 --> 00:40:18.785 
以及相机能提供一个小版本的照片

00:40:19.119 --> 00:40:22.389 
直接从相机获取
而不是从JPEG解压缩而来

00:40:23.590 --> 00:40:24.992 
然后你就能省略那些步骤

00:40:25.058 --> 00:40:27.327 
直接显示预览图了

00:40:28.161 --> 00:40:31.565 
我们在AVCapturePhotoOutput中
就提供了这种工作流

00:40:32.432 --> 00:40:33.267 
这个委托

00:40:37.304 --> 00:40:38.772 
我强烈建议用啊

00:40:39.039 --> 00:40:42.009 
这个委托回调函数能生成一个缩略图

00:40:42.075 --> 00:40:44.645 
给processed或者RAW照片

00:40:45.245 --> 00:40:47.414 
预览图是非压缩的

00:40:47.481 --> 00:40:50.584 
因此你可选择它是
420fv还是BGRA格式

00:40:51.385 --> 00:40:52.953 
如果你知道想要的尺寸

00:40:53.187 --> 00:40:56.356 
你可以声明你想要的具体大小

00:40:56.690 --> 00:41:00.194 
如果你不确定对于当前的平台
多大的预览图合适的话

00:41:00.394 --> 00:41:03.197 
PhotoOutput可以为你
选择一个合适的默认尺寸

00:41:04.898 --> 00:41:08.001 
这里有些如何请求预览图的示例代码

00:41:08.902 --> 00:41:12.606 
当以常规方式创建了
一个相片设置实例后

00:41:12.906 --> 00:41:15.275 
你可以选择
previewPixelType

00:41:15.609 --> 00:41:21.982 
再说明一下相片设置本身
就会告诉你哪些格式是可用的

00:41:22.049 --> 00:41:25.619 
并且它们都是排好序的
因此最优选择会排在第一位

00:41:25.786 --> 00:41:28.188 
在此我从数组中获取第一个元素

00:41:28.755 --> 00:41:30.824 
我所说的最优是指

00:41:30.891 --> 00:41:34.761 
需要从本地相机请求最少转换的

00:41:36.597 --> 00:41:41.468 
你利用该格式类型key来创建
CVPixelBuffer属性字典

00:41:41.902 --> 00:41:43.604 
第一部分是必需的

00:41:43.670 --> 00:41:45.973 
如果你想获得预览图

00:41:46.039 --> 00:41:48.942 
那你至少你得声明你想获得什么格式的

00:41:49.510 --> 00:41:53.680 
你还可以选择性的声明宽度和高度

00:41:54.815 --> 00:41:56.183 
如果你想要定制尺寸的话

00:41:56.683 --> 00:41:59.753 
你不需要知道明确的宽高比

00:41:59.820 --> 00:42:01.088 
关于你将获得的图片

00:42:01.388 --> 00:42:03.790 
我在这设成是160乘160

00:42:03.857 --> 00:42:06.360 
我不是想搞一个盒子出来

00:42:06.426 --> 00:42:09.530 
我只是给宽和高设一个最大值

00:42:09.897 --> 00:42:12.733 
AVCapturePhotoOutput
会进行改变大小的工作

00:42:12.799 --> 00:42:17.037 
为预览图
以便它能以预设的宽高比装进盒中

00:42:18.972 --> 00:42:21.642 
获取预览图也是非常直观的

00:42:22.142 --> 00:42:27.881  
我们在此请求一个JPEG照片
还有一个160乘160的预览图

00:42:29.183 --> 00:42:32.419  
当我们获得第一个回调函数
说明已经接到命令时

00:42:33.053 --> 00:42:37.591  
你会获得一个willBegin
CaptureForResolvedSettings

00:42:38.625 --> 00:42:41.562  
和一个ResolvedPhotoSettings对象
如果你注意到的话

00:42:41.628 --> 00:42:45.232  
预览图的大小不是160乘160

00:42:45.499 --> 00:42:46.767  
而是160乘120的

00:42:46.834 --> 00:42:49.636  
因为它已经因宽高比而改变

00:42:49.703 --> 00:42:52.439  
这个尺寸对于1200万像素
的照片是最合适的

00:42:54.308 --> 00:42:58.278  
当didFinishProcessingPhoto
SampleBuffer回调函数最后到来时

00:42:58.378 --> 00:43:00.247  
你会得到一个 而不是两张照片

00:43:01.014 --> 00:43:02.983  
全尺寸的JPEG文件是第一个参数

00:43:03.050 --> 00:43:05.986  
previewPhotoSampleBuffer
是第二个

00:43:06.220 --> 00:43:07.788  
如果你一直跟着我的思路

00:43:08.055 --> 00:43:09.256 
并在你的脑中思考

00:43:09.323 --> 00:43:13.060 
如果你要拍一个
RAW照片 加上包围曝光

00:43:13.794 --> 00:43:14.928 
加上JPEG

00:43:15.262 --> 00:43:16.463 
加上预览图

00:43:16.663 --> 00:43:21.635 
那么你会得到mRAWs
mJPEGs和mpreview照片

00:43:25.906 --> 00:43:27.641 
另一个预览图的好的应用是

00:43:27.708 --> 00:43:29.476 
作为嵌入的缩略图

00:43:29.910 --> 00:43:32.646 
在你的高质量JPEG或DNG文件中

00:43:33.380 --> 00:43:36.850 
在这段代码示例中 我会用
previewPhotoSampleBuffer这个参数

00:43:36.917 --> 00:43:40.888 
此参数在didFinishProcessingRAW
PhotoSampleBuffer回调函数中

00:43:41.021 --> 00:43:44.091 
作为放到DNG文件的嵌入式缩略图

00:43:44.558 --> 00:43:48.729 
当我调用PhotoOutput的
dngPhotoDataRepresentation时

00:43:48.795 --> 00:43:50.998 
我会将其作为第二个参数传递

00:43:51.532 --> 00:43:53.500 
你一直要这么做

00:43:53.967 --> 00:43:56.870 
嵌入一个缩略图是个不错的主意

00:43:56.937 --> 00:43:59.106 
因为你不知道它会从哪被观看

00:44:00.607 --> 00:44:07.147 
有些应用能观看DNG bits
RAW bits 有些则不能

00:44:07.481 --> 00:44:10.951 
但是如果你用到嵌入式缩略图的话
谁都能看到点什么

00:44:11.552 --> 00:44:13.720 
你绝对想这么做
若你添加一DNG文件

00:44:13.787 --> 00:44:16.857 
到照片库
以便获得更好的快速预览效果的话

00:44:18.725 --> 00:44:20.761 
预览图生成是被支持的

00:44:21.461 --> 00:44:22.462 
到处都是

00:44:25.332 --> 00:44:29.736 
今天的最后一个主题是 宽色域

00:44:29.970 --> 00:44:32.973 
如你所料 这是个很广泛的主题

00:44:37.644 --> 00:44:40.747 
你们肯定听说了那漂亮的真彩显示

00:44:40.814 --> 00:44:43.183 
在我们的9.7寸iPad Pro上

00:44:43.984 --> 00:44:49.890 
它是宽色域显示的
和4K 5K iMax处于同一水平

00:44:50.257 --> 00:44:54.261 
它可以显示出令人吃惊
栩栩如生的红色和黄色

00:44:54.494 --> 00:44:57.397 
以及非常深度饱和的青色和绿色

00:44:58.432 --> 00:45:01.468 
为了利用到显示的宽色域

00:45:01.668 --> 00:45:05.339 
我们在iOS9.3中
首次介绍了颜色管理

00:45:05.706 --> 00:45:07.274 
我不知道你是否注意到了

00:45:07.341 --> 00:45:10.777 
我们在9.7寸iPad Pro上
使用了颜色管理

00:45:11.745 --> 00:45:13.614 
既然显示效果这么棒了

00:45:14.181 --> 00:45:17.951 
用同样的宽色域来拍照才说得过去

00:45:18.418 --> 00:45:20.120 
以便增强我们的观看体验

00:45:20.187 --> 00:45:22.756 
另外还能保证
从现在起若干年后你再看这些照片

00:45:22.823 --> 00:45:24.491 
你会得到更多的颜色信息

00:45:25.125 --> 00:45:26.460 
从iOS10开始

00:45:27.094 --> 00:45:31.698 
9.7寸iPad Pro上
拍照会自动变成宽色域了

00:45:33.233 --> 00:45:37.070 
让我简单介绍下宽色域是什么意思
有关宽色域的术语

00:45:37.337 --> 00:45:39.806 
从颜色空间的概念开始

00:45:40.440 --> 00:45:42.409 
一个颜色空间描述的是

00:45:43.577 --> 00:45:45.679 
一个颜色的环境

00:45:45.746 --> 00:45:49.683 
颜色被呈现 排列 比较 或计算

00:45:50.284 --> 00:45:54.188 
在计算机显示中应用最普遍的颜色空间
就是sRGB

00:45:54.454 --> 00:45:56.924 
s代表标准 就是标准RGB

00:45:57.658 --> 00:46:01.628 
它是基于一个国际规范ITU709

00:46:02.296 --> 00:46:04.965 
它有大概2.2的gamma值

00:46:05.766 --> 00:46:09.203 
6500开尔文的白度

00:46:10.103 --> 00:46:14.208 
sRGB对显示很多常见颜色都很出色

00:46:14.274 --> 00:46:17.744 
像是面部 天空 草地等等

00:46:18.212 --> 00:46:21.849 
但也有很多颜色sRGB不能很好生成

00:46:23.050 --> 00:46:26.954 
例如 超过百分之40的职业足球队服

00:46:27.020 --> 00:46:28.755 
超出了sRGB的色域

00:46:29.556 --> 00:46:30.390 
谁知道呢

00:46:32.125 --> 00:46:36.864 
9.7寸iPad Pro支持宽色域
并使用了一个新的颜色空间

00:46:36.930 --> 00:46:39.433 
我们将其称为Display P3

00:46:40.501 --> 00:46:43.570 
它与SMPTE标准DCI P3类似

00:46:44.438 --> 00:46:47.341 
那是用在数字影院投影仪上的颜色空间

00:46:48.041 --> 00:46:51.645 
其色原与DCI P3是相同的

00:46:51.712 --> 00:46:54.147 
但是其gamma值和白度不同

00:46:55.682 --> 00:46:59.786 
它的gamma值与
白度和sRGB是相同的

00:47:00.854 --> 00:47:02.055 
我们为什么会这么做呢

00:47:02.656 --> 00:47:08.028 
是因为DCI P3的白度
是向绿色边倾斜的

00:47:09.029 --> 00:47:14.067 
选择这么做是为了给昏暗的
家庭影院场景提供最大的亮度

00:47:14.401 --> 00:47:16.703 
我们发现把白度设为6500的话

00:47:16.770 --> 00:47:20.574 
会得到与sRGB标准会兼容的超集

00:47:20.807 --> 00:47:25.779 
在这张幻灯片上你会发现
sRGB的灰色

00:47:25.846 --> 00:47:29.082 
然后你会发现
贴附的Display P3

00:47:29.149 --> 00:47:33.687 
它尽可能宽的覆盖了sRGB的超集

00:47:33.754 --> 00:47:34.922 
这就是为何我们选择它

00:47:36.690 --> 00:47:39.560 
如果使用OS 10上的
颜色同步工具的话

00:47:39.660 --> 00:47:42.896 
你就能看到Display P3的
虚拟呈现

00:47:42.963 --> 00:47:44.965 
我截了一些图来展示给你们

00:47:46.133 --> 00:47:49.169 
你们可以在三维将其与
sRGB进行比较

00:47:49.503 --> 00:47:51.772 
在此我选择Display P3

00:47:51.839 --> 00:47:53.841 
点击“作比较”

00:47:53.907 --> 00:47:54.741 
这是个不错的技术

00:47:55.108 --> 00:47:56.610 
然后我选择sRGB

00:47:56.677 --> 00:48:00.047 
接下来我会看到
其中一个贴附在另一个上

00:48:00.113 --> 00:48:04.184 
你会从里面看到sRGB
从外面看到Display P3

00:48:04.251 --> 00:48:09.256 
以此你能感受到Display P3
相比sRGB来说有多宽

00:48:09.690 --> 00:48:13.861 
并且能呈现的
颜色范围从视觉上看也更大

00:48:16.763 --> 00:48:18.465  
那么现在让我们看看所有的细节

00:48:18.532 --> 00:48:20.367  
用来获得Display P3内容

00:48:21.034 --> 00:48:23.971  
为了获得高保真度
所捕捉内容的颜色空间

00:48:24.037 --> 00:48:26.240  
需要在素材阶段就确定下来

00:48:26.607 --> 00:48:29.743  
这可不能向下在sRGB中完成了

00:48:29.810 --> 00:48:32.913  
然后再往上向宽色域转换
它必须在开始时就被设定好足够的宽度

00:48:33.614 --> 00:48:37.384  
如你所料 颜色空间其实就是
AVCaptureDevice

00:48:37.451 --> 00:48:40.120  
一个属性

00:48:40.854 --> 00:48:43.690  
因此我们会花些时间来讨论下
AVCaptureDevice

00:48:43.757 --> 00:48:46.260  
我们还会讨论下
AVCaptureSession

00:48:46.693 --> 00:48:50.531 
该会话就是
自动宽色域选择被决定的地方

00:48:50.597 --> 00:48:52.799 
为整个会话配置

00:48:54.301 --> 00:48:59.806 
AVCaptureDevice就是AV Foundation
如何呈现摄像头或是麦克风

00:49:00.707 --> 00:49:03.710 
每个AVCaptureDevice
都有一个格式属性

00:49:04.778 --> 00:49:07.948 
Formats是AVCaptureDevice
格式的一个数组

00:49:08.015 --> 00:49:09.650 
它们本身就是对象

00:49:09.983 --> 00:49:12.953 
同时它们还会代表设备捕捉内容的格式

00:49:13.820 --> 00:49:16.056 
如你所见 它们是成对出现的

00:49:16.557 --> 00:49:18.859 
对于每个分辨率和帧率

00:49:19.026 --> 00:49:22.629 
都有一个402v版本和402f版本

00:49:23.430 --> 00:49:27.668 
v是代表视频范围 从16到235

00:49:28.135 --> 00:49:31.271 
f是代表全范围 从0到255

00:49:32.372 --> 00:49:33.941 
iOS10中新出现的是

00:49:34.508 --> 00:49:38.645 
AVCaptureDevice格式
有了一个新支持的颜色空间属性

00:49:39.279 --> 00:49:40.581 
它是由数字组成的数组

00:49:40.647 --> 00:49:46.887 
0是代表sRGB
而1是代表P3 D65

00:49:47.955 --> 00:49:49.923 
我们将其代指为Display P3

00:49:49.990 --> 00:49:54.328 
但是在API中
它指的是P3 D65

00:49:54.394 --> 00:49:59.733 
d代表显示 65代表开尔文的白度

00:50:01.435 --> 00:50:07.174 
在9.7寸iPad Pro上
420v格式只支持sRGB

00:50:07.908 --> 00:50:12.145 
但是全范围420f格式支持sRGB

00:50:12.412 --> 00:50:13.847 
或是Display P3

00:50:14.815 --> 00:50:17.618 
该设备有个可设的格式属性

00:50:17.684 --> 00:50:18.585 
这不是新的东西

00:50:19.152 --> 00:50:22.723 
列表中的其中一个格式
一直是activeFormat

00:50:23.023 --> 00:50:26.026 
如你所见
我将激活的格式套上了一个黄色的格子

00:50:26.360 --> 00:50:29.396 
它正好是1200万像素
30FPS的版本

00:50:30.931 --> 00:50:34.067 
如果那个activeFormat
也就是f格式

00:50:34.368 --> 00:50:36.436 
正好支持Display P3的话

00:50:37.070 --> 00:50:40.908 
那么你可以设置一个叫做
activeColorSpace的新属性

00:50:40.974 --> 00:50:42.843 
如果activeFormat支持它

00:50:42.976 --> 00:50:46.146 
你就能从你的素材中获得宽色域的流

00:50:46.213 --> 00:50:47.948 
到session的所有输出中

00:50:49.449 --> 00:50:50.584 
这段说起来有点冗长

00:50:50.651 --> 00:50:52.853 
但我希望你记住的是

00:50:53.120 --> 00:50:54.922 
希望这些东西你一个也用不上

00:50:55.055 --> 00:50:58.358 
大多数客户从来不需要直接设置
activeColorSpace

00:50:58.592 --> 00:51:02.262 
那是因为AVCaptureSession
会试着为你自动完成

00:51:03.297 --> 00:51:07.701 
在iOS 10中
AVCaptureSession有一个长的新属性

00:51:07.935 --> 00:51:12.372 
叫做automaticallyConfigures
CaptureDeviceForWideColor

00:51:13.006 --> 00:51:15.342 
它什么时候会为你选择宽色域呢

00:51:16.510 --> 00:51:20.047 
在iOS 10中
宽色域仅在摄影中使用

00:51:20.781 --> 00:51:21.648 
让我再说一遍

00:51:22.349 --> 00:51:26.653 
在iOS 10中 宽色域仅在
摄影中使用而不是摄像

00:51:26.720 --> 00:51:27.988 
我后面马上会解释为什么

00:51:30.691 --> 00:51:33.493 
会话会自动选择

00:51:33.560 --> 00:51:37.531 
是否为整个会话配置宽色域

00:51:37.798 --> 00:51:41.301 
它会代表你将你设备的
activeColorSpace设为

00:51:41.502 --> 00:51:43.704 
P3 这取决于你的设置

00:51:44.271 --> 00:51:47.841 
你要在你的会话中
加入一个PhotoOutput

00:51:48.208 --> 00:51:51.411 
如果你没有PhotoOutput
你就不能拍照了

00:51:51.545 --> 00:51:52.713 
那么你也不需宽色域

00:51:54.114 --> 00:51:56.049 
这里有些警示

00:51:56.149 --> 00:51:58.785 
如果你开始往你的会话加入其它输出

00:51:59.019 --> 00:52:01.321 
或许你想要做什么就不那么明显了

00:52:02.189 --> 00:52:05.325 
如果你加上了一个
AVCaptureVideoPreviewLayer

00:52:05.392 --> 00:52:10.764 
会话还是会给你
自动挑选Display P3

00:52:11.098 --> 00:52:13.767 
因为你就是在拍照同时做了预览

00:52:14.268 --> 00:52:18.472 
如果你有一个MovieFileOutput
和一个PhotoOutput 那就模糊了

00:52:18.539 --> 00:52:20.340 
你可能更关心影片

00:52:20.574 --> 00:52:24.111 
所以它就不会为你
自动挑选Display P3了

00:52:24.611 --> 00:52:30.284 
VideoDataOutput是个特殊的例子
我们通过一个回调函数将缓冲送达给你

00:52:30.617 --> 00:52:33.287 
在此session只会挑选
Display P3

00:52:33.353 --> 00:52:35.355 
如果你在用预设照片的话

00:52:35.789 --> 00:52:37.491 
它很确信如果你正在用
VideoDataOutput

00:52:37.558 --> 00:52:40.761 
就意味着你会利用这些显示缓冲来摄影

00:52:42.196 --> 00:52:45.499 
如果你非常想要的话
你可以强制拍照设备

00:52:45.566 --> 00:52:47.634 
来使用宽色域
下面是怎么实现的

00:52:48.335 --> 00:52:52.039 
首先你要告诉会话
不要自动帮我实现了

00:52:52.206 --> 00:52:53.040 
不要妨碍我

00:52:54.041 --> 00:52:56.310 
然后你要进入设备

00:52:56.376 --> 00:52:59.847 
自己将activeFormat
设为支持宽色域的格式

00:53:00.113 --> 00:53:03.283 
然后你要将
activeColorSpace设为P3

00:53:04.451 --> 00:53:05.552 
你做完了之后

00:53:05.619 --> 00:53:10.424 
宽色域buffer会流到
所有接受视频数据的输出

00:53:10.524 --> 00:53:13.560 
包括VideoDataOutput
MovieFileOutput

00:53:13.627 --> 00:53:16.864 
甚至是已经不推荐使用的
AVCaptureStillImageOutput

00:53:18.432 --> 00:53:23.770 
当你强制将设备的
activeColorSpace设为display P3后

00:53:24.004 --> 00:53:26.406 
我强烈建议你不要这么做

00:53:26.473 --> 00:53:28.475 
除非你明确知道自己在干什么

00:53:29.543 --> 00:53:32.546 
因为宽色域是给照片服务的

00:53:32.713 --> 00:53:36.483 
我们对于宽色域的照片支持
有着良好的生态系统

00:53:36.850 --> 00:53:38.552 
但是对于视频就不怎么样了

00:53:39.186 --> 00:53:41.288 
对于Display P3
内容的主要担忧

00:53:41.355 --> 00:53:44.224 
就在于用户必须是宽色域敏感的

00:53:44.458 --> 00:53:46.693 
否则你的内容将会以sRGB渲染

00:53:46.760 --> 00:53:48.362 
颜色看起来就会不对头

00:53:48.762 --> 00:53:49.763 
它们被渲染得很糟糕

00:53:50.464 --> 00:53:53.300 
大多数视频播放服务都不是色敏感的

00:53:53.600 --> 00:53:58.338 
所以如果你保存一个
宽Display P3影片的话

00:53:58.572 --> 00:54:01.441 
然后你试图用某个服务来播放它

00:54:01.775 --> 00:54:03.977 
它很有可能会把颜色渲染错误

00:54:05.112 --> 00:54:06.613 
如果你选择这么做

00:54:06.680 --> 00:54:09.650 
确保你的VideoDataOutput
是色敏感的

00:54:10.083 --> 00:54:11.618 
它要传播颜色标签

00:54:11.685 --> 00:54:14.288 
它要是色敏感的

00:54:15.389 --> 00:54:20.394 
如果你选择用MovieFileOutput
来拍摄Display P3影片

00:54:20.727 --> 00:54:24.331 
注意它们可能在其他平台上
是错误渲染的

00:54:25.165 --> 00:54:25.999 
这里

00:54:26.066 --> 00:54:28.368 
我们确实允许这么做 因为我们意识到

00:54:28.435 --> 00:54:32.906 
其对于某些专业工作流是很重要的

00:54:32.973 --> 00:54:35.342 
也要能够制作宽色域影片

00:54:36.476 --> 00:54:38.512 
所以抛开警告不管

00:54:38.879 --> 00:54:42.182 
我可以告诉你我们对于照片
有个很好的解决方案

00:54:42.316 --> 00:54:43.884 
针对共享宽色域

00:54:44.551 --> 00:54:48.789 
我们应该注意到JPEG宽色域
是使用Display P3属性的

00:54:49.122 --> 00:54:51.892 
并且这些图片的用户也必须是色敏感的

00:54:52.359 --> 00:54:56.430 
好消息是通常照片服务

00:54:56.563 --> 00:54:58.098 
目前是色敏感的

00:54:58.632 --> 00:55:00.501 
iCloud照片库就是其中之一

00:55:00.634 --> 00:55:04.171 
它能智能的将你的照片
转换成sRGB格式

00:55:04.271 --> 00:55:06.306 
如果你的设备不支持宽色域的话

00:55:06.940 --> 00:55:10.344 
但仍会在cloud上
存储宽色域的照片

00:55:11.745 --> 00:55:13.947 
我们的业界目前也在转变

00:55:14.014 --> 00:55:17.718 
有些照片服务虽然不支持宽色域

00:55:17.784 --> 00:55:22.289 
但它们中绝大多数至少能将其
智能渲染成sRGB格式

00:55:23.724 --> 00:55:25.292 
对于混合共享的场景

00:55:25.359 --> 00:55:28.662 
像是通过信息或邮件来发送照片

00:55:28.962 --> 00:55:30.063 
你不知它被发送到哪

00:55:30.130 --> 00:55:31.999 
它可能会被发到多个设备

00:55:32.432 --> 00:55:34.001 
其中有些可能支持宽色域

00:55:34.067 --> 00:55:34.935 
有些则不支持

00:55:35.169 --> 00:55:39.706 
对于这种情况
我们要加上一个新的服务

00:55:39.773 --> 00:55:42.543 
叫做
Apple Wide Color Sharing Profile

00:55:42.976 --> 00:55:47.915 
你的内容将以一种方式被处理

00:55:47.981 --> 00:55:52.920 
我们会生成一个内容为准则
表格形式的ICC资料

00:55:53.220 --> 00:55:56.557 
对应那张JPEG照片

00:55:57.291 --> 00:56:00.427 
其好处就在于 如果它被某人渲染

00:56:00.494 --> 00:56:01.962 
而这个人不了解宽色域

00:56:02.029 --> 00:56:05.532 
那么在sRGB色域内的部分
肯定能被正确渲染

00:56:05.999 --> 00:56:11.004 
额外的信息会被放到
一个额外的ICC资料中

00:56:11.071 --> 00:56:14.107 
它们可以将宽色域信息恢复

00:56:14.174 --> 00:56:15.976 
到最小的质量损失程度

00:56:17.377 --> 00:56:20.314 
你可以学到更多有关
如何共享宽色域内容

00:56:20.647 --> 00:56:24.251 
在505和702会话中

00:56:24.318 --> 00:56:25.586 
它们都是在周四

00:56:25.919 --> 00:56:28.155 
第一个我已经提到三遍了

00:56:28.822 --> 00:56:31.225 
关于宽色域的那个也是个不错的会话

00:56:33.193 --> 00:56:34.928 
在9.7寸iPad Pro上

00:56:35.028 --> 00:56:38.232 
AVCapturePhotoOutput
广泛支持宽色域

00:56:38.632 --> 00:56:44.438 
它在420f BGRA和JPEG中都支持
不仅仅是420v

00:56:44.505 --> 00:56:49.743 
如果你的会话
配置了Display P3

00:56:49.810 --> 00:56:51.979 
但是然后你说你想要420v的照片

00:56:52.246 --> 00:56:54.515 
它会被转换为sRGB格式

00:56:56.149 --> 00:56:59.152 
Live Photos支持宽色域

00:56:59.319 --> 00:57:01.054 
静态和影片部分都支持

00:57:01.221 --> 00:57:03.690 
这是特殊的影片
这是Apple生态系统的一部分

00:57:03.757 --> 00:57:05.492 
因此那些都会是支持宽色域的

00:57:06.894 --> 00:57:09.830 
包围曝光拍摄也是支持宽色域的

00:57:12.432 --> 00:57:14.101 
有趣的是

00:57:14.501 --> 00:57:17.671 
我一直在说iPad Pro

00:57:18.305 --> 00:57:19.973 
我们支持RAW格式

00:57:20.507 --> 00:57:24.411 
RAW拍摄本身就是宽色域的

00:57:24.745 --> 00:57:27.481 
因为它有所有那些额外的比特信息

00:57:27.981 --> 00:57:29.917 
我们将其保存在传感器基元中

00:57:30.417 --> 00:57:36.957 
并且它也有足够的颜色信息
来被渲染成宽色域或是sRGB

00:57:37.024 --> 00:57:39.993 
再说一下 如果你随身带着原料的话

00:57:40.060 --> 00:57:43.764 
你能随时决定你是想渲染成
宽色域还是sRGB

00:57:44.198 --> 00:57:46.667 
因此拍摄RAW照片并后期渲染

00:57:47.034 --> 00:57:52.206 
可在许多iOS设备上生成宽色域内容
而不仅是在iPad Pro上

00:57:55.075 --> 00:57:59.346 
你可以学会更多有关宽色域的知识

00:57:59.413 --> 00:58:01.915 
不光是共享还有别的

00:58:01.982 --> 00:58:05.919 
最好的学习宽色域的会话是在周四下午

00:58:07.955 --> 00:58:11.592 
使用AVCapturePhotoOutput
来改善可用性

00:58:12.626 --> 00:58:14.795 
我们今天谈论了四个主要特性

00:58:14.862 --> 00:58:17.397 
我们讨论了在你的应用中
拍摄Live Photos

00:58:17.831 --> 00:58:21.268 
RAW RAW + JPEG DNG

00:58:22.503 --> 00:58:24.972 
用来更快渲染的小预览图

00:58:25.672 --> 00:58:27.341 
还有宽色域照片

00:58:28.876 --> 00:58:31.912 
一个小时真的不够啊

00:58:31.979 --> 00:58:33.514 
想要涵盖要讲的内容太短了

00:58:33.580 --> 00:58:36.183 
因此我们对于这个会话做了一个补充

00:58:36.250 --> 00:58:37.684 
它已经录制完了

00:58:37.751 --> 00:58:39.152 
现在已经放到网上了

00:58:39.786 --> 00:58:42.923 
它是一个包含语音的幻灯片
我们把它叫做Chalk Talk

00:58:43.991 --> 00:58:47.995 
它为你讲述了
我们没时间讲的深入的主题

00:58:48.262 --> 00:58:51.131 
AVCapturePhotoOutput
中的场景监控

00:58:51.632 --> 00:58:54.101 
资源准备和回收

00:58:54.801 --> 00:58:56.303 
然后是一个不相关的话题

00:58:56.570 --> 00:58:59.907 
iOS 10中相机隐私政策的变动

00:58:59.973 --> 00:59:02.743 
请看下那个视频
它大概20分钟长

00:59:04.344 --> 00:59:05.379 
有着更多的信息

00:59:05.445 --> 00:59:07.748 
501结尾你要记住

00:59:07.814 --> 00:59:11.585 
你会发现那个视频
有七段示例代码

00:59:11.652 --> 00:59:14.855 
还有
AVCapturePhotoOutput的新文档

00:59:15.055 --> 00:59:19.092 
文档编写人员真的很努力工作
他们写的文档真的不错

00:59:20.394 --> 00:59:22.796 
再次提醒一下这是相关的会话

00:59:23.430 --> 00:59:25.365 
这个是Chalk Talk

00:59:25.432 --> 00:59:28.602 
关于AVCapturePhotoOutput
的延伸知识

00:59:29.036 --> 00:59:30.470 
你什么时候想看都行

00:59:31.238 --> 00:59:33.707 
好了 好好享受下之后的演说
感谢你们的到来