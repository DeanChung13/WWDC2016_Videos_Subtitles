使用Core Image編輯Live Photo和RAW處理
非常感謝各位 早上好
我叫David Hayward今天我要講的是
關於使用Core Image編輯Live Photos和Raw圖片
我們今天要講很多不錯的東西
首先我簡單介紹一下Core Image
如果你對它一無所知的話
接下來我們會談下我們今早的三個主要話題
第一 在iOS上調整RAW圖片
第二 編輯Live Photos
第三 如何擴展Core Image
通過全新的方式 即利用CIImageProcessor節點
首先 是對於Core Image的簡單介紹
選擇Core Image的原因是它提供了一個非常簡單
高性能的API來將濾鏡應用到圖片上
基本的想法就是你開始有一張圖片
其來自於JPEG或某個文件或內存你可以選擇
對其應用一個濾鏡 結果就是輸出圖片
在你的代碼中實現是非常非常簡單的
你只需要調取你的圖片調用applyingFilter
並聲明濾鏡的名字
以及其他適用於該濾鏡的參數
這非常簡單
當然了你可以完成更復雜的事情
你可以將多個濾鏡鏈在一起使用...
應用到序列或是圖片上並獲得非常複雜的效果
Core Image的一個非常棒的特性就是它提供了自動顏色管理
這對於現如今很重要
我們現在有很多設備
支持寬色域的輸入和輸出
Core Image所做的就是它會自動插入
恰當的節點到渲染圖中去
以便它與你的輸入圖像匹配
到Core Image的工作域
而到了要顯示的時候
它會從工作域匹配到顯示域
這是你應該特別注意的
因爲寬色域圖片和寬色域顯示現在都很常見了
而很多做圖像處理的開源庫
不會自動處理它
這是Core Image很棒的特性因爲它處理了所有這些
讓你很容易的使用
另一個要注意的是每個濾鏡
實際上是附帶着一小段代碼的
叫做kernel的小小子程序
我們所有內置濾鏡都有這些kernel
一個不錯的特性是如果你將一個序列的濾鏡鏈在一起
Core Image會自動連接這些
子程序成單個程序
這麼做是爲了提高性能
通過減少
通過減少中間緩存的數量
Core Image有逾180個內置濾鏡
它們在我們的所有平臺上都是一樣的
不管是macOS tvOS還是iOS
我想談下今年我們新發布的一些濾鏡
其中一個是用來生成色彩飽和度和梯度
它會生成色彩和飽和度的梯度
然後你可以聲明一個參數
關於圖片的亮度
也聲明瞭顏色輪內的色域
如你所料此濾鏡目前在用在macOS上
作爲顏色選擇器的基礎
目前可以識別幾個不同類型的顯示色域
另一個新濾鏡是CINinePartStretched and NinePartTiled
你可能有一個小的資源
像是這個畫框
而你想要拉伸它使其適應一個特定尺寸
這個濾鏡非常容易使用
你需要提供一個輸入圖片和四個斷點
水平的兩個 垂直的兩個
一旦你聲明瞭這些點之後 你可以聲明
你想讓其拉伸到多大的尺寸
它非常容易用
第三個新濾鏡很有意思
開始時我們有個很小的輸入圖片
在這裏有一個包含有顏色數據的圖片
但它也可以包含參數數據
假設你有一個小的顏色或者參數集合
可能只有6乘7個像素
你想要擴展到全尺寸的圖片上
我們要做的是擴展顏色圖像這個小的顏色圖像
但是維護底圖圖形的邊
如果你不維護底圖圖形而只是拉伸
小的圖片和全尺寸的圖像一邊大
你只會得到一張混合顏色的圖片
但利用這個濾鏡你可得到更多東西
你可以得到
維護邊和顏色的圖片
這對於很多其他類型的算法來說也是個有用的特性
事實上我們在新版本的照片應用裏就用到了它
來提高調光滑條的表現
我期待看到你在你的應用裏會怎麼用
我們今年也做了一些新的性能控制
今年還對Core Image性能做了改善
其中一個就是我們默認打開了Metal功能
所以如果你用了任何一個我們內置的180個濾鏡
或者你自定義的kernel
所有的kernel都會被快速轉換爲Metal的供你使用
這是個不錯的方式來利用
Metal的作用而你幾乎不用做什麼
我們還對一個重要的API做了很大的改進
從CIImage中創造了UIImage
相比原來它的性能提高很多
因此你可用它高效地在UIImage視圖中使一個圖片動畫化
另一個新特性是
Core Image現支持了一個新Core Graphics特性
就是Core Graphics現支持半浮點數了
讓我們談談像素格式因爲這會引出一個很有意思的點
我們對於傳統的像素格式RGBA8都很熟悉
它僅需要花費每像素4字節來存儲擁有8比特的深度
並且可以在0到1範圍內編碼
然而 這個格式不利於呈現寬色域數據
因爲它只有8比特而且值被限定在0到1的範圍內
過去的替代方案是使用RGBAfloat
它每像素有16字節 需要四倍的內存
但會帶給你想要的深度和範圍
另一個特性是它使用了浮點數
也就是會分層 它是呈對數分佈的
這很好地適應了人眼感應顏色的方式
還有個Core Image支持的新特性
Core Graphics現也支持
我將其成爲Goldilocks像素格式 即RGBAh
這會讓你在每像素8字節的情況下
存儲10比特深度的數據
允許的值區間是負65000到正65000
這些值是對數性量化的
它對於存儲線性數據很好
這些數據是不會被識別爲量子化的
因此我高度推薦這個像素格式
另一個我要提到的新格式是
Core Video支持新像素格式
它名字很長 叫做30RGBLEPackedWideGamut
它也支持10比特的深度
但通過犧牲alpha信道它只需要每像素4字節就能存儲
它對於很多情況都很有用
Core Image支持或是渲染自
或者渲染到CV像素緩存利用這個格式
接下來我想談下一個主要的話題
關於利用Core Image調整RAW圖片
我很高興今天能講下這個
我們致力於此已經很長時間了
它包含了我們大量的辛苦工作我很興奮
我們將其引入了iOS中
我要先說下什麼是RAW文件
如何使用CIRAWFilter API
一些關於支持寬色域輸出的說明
還有關於管理內存的技巧
那麼首先 什麼是RAW文件呢
大部分相機的運作方式都包括兩個關鍵的部件
顏色過濾陣列和傳感器陣列
其工作原理就是光線從場景內進入
通過顏色過濾陣列並被傳感器陣列所計數
當然了該數據實際上是一個更大圖像的一部分
但是爲了將其轉換爲可用的圖像
需要進行大量的圖像處理
以便爲用戶生成一張不錯的圖片
我想談一下這個 其主要思路就是
如果你獲取由傳感器所捕捉的數據那就是RAW文件
如果你獲取的數據是捕獲於
圖像處理之後那就是一張TIFF或者JPEG圖片
RAW存儲着未處理的場景數據
而JPEG文件存儲處理過的輸出圖像
換句話說
RAW存儲的是你要生成一張圖片的原料
而JPEG存儲的是原料的結果
將這些原料烤成漂亮的蛋糕後
爲了從原料
做成最終的蛋糕是需要很多階段的
讓我大概說下其中的幾個
首先 我們要提取文件中的元數據
其會告訴我們要花多久來做蛋糕接着剛纔的比喻來說
我們還需要將從傳感器中獲得的RAW數據解碼
我們需要將圖像去馬賽克以重構整張有色圖
從所獲取的數據中
每個像素位置只有一個RGB值
我們需要應用幾何畸變來進行鏡頭矯正
減少噪點 也是處理中的一個重要點
我們需要從場景數據中做顏色匹配
這些由傳感器捕獲的數據會傳到輸出數據用以顯示圖像
接下來我們要做的事就是諸如調整曝光
色溫 還有色調
最後 非常重要的是 增強銳度
對比度和飽和度來使圖片看起來更漂亮
這麼多階段可真不少
RAW的優點有哪些呢？
最大的優點就是
RAW文件包含了線性的深度像素數據
這使得可編輯性很好
RAW的另一個特性是它的圖像處理每年都變得更好
因此也就保證了利用RAW你昨天所拍的照片
可能在你來年處理它時效果更好
RAW文件還有色彩空間的不可知性
它們可以被渲染到任何目標的輸出空間
這對於我們如今諸多的顯示標準來說是個不錯的特性
用戶可以選擇使用不同的軟件
來解釋RAW文件
就像是把相同原料交給兩個不同的廚師
你會得到兩個不同的結果
有些用戶可能更喜歡另一個廚師
JPEG也是有很多優點的
首先就是由於已經處理過了
它們加載和顯示非常快
它們包含針對特定輸出的顏色和調整
這可能很有用
它也會給你可預見的結果
還有值得一提的是如今的相機表現出色
對於拍攝JPEG照片來說
並且我們的iOS相機尤其是一個好例子
說到RAW 讓我再說一點
關於我們的平臺是如何支持RAW的吧
好消息是我們現在在iOS上完全支持了RAW
即將到來的tvOS推送也是
這意味着我們支持超過400個獨特的相機型號
來自於16個不同的廠商
我們也支持被捕獲的DNG文件
用我們自己的iOS設備
iOS設備包括iPhone 6S、6S Plus
SE 還有iPad Pro 9.7
這真讓人興奮
我推薦如果你們還沒有看回去看看
iOS攝影進階
那個演講是關於
可在這些設備上捕捉RAW照片的API
另一個很棒的東西是我們現在擁有了同樣同性能的RAW管道
iOS平臺 如我們在macOS完成的一樣 可算是一個成就了
我那天計算了一下我們的管道
它包含了超過4500行的CIKernel代碼
而且運行的很高效
它是我們能力的確切證明 也是
Core Image可以處理複雜渲染場景的證明
我們iOS上的管道需要A8或以上的設備
你可以通過你的應用來測試
通過檢查iOSGPU Family 2
另一個關於平臺支持的說明是
我們一直在增加對新相機的支持從它一上市就開始
而且也在改進對已支持相機的支持質量
新相機被加到未來的軟件更新中
我們也在週期性的改進我們的管道
我們的管道有不同的版本你既可以用我們的最新版本
也可以倒回使用你想要的舊版本
爲了避免後面的麻煩 我想做個演示
它看起來是怎麼樣的
我這裏有些示例代碼有一個早前版本的
可供下載 它叫RAWExposed
它是個應用 同時最新版本也是
相片編輯擴展
我們可以進入Photos程序並實際運用這段示例代碼
我們有三張24兆像素的RAW照片
是用Canon 5DMark III拍的
你可以看出來這張照片有點過曝了
RAW的一個很棒的特性就是你可以修補這樣的照片
我們來這裏 點“編輯” 然後...
用我們的照片編輯擴展程序來編輯這個RAW文件
那麼現在既然我們是在將其當做RAW文件來編輯 就可以做些調整
［聽不清］
我們可以上下調整曝光量
我們可以在這24兆像素上瀏覽
而且得到了不錯的結果
我現在對這張照片很滿意看上去比之前強多了
我會點擊“完成” 之後它會生成
一張新的全分辨率照片 它會顯示在
Photos應用中
另一個關於RAW文件不錯的特性是你可以做出不錯的調整
對於一張照片的白平衡
這張照片不錯 但是有點不正而且白平衡也是關閉的
我要進到這裏
稍微調整下白平衡
以此得到一張好看得多的照片我們可以放大來看看成果
我們可以實時地調整這些結果
然後點擊“完成”以保存
另一張我想展示的照片
是張噪點很多的
我想向你們展示一下我們的噪點減少算法
我們的4500行kernel代碼有超過一半是涉及到噪點減少的
我要進到這裏 編輯下這張照片
你們可以看到 至少在前排的人可以
照片上的顆粒
我們API中的一個特性就是可以
關掉我們的噪點減少算法
然後你就可以看到RAW文件中噪點的自然呈現
這是個挺有挑戰性的任務
既要對照片實施噪點減少
使其沒有這些帶顏色的點還要保留顏色邊緣
照片所傾向於保留的
我保存下照片
最後 我想演示一下
我們這周早些時候拍的一張照片
在大堂裏 用這個iPad拍的
我就是那些拿iPad拍照的人其中之一
在此我想展示給你
一張本身就帶有挑戰性的照片
因爲它有些地方太暗而有些地方過曝了
我有個能做的事情就是
降低曝光量
我有個高光的滑動條可讓我把高光調高一點
我也可以降低曝光量
現在我能看到窗外發生了什麼
但是現在影子太暗了我可以調高一下那塊
這裏展現了你可以對RAW文件做些什麼調整
這是你像素數據擁有更深精確度的優勢
這是RAW文件所帶來的
我要點擊下“完成”
這就是我們關於iOS上RAW的演示
非常感謝我們的團隊使這一切成真
讓我談下API 因爲它僅僅是
提供一個演示程序是不夠的
我們想要使你們的應用也能用到它
我們有一個相關的API叫CIRAWFilter API
它爲你的應用提供了一些關鍵性的東西
它爲你的應用提供一個CIImage擁有寬色域
擴展的區間 半浮點精度運算
它也賦予你對於很多個階段的控制權
就比如我剛纔演示過的RAW演示管道
它也利用GPU提供快速交互表現
在我們的所有設備上
這是怎麼實現的呢 API其實很簡單
你開始有一個輸入可以使文件URL或者數據
甚至是利用我們下次推送中會帶來的CVPixelBuffer API
這是我們的輸入
我們會通過輸入來創建一個CIRAWFilter的實例
過濾器被實例化的時候它將會
給所有用戶可調整的參數賦上默認值
而這些是你應該想呈現給用戶的
你有了CIRAWFilter以後你可以
向它請求一個CIImage你可在這裏開始做很多事
讓我給你展示一下代碼看看它多簡單就能實現
我們只需要給它一個URL
我們要創建一個接受該URL的CIFilter實例
接下來 如果我們想獲得值
該值是關於當前的噪點減少量我們可以獲取該值
forKey: kCIInputImageNoiseReductionAmount
如果我們想改變它非常的簡單
我們只需給該鍵設一個新值
做完這些改變後請求outputImage就完成了
我們就需要做這些
你可能想要顯示這張照片
通常你會獲取這張照片 並將其顯示在
UIImage或MetalKit視圖或其他類型的顯示系統中
用戶可能會提出
可能這張照片有點過曝了
所以在你的UI中應該有調整曝光的滑條
以便用戶可以做出調整
你可將其作爲一個新值傳給CIRAWFilter
然後你可以請求一個CIImage
然後你就可以顯示這張曝光調整稍微亮一些的新照片
這也非常容易
你還可能想獲得你的CIImage——
有些時候可能你想將你的照片導出到背景
來生成一張全尺寸的照片
或者你可能要導出幾張照片到背景
在這些情況下 你應該
或是創建一個CGImage用來將其傳到其他API
或直接用JPEG或TIFF我們現有很容易用的API來實現這個
如果你要實現諸如RAW這類大文件的後臺處理
我們推薦創建一個CIContext來明確用於此目的
你要聲明一個上下文
被保存在一個單例變量中
不需要給每張照片都創建一個新的上下文
這使得CI可以緩存所有涉及到的kernel的編譯文件
不過因爲我們只需要渲染一張照片一次
我們不需要Core Image來緩存中間文件
所以你可以在這聲明爲假
這會幫助減少此場景下的內存需求
還有一個設置是關於你想要使用低優先級的GPU渲染
如果你是要做一個後臺保存
你不會想讓所需的GPU使用度
對於該後臺操作會拖慢性能
對於你的前臺UI
不管在Core Image或Core Animation中被完成的
這對於後臺處理很棒
我們今年要發佈的一個很棒的東西就是
該選項對於macOS也可用
一旦你有了上下文就很簡單了
你要決定你要渲染的顏色空間是什麼
例如 DisplayP3顏色空間
我們有個新的很方便的API
用來生成CIImage然後將其寫成JPEG
非常容易 你要聲明CIImage
目標URL和顏色空間
在此你也正好可以決定要給JPEG用什麼樣的壓縮質量
在這裏會生成一個JPEG圖片
其已經被標記於P3空間
這是個不錯的方式來生成寬色域圖片
它會正確顯示
在任何支持基於ICC顏色管理的平臺
如果你覺得你的照片會出現在一個平臺
其並不支持顏色管理
我們還有一個新選項供你選擇
該選擇是作爲CGImageDestination API的一部分
並且它是CGImageDestinationOptimizeForSharing
它會存儲所有的顏色
這些顏色都在P3顏色空間內
但是將它們這樣存儲並有一個定製的檔案
以便該照片仍然會被正確顯示
若這張照片的接收者不支持顏色管理
所以這也是個不錯的特性
還有若你想要創建一個CGImage
從CIImage 我們有一個新API和一些新選項
我們的這個方便的API可以使你
聲明什麼顏色空間和像素格式
你想要渲染
你可以選擇創建一個CGImage
其格式爲RGBAh
也就是我之前談到的Goldilocks像素格式
在這種情況下你也可以選擇使用一個特殊的顏色空間
也就是extendedLinearSRGB空間
因爲像素格式支持0到1區間之外的值
你要讓顏色空間也是如此
另一個新選項是可以聲明
創建CGImage的行動
是要延遲還是立即進行
如果你聲明要延遲 則相關的工作
用來渲染CIImage到CGImage
會在CGImage繪製完成後進行
這樣會很好的減少內存佔用
特別是如果你之後只會畫CGImage的一部分
或者只畫一次
然而如果你要渲染那張照片很多次的話
你可以把延遲設爲假
在此情況下Core Image會完成
將其渲染到CGImage的工作當此方法被調用時
這是個我們給你們的應用配備的很棒且靈活的新API
另一個關於Core Image過濾器API的高級特性
我今天想談下的就是 這個
如我之前所說的管道有很長的階段
用來處理RAW文件 有很多人問我
我如何將我自己的處理加入到管道上
一個常見的開發者想要加入
處理到RAW管道上中間某處
在去馬賽克完成後
但是在所有非線性操作之前 像是銳化
還有對比度和顏色加速完成後
對此我們有個API
它是CIRAWFilter一個屬性
可以允許你聲明一個可插入的過濾器
其被插入到圖表的中間
我希望看到你們可以想象
並思考什麼被帶到了該位置
一些我之前提過的關於寬色域輸出的說明
CIKernel語言將浮點精度作爲一門語言來支持
不過當CIFilter需要被渲染到
中間過濾器時 我們會用能用的格式
基於當前的CIContext
macOS上默認可用的格式是RGBA
我們的Goldilocks格式
在iOS和tvOS上我們的默認格式還是BGRA8
其性能良好
但是如果你要渲染擴展區間數據
這可能不是你想要做的
記住我們的RAW管道
我們管道的所有kernel
強制使用RGBA半浮點精度
這對於RAW文件很關鍵
但如果你擔心
寬色域輸入和輸出
要在渲染圖上保留該數據
那麼你應該修改CIContext當你創建它來聲明
你想要一個可用的格式也就是RGBAh時
我想再提一下Core Image支持很廣泛的
寬色域輸出空間
例如 你可以渲染到
extendedLinearSRGB或Adobe RGB或DisplayP3 無論哪種都行
如我之前提到的我要演示一張24兆像素的照片
RAW文件可以比你想象的大得多
RAW文件除了大也需要
一些中間緩存來渲染管道的所有階段
這很重要
以便減少你程序中的高度佔用內存的水印
通過使用我今天談到的這些API
比如當你不需要的時候關掉中間緩存
或者使用新的JPEG寫入形式其非常高效
或是當創建CGImage時聲明延遲渲染
這是些關於RAW文件限制的說明
其支持內存大於2GB的iOS設備
我們支持最大120萬像素的RAW文件
我們很驕傲能將其實現
對於運行在1GB內存設備的應用我們支持
處理最大60兆像素的照片這也很驚人了
這對於照片編輯擴展也適用
會使其花費更少的內容就可以運行
這就是關於RAW的討論
我很容易今天可以爲你們做演示
接下來我要把講臺交給Etienne
和你們講下另一個很棒的新圖片格式
以及你們如何在程序中編輯Live Photos 謝謝
謝謝你 David
大家好
我很高興今天站在這裏
跟你們談談如何在程序中編輯Live Photos
首先我們要進行一個簡要的介紹
什麼是Live Photos然後看看你都可以編輯什麼
接下來我們會一步步的看看代碼
看看你如何得到一張Live Photo以供編輯
你如何設置Live Photo編輯環境
你如何將Core Image濾鏡應用到Live Photo上
以及你如何在你的程序中預覽Live Photo
最後就是你如何將編輯好的Live Photo保存到照片庫
我們最後會做個快速的演示
那麼讓我們開始吧
正如你所知 Live Photos
就是包含動作和聲音的照片
從拍攝前到拍攝後
Live Photos可以用新的設備拍攝
如iPhone 6S、6S PlusiPhone SE和iPad Pro
事實上 Live Photo是這些設備上的默認拍攝模式
因此你可以預期你的用戶
已在他們的照片庫有大量的Live Photos了
今年Live Photos有何新特性？
首先是用戶可以在Photos中完全編輯Live Photos了
他們可以做出所有的調整
如普通照片那樣應用到Live Photo上
我們有新API用以在你應用中拍攝Live Photos
更多關於此的信息
我強烈推薦你們去看下進階
本週早些時候舉行的iOS攝影演講
它也包含了關於Live Photos的許多信息
基於拍攝者的角度
最後我們有新API編輯Live Photos
這也是我爲什麼今天要站在這講的原因
好了
到底什麼能被編輯呢
首先就是你可以編輯照片的內容
而且你還可以編輯視頻的所有幀
你也可以調整音頻的音量
你可改變Live Photo的大小
你不能實現的就是
你不能改變Live Photo的持續時間
爲了獲得可供編輯的Live Photo
首先就是要從照片庫中獲得一張Live Photo
有兩種方法可以實現
取決於你是要創建一個照片編輯擴展
還是一個PhotoKit應用
如果是照片編輯擴展的話
你若要實現Live Photo編輯首先需要
添加LivePhoto字符串
爲你的擴展將其加入支持的媒體類型數組
然後在startContentEditing實現中
它會被自動調用
你會得到你收到的編輯輸入的內容
你還可以檢查媒體類型以及媒體子類型
以確保它是張Live Photo
好的
另一方面如果你創建一個PhotoKit應用
你已從PHAsset請求了contentEditingInput
那麼你就可以以同樣方式來檢查媒體類型和媒體子類型
接下來要設置一個LivePhotoEditingContext
一個LivePhotoEditingContext包含所有資源
即編輯Live Photos所需的
它包含有關Live Photo信息
諸如照片的持續時間
Live Photo的尺寸還有方向性
它也有幀處理器屬性
你可以用來編輯Live Photo的內容
我會後面再跟你們多介紹一些
你也可以調整音頻的音量
你可請求LivePhotoEditingContext來爲Live Photo準備回放
你可以請求LivePhotoEditingContext
來保存和處理Live Photo用來保存到照片庫
創建一個LivePhotoEditingContext非常簡單
你只需要創建一個新的
從LivePhotoEditingInput爲了Live Photo
好了
現在讓我們來看下如何
使用我之前提到的幀處理器
我會通過描述一個PHLivePhotoFrame對象來介紹Live Photo的幀
其包含了輸入圖像也就是該幀的CIImage
類型 即它是一個視頻幀還是相片幀
和Live Photo中的時間幀
還有該幀被渲染時的分辨率
爲了實現一個幀處理器
你要在LivePhotoEditingContext中設置幀處理器屬性
使其成爲一個塊來以參數形式接收一幀
並返回一張圖片或者報錯
我們剛返回了幀的輸入圖片
它其實就是節點幀處理器
現在讓我們看看真實的例子
這是張Live Photo就像你在Photos中看到的
我可以播放一下
就是這
還有
假如我們想要對Live Photo做個簡單的調整
就從一個簡單的矩形剪切功能開始吧
這裏是如何實現
對於你幀處理器的實現
你要從幀的輸入圖像開始入手
然後你需要計算剪切矩形的數據
然後你可以用這裏的方法來剪切圖片
即對rect調用剪切然後返回剪切完成的圖片
這樣就可以完成編輯和剪切Live Photo
這裏是得到的結果
我可以放側面圖你可以看出照片是被剪切過的
而我播放的視頻也是被剪切過的
好了
這就是關於非常基本的靜態調整的例子
如果我們想要做個更動態的調整
這張照片依時間而改變
Live Photo播放時隨之改變
你也可以實現這個
讓我們做個剪切的例子來實現動態剪切
這裏是我們要如何實現
首先我們需要獲得一些信息
關於Live Photo的時間選擇像是照片的確切時間
因爲我們想保持相同的效果
讓你的剪切矩形位於Live Photo中心位置
接下來是我們捕獲Live Photo的時長
你會注意到我們是在幀處理器代碼塊之外完成它的
以此來避免循環依賴
在這代碼塊裏我們可以請求關於該幀確切的時間
然後我們可以寫一個時間的方法
使用所有這些信息來幫助運行矩形剪切
這裏是——
結果 看得出來Live Photo以相同方式被剪切
就如照片一樣 但當我播放它時
你可以看到矩形剪切現在從底部移動到了頂部
這裏是一個基於時間調整的例子
現在讓我們看點別的
這個效果很有意思
因爲它是一個依賴於分辨率的效果
意思就是濾鏡的參數是怎麼聲明的
它們在像素中被聲明
也就意味着你需要額外的仔細
當你應用這類效果時要確保
此效果是視覺上一致的
無論Live Photo所渲染的分辨率是多少
在此我播放它 你可以看見視頻
特效被如應用到照片那樣應用到視頻上
真不錯
讓我們看看怎麼能正確實現
在你的幀處理器中你要注意
幀上的renderScale屬性
它會給你當前幀的分辨率
與Live Photo中的一比一全尺寸的靜態圖片相比
所以請記住
視頻幀和圖片也是不同的尺寸
通常視頻會比照片小得多
因此你要確保能正確的實現它
爲了實現這個目的
你可以使用這的比例尺
來案例比縮小寬度參數以便一比一
的全尺寸照片的參數將會是50
但它會在小分辨率下變得更小
另一個可以用來做出依賴分辨率的調整的方法就是
使用
利用圖片的範圍就如我現在這裏做的那樣——
對inputCenter參數
我實際上使用了圖片的中點 這也成功
正確的縮放了
好的
對於這張圖片還有一個編輯的地方
你們可以注意到我在這邊做了一個標識
可能看上去很熟悉 當我播放它時
你會看到標識從視頻中消失了
就是關於如何將一個調整只應用到照片上
而不是視頻中
這裏是如何實現的
在你幀處理器的實現中
你要看一下幀類型在此我們要檢查下它是不是一張圖片
然後我們將靜態標識整合到圖片中去而不是視頻中
就是這麼容易
你們或許知道 有一些調整
可能是一個本地廣告或是單個廣告
你不想或者不能應用到視頻中
而這麼做就能很好的實現這一功能
好了
我們現有了一張編輯過的Live Photo
讓我們看看如何在應用中預覽它吧
你用PHLivePhotoView來預覽一張Live Photo
這個視圖在iOS中早就可用了而今年引入了macOS中
爲了預覽Live Photo你需請求LivePhotoEditingContext
以準備回放一張Live Photo你要傳入
目標尺寸也就是你視圖的像素尺寸
然後你要異步地回調
附着一張渲染過的Live Photo在主線程上
接下來你要做的就是設置
LivePhotoView的Live Photo屬性
以便你的用戶可與其Live Photo交互且獲得
編輯過的Live Photo看起來如何的印象
現在
最後一步就是將其保存到照片庫中
這取決於你開發的是一個照片編輯
擴展或PhotoKit應用
若是照片編輯擴展 你就要實現finishContentEditing
第一步 創建一個新的contentEditingOutput
從你早先接收到contentEditingInput中
接下來你要請求LivePhotoEditingContext
以保存Live Photo到該輸出中
這會處理全分辨率的Live Photo
以異步的方式 並且在主線程上回調
成功還是報錯
如果所有都順利的話
你還要確保你除了編輯的內容還保存了調整的數據
這將會允許你的用戶回到
接下來在你的應用或者擴展中並繼續在那編輯
最後要調用completionHandler
對於該擴展 然後你就完成了
若你開發的是PhotoKit應用步驟就很類似的
唯一的區別就在於你要
它們是來自於你本身的變化
使用PHAssetChangeRequest
現在我要給你們展示一個快速的演示
好了
我創建了一個Live Photo擴展的簡單演示
我今天想要展示給你們看
我現在Photos應用裏可以看到一些Live Photos
可以來挑選看看這些內容
我可以滑動來看它們活動起來
這就是我今天要編輯的照片
現在我要開始編輯了正如我之前提到的
我在Photos裏就能編輯Live Photo
讓我來編輯看看
我想要應用下David之前提到的這個新的亮度滑動條
好了
我可以在Photos應用中播放它
當然了 我可以
在這就停下但我想也應用下我的示例編輯
我要在這選擇我的擴展
我們應用的是貫穿幻燈片所提的相同的調整
你們能看出來這是個挺簡單的擴展
它顯示LivePhotoView因此我可與之交互
我可以點按來播放它就像在我的擴展這樣
這很簡單
下面一步就是要點擊“完成”來保存
而且要處理一個全分辨率的Live Photo
並將其發送回照片庫
就是在Photos那兒
好了
這就是這個演示
現在回到幻燈片上
謝謝
好的
這裏是我們今天目前爲止所介紹的一個簡要總結
我們已經學到如何獲得一張Live Photo
從照片庫中
如何使用和設置一個LivePhotoEditingContext
如何使用幀處理器來編輯Live Photo的內容
我們介紹瞭如何在你的應用中利用LivePhotoView來預覽Live Photo
我們看到了如何將Live Photo保存到照片庫中
我現在迫不及待地想看到你們會用這個新API做出些什麼
有幾點是需要記住的
首先如果你是要開發一個照片編輯擴展
別忘記...將LivePhotoEditing加到
你info.plist中來擴展
否則你得到的是一張靜態圖片而非Live Photo
就如我所說的你要確保保存了調整數據
以便你的用戶們可以回到你的應用中
繼續無損的編輯
最後 我覺得如果你已經有了一個照片編輯應用
採用Live Photo及添加對於LivePhotoEditing的支持
使用這新API實現就該非常容易
特別是如果你的應用已經使用了Core Image的情況下
如果沒有Core Image裏有個新API
可以讓你將自定義的處理集成到Core Image裏
我會請Alex上臺給你們詳細介紹
謝謝
謝謝 Etienne
我叫Alexandre Naaman
我今天要講的是關於一些新功能
關於Core Image之前所沒有的額外特效
這會用到一個叫CIImageProcessor的新API
就如David之前提到在Core Image中 你可實現很多東西
使用我們內置的180個濾鏡
你還可通過編寫自定義的kernel來做進一步的擴展
有CIImageProcessor我們能實現的就更多
我們可以在渲染圖中插入一個新的節點
它能實現我們想要的一切
還與現存的圖完美融合
我們可編寫自定義的CPU代碼...或是Metal代碼
使用CIImageProcessor時
與編寫通用kernel有類似
過去你寫通用kernel要聲明某些字符串
然後重寫你CIFilter中的輸出圖像方法
並且提供範圍 也就是
你要創建的輸出圖片尺寸
還有roiCallback函數
最後
無論你要將何參數傳入kernel中
這與創建CIImageProcessors有許多的相似性
所以我們今天不會再深入討論它們了
我們建議你去看看2014 WWDC的演講515
若你想創建一個CIImageProcessors
我們強烈推薦你回去看下那個講座
因爲我們討論瞭如何處理範圍
和ROI參數
現在讓我們看下這個API
用來創建CIImage處理器的是什麼樣的
這可能在將來更新中會有些許變化
但是它現在的樣子
相似性是這些
我們需要提供範圍
也就是我們要生成的輸出圖片的尺寸
給它一個輸入圖像
還有ROI
我們需要提供很多額外的參數
例如我們要創建的節點的描述
我們需要提供一個摘要有着某種哈希值
對於我們所有的輸入參數
這對於Core Image很重要
因爲這是Core Image如何決定
我們是否要緩存那些值
還有我們是否需要重渲染
你需要確保每次你的參數改變的時候
你要更新哈希值
接下來我們可以聲明是輸入格式
在這個例子中我們用了BGRA8
但你也可以聲明爲0
這意味着你會獲得對於該上下文可用的格式——
作爲一個輸入圖像格式
你也可以聲明輸出格式
在此我們用的是RGBAf因爲我們詳細介紹
的例子
需要精度很高因此我們需要在此使用全流量
最後我們要看下處理器代碼塊
在這我們有兩個參數
CIImageProcessorInput和CIImageProcessorOutput
它們在這裏面以便我們可以完成所需的所有工作
讓我們看看如何來實現它
還有你爲什麼要實現它
CIImageProcessor特別有用
對於你有某個算法的時候或者你想用一個庫
其實現了Core Image外某些東西
且還是對於CIKernel語言不合適的東西
一個好例子就是積分圖像
積分圖像就是憑藉輸出像素的圖像
它包含了其上所有像素的總和
還有它左邊的像素 包括它自身
這是個好例子 對於不能完成的事情
在數據平行類的着色器
也就是當你編寫CIKernel時所寫那種着色器
讓我們來看下
關於積分圖像的更多細節
如果我們從左邊的輸入圖像開始
也就是說與某些單信道 8比特數據相對應
我們的積分圖像會成爲右邊的圖像
如果我們看下這邊的像素的話
7
它實際上對應着左邊所有像素的和
也就是1加4加0加2
對於另外的像素也是如此45對應的是和
也就是那些像素的上邊 左邊再加上它自己
讓我們來看看你會做些什麼
如果你要寫CPU代碼到圖像處理器代碼塊的話
你也可以使用V Image
或是我們系統裏有的其他任何庫
首先重中之重的就是
我們要獲取一些指針返回到輸入數據
從CIImageProcessorInput我們會得到基地址
而且我們要確保使用8比特數據也就是UInt8
接着我們會得到outputPointer
也就是我們寫入所有結果的地方
要作爲浮點類型寫入因爲我們聲明要寫到RGBAf
接下來我們要確保考慮到
輸入輸出圖像相關的偏移量
Core Image很可能提供給你
更大的輸入圖像
至少和你的輸出圖像不一樣大
所以你要小心處理所有可能的偏移量
當你創建輸出圖像還有寫for循環的時候
在這種情況下一旦我們弄清楚所需要的偏移量
就可以執行我們的for循環來計算輸出值
通過使用i-j位置的輸入
加上我們得到的偏移量
現在我們已經看到如何利用定製CPU循環來實現它
也看看如何利用Metal來實現
在這個例子中我們會使用
Metal性能着色器
在Metal性能着色器中有個很不錯的初始點
來計算積分圖像 叫做MPSImageIntegral
從CIImageProcessorOutput中我們可以得到commandBuffer
Metal command buffer 所以我們創建了一個MPSImageIntegral
利用那個commandBuffer
我們要小心留意需要處理的偏移量
然後對該commandBuffer編寫相應kernel即可
還要提供我們得到的輸入紋理作爲輸入
其是從CIImageProcessorInput得到的
還要將output.MetalTexture作爲目的地
這就是我們如何使用Metal
在現存CIFilter圖之內
現在讓我們看看我們能完成什麼
通過目前得到的積分圖像
我們從像是這麼一張圖片開始
我們的目標是生成一張新的圖片
其每像素變量都有盒裝模糊
該張圖片的每個像素都有不同的模糊量
我們利用積分圖像很快就可以實現
我要說的是 盒狀模糊是很有用的
對於實現快速盒狀相加
如果我們就從這張輸入圖片開始 想要
得到這九個像素點的和 通常來講
這需要進行九次讀取也就意味着這是個n平方複雜度的問題
這可不會太快
這不完全對 如果你稍微聰明點的話
你可以通過多通道方法來實現它
通過兩個n次讀取來實現但你仍然要進行六次讀取
也沒有明顯縮小多少
不過利用積分圖像的話 我們就可以
如果想得到這九個像素點的和
我們只需要讀取幾個位置
我們要讀取右下角的位置
然後再讀取
從一個到最左邊 所有值的和
然後再從中減去我們讀取的頭一個值
然後我們要讀取一個像素點它就在我們所需的上面
並減去目前爲止
所有像素相加所對應的行
你們現可看到我們將左上角設爲高亮
設爲1 因爲我們已經減了兩次那個值
所以我們要再把它加回來
這意味着我們可以創建一個任意尺寸的盒狀模糊
就通過四次讀取
如果我們要 謝謝你們
如果我們要手動做計算
你可以看出來這些數加起來是對的
也就是2加4加6等等 完全相同
和66減10減13加1
讓我們回到Core Imagekernel語言
看看我們如何使用積分圖像該圖像或是我們利用CPU代碼計算的
或使用Metal性能着色器基類型得到的
並繼續實現創建盒狀模糊特效
我們要做的第一件事就是計算左下角
和右上角 從我們的圖片中
這會告訴我們需要要從哪進行加減
然後我們要計算一些其他的值
它們會幫助我們決定所需alpha值
也就是我們當前要生成的像素的透明度
我們取得四個角的樣值
做了所需的加法和減法
再乘上所決定的合適的
對於該輸出像素的透明度
該kernel接收單個參數
作爲輸入半徑 也就是
如果你要在圖片上調用它
你會在整個圖片上應用相同的半徑
不過我們可以簡單
去創建一個盒裝模糊變量
通過傳入一個掩膜圖像我們可以利用該掩膜圖像
來決定多大
的半徑對於每像素爲基礎合適
我們要傳入一個額外的參數也就是掩膜圖像
我們從中進行讀取
我們來看下紅信道中有什麼
也可能從任何一個信道而來
然後我們要把它乘上半徑
如果我們的半徑是15而在當前像素位置的值是0.5
那麼最終的半徑是7.5
我們可以得到這些值後 傳到
我們剛寫好的盒狀模糊kernel中
這就是我們如何創建一個盒狀模糊變量
利用Metal性能着色器和CIImageProcessor節點
還有個我們今天沒有提到的事情是
我們現在有了可以聲明的屬性
它們在你所寫的CIKernels中
實際上我們現在就有一個 也就是輸出格式
在這裏我們要請求RGBAf不需要真的有用
關鍵是說你想要寫
單信道還是雙信道數據
所以如果你想要
如有些人所注意到有個好方法
來減少你的內存佔用 也可以來聲明
對於某個特定kernel你想要個確切的精度
在可能和圖剩餘部分不相對應的kernel
就如我們在iOS上處理RAW圖片那樣
我們的所有kernel都標記着RGBAh
另外 我們要創建此特效還得
提供某種掩膜圖像
調用CIFilter(name,就可輕鬆實現
然後附帶參數請求一個CIRadialGradient
也就是要決定有多大
的掩膜 還有它位於哪裏
然後我們要在0和1間插入
非黑即白
然後我們要從CIFilter中請求輸出圖像
之後我們就有了一個完美可用的掩膜
現在讓我們看看它實際看起來
運行在設備上時是什麼樣的
這是從iPhone 6S上錄製的
如果我們從輸入圖像開始並看看掩膜的話
我們可以移動它
它非常具有可交互性
可以改變半徑 甚至將其設爲負數
如果我們使用此掩膜圖像 並使用它在
我們的盒狀模糊變量kernel代碼中
就可以得到這個類型的結果它是非常可交互的
因爲積分圖像也需要計算一次
Core Image爲你緩存這些結果
它幾乎就是你現在所看到的這些東西
就包括四次讀取 所以它非常的快
有些要你們記住的當你使用CIImageProcessor時
如果你要使用的在圖像處理器中的數據
不是在當前workingColorSpace的上下文中
你就要調用CIImage.byColorMatching
WorkingSpace(to,來提供一個顏色空間
類似的 在出口處如果你想要數據
位於不同的顏色空間
你就要調取CIImage.byColorMatching
ColorSpace(toWorking,並給它一個顏色空間
現在我們已經看到如何創建CIImageProcessor
並使用它
讓我們來看看會發生什麼
當我們使用環境變量CI PRINT TREE時
我們用它來得到實際的圖
我們渲染完會是什麼樣
它看起來就會是這樣的
當你使用環境變量CI PRINT TREE時
而且將其值設爲1
是自底向上讀取 而且它可以很冗長
它從我們創建的radialGradient輸入開始
接下來我們得到與工作空間相匹配的輸入圖像
然後就是我們的處理器節點被調用
此十六進制值就是我們已經計算過的摘要
處理器和顏色kernel結果
來自radialGradient的被傳入variableBoxBlur中
最後我們對於輸出顯示做顏色匹配
這是我們的原始菜單
用來聲明才特效但它不是實際被渲染的那個
如果我們將環境變量CI PRINT TREE設爲8
就可以看到很多東西都已經被壓塌了
並且處理看來參與的少了
我們還是有處理器節點
單獨位於一行
也就意味着它需要一箇中間緩存
這就是CIImageProcessors非常好的原因
不過你只應該在特定情況下才使用
當你要生成的特效 你所有的算法
不能在CIKernel語言內被表達時
如你所見處理的剩餘部分都會被連接到一起
因此我們有variableBoxBlur來處理剩餘的顏色匹配
還有clamptoalpha都在一次傳值中完成
這也是爲什麼總要在這些API中有所取捨的原因
如果你可以的話就應該寫在CIKernel語言內
這可能會有點難讀
所以你也可以聲明
使用了CI PRINTTREE 即graphviz
在這裏我們使用了CI PRINT TREE=8
通過利用graphviz選項
我們可以看到處理器節點 還有其與
圖的其他部分完全融合
我們還可以看到所請求的RGBAf輸出
我們複習下今天都學了些什麼吧
David給我們展示了如何在iOS上編輯RAW圖像
然後Etienne跟我們講了
你如何利用Core Image編輯Live Photos
最後我們看到了如何使用
CIImage上叫做CIImageProcessor的新API
還有如何在你的kernels上聲明一個輸出格式
藉以減少內存佔用
爲了獲取更多信息
請訪問developer.apple.com
有一些相關的演講你們可能會感興趣
特別是如果你打算在iOS上做RAW處理的話
還有Etienne提到的“iOS攝影進階”
今天晚些時候還有個講座叫“用廣色域來工作”
還是在這進行
非常感謝大家的到來
我希望你們在接下來的WWDC過得愉快