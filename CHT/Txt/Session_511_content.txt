大家好 歡迎來到511會話
AVCapturePhotoOutput的基礎功能拓展
本期節目是第501期的補充
即對iOS Photography新進展的演示及說明
我是Brad Ford
Apple核心多媒體擷取團隊工程師
501會話重點講解了AV foundations的攝影捕獲API
特別是AVCapturePhotoOutput
它是iOS 10下新的拍照接口
該輸出端支持實時圖象捕獲
RAW + DNG
寬色域內容
圖片預覽或縮略圖
如果你還未看過501會話
建議你暫停一下 先去收看501會話
以便你能從本期節目中獲得更多知識
在本期中 我們將會拓展AVCapturePhotoOutput基礎
並討論501會話中未講解的兩個重點
即 場景監控
以及資源分配與回收
最後 我們將花幾分鐘
講解一個不相關 但很重要的東西
iOS 10下的相機隱私策略變化
簡要的回顧一下
新的AVCapturePhotoOutput擁有增強型接口
可應對AVCaptureStillImangeOutput的一些設計挑戰
使用一種功能化的程序模型
在可變數據與不可變數據之間有明確的界線
它使用獨立的對象封裝各相片設置
這些設置稱爲AVCapturePhotoSettings
當發出照片捕獲請求時就需要調用它.
該設置使用委託式的接口
以跟蹤照片捕獲請求
這稱爲AVCapturePhoto的捕獲委託協議
委託協議中的所有回調函數
將返回AVCaptureResolvedPhoto設置的一個實例
這是個不可變對象 其中所有相片設置
都已確定
AVCapturePhotoOutput還支持場景監控功能
運用剛纔說過的那些捕獲對象的子集
場景監控可讓你呈現UI
該界面將場景特徵告知用戶
這些場景都是當前活動的場景
在這個Apple相機應用的截圖中
用戶明顯處於光度低的環境
屏幕下方閃光燈圖標
顯示用戶處於自動閃光模式下
意味着只有在情景需要時才能使用閃光功能
Apple相機應用是AVCapturePhotoOutput的客戶端
進行場景監控
以驅動閃光燈激活爲黃色閃光圖標
你在屏幕正上方看見的
黃色的閃光圖標表示
如果用戶現在拍照的話閃光燈就會啓動
AVCapturePhotoOutput執行場景監控功能
在兩種情況下
第一種是閃光燈
當前Apple所有的iPhone型號
以及9.7英寸的iPad Pro
都配備了雙色閃光燈以照亮黑暗的場景
通過後置視力相機
和retina閃光技術將你的視網膜顯示器
變成雙色閃光燈
將亮度提高到正常情況的三倍
以便將低亮度的自拍照變亮
支持場景監控的第二種類型是
靜態圖象穩定技術
靜態圖象穩定是一種多重圖象融合的捕獲技術
通過不同方式融合曝光圖片以減少低亮度下的圖片模糊
有一點可能還不是很清楚爲什麼靜態圖象穩定技術
具有低光度特點
這並是說你的手在黑暗中抖得更厲害
而僅僅是因爲相機需要更長的曝光時間
以獲取相同的光子數量
這要求攝影者得非常非常穩定才行
而靜態圖象穩定技術能解決這個問題
通過捕獲不同曝光水平的多重圖象
並將它們融合在一起以消除幹擾與運動僞影
所以乍看起來 閃光燈的作用或靜態圖象穩定技術的作用
似乎是無關的,但事實上 它們密切相關
而這會造成接口衝突
從這張圖上可以看到適用的光亮範圍
在Flash Capture是否帶有靜態圖象穩定時的對比情況
我將靜態圖象穩定技術簡稱爲SIS
藍條表示亮度級別
即照片輸出使用閃關燈的亮度
如果你選擇開啓SIS的話
綠條表示適於閃光燈啓動的光照強度
如果你選擇關閉SIS的話
注意到 在開啓SIS時
在相對黑暗的環境下能夠不通過閃光燈來進行照片輸出
這是因爲SIS一定程度上降低了圖象中的幹擾
因此不需要閃光燈介入
如果你當前所處環境的光強度在此那麼問題的答案是
閃光燈一定會介入
但如果光強度在此
那完全取決於你是否想開啓靜態圖象穩定技術
反之亦然
那麼 具體該怎麼做呢？
AVCapturePhotoOutput並不知道你希望抓拍的類型
除非你向它提出要求
可如果開啓場景監控就得不停運行
當前是SIS場景還是flash場景呢？
在AVCapturePhotoOutput中我們解決了這個問題
通過使用特定的場景監控端口
該端口叫做 關於場景監控的照片設置
並且我們提供了兩項鍵值觀察屬性
該屬性可對你進行非同步通知
當場景的適合性發生改變時
關於使用靜態圖像穩定技術還是閃光燈
你創建一個AVCapturePhotoSettings實例
具體來說是關於場景監控的實例
並明確你希望AVCapturePhotoOutput具備的功能
現在我將閃光燈設置爲自動模式
這說明我希望在使用閃光燈時
它已處於適用狀態
並且我還將AutoStillImageStabilization的Enabled屬性
設置爲true
那麼 對SIS也應該進行同樣設置
SIS會一貫地輸出比flash質量更高的圖片
那麼當場景陷入一種交叉範圍
該範圍處於SIS與flash之間
photoOutput報告此種情況屬於SIS場景
接下來我將該對象指定爲照片設置
在SceneMonitoring屬性中
該屬性可在任何時候進行設置
甚至包括在你運行AVCaptureSession前
爲獲知閃光燈的變化情況
及靜態圖象穩定技術的價值
我對之前提及的isFlashScene添加了鍵值監測
並對isStillImageStabliziationScene也進行了該操作
然後隨着場景值變化我進行了回調操作
對於那兩個屬性
現在我們來討論場景監控的默認配置
photoSettingsforSceneMonitoring的屬性是可空
並且該默認值爲nil,
這意味着沒有對場景進行監控
如果你在查詢isStillImageStabilization
或isFlashScene時若沒對場景監控功能進行相片設置配置
那麼它們將會一直報告錯誤
一旦你爲場景監控成功配置相片設定後
你可以查詢或通過鍵值觀察兩種isScene的屬性
並得到恰當的回覆
但請注意如果你對場景監控進行的照片設置中
包含關閉的flash模式的話
isFlashScene將依舊報告錯誤
對於AutoStillImageStabilization的Enabled屬性來說也一樣
對於場景監控 我的建議很簡單
如果你的應用不顯示任何用戶界面
僅顯示用戶正看到的場景
那麼你沒有必要啓動場景監控功能.
但如果啓動了該功能它將會監控你希望捕獲的畫面
比如你希望使用Auto Flash來拍攝而非SIS
那麼帶閃光模式的監控器設爲自動或者自動SIS關閉
如果不這樣做 將會使用戶混淆
因爲你的用戶界面可能會報告目前不處於閃光燈場景
儘管在實際拍照時 閃光燈會被啓動
以上爲場景監控功能的內容
在接下來的課程中 將介紹
資源調配與回收功能
爲了解按需資源調配功能的需要
我們來看看AVCaptureSession的正常數據流程圖
當AVCaptureSession開始運行
數據即開始從各個AVCapture輸入端
流向各個 AVCapture輸出端
大部分輸出端口對數據流形式的數據進行接收與處理
比如VideoPreviewLayer
該輸出口將輸入的數據不斷地顯示在屏幕上
或VideoDataOutput該輸出口通過委託回調來緩存至應用
此類流輸出
需要分裂性的捕獲渲染管道重建
如果改變它們的結構
你就不得不爲一種輸出模式進行配置
在運行程序之前
而AVCapturePhotoOutput不同
因爲它僅根據需要來從輸入接受數據
當你通過CapturePhoto請求一張照片
並進行設置與代理
照片輸出端僅輸出一個結果或結果的集合
不像流輸出口
照片輸出具有充分的等待時間
因此能夠在完美的位置上 按要求進行資源調配或回收
而不會造成擾亂性的渲染模式重組
雖然看不見 但整個調配過程卻十分華麗
當然 資源調配過程並非免費的
AVCapturePhotoOutput的功能集很廣
拍攝420像素的未壓縮照片
這些照片都爲AVCapture設備的原始格式
僅需要極少的一部分資源
像EGRA或JPEG這類經處理過後的輸出格式
則需要另外一些資源
因爲有格式轉換功能介入
閃光拍攝則需要它們自己的硬件資源集
以傳遞與預閃光序列及頻閃同圖像
靜態圖象穩定功能需要對多個緩衝進行融合
拍攝RAW格式圖片則需要十分大量的緩衝
RAW加JPEG格式的圖片則需要大小資源的組合
Bracketed捕捉需要大量的緩衝
以便將多個圖片返回到客戶端
當然 許多這樣的特徵都能被混合並匹配
並需要資源超集
由於那麼多適用的捕獲特徵
AVCapturePhotoOutput很難
估計需要預先準備多少資源
過度準備及準備不足都是不好的
我們將過度準備比喻成烤蛋糕
一年中的每天都在烤蛋糕以防止這一天就是你的生日
對我門而言 這需要付出很大努力
需要投入很多材料
扔掉很多沒有吃過的蛋糕
造成視頻預覽可能每次來的更慢
而內存消耗則可能高得毫無必要
沒作充分準備就算不比前者糟糕也不是件好事
如果我們沒有準備好
使用所要求的特徵集進行照片捕捉我們可能會錯過這次拍攝
直到按要求分配資源
幸運的是, 我們提供瞭解決方案
AVCapturePhotoOutput會讓你事先告知
你希望捕捉的類型
只需要啓動setPreparedPhotoSettingsArray功能
傳遞AVCapturePhotoSettings的數組
包括各個代表不同捕捉類型的數據
你希望爲之準備的
你可以選擇性地傳遞完成處理程序
待準備完成時 即可調用該程序
照片輸出端口還提供
一種只讀屬性的preparedPhotoSettingsArray
因此你可以查詢最終設定的設置數組
setPreparedPhotoSettingsArray功能可以做很多事
它可以爲所有的捕捉類型準備資源
在你的設置數組中
另外 如果存在不需要的資源該功能會對其進行回收
並且你還可以通過傳遞一個空數組來回收所有的資源
當所有資源準備完畢該功能會通知你
如果資源無法準備該功能會返回錯誤
整個數據傳遞都通過完成回調進行
preparedPhotoSettingsArray的默認值
是一種關於AVCapturePhotoSettings的默認函數
該函數將JPEG設置爲輸出格式
和AutoStillImageStabilization的enabled屬性
preparedPhotoSettingsArray具備sticky屬性
它會在AVCaptureSession的啓動及結束之間
配置開始或確認期間持續存在並且你可以對其進行設置或忽略
如果你總是通過你的應用拍攝同種類型的照片
setpreparedPhotoSettingsArray的另一好處是
它能加入AVCaptureSession的
begin/commitConfiguration延期工作語義
也就是說如果你調用beginConfiguration
之後改變會話的拓撲模型
通過添加或移除輸出端口或輸入端口
之後設置新的preparedPhotoSettingsArray
然後確認配置
除非配置確認被調用否則不會進行準備程序
你可以按照原子的方式來對會話配置進行變更
並同時準備照片輸出
爲新的配置
你可以在運行AVCaptureSession前進行準備
以確保app處於準備捕捉相片的狀態
只要視頻預覽開始運行
在會話停止時 如果你調用setPreparedPhotoSettingsArray
它不會立即回調完成處理程序
相反 完成處理程序會在準備完成時被調用
在你調用會話啓動程序之後
如果你的會話被終止並且你已經準備了一組設定參數
之後 你改變了注意
使用另一組設定參數重新調用該程序
你最初的完成處理程序將即刻啓動
通過設置爲false的準備數據
實際上 這是對最初準備數據的註銷
我們提三個簡單的建議
關於如何使用我們準備的API
首先 準備
你可在不進行最初準備的情況下發出捕捉請求
但 如果未對照片輸出
準備你希望捕捉的精確類型
則你可能會很慢地獲取的第一張照片
第二 在啓動你的會話程序之前進行準備
知道你感興趣的捕捉類型
讓會話程序爲你分配最佳數量
在啓動時
第三 僅在你的UI界面發生變更時重新進行準備
你不必在捕捉圖片的各時刻重新進行準備
僅在你改變了將要捕捉的類型時
例如當你的用戶將RAW Capture或Bracketed Capture
在應用中切換成打開或關閉
不是所有AVCapturePhotoOutput特徵
都具有按需資源準備的資格
首當其衝的isHighResolutionCaptureEnabled
一些照相格式可以讓你捕捉高清晰的靜態圖像
比該格式可支持的流分辨率還要大
比如 前置相機的照片格式
在iPhone 6s及6s Plus上的
支持五百萬像素的靜態圖像
但僅能傳輸1280x960的圖片
當相機配置該種格式
要麼傳輸1280x960的靜態圖像
要麼傳輸五百萬像素的靜態圖像
根據你的照片設置是否規定了高分辨率捕捉
但事先必須對相機配置爲五百萬像素的靜態圖像
所以AVCapturePhotoOutput要求你選擇其特徵
在你準備啓動程序前
通過設定isHighResolutionCaptureEnabled爲true
一旦你選定 就可以在啓動或未啓動高分辨率捕捉功能的情況下 拍攝靜態圖
而不會造成複雜的圖形重建
類似地  LivePhotoCapture涉及動態影片
及靜態圖像的拍攝
電影包含的樣本來自過去
在你發出捕捉請求之前1.5秒
因此 對捕捉渲染模式的配置操作
必須在進行該項捕捉程序之前
最後 動態圖像能夠以智能及自動的方式在捕捉時間進行調整
如果檢測到大幅度的目的性運動
比如某人將手臂放下 把設備裝進口袋
如果你想捕獲原始動態照片的整個過程
你必須在啓動程序前退出自動調整功能
在你的AVCaptureSession上
今天最後要討論的是
iOS 10中的相機隱私策略變更
讓我們回顧一下Apple關於媒體的隱私策略
用戶iOS設備上的照片與視頻是個人的
私人的以及敏感的數據
照相機與麥克風的使用需要特別授權
必須經用戶的明確授權
因此從iOS 7開始
用戶被告知 首次使用的應用
照相機或麥克風都有一次被禁止使用的機會
這件事非常好
爲了透明與信任
別爲點擊一次OK而惱怒 這是值得的
在iOS 10 我們要求應用在透明度方面多一步確認
通知用戶爲什麼它們要訪問敏感數據
有時 你的UI會做得很明顯但有時卻不會
你的原因字符串應沒有任何歧義
例如：此處 AVCam告訴用戶
它想要使用相機拍攝照片和視頻
這非常明確的交代了它將用相機做什麼
同樣 iOS 10中的應用
必須提供原因字符串以使用麥克風
最後是Photos Library
你該在Photos Library的原因字符串中明確交代
你是把它用來讀或寫 還是兩者兼而有之？
在Xcode的最新版本中
你會發現一連串的可能的隱私描述說明
不僅侷限於攝像頭、麥克風和照片
而是針對所有敏感數據的訪問
爲了使用這些服務你必須提供原因字符串
如果沒有
你的應用將無法獲得所需服務的訪問權限
Capture的三個特殊關鍵要點是
NSCameraUsageDescription
NSMicrophone3UsageDescription
以及NSPhotoLibraryUsageDescription
下面讓我們總結一下剛學習的內容
AVCapturePhotoOutput允許對場景監控行爲進行精準控制
它還可以按需進行資源分配和回收
Capture客戶端必須提供原因才能使用攝像頭、麥克風
以及照片這些iOS 10功能組件的原因
想要了解更多詳情 請訪問URL
瞭解iOS Photography的新進展這期節目
也就是501會話
如果你還在觀看節目我們邀請你訪問
所有相關的三期節目
與攝影、RAW以及Wide Color相關
謝謝收看祝你捕獲快樂瞬間
請繼續享受其餘會話