IOS PHOTOGRAPHY的新特性
早上好
早上好各位歡迎來到501會話
我是Brad Ford
我在Apple的Core Media和AV Foundation Capture團隊工作
本次會議全是關於iOS相機的
希望你們現在都已經知道了
這是世界上最流行的相機
本次會議也是關於攝影的
如果你開發一個攝影的應用
或是正考慮開發一個攝影應用
那麼這對你來說是個不錯的OS
我覺得你和iOS 10很快就能交上朋友
今天我們將把注意力集中到AV Foundation框架
它是我們最底層並且最強大的訪問相機的框架
AV Foundation有着廣度和深度
如果你是iOS拍照的新手
我邀請你看下列過去WWDC 的相機主題演講視頻
它們會給你聽今天的演講打下良好的基礎
另外 你可以看到我優雅地老去
在接下來的58分鐘裏我們將要進行這些
我會展示全新的AVCaptureOutput
用來捕捉拍攝內容
然後我們會關注四個特性
我們會關注Live Photos
你們將學會如何用你的應用拍攝Live Photos
就如Apple的相機應用一樣
你們將學會如何拍攝原生RAW格式圖片
並將它們保存爲DNG文件其在iOS上首次出現
你們將學到如何獲得預覽或者縮略圖
爲你的常規圖片拍攝以獲得一個更具響應性的UI
最後 你會學到如何用寬色域拍攝漂亮的栩栩如生的照片
讓我們現在開始吧
我們先快速回顧一下AV Foundation的捕獲類是怎麼工作的
我們拍照的宇宙中心是AVCaptureSession
你告訴這個對象開始或結束運行
它需要一些輸入來使其可以幹些有用的事
像是相機或是麥克風這類輸入
它們給會話提供了數據
它也需要輸出來接收數據
比如一個StillImageOutput可以捕捉靜態的圖像
或是一個QuickTimeMovieFileOutput可以用來錄製Quicktime影片
還有connections
它們被作爲AVCaptureConnections在API中所呈現
這是我們的對象概覽圖
你們該看出來我們如何把所有東西整合到一起
所有我剛提到的這些特性都與拍攝靜態圖片有關
所以你可能預計今天會花很長時間在AVCaptureStillImageOutput上
但是你錯了
今天介紹iOS 10中全新的CaptureOutput
它叫做AVCapturePhotoOutput
值得強調的是現如今我們的照片可不止是靜態的圖片
AVCapturePhotoOutput解決了AVStillImageOutput的設計難題
從四個主要方面
它以一個函數式的編程模型爲主要特色
它對於可變和不可變的數據間有明確的劃分
我們將照片設置信息封裝到一個特有的對象作用到其自身
PhotoOutput可追蹤照片從請求到完成的全過程
通過一個回調的代理式接口
最後 它解決了
你在早先拍攝階段不確定的圖片設置
因此你知道你會得到什麼
讓我們再多講一些最後一個特性
AVCapturePhotoOutput看起來是這樣的
即便有着諸多的新特性它仍是個簡潔的接口
甚至比AVCaptureStillImageOutput還要小
它有一個只讀屬性的小集合
來告訴你是否支持一個特性
像是isLivePhotoCaptureSupported
它有一個更小的可寫屬性的集合讓你可以參與進來
當某個特性被支持時
有些拍攝特性會影響拍攝渲染管道的建立
所以你們要提前指明它們
其中一個是isHighResolutionCapture
如果你想拍攝高分辨率的照片
像是在iPhone 6s上五百萬像素的自拍
你得先採用這個特性
在調用AVCapture session的startRunning之前
最後 你可以調用一個簡單的方法來開始拍攝照片
僅僅一個動詞
你可能會問所有那些相片生成狀態怎麼辦
我怎麼請求閃光燈拍攝
我怎麼獲得BGRA
我怎麼獲得靜態圖片防抖
這些還有一些其他特性都被移動到
一個叫做AVCapturePhotoSettings的新對象中
這個對象包含所有這些設置
關於拍攝一張照片的請求
把它想成是個列表項可供選擇
像是當你在Apple線上商店買Mac的時候
你在網上表格里填上所有你想要的特性
然後點擊提交訂單按鈕
提交訂單就像是調用capturePhoto
將AVCapturePhotoSettings作爲你所傳的第一個參數
當你在網上下單時
商店需要你的電郵地址來和你溝通訂單的信息
在AVCapturePhotoOutput世界你所提供的電郵地址就是遵從
AVCapturePhotoCaptureDelegate協議的對象
這個delegate會被回調作爲和你的拍照發生相關的事件
這個對象是傳給CapturePhoto第二個參數
那麼AVCapturePhotoSettings有什麼好處呢
首先 它們是原子性的
所有設置都被封裝到一個單一對象
所有的設置都不可能會不同步
因爲它們不是AVCapturePhotoOutput的屬性
而是每一設置相關的對象
它們是獨一無二的
每個照片設置實例都有唯一的ID屬性
你只允許使用一個照片設置一次
並且不能再用
因此你每次拍照請求將收到正好一組結果
在附加一組設置請求拍照後你可以堅持不變動
並驗證它們返回給你的結果
就有點像做了一個你在線訂單表格的備份
那麼相片委託有什麼好處呢
它是一個單一的回調函數集合
而且又是隨着每個照片設置而變
序列是被記錄下來的
你可以明確知道你將獲得哪個回調函數
何時 以什麼順序
並且它是個用來解決不確定設置的手段
我想這點我得再多解釋一點
假如說你的應用在時間軸上的這個位置請求照片
你指明照片設置是帶有自動閃光燈
和自動靜態圖片防抖
我把“靜止圖像穩定”縮寫成SIS
以便能在幻燈片上顯示的更好
你告訴PhotoOutput我想使用閃光燈或者SIS
但是隻在你需要的時候還有它們適合於當前場景的時候
很快你提出了請求
PhotoOutput會調用你委託的第一個回調函數
也就是willBeginCaptureForResolvedSettings
這個回調函數永遠都是第一個被調用
它就有點像是你從Apple收到的禮節性郵件
告訴你我們已經收到了你的訂單
我們會發送給你什麼
這個回調函數傳給你一個實例
實例是一個新對象的 叫做AVCapturePhotoResolvedSettings
它就像你填寫的照片設置
不同的是所有問題都解決了
它們有着相同的唯一ID
你未確定和決定的版本共享一個唯一ID
以便你將它們一起比較
它也告訴你照片的輸出爲你挑出了什麼特性
注意 在這個例子中閃光燈被設定爲開
SIS被設定爲關
我們現在很明顯是處在極度弱光環境像是這個會議室
接下來的回調函數是willCapturePhotoForResolvedSettings
它是正好在拍照片的時候被送到
或是當虛擬相機快門正在閉合
並且播放了快門聲的時候
如果你想播放一個快門動畫效果
那麼這正是時候
接下來馬上就是didCapturePhotoForResolvedSettings
就在圖像被完全曝光呈現出來
而且虛擬快門開啓之後
然後你要等一下因爲圖像正在被處理
加上所有你要求的特性
當照片最後處理完成時
你獲得didProcessingPhotoSampleBuffer這個回調函數
還有你一直在等的ImageSampleBuffer
耶 就像是嶄新的Mac送到了你的門口
最後 你獲得的回調函數是didFinishCaptureForResolvedSettings
它肯定是最後被送達的
它就像是你收到的來自Apple的回訪郵件
告訴你所有包裹已經送到了
與你打交道非常愉快 完畢
現在是你清理圖片生成中間階段存儲的好時機
讓我們詳細討論下那些委託
回調函數會追蹤一個單一拍照請求
照片輸出會保留一個對你委託的弱引用
所以它不會一直給你保留那個對象
記着在你的代碼裏給它保留一個強引用
所有在這個協議裏的回調函數都被標爲可選的
但其中有些在runtime會變爲必需
這取決於你的照片設置
例如 當你正拍一個壓縮的跑步圖片時
你的委託需要在你獲得照片的時候就實現一個回調函數
否則 我們就會無處送達它
此規則在AVCapturePhotoOutput.h頭文件中就明確寫出了
所有回調函數都會傳一個ResolvedPhotoSettings對象的實例
就是我告訴你們的那個因此你總會知道你將要得到什麼
或是你剛剛得到了什麼
說到設置
我們來看段代碼 它展示了如何初始化照片拍攝
利用AVCapturePhotoSettings的諸多特性
首先第一個takeHighResolutionPhoto
如我前面所說iPhone 6s的前置攝像頭
支持五百萬像素的高分辨率自拍
但是它不能支持五百萬像素的連續流暢拍照
它只支持單個高像素的定格照
所以你必須創建一個PhotoSettings對象
並設置啓用HighResolutionPhotoCaptureEnabled
這樣你就生成了帶有參數的結構體AVCapturePhotoSettings
它默認將輸出格式設爲JPEG
並啓用了靜態圖像防抖
然後我將isHighResolutionPhotoEnabled設爲真
並調用CapturePhoto
在第二個例子takeFlashPhoto中
注意flashMode現在是settings對象的一個屬性了
如果你過去用過StillImageOutput
你就會知道Flash原來是AVCaptureDevice的一部分
所以這會產生問題就是你需要訪問
兩個不同的對象來設置settings
現在它是單獨一個對象的一部分了
太棒了
最後一個例子用了一個挺複雜的AVCapturePhotoSettings的結構體
這回我們要傳遞我們想要的輸出格式
在這裏我們想要非壓縮的BGRA格式
我們要建立一個CV像素緩存屬性的字典
然後將其作爲AVCapturePhotoSettings的參數傳遞
這樣就行了
當你調用capturePhoto時
AVCapturePhotoOutput會驗證你的設置
來確保你不是在請求一些荒唐的東西
它將保證自治性
也將確保你所請求的東西真的被支持
如果不被支持 它會拋出一個異常
Result設置如你所想是完全不能變動的
所有屬性都是隻讀的
它們僅供你參考用
而且這是函數式編程不可變的部分
它有一個唯一ID來讓你和
你的未設置的settings對象作比較
這是個不錯的特性
它讓你在沒得到你的照片前就知道照片的尺寸
所以你能提前計劃 做一些分配或是其他你需要做的事
它會告訴你flash被設爲on還是off
靜態圖片防抖是被設爲on還是off
它也支持包圍曝光拍攝
這是一種你請求多張圖片時的特殊拍攝手法
有時候伴隨着不同的曝光值
例如 可能是這麼來做的如果你想將多張曝光圖片合併在一起
來生成像是HDR這樣的效果
我在2014年的508會議上講了很多關於這類拍攝的問題
去看下那個視頻來回想一下
在AVCaptureStillImageOutput中我們支持自動包圍曝光和定製包圍曝光
而請求包圍曝光的新方法是
初始化一個AVCapturePhotoBracketSettings
它像是照片設置但它是一個子類
它有你額外所需的東西
用來完成包圍曝光拍攝
當你想創建一個包圍曝光時你要聲明一個數組
數組是AVCaptureBracketedStillImageSettings的
這是個從AVCaptureStillImageOutput時代就有的對象
你給每個曝光表明其中一個值
例如 -2EV +2EV 0EV
如果你是用iPhone 6s或者6s Plus
你可以選擇啓用鏡頭防抖
利用isLensStabilizationEnabled屬性
請你回憶下我之前幻燈片展示給你們的時間軸
照片被傳到didFinishProcessingPhotoSampleBuffer回調函數
當你請求三張圖片的包圍曝光時
該回調函數會被調用三次
每張圖片一次
第五個參數告訴你是哪個包圍曝光設置
在這個圖片請求中與之協同的
我們很喜歡新的AVCapturePhotoOutput
所以我們想讓你馬上就用它
因此我們在iOS10中不贊成使用AVCaptureStillImageOutput
和其他所有AVCaptureDevice中閃光燈相關的屬性
這纔是你應該用的
如我所說閃光燈拍攝的一部分被打包到
相片設置中它是一個更好的程序接口
儘快的使用它吧
最後一項是
在我們在說下面之前說下photo的好處
它們使書籤功能更容易
即時的設置設定
有把握的請求追蹤
它對Apple來說也有益處
因爲它對我們來說像是個可擴展的回調函數調色板
我們可以在將來加入新的方法並回調給你
最後一點對於接下來我要說的特性很重要
我要說的就是Live Photos
Apple.com上有關於何謂Live Photos好的宣傳廣告
靜態照片捕捉到的是瞬間凝結的記憶
而有了Live Photos你能將這些瞬間變成
令人難忘 鮮活生動的回憶
Live Photos的美妙之處在於
它們會珍藏你留存於記憶深處的美好瞬間
在這張照片裏這是張不錯的靜態照片
巨大惡心的沙蟹這是我外甥從沙灘上挖出來的
一張不錯的照片
如果我3D touch它
好了 現在我想起來了那天太冷了
他從來沒到過海邊他的嘴脣都凍青了
他在海水裏時間太長手都一直在發抖
我還在開始時候聽到我哥哥的聲音
所有這些都幫我進行了回憶
因爲我更多的感官被喚醒了
人們發現了各種新的方式
把Live Photos當做藝術創作的媒介使用
這張是一個旋轉的自拍
我們的相機產品團隊把它叫做甜甜圈自拍
要完成它可是相當有難度的
有張用Live Photo拍的正在旋轉的轉椅也很流行
看看那張吧
我是個展現驚喜的live photo的大粉絲
不幸的是 我們孩子們也是
一個三秒的窗口實在太有誘惑力了
對於我這麼一個天生的嚇人照片愛好者來說
Live Photos是從Apple設計工作室思考體驗中誕生
其誕生的前提是
即便我們現在有了這麼多好的屏幕
來分享和觀看內容
照片體驗已經保持靜態有150年了
我們劃過屏幕瀏覽的那些JPEG文件只不過就是數字版本的
那些我們留存在鞋盒中相紙的化學藥劑
而它仍然是人們保存他們回憶的主要方式
所以難道我們不能做得更好麼
經過了很多的試驗和原型體驗
我們得出了這個新的媒體體驗
一個時刻或是一個記憶
首先最重要的是它還是一張靜態照片
它仍然和以前照片的質量一樣好
它是一張1200萬像素全分辨率的靜態JPEG圖片
它與非LIve Photos有着相同的質量
讓我再強調一遍
Live Photos有Apple非Live Photos的一切優點
所以你把它打開沒有犧牲任何東西
另一個很棒的點子是平滑拍攝
這意味着你不需要學習任何新的東西
你就如你原來一樣拍攝照片就可以
還是那樣 定景 按快門
不用考慮別的
一張Live Photo同樣也是一段記憶
它能比靜態圖片調動更多感覺
它可以幫你喚起回憶
所以它就像是一部短電影 3秒的電影
1.5秒是靜態圖之前發生的事1.5秒是之後的
我們能以屏幕分辨率或者1080p拍攝它
而且它包含音頻
我們還在持續改進它的設計
iOS9.1中我們加入挺棒的特性自動裁剪Live Photos
以防你你衝着你的鞋子或者口袋做出揮動的動作
我們會自動裁掉這些去除掉
你不想在影片中看到的部分
在iOS 10中我們加入新特性讓它變得更好
現在所有的Live Photo影片都是防抖的了
另一個iOS10的新特性是拍攝時可以播放音樂
如果你正在放音樂
是啊 這個特性不錯
我也挺喜歡的
爲了讓它成爲一個時刻也是一段記憶
如你所料的Live Photo有兩部分組成
JPEG及QuickTime電影文件
這兩部分共享一個通用的UUID以此來連繫它們
JPEG文件的UUID被存儲在
Apple Maker Note裏
影片資源 也就是我說的
通常三秒長 有視頻軌
大概是1080p有着3比1的寬高比
它包含一個帶有示例的定時元軌道
就相當於是對應靜態圖片的時間
在影片的時間軸上
它還包含了一些上層影片的元數據
可以用來與JPEG的元數據來配對
這叫做QuickTime內容識別器
它的值是一個UUID風格的流
需要怎樣才能拍攝Live Photos呢
在AVCapturePhotoOutput裏
有一個屬性叫isLivePhotoCaptureSupported
你得確保它被支持
它不是在所有設備上都被支持的
目前它只支持AVCaptureSessionPresetPhoto
你要使用AVCapturePhotoOutput.isLivePhotoCaptureEnabled
將其設爲真
你需要在你開始運行會話之前啓用它
否則會造成會話破壞性的重新配置
你絕對想避免這麻煩
如果你在你的Live Photo影片中播放音頻
你要爲麥克風添加一個AVCaptureDeviceInput
這很重要 不要忘了
而且不支持同時錄製
使用AVCaptureMovieOutput錄製的常規電影
和Live Photos
因此如果在會話的拓撲圖上有一個影片文件輸出
它會使Live Photo拍攝禁用
可按通常方式配置LivePhotoCapture
它有默認的結構體
不過你要額外聲明一個LivePhotoMovieFileURL
在這裏我們會寫入影片
並且它必須在你的沙盒內你還得能訪問它
你不需要聲明任何的livePhotoMovieMetadata
但是如果你想的話也可以
在此我舉個使用author元數據的例子
我把自己設爲author
以便全世界都知道這是我的影片
你也可以加些有趣的東西像是往你的影片里加入GPS標籤
讓我們談談跟Live Photo有關的委託方法
如我之前所說的我們有個可擴展的調色板
關於委託回調函數的我們將會用到它
當拍攝Live Photo時你的第一個回調函數讓你知道
有一個Live Photo將會被錄製
藉由告訴你影片定好的尺寸
看到了嗎 你不僅調整了照片的尺寸
你還知道了Live Photo的尺寸會是多大
你收到了預期的回調函數
還包含了一張和以前一樣會保存在內存中的JPEG文件
不過我們會給你一些新的東西
一個Live Photo影片實際就是三秒的影片
在其正中間夾着一張靜態圖片
這意味着在你的拍攝請求發出的最多1.5秒內
你將會收到一個新的回調函數
而該回調函數有個古怪名字
叫didFinishRecordingLivePhotoMovieForEventualFileAtURL.
試試分析下語法吧
它的意思是文件還沒被寫好但是已經採好樣了
爲這部影片
換句話說若UI中有Live Photo標記
現在最好把它去掉了
讓人們知道不用再舉着相機不動了
現在最好把Live Photo標記去掉
很快地 影片文件就會被寫入完成
然後你會得到didFinishProcessingLivePhotoToMovieFileAtURL.
如果你製作Live Photos那這是必需的回調函數
現在你可以欣賞影片了
最後你豎個大拇指吧 都完成了
我們所有該做的都做完了
要注意的是拍攝Live Photo的JPEG部分
和拍攝靜態照片是一樣的
它作爲樣例緩存保存在內存中
利用didFinishProcessingPhotoSampleBuffer這個回調函數
如我們已見過的方式
如果你想把它寫到硬盤上那可是個瑣碎的活
我們在AVCapturePhotoOutput裏有一個類方法
用來把JPEG重寫成Data文件D是大寫的
這個方法很適合將JPEG文件寫入硬盤中
你可以在這裏的action看到
我先跳過第二個參數也就是previewPhotoSampleBuffer
我們一會兒再講它
在此我有個做Live Photo的建議
拍攝Live Photo是某一類拍攝的例子
也就是傳遞多種資源的拍攝
這有點像分單購物
比如你使用一個訂單購買電腦和使用另外一個訂單購買適配器
所以我們發現當傳遞多種資源時我們可以很便捷的
我們所寫的測試應用中進行測試
來實例化一個新的AVCapturePhotoDelegate對象
爲當前場景的每個照片請求
接下來在這個對象裏你可以彙集
所有你得到的東西
面向這個請求的樣本緩衝影片等等
然後有個方便的地方來處理這個對象
即thumbs up回調函數標誌着我們完成了
這是一個有用的小提示
在你的資源被寫入硬盤時
你還需要做幾個步驟
來獲取完全的動態圖片體驗
儘管視頻部分是標準的QuickTime影片
但那並不意味着它可被從頭到尾播放
像是用一個AVPlayer播放普通電影那樣
這裏有一個可以回放它的小竅門
它應該可以在照片的動態圖像時間緩入緩出
當你在這些資源間滑動的時候
它們會在photos應用裏有些許移動
爲獲得完全的Live Photo回放體驗
你需要使用photos和photos UI框架
還有與Live Photo相關的類
用來將你的RAW資源攝取到照片庫中
並恰當的播放它們 例如通過LivePhotoView
且iOS 10中新提供了
photos框架可以讓你就像編輯靜態照片來編輯Live Photo
這是個很棒的消息
我想做一下演示
在此我們有一些示例代碼令人尊敬的AVCam
得有五年沒有被用過了
但我們現在又重新裝扮它
以便它有特定的照片模式和影片模式
這是因爲只能在照片模式使用Live Photos
你要注意的是在頂部有標記告訴你
Live Photo模式是開還是關
你還可以切換攝像頭
我會試着做下那個很難的甜甜圈自拍
讓我們來看看我做的成不成功
你要做的就是開始在中間拍一下 然後結束
注意看當我在自拍的時候是有一個live標記出現的
而這就是在運用我之前跟你說的回調函數
好了 現在它被寫入了照片庫
然後 在中間的某處拍一下
不錯吧
但這還不是我們所能做的全部
在iOS 9中當你想編輯Live Photo時
你會丟失其中的影片部分
但是現在你既可以在photos應用中本地編輯
也可以使用應用內你所提供的代碼
比如這個叫做LivePhotoEditor的小例子
它在我所包含的照片編輯擴展應用中
我可以加上簡單的濾鏡或是裁剪這部影片
通過它來加上有色濾鏡非常的簡單
值得注意的是它並沒有丟失影片
我還可以播放它
然後 在中間的某處拍一下
棒極了你可以編輯Live Photos了
好的 現在說回AVCam
就如我所說的它有單獨的視頻和照片錄製模式
所以你能獲得最棒的照片體驗
你可以獲得最棒的影片製作體驗
而且它展示了恰當的live標記技術
就如我談到的
它也向你展示瞭如何將其寫入到資源庫
該示例代碼現在已經可見了
你會在我們會話的頁面上找到它
它甚至都被Swift化了
如果你想了解更多關於Live Photo編輯的內容
請在週四上午11點參加505會話
你會聽到其內容
我們還支持了一個叫做LivePhotoCaptureSuspension的特性
在這個小例子裏展示了它什麼時候會有用
假如說你有一個拍照的app
能發出煩人的霧角的聲音
就跟着我想象該例子的場景
它會拍照
發出煩人的霧角聲
現在假如說在時間軸上
你的用戶在此拍了張Live Photo
然後他們在這裏發出了煩人的霧角聲
接下來在聲音放完後又在此拍了另一張Live Photo
這就會產生一個問題
因爲兩張照片的影片部分與
煩人的霧角聲重疊了
你這下同時毀了兩部Live Photos影片
你會在一張照片裏聽到霧角聲的結尾
而在另一張聽到霧角聲的開頭
這可不太好 因此爲了應對這個問題
你可以將isLivePhotoCaptureSuspended設爲真
就在你要放煩人的霧角聲之前
這會使得任何在處理過程中的Live Photos
被強行裁減到該點
你可以同樣如此處理
把isLivePhotoCaptureSuspended設爲假
這會使結尾處有一個清楚的中斷
以便沒有任何早於該點的內容
會在你取消暫停的時候出現在你的影片中
一個不錯的小特性
讓我們談談設備支持
我們應該讓什麼設備支持LivePhoto拍攝呢
我們在所有近年的iOS設備上支持它
有個簡單的方法來記憶就是所有具有1200萬像素攝像頭
設備都會支持Live Photos
接下來進入我們今天的下一個重要特性介紹
那就是RAW相片拍攝
爲了解釋什麼是RAW圖像
我得先高度概述一下CMOS傳感器是如何工作的
CMOS傳感器會採集光中的光子通過二維陣列的傳感器
數組的上層叫做顏色過濾陣列
當光線透過上層時
它只允許一種顏色通過
紅 綠 藍 其一依照Bayer模式
綠色在這個小棋盤上是其他兩種顏色的兩倍多
因爲我們的眼睛對於綠色光有着兩倍的敏感度
相比於其他兩種顏色來說
底層被稱爲傳感器陣列
在RAW文件中實際存儲的是強度此強度即紅 綠 藍光的數量
穿過傳感器每個探測器
也需要被存儲在Bayer模式中
換句話說 就是紅 綠 藍光的排列
以便之後將其去馬賽克化
你還要存許多其他元數據
像是顏色信息 曝光信息
因此RAW轉換器工作很繁重
RAW會提取所有這些東西
並將其轉換爲RGB圖像
去馬賽克化只不過是冰山一角
在其被最終呈現在屏幕上之前有許多工作需要完成
如果做個類比的話
存儲RAW文件很大程度上就像是存儲用來烤蛋糕的原料
然後你走到哪都得帶着這些原料
這樣可太重了
也太糟糕了
每次你都要花些時間來烘烤它
如果你讓兩個不同的烘焙師
用相同的原料來烤蛋糕
你或許會得到口味有些許不同的蛋糕
但是使用RAW也有一些很大的好處
首先最重要的是你可以靈活掌握烘焙的時間
你是把原料都在身邊但你可以來年再做一個更好的蛋糕
這裏不會有像是BGRA或者420那樣的壓縮出現
你有更多的比特可供操作
有一個10比特的RAW傳感器包括在每像素14比特而不是8比特
另外你有很多的淨空間可供編輯
而且還給予你創作空間來做出不同的決定
其實你就是把烘焙時間往後拖
那麼JPEG又是什麼呢
RAW圖像提供了很多優勢
但它們不是最終的存在形式
重要的是你要清楚你選擇RAW時是要有所取捨的
JPEG仍然是一個有吸引力的選項
JPEG就像是專爲你烘焙的Apple蛋糕
這是個不錯的蛋糕
它包含着Apple的所有善意
快得多的渲染速度
你就不必再帶着這麼多原料了
你還會獲得像是防抖那樣的好東西
就如我之前提到的我們使用多張圖片融合來進行防抖
你用一單張RAW照片是得不到的
不管它質量多好也不行因爲我們是要拍
我覺得就有點像是多層的蛋糕
所以你用單張的圖片是做不到的
而且你也獲得了更小的文件尺寸
因此所有這些東西使得JPEG變成非常有吸引力的替代方案
你得決定你想要用哪一個
纔對你的應用來說更好
我們用四個字符的編碼來識別RAW格式
如我們在Core Video框架中識別普通像素格式那樣
在CVPixelBuffer.h中加入了四個新的常量
用來描述四種不同的Bayer樣式
你會在相機應用中遇到的
它們被列在這
它們基本上是描述了
紅 綠 藍光在棋盤上的順序
你怎麼用AVCapturePhotoOutput來拍攝RAW呢
其實挺簡單的
RAW僅在使用相片格式時才被支持
也就是預設的照片跟Live Photo一樣
而且它只支持後置攝像頭
我們支持RAW的包圍曝光所以你可以拍攝包圍曝光
例如 給三張RAW照片
爲了請求一個RAW拍攝
你要創建一個AVCapturePhotoSettings對象
但是神奇吧這裏有個不同的結構體
該結構體接收rawPixelFormat
那你怎麼決定應該讓它生成哪種RAW格式呢
你可以問下PhotoOutput
它會告訴你我有RAW相片像素格式
你可以從中選擇一個
你聲明的RAW格式必須要被硬件所支持
還有一個重要的事是在這些RAW設置當中
SIS是沒有意義的因爲這不是一個多圖片融合的場景
因此autoStillImageStabilizationEnabled
需要被設爲no否則會拋出異常
highResolutionPhotoEnabled也是
毫無意義的因爲你只是要獲得RAW的功能
所以它也要被設爲false
有一個關於RAW照片的單獨委託回調函數
叫做didFinishProcessingRAWPhotoSampleBuffer
你非常才思敏捷的話
你就會注意到它有着完全相同的參數
就和你之前獲得常規照片時的回調函數一樣
didFinishProcessingRAWPhotoSampleBuffer這個回調函數
現在你可能想問
我們爲何還這麼麻煩給RAW樣本緩衝弄一個新的委託回調函數呢
既然它和另一個有着完全相同的參數
其實有一個很好的理由
這個理由就是
爲了支持RAW plus processed圖片
我們支持該種照片就像DSLR相機 無反光板相機那樣
這是種能讓你同時得到RAW和JPEG的工作流
即processed圖片的意思
能同時拍攝RAW和JPEG可是相當專業的特性
你能獲得RAW plus processed圖片
它不是必須得是JPEG它也能是BGRA 420
processed圖像被生成到另一個回調函數
叫做didFinishProcessingPhotoSampleBuffer
RAW被生成到名字當中帶有RAW的那個回調函數
RAW plus processed brackets也被支持
看看你是不是能想明白
其實就是我要做一個包圍曝光
同時我請求RAW plus JPEG
所以我做了三次包圍曝光
我會得到三張RAW和三張JPEG圖片
但是其並不支持RAW plus靜態照片防抖
爲了拍攝RAW plus JPEG
你還得需要另一個叫AVCapturePhotoSettings的結構體
在這個結構體中你要聲明RAW像素格式
還有你想要的processed格式
在此我選擇了JPEG和RAW作爲輸出格式
當你選擇JPEGPlusRAW時HighResolutionPhotoEnabled
是有用的
因爲它現在被應用到JPEG上
讓我們討論下如何存儲RAW緩衝
如果你在內存層面跟它們打交道的話那它們就不那麼有用了
所以與其介紹一個Apple專利的RAW文件格式
就像許多其他相機供應商做的那樣
不如選使用Adobe的數字式負格式來存儲
DNG是一個標準化的方式來儲存比特和元數據
它並不是指一種文件格式
回到我們的烤蛋糕類比
DNG就像是存原料的盒子
還是取決於個體的RAW轉換器
來決定怎麼解釋那些原料
因此由第三方應用所打開的DNG可能看起來不太一樣
與另一個應用打開的DNG相比
所以存儲DNG是相當瑣碎麻煩的
你要調用一個叫做dngPhotoDataRepresentation的類函數
把你從委託回調函數中獲得的RAW緩衝傳出去
這會在內存中生成一個可被寫入文件的Data
並且這個API會寫入很多的壓縮DNG文件
來保存空間
這裏該有個演示了
對於RAW拍攝
我們更新了另一部分的令人尊敬的代碼叫做AVCamManual
我們是2014年發佈的
在我們展示手動控制API時
它讓你選擇對焦 曝光 白平衡
你可以手動或自動控制這些功能
在左邊的HUD裏有個新東西
可以讓你選擇開或者關RAW
你可以選擇在該應用裏拍攝RAW照片
讓我們看看曝光吧
我看看能不能故意過曝一點
然後我再拍張照
現在我要退出這個應用
我要打開一個叫RAWExpose的應用
這個應用不是AV Foundation團隊寫的
而是Core Image團隊寫的
他們很有風度的把它借給我來做演示
我們來看下剛剛拍的照片
這是張RAW照片
它會讀取DNG文件
我們可以做到用JPEG永遠都做不到的事
像是我們可以恢復EV值
還能調整色溫和色調
所有這些都是在後期完成的而且完全可逆
我也可以看看有或沒有減少噪點看着是什麼樣的
這就是編輯RAW的新Core image API的部分特性
我們再回到幻燈片中
AVCamManual的示例代碼現在可見了
你可以找得到
它和這節課的幻燈片是有關聯的
如果你想學到更多關於RAW編輯的內容
你可以去我剛纔提過的同個會話505會話
他們會同時談到這兩點
第二個部分是通過Core Image來處理RAW
這是個不錯的部分
RAW照片拍攝都被什麼設備支持呢
巧合的是
和我們Live Photos支持的設備一樣
所有具有1200萬像素攝像頭的設備都支持RAW照片拍攝
我們的下一個話題是
拍攝預覽圖像 也就是縮略圖
攝影app通常會拍照
然後想快速顯示預覽結果
像是Apple Zone相機應用
當照片播放時注意看下左底角
你一按下快門鍵
幾乎同時就有一張照片預覽出現在左底角
這會令你的用戶感到欣慰
知道他們拍的照片沒問題
這會給他們即時反饋
有許多的圖像處理算法
像是Core Images CIRectangleDetector或是CIQRCodeDetector
能很好兼容小圖像或是未壓縮的小圖像
它們不需要整張1200萬像素的JPEG來找到人的臉
不幸的是 這裏有個繼承阻抗的不匹配
你請求一張高質量的JPEG圖片
因爲你想要將其保存在硬盤上
那是你想要留下來的
但是你也想要很快在屏幕上顯示一個預覽圖
所以如果你要自己實現的話你要解壓縮JPEG
你要縮減它的大小
並最終顯示出來
這些都需要費時佔空間還增加了複雜度
最好是能同時得到供保存的高質量JPEG圖片
以及相機能提供一個小版本的照片
直接從相機獲取而不是從JPEG解壓縮而來
然後你就能省略那些步驟
直接顯示預覽圖了
我們在AVCapturePhotoOutput中就提供了這種工作流
這個委託
我強烈建議用啊
這個委託回調函數能生成一個縮略圖
給processed或者RAW照片
預覽圖是非壓縮的
因此你可選擇它是420fv還是BGRA格式
如果你知道想要的尺寸
你可以聲明你想要的具體大小
如果你不確定對於當前的平臺多大的預覽圖合適的話
PhotoOutput可以爲你選擇一個合適的默認尺寸
這裏有些如何請求預覽圖的示例代碼
當以常規方式創建了一個相片設置實例後
你可以選擇previewPixelType
再說明一下相片設置本身就會告訴你哪些格式是可用的
並且它們都是排好序的因此最優選擇會排在第一位
在此我從數組中獲取第一個元素
我所說的最優是指
需要從本地相機請求最少轉換的
你利用該格式類型key來創建CVPixelBuffer屬性字典
第一部分是必需的
如果你想獲得預覽圖
那你至少你得聲明你想獲得什麼格式的
你還可以選擇性的聲明寬度和高度
如果你想要定製尺寸的話
你不需要知道明確的寬高比
關於你將獲得的圖片
我在這設成是160乘160
我不是想搞一個盒子出來
我只是給寬和高設一個最大值
AVCapturePhotoOutput會進行改變大小的工作
爲預覽圖以便它能以預設的寬高比裝進盒中
獲取預覽圖也是非常直觀的
我們在此請求一個JPEG照片還有一個160乘160的預覽圖
當我們獲得第一個回調函數說明已經接到命令時
你會獲得一個willBeginCaptureForResolvedSettings
和一個ResolvedPhotoSettings對象如果你注意到的話
預覽圖的大小不是160乘160
而是160乘120的
因爲它已經因寬高比而改變
這個尺寸對於1200萬像素的照片是最合適的
當didFinishProcessingPhotoSampleBuffer回調函數最後到來時
你會得到一個 而不是兩張照片
全尺寸的JPEG文件是第一個參數
previewPhotoSampleBuffer是第二個
如果你一直跟着我的思路
並在你的腦中思考
如果你要拍一個RAW照片 加上包圍曝光
加上JPEG
加上預覽圖
那麼你會得到mRAWsmJPEGs和mpreview照片
另一個預覽圖的好的應用是
作爲嵌入的縮略圖
在你的高質量JPEG或DNG文件中
在這段代碼示例中 我會用previewPhotoSampleBuffer這個參數
此參數在didFinishProcessingRAWPhotoSampleBuffer回調函數中
作爲放到DNG文件的嵌入式縮略圖
當我調用PhotoOutput的dngPhotoDataRepresentation時
我會將其作爲第二個參數傳遞
你一直要這麼做
嵌入一個縮略圖是個不錯的主意
因爲你不知道它會從哪被觀看
有些應用能觀看DNG bitsRAW bits 有些則不能
但是如果你用到嵌入式縮略圖的話誰都能看到點什麼
你絕對想這麼做若你添加一DNG文件
到照片庫以便獲得更好的快速預覽效果的話
預覽圖生成是被支持的
到處都是
今天的最後一個主題是 寬色域
如你所料 這是個很廣泛的主題
你們肯定聽說了那漂亮的真彩顯示
在我們的9.7寸iPad Pro上
它是寬色域顯示的和4K 5K iMax處於同一水平
它可以顯示出令人吃驚栩栩如生的紅色和黃色
以及非常深度飽和的青色和綠色
爲了利用到顯示的寬色域
我們在iOS9.3中首次介紹了顏色管理
我不知道你是否注意到了
我們在9.7寸iPad Pro上使用了顏色管理
既然顯示效果這麼棒了
用同樣的寬色域來拍照才說得過去
以便增強我們的觀看體驗
另外還能保證從現在起若干年後你再看這些照片
你會得到更多的顏色信息
從iOS10開始
9.7寸iPad Pro上拍照會自動變成寬色域了
讓我簡單介紹下寬色域是什麼意思有關寬色域的術語
從顏色空間的概念開始
一個顏色空間描述的是
一個顏色的環境
顏色被呈現 排列 比較 或計算
在計算機顯示中應用最普遍的顏色空間就是sRGB
s代表標準 就是標準RGB
它是基於一個國際規範ITU709
它有大概2.2的gamma值
6500開爾文的白度
sRGB對顯示很多常見顏色都很出色
像是面部 天空 草地等等
但也有很多顏色sRGB不能很好生成
例如 超過百分之40的職業足球隊服
超出了sRGB的色域
誰知道呢
9.7寸iPad Pro支持寬色域並使用了一個新的顏色空間
我們將其稱爲Display P3
它與SMPTE標準DCI P3類似
那是用在數字影院投影儀上的顏色空間
其色原與DCI P3是相同的
但是其gamma值和白度不同
它的gamma值與白度和sRGB是相同的
我們爲什麼會這麼做呢
是因爲DCI P3的白度是向綠色邊傾斜的
選擇這麼做是爲了給昏暗的家庭影院場景提供最大的亮度
我們發現把白度設爲6500的話
會得到與sRGB標準會兼容的超集
在這張幻燈片上你會發現sRGB的灰色
然後你會發現貼附的Display P3
它儘可能寬的覆蓋了sRGB的超集
這就是爲何我們選擇它
如果使用OS 10上的顏色同步工具的話
你就能看到Display P3的虛擬呈現
我截了一些圖來展示給你們
你們可以在三維將其與sRGB進行比較
在此我選擇Display P3
點擊“作比較”
這是個不錯的技術
然後我選擇sRGB
接下來我會看到其中一個貼附在另一個上
你會從裏面看到sRGB從外面看到Display P3
以此你能感受到Display P3相比sRGB來說有多寬
並且能呈現的顏色範圍從視覺上看也更大
那麼現在讓我們看看所有的細節
用來獲得Display P3內容
爲了獲得高保真度所捕捉內容的顏色空間
需要在素材階段就確定下來
這可不能向下在sRGB中完成了
然後再往上向寬色域轉換它必須在開始時就被設定好足夠的寬度
如你所料 顏色空間其實就是AVCaptureDevice
一個屬性
因此我們會花些時間來討論下AVCaptureDevice
我們還會討論下AVCaptureSession
該會話就是自動寬色域選擇被決定的地方
爲整個會話配置
AVCaptureDevice就是AV Foundation如何呈現攝像頭或是麥克風
每個AVCaptureDevice都有一個格式屬性
Formats是AVCaptureDevice格式的一個數組
它們本身就是對象
同時它們還會代表設備捕捉內容的格式
如你所見 它們是成對出現的
對於每個分辨率和幀率
都有一個402v版本和402f版本
v是代表視頻範圍 從16到235
f是代表全範圍 從0到255
iOS10中新出現的是
AVCaptureDevice格式有了一個新支持的顏色空間屬性
它是由數字組成的數組
0是代表sRGB而1是代表P3 D65
我們將其代指爲Display P3
但是在API中它指的是P3 D65
d代表顯示 65代表開爾文的白度
在9.7寸iPad Pro上420v格式只支持sRGB
但是全範圍420f格式支持sRGB
或是Display P3
該設備有個可設的格式屬性
這不是新的東西
列表中的其中一個格式一直是activeFormat
如你所見我將激活的格式套上了一個黃色的格子
它正好是1200萬像素30FPS的版本
如果那個activeFormat也就是f格式
正好支持Display P3的話
那麼你可以設置一個叫做activeColorSpace的新屬性
如果activeFormat支持它
你就能從你的素材中獲得寬色域的流
到session的所有輸出中
這段說起來有點冗長
但我希望你記住的是
希望這些東西你一個也用不上
大多數客戶從來不需要直接設置activeColorSpace
那是因爲AVCaptureSession會試着爲你自動完成
在iOS 10中AVCaptureSession有一個長的新屬性
叫做automaticallyConfiguresCaptureDeviceForWideColor
它什麼時候會爲你選擇寬色域呢
在iOS 10中寬色域僅在攝影中使用
讓我再說一遍
在iOS 10中 寬色域僅在攝影中使用而不是攝像
我後面馬上會解釋爲什麼
會話會自動選擇
是否爲整個會話配置寬色域
它會代表你將你設備的activeColorSpace設爲
P3 這取決於你的設置
你要在你的會話中加入一個PhotoOutput
如果你沒有PhotoOutput你就不能拍照了
那麼你也不需寬色域
這裏有些警示
如果你開始往你的會話加入其它輸出
或許你想要做什麼就不那麼明顯了
如果你加上了一個AVCaptureVideoPreviewLayer
會話還是會給你自動挑選Display P3
因爲你就是在拍照同時做了預覽
如果你有一個MovieFileOutput和一個PhotoOutput 那就模糊了
你可能更關心影片
所以它就不會爲你自動挑選Display P3了
VideoDataOutput是個特殊的例子我們通過一個回調函數將緩衝送達給你
在此session只會挑選Display P3
如果你在用預設照片的話
它很確信如果你正在用VideoDataOutput
就意味着你會利用這些顯示緩衝來攝影
如果你非常想要的話你可以強制拍照設備
來使用寬色域下面是怎麼實現的
首先你要告訴會話不要自動幫我實現了
不要妨礙我
然後你要進入設備
自己將activeFormat設爲支持寬色域的格式
然後你要將activeColorSpace設爲P3
你做完了之後
寬色域buffer會流到所有接受視頻數據的輸出
包括VideoDataOutputMovieFileOutput
甚至是已經不推薦使用的AVCaptureStillImageOutput
當你強制將設備的activeColorSpace設爲display P3後
我強烈建議你不要這麼做
除非你明確知道自己在幹什麼
因爲寬色域是給照片服務的
我們對於寬色域的照片支持有着良好的生態系統
但是對於視頻就不怎麼樣了
對於Display P3內容的主要擔憂
就在於用戶必須是寬色域敏感的
否則你的內容將會以sRGB渲染
顏色看起來就會不對頭
它們被渲染得很糟糕
大多數視頻播放服務都不是色敏感的
所以如果你保存一個寬Display P3影片的話
然後你試圖用某個服務來播放它
它很有可能會把顏色渲染錯誤
如果你選擇這麼做
確保你的VideoDataOutput是色敏感的
它要傳播顏色標籤
它要是色敏感的
如果你選擇用MovieFileOutput來拍攝Display P3影片
注意它們可能在其他平臺上是錯誤渲染的
這裏
我們確實允許這麼做 因爲我們意識到
其對於某些專業工作流是很重要的
也要能夠製作寬色域影片
所以拋開警告不管
我可以告訴你我們對於照片有個很好的解決方案
針對共享寬色域
我們應該注意到JPEG寬色域是使用Display P3屬性的
並且這些圖片的用戶也必須是色敏感的
好消息是通常照片服務
目前是色敏感的
iCloud照片庫就是其中之一
它能智能的將你的照片轉換成sRGB格式
如果你的設備不支持寬色域的話
但仍會在cloud上存儲寬色域的照片
我們的業界目前也在轉變
有些照片服務雖然不支持寬色域
但它們中絕大多數至少能將其智能渲染成sRGB格式
對於混合共享的場景
像是通過信息或郵件來發送照片
你不知它被髮送到哪
它可能會被髮到多個設備
其中有些可能支持寬色域
有些則不支持
對於這種情況我們要加上一個新的服務
叫做Apple Wide Color Sharing Profile
你的內容將以一種方式被處理
我們會生成一個內容爲準則表格形式的ICC資料
對應那張JPEG照片
其好處就在於 如果它被某人渲染
而這個人不瞭解寬色域
那麼在sRGB色域內的部分肯定能被正確渲染
額外的信息會被放到一個額外的ICC資料中
它們可以將寬色域信息恢復
到最小的質量損失程度
你可以學到更多有關如何共享寬色域內容
在505和702會話中
它們都是在週四
第一個我已經提到三遍了
關於寬色域的那個也是個不錯的會話
在9.7寸iPad Pro上
AVCapturePhotoOutput廣泛支持寬色域
它在420f BGRA和JPEG中都支持不僅僅是420v
如果你的會話配置了Display P3
但是然後你說你想要420v的照片
它會被轉換爲sRGB格式
Live Photos支持寬色域
靜態和影片部分都支持
這是特殊的影片這是Apple生態系統的一部分
因此那些都會是支持寬色域的
包圍曝光拍攝也是支持寬色域的
有趣的是
我一直在說iPad Pro
我們支持RAW格式
RAW拍攝本身就是寬色域的
因爲它有所有那些額外的比特信息
我們將其保存在傳感器基元中
並且它也有足夠的顏色信息來被渲染成寬色域或是sRGB
再說一下 如果你隨身帶着原料的話
你能隨時決定你是想渲染成寬色域還是sRGB
因此拍攝RAW照片並後期渲染
可在許多iOS設備上生成寬色域內容而不僅是在iPad Pro上
你可以學會更多有關寬色域的知識
不光是共享還有別的
最好的學習寬色域的會話是在週四下午
使用AVCapturePhotoOutput來改善可用性
我們今天談論了四個主要特性
我們討論了在你的應用中拍攝Live Photos
RAW RAW + JPEG DNG
用來更快渲染的小預覽圖
還有寬色域照片
一個小時真的不夠啊
想要涵蓋要講的內容太短了
因此我們對於這個會話做了一個補充
它已經錄製完了
現在已經放到網上了
它是一個包含語音的幻燈片我們把它叫做Chalk Talk
它爲你講述了我們沒時間講的深入的主題
AVCapturePhotoOutput中的場景監控
資源準備和回收
然後是一個不相關的話題
iOS 10中相機隱私政策的變動
請看下那個視頻它大概20分鐘長
有着更多的信息
501結尾你要記住
你會發現那個視頻有七段示例代碼
還有AVCapturePhotoOutput的新文檔
文檔編寫人員真的很努力工作他們寫的文檔真的不錯
再次提醒一下這是相關的會話
這個是Chalk Talk
關於AVCapturePhotoOutput的延伸知識
你什麼時候想看都行
好了 好好享受下之後的演說感謝你們的到來