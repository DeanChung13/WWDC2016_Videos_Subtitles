00:00:20.087 --> 00:00:22.956
使用Core Image編輯
Live Photo和RAW處理

00:00:29.396 --> 00:00:30.831
非常感謝各位 早上好

00:00:30.898 --> 00:00:34.168
我叫David Hayward
今天我要講的是

00:00:34.234 --> 00:00:37.671
關於使用Core Image編輯
Live Photos和Raw圖片

00:00:37.738 --> 00:00:40.307
我們今天要講很多不錯的東西

00:00:40.741 --> 00:00:42.910
首先我簡單介紹一下
Core Image

00:00:42.976 --> 00:00:44.878
如果你對它一無所知的話

00:00:45.145 --> 00:00:48.015
接下來我們會談下
我們今早的三個主要話題

00:00:48.081 --> 00:00:50.918
第一 在iOS上調整RAW圖片

00:00:51.485 --> 00:00:53.921
第二 編輯Live Photos

00:00:54.154 --> 00:00:56.557
第三 如何擴展Core Image

00:00:56.623 --> 00:00:59.426
通過全新的方式 即利用
CIImageProcessor節點

00:01:01.195 --> 00:01:03.664
首先 是對於Core Image的
簡單介紹

00:01:04.697 --> 00:01:07.701
選擇Core Image的原因是
它提供了一個非常簡單

00:01:07.768 --> 00:01:10.871
高性能的API來將濾鏡應用到圖片上

00:01:11.371 --> 00:01:14.041
基本的想法就是你開始有一張圖片

00:01:14.107 --> 00:01:16.844
其來自於JPEG或某個文件或內存
你可以選擇

00:01:16.910 --> 00:01:19.646
對其應用一個濾鏡 結果就是輸出圖片

00:01:20.013 --> 00:01:22.349
在你的代碼中實現是非常非常簡單的

00:01:22.716 --> 00:01:26.553
你只需要調取你的圖片
調用applyingFilter

00:01:26.620 --> 00:01:28.188
並聲明濾鏡的名字

00:01:28.488 --> 00:01:31.058
以及其他適用於該濾鏡的參數

00:01:31.458 --> 00:01:32.359
這非常簡單

00:01:32.659 --> 00:01:34.728
當然了你可以完成更復雜的事情

00:01:34.795 --> 00:01:36.897
你可以將多個濾鏡鏈在一起使用...

00:01:37.297 --> 00:01:41.168
應用到序列或是圖片上
並獲得非常複雜的效果

00:01:42.269 --> 00:01:46.106
Core Image的一個非常棒
的特性就是它提供了自動顏色管理

00:01:46.373 --> 00:01:48.375
這對於現如今很重要

00:01:48.542 --> 00:01:50.477
我們現在有很多設備

00:01:50.677 --> 00:01:53.647
支持寬色域的輸入和輸出

00:01:54.114 --> 00:01:56.550
Core Image所做的就是
它會自動插入

00:01:56.617 --> 00:01:58.785
恰當的節點到渲染圖中去

00:01:58.986 --> 00:02:01.355
以便它與你的輸入圖像匹配

00:02:01.421 --> 00:02:03.123
到Core Image的工作域

00:02:03.190 --> 00:02:04.825
而到了要顯示的時候

00:02:04.892 --> 00:02:07.561
它會從工作域匹配到顯示域

00:02:08.562 --> 00:02:10.830
這是你應該特別注意的

00:02:10.898 --> 00:02:14.801
因爲寬色域圖片和寬色域顯示
現在都很常見了

00:02:15.636 --> 00:02:18.605
而很多做圖像處理的開源庫

00:02:19.106 --> 00:02:20.440
不會自動處理它

00:02:20.507 --> 00:02:23.143
這是Core Image很棒的特性
因爲它處理了所有這些

00:02:23.210 --> 00:02:24.878
讓你很容易的使用

00:02:27.114 --> 00:02:29.416
另一個要注意的是每個濾鏡

00:02:29.950 --> 00:02:32.119
實際上是附帶着一小段代碼的

00:02:32.186 --> 00:02:33.921
叫做kernel的小小子程序

00:02:34.621 --> 00:02:37.591
我們所有內置濾鏡
都有這些kernel

00:02:37.791 --> 00:02:41.595
一個不錯的特性是
如果你將一個序列的濾鏡鏈在一起

00:02:41.895 --> 00:02:44.264
Core Image會自動連接這些

00:02:44.331 --> 00:02:46.333
子程序成單個程序

00:02:46.700 --> 00:02:49.069
這麼做是爲了提高性能

00:02:49.136 --> 00:02:51.505
通過減少

00:02:51.572 --> 00:02:53.774
通過減少中間緩存的數量

00:02:56.677 --> 00:02:58.979
Core Image
有逾180個內置濾鏡

00:02:59.046 --> 00:03:01.748
它們在我們的所有平臺上都是一樣的

00:03:02.115 --> 00:03:05.219
不管是macOS tvOS
還是iOS

00:03:05.519 --> 00:03:08.155
我想談下今年我們新發布的一些濾鏡

00:03:08.488 --> 00:03:12.392
其中一個是用來生成色彩飽和度和梯度

00:03:12.860 --> 00:03:15.362
它會生成色彩和飽和度的梯度

00:03:15.596 --> 00:03:17.698
然後你可以聲明一個參數

00:03:17.998 --> 00:03:19.266
關於圖片的亮度

00:03:19.333 --> 00:03:21.835
也聲明瞭顏色輪內的色域

00:03:22.302 --> 00:03:26.273
如你所料
此濾鏡目前在用在macOS上

00:03:26.340 --> 00:03:28.775
作爲顏色選擇器的基礎

00:03:29.343 --> 00:03:32.880
目前可以識別幾個不同類型的顯示色域

00:03:35.249 --> 00:03:40.821
另一個新濾鏡是
CINinePartStretched and NinePartTiled

00:03:40.888 --> 00:03:43.423
你可能有一個小的資源

00:03:43.490 --> 00:03:44.958
像是這個畫框

00:03:45.025 --> 00:03:48.262
而你想要拉伸它使其適應一個特定尺寸

00:03:48.328 --> 00:03:49.863
這個濾鏡非常容易使用

00:03:49.930 --> 00:03:55.002
你需要提供一個輸入圖片和四個斷點

00:03:55.068 --> 00:03:56.570
水平的兩個 垂直的兩個

00:03:56.637 --> 00:03:59.306
一旦你聲明瞭這些點之後 你可以聲明

00:03:59.373 --> 00:04:00.908
你想讓其拉伸到多大的尺寸

00:04:01.375 --> 00:04:02.442
它非常容易用

00:04:05.546 --> 00:04:07.881
第三個新濾鏡很有意思

00:04:07.948 --> 00:04:11.652
開始時我們有個很小的輸入圖片

00:04:11.952 --> 00:04:13.754
在這裏有一個包含有顏色數據的圖片

00:04:13.820 --> 00:04:16.089
但它也可以包含參數數據

00:04:16.356 --> 00:04:19.560
假設你有一個小的顏色或者參數集合

00:04:19.826 --> 00:04:21.894
可能只有6乘7個像素

00:04:22.162 --> 00:04:25.299
你想要擴展到全尺寸的圖片上

00:04:26.233 --> 00:04:30.304
我們要做的是擴展顏色圖像
這個小的顏色圖像

00:04:30.838 --> 00:04:34.041
但是維護底圖圖形的邊

00:04:34.441 --> 00:04:37.578
如果你不維護底圖圖形
而只是拉伸

00:04:37.644 --> 00:04:40.647
小的圖片和全尺寸的圖像一邊大

00:04:40.714 --> 00:04:43.283
你只會得到一張混合顏色的圖片

00:04:43.350 --> 00:04:45.152
但利用這個濾鏡你可得到更多東西

00:04:45.219 --> 00:04:46.553
你可以得到

00:04:46.620 --> 00:04:49.623
維護邊和顏色的圖片

00:04:49.823 --> 00:04:53.060
這對於很多其他類型的算法來說
也是個有用的特性

00:04:53.126 --> 00:04:56.864
事實上
我們在新版本的照片應用裏就用到了它

00:04:56.930 --> 00:05:00.334
來提高調光滑條的表現

00:05:01.535 --> 00:05:04.137
我期待看到你在你的應用裏會怎麼用

00:05:04.638 --> 00:05:07.040
我們今年也做了一些新的性能控制

00:05:07.608 --> 00:05:10.410
今年還對Core Image性能
做了改善

00:05:10.677 --> 00:05:13.447
其中一個就是
我們默認打開了Metal功能

00:05:13.514 --> 00:05:16.950
所以如果你用了
任何一個我們內置的180個濾鏡

00:05:17.017 --> 00:05:18.552
或者你自定義的kernel

00:05:18.619 --> 00:05:23.123
所有的kernel都會被
快速轉換爲Metal的供你使用

00:05:23.190 --> 00:05:24.658
這是個不錯的方式來利用

00:05:24.725 --> 00:05:27.861
Metal的作用
而你幾乎不用做什麼

00:05:29.429 --> 00:05:32.533
我們還對一個重要的API
做了很大的改進

00:05:32.599 --> 00:05:35.169
從CIImage中
創造了UIImage

00:05:35.469 --> 00:05:38.438
相比原來它的性能提高很多

00:05:38.505 --> 00:05:43.777
因此你可用它高效地在UIImage
視圖中使一個圖片動畫化

00:05:45.812 --> 00:05:47.581
另一個新特性是

00:05:47.648 --> 00:05:50.284
Core Image現支持了一個
新Core Graphics特性

00:05:50.350 --> 00:05:52.920
就是Core Graphics
現支持半浮點數了

00:05:53.587 --> 00:05:56.890
讓我們談談像素格式
因爲這會引出一個很有意思的點

00:05:58.225 --> 00:06:02.930
我們對於傳統的
像素格式RGBA8都很熟悉

00:06:03.263 --> 00:06:09.102
它僅需要花費每像素4字節來存儲
擁有8比特的深度

00:06:09.169 --> 00:06:11.538
並且可以在0到1範圍內編碼

00:06:12.439 --> 00:06:16.543
然而 這個格式不利於呈現寬色域數據

00:06:16.743 --> 00:06:20.948
因爲它只有8比特
而且值被限定在0到1的範圍內

00:06:21.615 --> 00:06:25.252
過去的替代方案是
使用RGBAfloat

00:06:25.619 --> 00:06:28.755
它每像素有16字節 需要四倍的內存

00:06:28.956 --> 00:06:32.125
但會帶給你想要的深度和範圍

00:06:33.160 --> 00:06:35.362
另一個特性是它使用了浮點數

00:06:35.429 --> 00:06:38.398
也就是會分層 它是呈對數分佈的

00:06:38.465 --> 00:06:41.468
這很好地適應了人眼感應顏色的方式

00:06:43.270 --> 00:06:45.405
還有個Core Image
支持的新特性

00:06:45.472 --> 00:06:47.608
Core Graphics現也支持

00:06:47.674 --> 00:06:52.279
我將其成爲Goldilocks
像素格式 即RGBAh

00:06:52.479 --> 00:06:55.616
這會讓你在每像素8字節的情況下

00:06:55.682 --> 00:06:58.619
存儲10比特深度的數據

00:06:58.852 --> 00:07:03.223
允許的值區間是
負65000到正65000

00:07:03.524 --> 00:07:05.726
這些值是對數性量化的

00:07:05.792 --> 00:07:07.995
它對於存儲線性數據很好

00:07:08.061 --> 00:07:09.930
這些數據是不會被識別爲量子化的

00:07:10.531 --> 00:07:12.966
因此我高度推薦這個像素格式

00:07:13.367 --> 00:07:16.236
另一個我要提到的新格式是

00:07:16.336 --> 00:07:18.338
Core Video支持新像素格式

00:07:18.405 --> 00:07:23.744
它名字很長 叫做30RGBLE
PackedWideGamut

00:07:24.211 --> 00:07:26.980
它也支持10比特的深度

00:07:27.047 --> 00:07:31.752
但通過犧牲alpha信道
它只需要每像素4字節就能存儲

00:07:31.885 --> 00:07:34.454
它對於很多情況都很有用

00:07:34.688 --> 00:07:37.524
Core Image支持或是渲染自

00:07:37.591 --> 00:07:40.127
或者渲染到CV像素緩存
利用這個格式

00:07:42.863 --> 00:07:45.699
接下來我想談下一個主要的話題

00:07:45.766 --> 00:07:49.303
關於利用Core Image
調整RAW圖片

00:07:49.369 --> 00:07:51.605
我很高興今天能講下這個

00:07:51.672 --> 00:07:53.240
我們致力於此已經很長時間了

00:07:53.307 --> 00:07:55.709
它包含了我們大量的辛苦工作
我很興奮

00:07:55.776 --> 00:07:58.011
我們將其引入了iOS中

00:07:58.979 --> 00:08:01.882
我要先說下什麼是RAW文件

00:08:02.115 --> 00:08:04.484
如何使用
CIRAWFilter API

00:08:04.551 --> 00:08:06.987
一些關於支持寬色域輸出的說明

00:08:07.054 --> 00:08:09.423
還有關於管理內存的技巧

00:08:11.391 --> 00:08:13.093
那麼首先 什麼是RAW文件呢

00:08:13.260 --> 00:08:17.831
大部分相機的運作方式都包括
兩個關鍵的部件

00:08:18.065 --> 00:08:20.667
顏色過濾陣列和傳感器陣列

00:08:20.801 --> 00:08:24.104
其工作原理就是光線從場景內進入

00:08:24.171 --> 00:08:27.975
通過顏色過濾陣列
並被傳感器陣列所計數

00:08:28.575 --> 00:08:31.879
當然了
該數據實際上是一個更大圖像的一部分

00:08:32.179 --> 00:08:34.948
但是爲了將其轉換爲可用的圖像

00:08:35.414 --> 00:08:38.085
需要進行大量的圖像處理

00:08:38.150 --> 00:08:40.687
以便爲用戶生成一張不錯的圖片

00:08:41.554 --> 00:08:45.192
我想談一下這個 其主要思路就是

00:08:45.259 --> 00:08:49.530
如果你獲取由傳感器所捕捉的數據
那就是RAW文件

00:08:49.596 --> 00:08:51.398
如果你獲取的數據是捕獲於

00:08:51.465 --> 00:08:54.668
圖像處理之後
那就是一張TIFF或者JPEG圖片

00:08:55.769 --> 00:08:58.705
RAW存儲着未處理的場景數據

00:08:58.772 --> 00:09:02.509
而JPEG文件存儲處理過的輸出圖像

00:09:03.510 --> 00:09:04.711
換句話說

00:09:04.778 --> 00:09:08.348
RAW存儲的是
你要生成一張圖片的原料

00:09:08.649 --> 00:09:12.386
而JPEG存儲的是原料的結果

00:09:12.452 --> 00:09:14.788
將這些原料烤成漂亮的蛋糕後

00:09:17.558 --> 00:09:19.259
爲了從原料

00:09:19.326 --> 00:09:22.196
做成最終的蛋糕是需要很多階段的

00:09:22.262 --> 00:09:24.264
讓我大概說下其中的幾個

00:09:24.731 --> 00:09:27.000
首先 我們要提取文件中的元數據

00:09:27.067 --> 00:09:30.237
其會告訴我們要花多久來做蛋糕
接着剛纔的比喻來說

00:09:31.071 --> 00:09:33.740
我們還需要將從傳感器中
獲得的RAW數據解碼

00:09:34.474 --> 00:09:39.479
我們需要將圖像去馬賽克
以重構整張有色圖

00:09:39.546 --> 00:09:41.315
從所獲取的數據中

00:09:41.381 --> 00:09:44.284
每個像素位置只有一個RGB值

00:09:45.152 --> 00:09:48.789
我們需要應用幾何畸變來進行鏡頭矯正

00:09:49.890 --> 00:09:53.794
減少噪點 也是處理中的一個重要點

00:09:54.361 --> 00:09:57.264
我們需要從場景數據中做顏色匹配

00:09:57.331 --> 00:10:01.001
這些由傳感器捕獲的數據
會傳到輸出數據用以顯示圖像

00:10:02.169 --> 00:10:04.371
接下來我們要做的事就是諸如調整曝光

00:10:04.438 --> 00:10:05.672
色溫 還有色調

00:10:05.739 --> 00:10:08.675
最後 非常重要的是 增強銳度

00:10:08.742 --> 00:10:11.912
對比度和飽和度來使圖片看起來更漂亮

00:10:12.045 --> 00:10:13.347
這麼多階段可真不少

00:10:15.382 --> 00:10:16.884
RAW的優點有哪些呢？

00:10:16.950 --> 00:10:18.519
最大的優點就是

00:10:18.585 --> 00:10:21.622
RAW文件包含了線性的深度像素數據

00:10:21.688 --> 00:10:24.224
這使得可編輯性很好

00:10:25.859 --> 00:10:29.596
RAW的另一個特性是
它的圖像處理每年都變得更好

00:10:29.663 --> 00:10:33.534
因此也就保證了利用RAW
你昨天所拍的照片

00:10:33.600 --> 00:10:37.271
可能在你來年處理它時效果更好

00:10:39.406 --> 00:10:42.042
RAW文件還有色彩空間的不可知性

00:10:42.109 --> 00:10:44.578
它們可以被渲染到任何目標的輸出空間

00:10:44.645 --> 00:10:48.282
這對於我們如今諸多的顯示標準來說
是個不錯的特性

00:10:49.583 --> 00:10:51.985
用戶可以選擇使用不同的軟件

00:10:52.052 --> 00:10:53.620
來解釋RAW文件

00:10:53.687 --> 00:10:56.056
就像是把相同原料交給兩個不同的廚師

00:10:56.123 --> 00:10:57.491
你會得到兩個不同的結果

00:10:57.558 --> 00:11:00.327
有些用戶可能更喜歡另一個廚師

00:11:02.596 --> 00:11:05.465
JPEG也是有很多優點的

00:11:06.200 --> 00:11:08.435
首先就是由於已經處理過了

00:11:08.502 --> 00:11:10.204
它們加載和顯示非常快

00:11:11.071 --> 00:11:15.108
它們包含針對特定輸出的顏色和調整

00:11:15.175 --> 00:11:16.310
這可能很有用

00:11:17.277 --> 00:11:19.346
它也會給你可預見的結果

00:11:20.414 --> 00:11:24.051
還有值得一提的是如今的相機表現出色

00:11:24.117 --> 00:11:25.819
對於拍攝JPEG照片來說

00:11:25.886 --> 00:11:29.022
並且我們的iOS相機
尤其是一個好例子

00:11:31.925 --> 00:11:34.528
說到RAW 讓我再說一點

00:11:34.595 --> 00:11:36.630
關於我們的平臺是如何支持RAW的吧

00:11:37.431 --> 00:11:41.735
好消息是我們現在在iOS上
完全支持了RAW

00:11:41.802 --> 00:11:44.638
即將到來的tvOS推送也是

00:11:45.772 --> 00:11:48.509
這意味着我們支持超過400個
獨特的相機型號

00:11:48.575 --> 00:11:50.344
來自於16個不同的廠商

00:11:50.410 --> 00:11:53.547
我們也支持被捕獲的DNG文件

00:11:53.614 --> 00:11:55.382
用我們自己的iOS設備

00:11:55.782 --> 00:12:00.854
iOS設備包括
iPhone 6S、6S Plus

00:12:00.921 --> 00:12:04.157
SE 還有iPad Pro 9.7

00:12:05.325 --> 00:12:06.593
這真讓人興奮

00:12:06.894 --> 00:12:09.162
我推薦如果你們還沒有看
回去看看

00:12:09.229 --> 00:12:11.331
iOS攝影進階

00:12:11.398 --> 00:12:13.800
那個演講是關於

00:12:13.867 --> 00:12:15.802
可在這些設備上捕捉RAW照片的API

00:12:17.871 --> 00:12:21.775
另一個很棒的東西是我們現在擁有了
同樣同性能的RAW管道

00:12:22.309 --> 00:12:27.114
iOS平臺 如我們在macOS
完成的一樣 可算是一個成就了

00:12:27.181 --> 00:12:29.750
我那天計算了一下我們的管道

00:12:29.816 --> 00:12:34.354
它包含了超過4500行的
CIKernel代碼

00:12:34.555 --> 00:12:36.390
而且運行的很高效

00:12:36.456 --> 00:12:39.526
它是我們能力的確切證明 也是

00:12:39.593 --> 00:12:43.330
Core Image可以處理
複雜渲染場景的證明

00:12:45.632 --> 00:12:49.603
我們iOS上的管道需要
A8或以上的設備

00:12:49.670 --> 00:12:51.972
你可以通過你的應用來測試

00:12:52.039 --> 00:12:54.474
通過檢查iOS
GPU Family 2

00:12:57.711 --> 00:12:59.580
另一個關於平臺支持的說明是

00:12:59.646 --> 00:13:02.983
我們一直在增加對新相機的支持
從它一上市就開始

00:13:03.050 --> 00:13:06.653
而且也在改進對已支持相機的支持質量

00:13:07.187 --> 00:13:10.157
新相機被加到未來的軟件更新中

00:13:10.390 --> 00:13:13.360
我們也在週期性的改進
我們的管道

00:13:13.427 --> 00:13:16.830
我們的管道有不同的版本
你既可以用我們的最新版本

00:13:16.897 --> 00:13:19.333
也可以倒回使用你想要的舊版本

00:13:21.902 --> 00:13:24.471
爲了避免後面的麻煩 我想做個演示

00:13:24.538 --> 00:13:25.806
它看起來是怎麼樣的

00:13:32.045 --> 00:13:35.549
我這裏有些示例代碼
有一個早前版本的

00:13:35.616 --> 00:13:38.352
可供下載 它叫RAWExposed

00:13:38.418 --> 00:13:41.455
它是個應用 同時最新版本也是

00:13:41.522 --> 00:13:42.856
相片編輯擴展

00:13:43.423 --> 00:13:46.894
我們可以進入Photos程序
並實際運用這段示例代碼

00:13:47.394 --> 00:13:50.397
我們有三張24兆像素的RAW照片

00:13:50.464 --> 00:13:53.033
是用Canon 5D
Mark III拍的

00:13:53.100 --> 00:13:56.470
你可以看出來這張照片有點過曝了

00:13:56.670 --> 00:14:00.073
RAW的一個很棒的特性就是
你可以修補這樣的照片

00:14:00.340 --> 00:14:02.643
我們來這裏 點“編輯” 然後...

00:14:02.976 --> 00:14:07.414
用我們的照片編輯擴展程序
來編輯這個RAW文件

00:14:07.881 --> 00:14:12.052
那麼現在既然我們是在將其當做
RAW文件來編輯 就可以做些調整

00:14:12.953 --> 00:14:14.087
［聽不清］

00:14:15.489 --> 00:14:17.491
我們可以上下調整曝光量

00:14:18.559 --> 00:14:21.762
我們可以在這24兆像素上瀏覽

00:14:22.095 --> 00:14:23.730
而且得到了不錯的結果

00:14:24.531 --> 00:14:28.268
我現在對這張照片很滿意
看上去比之前強多了

00:14:28.335 --> 00:14:30.204
我會點擊“完成” 之後它會生成

00:14:30.637 --> 00:14:34.608
一張新的全分辨率照片 它會顯示在

00:14:34.675 --> 00:14:36.043
Photos應用中

00:14:43.684 --> 00:14:46.887
另一個關於RAW文件不錯的特性是
你可以做出不錯的調整

00:14:46.954 --> 00:14:49.256
對於一張照片的白平衡

00:14:49.323 --> 00:14:52.826
這張照片不錯 但是有點不正
而且白平衡也是關閉的

00:14:53.327 --> 00:14:54.761
我要進到這裏

00:14:54.828 --> 00:14:57.130
稍微調整下白平衡

00:14:58.198 --> 00:15:01.902
以此得到一張好看得多的照片
我們可以放大來看看成果

00:15:02.269 --> 00:15:04.505
我們可以實時地調整這些結果

00:15:06.473 --> 00:15:07.908
然後點擊“完成”以保存

00:15:10.110 --> 00:15:11.311
另一張我想展示的照片

00:15:11.378 --> 00:15:13.680
是張噪點很多的

00:15:13.747 --> 00:15:17.084
我想向你們展示一下
我們的噪點減少算法

00:15:17.150 --> 00:15:21.722
我們的4500行kernel代碼有
超過一半是涉及到噪點減少的

00:15:22.289 --> 00:15:23.924
我要進到這裏 編輯下這張照片

00:15:24.858 --> 00:15:27.427
你們可以看到 至少在前排的人可以

00:15:27.494 --> 00:15:29.029
照片上的顆粒

00:15:29.963 --> 00:15:32.299
我們API中的一個特性就是可以

00:15:32.366 --> 00:15:34.434
關掉我們的噪點減少算法

00:15:34.735 --> 00:15:39.173
然後你就可以看到RAW文件中
噪點的自然呈現

00:15:39.873 --> 00:15:42.109
這是個挺有挑戰性的任務

00:15:42.943 --> 00:15:45.012
既要對照片實施噪點減少

00:15:45.078 --> 00:15:49.449
使其沒有這些帶顏色的點
還要保留顏色邊緣

00:15:49.516 --> 00:15:51.084
照片所傾向於保留的

00:15:52.286 --> 00:15:53.453
我保存下照片

00:15:55.422 --> 00:15:57.624
最後 我想演示一下

00:15:57.691 --> 00:15:59.860
我們這周早些時候拍的一張照片

00:16:00.093 --> 00:16:02.362
在大堂裏 用這個iPad拍的

00:16:02.429 --> 00:16:04.898
我就是那些拿iPad拍照的人
其中之一

00:16:06.567 --> 00:16:09.269
在此我想展示給你

00:16:09.336 --> 00:16:11.338
一張本身就帶有挑戰性的照片

00:16:11.405 --> 00:16:14.441
因爲它有些地方太暗
而有些地方過曝了

00:16:15.509 --> 00:16:17.544
我有個能做的事情就是

00:16:17.678 --> 00:16:19.046
降低曝光量

00:16:19.112 --> 00:16:22.216
我有個高光的滑動條
可讓我把高光調高一點

00:16:25.652 --> 00:16:27.688
我也可以降低曝光量

00:16:27.754 --> 00:16:30.357
現在我能看到窗外發生了什麼

00:16:30.724 --> 00:16:33.794
但是現在影子太暗了
我可以調高一下那塊

00:16:34.261 --> 00:16:37.431
這裏展現了你可以對RAW文件
做些什麼調整

00:16:37.497 --> 00:16:41.702
這是你像素數據擁有更深精確度的優勢

00:16:41.768 --> 00:16:43.170
這是RAW文件所帶來的

00:16:43.904 --> 00:16:45.005
我要點擊下“完成”

00:16:48.041 --> 00:16:51.445
這就是我們關於iOS上RAW的演示

00:16:55.983 --> 00:16:58.619
非常感謝我們的團隊使這一切成真

00:16:59.119 --> 00:17:02.022
讓我談下API 因爲它僅僅是

00:17:02.089 --> 00:17:03.891
提供一個演示程序是不夠的

00:17:03.957 --> 00:17:07.426
我們想要使你們的應用也能用到它

00:17:07.961 --> 00:17:11.765
我們有一個相關的API
叫CIRAWFilter API

00:17:11.832 --> 00:17:14.434
它爲你的應用提供了一些關鍵性的東西

00:17:14.501 --> 00:17:17.704
它爲你的應用提供一個CIImage
擁有寬色域

00:17:17.771 --> 00:17:20.907
擴展的區間 半浮點精度運算

00:17:21.742 --> 00:17:24.344
它也賦予你對於很多個階段的控制權

00:17:24.411 --> 00:17:27.548
就比如我剛纔演示過的
RAW演示管道

00:17:28.715 --> 00:17:31.852
它也利用GPU提供快速交互表現

00:17:31.919 --> 00:17:33.187
在我們的所有設備上

00:17:34.454 --> 00:17:37.324
這是怎麼實現的呢 API其實很簡單

00:17:37.391 --> 00:17:41.295
你開始有一個輸入
可以使文件URL或者數據

00:17:41.361 --> 00:17:45.599
甚至是利用我們下次推送中
會帶來的CVPixelBuffer API

00:17:46.166 --> 00:17:47.367
這是我們的輸入

00:17:47.434 --> 00:17:50.971
我們會通過輸入來創建一個
CIRAWFilter的實例

00:17:53.006 --> 00:17:55.242
過濾器被實例化的時候它將會

00:17:55.309 --> 00:17:58.779
給所有用戶可調整的參數賦上默認值

00:17:58.846 --> 00:18:01.348
而這些是你應該想呈現給用戶的

00:18:02.816 --> 00:18:05.219
你有了CIRAWFilter以後
你可以

00:18:05.285 --> 00:18:07.988
向它請求一個CIImage
你可在這裏開始做很多事

00:18:08.055 --> 00:18:11.091
讓我給你展示一下代碼
看看它多簡單就能實現

00:18:12.092 --> 00:18:14.394
我們只需要給它一個URL

00:18:14.962 --> 00:18:17.865
我們要創建一個接受
該URL的CIFilter實例

00:18:18.632 --> 00:18:21.068
接下來 如果我們想獲得值

00:18:21.134 --> 00:18:24.404
該值是關於當前的噪點減少量
我們可以獲取該值

00:18:24.471 --> 00:18:27.708
forKey: kCIInputImageNoiseReductionAmount

00:18:28.642 --> 00:18:30.544
如果我們想改變它
非常的簡單

00:18:30.611 --> 00:18:32.246
我們只需給該鍵設一個新值

00:18:32.813 --> 00:18:36.416
做完這些改變後
請求outputImage就完成了

00:18:36.483 --> 00:18:37.684
我們就需要做這些

00:18:38.619 --> 00:18:40.554
你可能想要顯示這張照片

00:18:40.621 --> 00:18:44.057
通常你會獲取這張照片 並將其顯示在

00:18:44.124 --> 00:18:48.962
UIImage或MetalKit
視圖或其他類型的顯示系統中

00:18:49.496 --> 00:18:51.398
用戶可能會提出

00:18:51.465 --> 00:18:53.500
可能這張照片有點過曝了

00:18:53.567 --> 00:18:57.538
所以在你的UI中
應該有調整曝光的滑條

00:18:58.005 --> 00:19:00.107
以便用戶可以做出調整

00:19:00.174 --> 00:19:03.377
你可將其作爲一個新值
傳給CIRAWFilter

00:19:03.677 --> 00:19:06.246
然後你可以請求一個CIImage

00:19:06.780 --> 00:19:11.218
然後你就可以顯示這張曝光
調整稍微亮一些的新照片

00:19:12.252 --> 00:19:13.854
這也非常容易

00:19:15.889 --> 00:19:17.991
你還可能想獲得
你的CIImage——

00:19:18.425 --> 00:19:21.395
有些時候
可能你想將你的照片導出到背景

00:19:21.461 --> 00:19:22.863
來生成一張全尺寸的照片

00:19:23.063 --> 00:19:25.632
或者你可能要導出幾張照片到背景

00:19:25.899 --> 00:19:27.801
在這些情況下 你應該

00:19:28.035 --> 00:19:31.738
或是創建一個CGImage
用來將其傳到其他API

00:19:32.506 --> 00:19:37.177
或直接用JPEG或TIFF
我們現有很容易用的API來實現這個

00:19:38.612 --> 00:19:41.982
如果你要實現諸如RAW這類
大文件的後臺處理

00:19:42.049 --> 00:19:46.520
我們推薦創建一個CIContext
來明確用於此目的

00:19:46.920 --> 00:19:49.756
你要聲明一個上下文

00:19:49.823 --> 00:19:51.959
被保存在一個單例變量中

00:19:52.025 --> 00:19:54.761
不需要給每張照片都創建
一個新的上下文

00:19:55.128 --> 00:19:59.867
這使得CI可以緩存所有涉及到
的kernel的編譯文件

00:20:01.401 --> 00:20:03.437
不過因爲我們只需要渲染一張照片一次

00:20:03.504 --> 00:20:06.373
我們不需要Core Image
來緩存中間文件

00:20:06.440 --> 00:20:07.808
所以你可以在這聲明爲假

00:20:07.875 --> 00:20:11.211
這會幫助減少此場景下的內存需求

00:20:12.312 --> 00:20:16.517
還有一個設置是關於你想要使用
低優先級的GPU渲染

00:20:16.817 --> 00:20:18.986
如果你是要做一個後臺保存

00:20:19.052 --> 00:20:21.088
你不會想讓所需的GPU使用度

00:20:21.154 --> 00:20:24.091
對於該後臺操作會拖慢性能

00:20:24.157 --> 00:20:25.559
對於你的前臺UI

00:20:25.859 --> 00:20:28.262
不管在Core Image或
Core Animation中被完成的

00:20:29.263 --> 00:20:30.898
這對於後臺處理很棒

00:20:30.964 --> 00:20:33.800
我們今年要發佈的一個很棒的東西就是

00:20:33.867 --> 00:20:36.603
該選項對於macOS也可用

00:20:39.406 --> 00:20:42.242
一旦你有了上下文
就很簡單了

00:20:42.309 --> 00:20:44.745
你要決定你要渲染的顏色空間是什麼

00:20:44.811 --> 00:20:47.047
例如 DisplayP3顏色空間

00:20:47.581 --> 00:20:49.650
我們有個新的很方便的API

00:20:49.716 --> 00:20:52.085
用來生成CIImage然後將其
寫成JPEG

00:20:52.152 --> 00:20:55.122
非常容易 你要聲明CIImage

00:20:55.189 --> 00:20:57.791
目標URL和顏色空間

00:20:58.725 --> 00:21:03.630
在此你也正好可以決定要給JPEG
用什麼樣的壓縮質量

00:21:04.798 --> 00:21:07.201
在這裏會生成一個JPEG圖片

00:21:07.267 --> 00:21:09.436
其已經被標記於P3空間

00:21:09.503 --> 00:21:12.272
這是個不錯的方式來生成寬色域圖片

00:21:12.339 --> 00:21:13.907
它會正確顯示

00:21:13.974 --> 00:21:18.812
在任何支持基於ICC顏色管理的平臺

00:21:19.513 --> 00:21:21.748
如果你覺得你的照片會出現在一個平臺

00:21:21.815 --> 00:21:23.550
其並不支持顏色管理

00:21:23.617 --> 00:21:25.652
我們還有一個新選項供你選擇

00:21:25.919 --> 00:21:29.690
該選擇是作爲
CGImageDestination API的一部分

00:21:30.290 --> 00:21:33.961
並且它是CGImageDestination
OptimizeForSharing

00:21:34.661 --> 00:21:37.130
它會存儲所有的顏色

00:21:37.197 --> 00:21:39.032
這些顏色都在P3顏色空間內

00:21:39.499 --> 00:21:41.869
但是將它們這樣存儲
並有一個定製的檔案

00:21:41.935 --> 00:21:44.137
以便該照片仍然會被正確顯示

00:21:44.204 --> 00:21:48.275
若這張照片的接收者不支持顏色管理

00:21:48.809 --> 00:21:50.344
所以這也是個不錯的特性

00:21:53.180 --> 00:21:55.682
還有若你想要創建一個CGImage

00:21:55.749 --> 00:21:59.419
從CIImage 我們有一個
新API和一些新選項

00:22:00.120 --> 00:22:02.089
我們的這個方便的API可以使你

00:22:02.155 --> 00:22:04.658
聲明什麼顏色空間和像素格式

00:22:04.725 --> 00:22:06.159
你想要渲染

00:22:07.561 --> 00:22:10.397
你可以選擇創建一個CGImage

00:22:10.464 --> 00:22:12.599
其格式爲RGBAh

00:22:12.666 --> 00:22:15.269
也就是我之前談到的
Goldilocks像素格式

00:22:15.536 --> 00:22:18.672
在這種情況下你也可以選擇使用
一個特殊的顏色空間

00:22:18.739 --> 00:22:21.041
也就是
extendedLinearSRGB空間

00:22:21.341 --> 00:22:24.611
因爲像素格式支持0到1區間之外的值

00:22:24.878 --> 00:22:26.680
你要讓顏色空間也是如此

00:22:28.549 --> 00:22:31.218
另一個新選項是可以聲明

00:22:31.285 --> 00:22:33.387
創建CGImage的行動

00:22:33.453 --> 00:22:36.023
是要延遲還是立即進行

00:22:36.323 --> 00:22:39.826
如果你聲明要延遲 則相關的工作

00:22:39.893 --> 00:22:42.763
用來渲染CIImage
到CGImage

00:22:42.829 --> 00:22:45.098
會在CGImage繪製完成後進行

00:22:45.165 --> 00:22:47.167
這樣會很好的減少內存佔用

00:22:47.234 --> 00:22:50.504
特別是如果你之後只會畫
CGImage的一部分

00:22:50.571 --> 00:22:53.273
或者只畫一次

00:22:53.473 --> 00:22:56.710
然而
如果你要渲染那張照片很多次的話

00:22:56.777 --> 00:22:59.079
你可以把延遲設爲假

00:22:59.146 --> 00:23:01.715
在此情況下
Core Image會完成

00:23:01.782 --> 00:23:04.885
將其渲染到CGImage的工作
當此方法被調用時

00:23:04.952 --> 00:23:08.956
這是個我們給你們的應用配備的
很棒且靈活的新API

00:23:11.491 --> 00:23:15.429
另一個關於Core Image
過濾器API的高級特性

00:23:15.495 --> 00:23:18.131
我今天想談下的就是 這個

00:23:18.198 --> 00:23:20.701
如我之前所說的管道
有很長的階段

00:23:20.767 --> 00:23:24.104
用來處理RAW文件 有很多人問我

00:23:24.171 --> 00:23:27.574
我如何將我自己的處理
加入到管道上

00:23:27.741 --> 00:23:31.678
一個常見的開發者想要加入

00:23:31.745 --> 00:23:34.515
處理到RAW管道上
中間某處

00:23:34.581 --> 00:23:36.250
在去馬賽克完成後

00:23:36.316 --> 00:23:39.686
但是在所有非線性操作之前 像是銳化

00:23:39.753 --> 00:23:42.756
還有對比度和顏色加速完成後

00:23:42.856 --> 00:23:44.691
對此我們有個API

00:23:44.758 --> 00:23:46.927
它是CIRAWFilter一個屬性

00:23:46.994 --> 00:23:49.563
可以允許你聲明一個可插入的過濾器

00:23:49.630 --> 00:23:50.964
其被插入到圖表的中間

00:23:51.398 --> 00:23:53.767
我希望看到你們可以想象

00:23:53.834 --> 00:23:56.837
並思考什麼被帶到了該位置

00:23:58.906 --> 00:24:02.209
一些我之前提過的
關於寬色域輸出的說明

00:24:02.743 --> 00:24:06.313
CIKernel語言將浮點精度
作爲一門語言來支持

00:24:06.813 --> 00:24:09.917
不過
當CIFilter需要被渲染到

00:24:09.983 --> 00:24:13.687
中間過濾器時 我們會用能用的格式

00:24:13.754 --> 00:24:15.556
基於當前的CIContext

00:24:16.623 --> 00:24:20.093
macOS上
默認可用的格式是RGBA

00:24:20.160 --> 00:24:21.428
我們的Goldilocks格式

00:24:22.329 --> 00:24:26.834
在iOS和tvOS上
我們的默認格式還是BGRA8

00:24:27.234 --> 00:24:28.702
其性能良好

00:24:28.769 --> 00:24:30.938
但是如果你要渲染擴展區間數據

00:24:31.004 --> 00:24:33.507
這可能不是你想要做的

00:24:34.875 --> 00:24:36.944
記住我們的RAW管道

00:24:37.377 --> 00:24:39.513
我們管道的
所有kernel

00:24:39.880 --> 00:24:43.450
強制使用RGBA半浮點精度

00:24:43.517 --> 00:24:45.419
這對於RAW文件很關鍵

00:24:46.119 --> 00:24:48.622
但如果你擔心

00:24:48.689 --> 00:24:50.657
寬色域輸入和輸出

00:24:50.724 --> 00:24:53.527
要在渲染圖上保留該數據

00:24:53.694 --> 00:24:57.664
那麼你應該修改CIContext
當你創建它來聲明

00:24:57.731 --> 00:25:00.901
你想要一個可用的格式
也就是RGBAh時

00:25:03.303 --> 00:25:06.640
我想再提一下
Core Image支持很廣泛的

00:25:06.707 --> 00:25:08.375
寬色域輸出空間

00:25:08.442 --> 00:25:10.077
例如 你可以渲染到

00:25:10.143 --> 00:25:14.748
extendedLinearSRGB或Adobe RGB
或DisplayP3 無論哪種都行

00:25:17.451 --> 00:25:21.021
如我之前提到的
我要演示一張24兆像素的照片

00:25:21.088 --> 00:25:23.323
RAW文件可以比你想象的大得多

00:25:23.790 --> 00:25:25.959
RAW文件除了大也需要

00:25:26.026 --> 00:25:29.329
一些中間緩存來渲染
管道的所有階段

00:25:29.930 --> 00:25:31.331
這很重要

00:25:31.398 --> 00:25:34.568
以便減少你程序中的
高度佔用內存的水印

00:25:34.635 --> 00:25:37.337
通過使用我今天談到的這些API

00:25:37.404 --> 00:25:41.041
比如當你不需要的時候關掉中間緩存

00:25:41.108 --> 00:25:45.512
或者使用新的JPEG寫入形式
其非常高效

00:25:45.579 --> 00:25:48.515
或是當創建CGImage時
聲明延遲渲染

00:25:50.384 --> 00:25:53.787
這是些關於RAW文件限制的說明

00:25:54.688 --> 00:25:58.325
其支持內存大於2GB的iOS設備

00:25:58.392 --> 00:26:00.928
我們支持最大120萬像素的RAW文件

00:26:00.994 --> 00:26:03.230
我們很驕傲能將其實現

00:26:08.569 --> 00:26:13.207
對於運行在1GB內存設備的應用
我們支持

00:26:13.273 --> 00:26:16.743
處理最大60兆像素的照片
這也很驚人了

00:26:16.810 --> 00:26:19.513
這對於照片編輯擴展也適用

00:26:19.580 --> 00:26:21.782
會使其花費更少的內容就可以運行

00:26:24.852 --> 00:26:26.687
這就是關於RAW的討論

00:26:26.753 --> 00:26:28.822
我很容易今天可以爲你們做演示

00:26:28.889 --> 00:26:30.791
接下來我要把講臺交給Etienne

00:26:30.858 --> 00:26:33.293
和你們講下另一個很棒的新圖片格式

00:26:33.360 --> 00:26:36.930
以及你們如何在程序中
編輯Live Photos 謝謝

00:26:43.237 --> 00:26:44.171
謝謝你 David

00:26:44.271 --> 00:26:45.272
大家好

00:26:45.906 --> 00:26:47.474
我很高興今天站在這裏

00:26:47.541 --> 00:26:50.577
跟你們談談如何在程序中
編輯Live Photos

00:26:52.312 --> 00:26:55.082
首先我們要進行一個簡要的介紹

00:26:55.148 --> 00:26:58.151
什麼是Live Photos
然後看看你都可以編輯什麼

00:27:00.020 --> 00:27:03.056
接下來我們會一步步的看看代碼

00:27:03.123 --> 00:27:06.493
看看你如何得到一張
Live Photo以供編輯

00:27:06.860 --> 00:27:10.631
你如何設置Live Photo
編輯環境

00:27:11.498 --> 00:27:14.535
你如何將Core Image
濾鏡應用到Live Photo上

00:27:15.135 --> 00:27:19.506
以及你如何在你的程序中
預覽Live Photo

00:27:19.673 --> 00:27:24.077
最後就是你如何將編輯好的
Live Photo保存到照片庫

00:27:24.478 --> 00:27:26.046
我們最後會做個快速的演示

00:27:26.747 --> 00:27:28.282
那麼讓我們開始吧

00:27:28.482 --> 00:27:31.752
正如你所知 Live Photos

00:27:31.818 --> 00:27:34.588
就是包含動作和聲音的照片

00:27:34.655 --> 00:27:37.824
從拍攝前到拍攝後

00:27:39.026 --> 00:27:42.629
Live Photos
可以用新的設備拍攝

00:27:42.896 --> 00:27:47.968
如iPhone 6S、6S Plus
iPhone SE和iPad Pro

00:27:48.902 --> 00:27:53.440
事實上 Live Photo是
這些設備上的默認拍攝模式

00:27:53.507 --> 00:27:55.142
因此你可以預期你的用戶

00:27:55.209 --> 00:27:57.945
已在他們的照片庫
有大量的Live Photos了

00:27:59.613 --> 00:28:01.815
今年Live Photos
有何新特性？

00:28:02.349 --> 00:28:07.287
首先是用戶可以在Photos
中完全編輯Live Photos了

00:28:07.354 --> 00:28:09.756
他們可以做出所有的調整

00:28:09.823 --> 00:28:12.226
如普通照片那樣
應用到Live Photo上

00:28:13.293 --> 00:28:17.798
我們有新API用以在
你應用中拍攝Live Photos

00:28:17.965 --> 00:28:20.834
更多關於此的信息

00:28:20.901 --> 00:28:23.570
我強烈推薦你們去看下進階

00:28:23.637 --> 00:28:26.673
本週早些時候舉行的iOS攝影演講

00:28:26.740 --> 00:28:29.510
它也包含了關於
Live Photos的許多信息

00:28:29.743 --> 00:28:31.512
基於拍攝者的角度

00:28:32.079 --> 00:28:34.481
最後我們有新API
編輯Live Photos

00:28:34.548 --> 00:28:36.617
這也是我爲什麼今天要站在這講的原因

00:28:37.518 --> 00:28:38.418
好了

00:28:38.652 --> 00:28:40.654
到底什麼能被編輯呢

00:28:40.721 --> 00:28:44.892
首先就是你可以編輯照片的內容

00:28:45.526 --> 00:28:48.695
而且你還可以編輯視頻的所有幀

00:28:49.863 --> 00:28:51.932
你也可以調整音頻的音量

00:28:53.667 --> 00:28:56.670
你可改變Live Photo的大小

00:28:57.171 --> 00:28:58.805
你不能實現的就是

00:28:58.872 --> 00:29:02.342
你不能改變Live Photo
的持續時間

00:29:04.711 --> 00:29:08.148
爲了獲得可供編輯的
Live Photo

00:29:08.882 --> 00:29:12.019
首先就是要從照片庫中
獲得一張Live Photo

00:29:12.085 --> 00:29:13.253
有兩種方法可以實現

00:29:13.320 --> 00:29:16.690
取決於你是要創建一個照片編輯擴展

00:29:16.757 --> 00:29:18.592
還是一個PhotoKit應用

00:29:18.659 --> 00:29:20.827
如果是照片編輯擴展的話

00:29:21.628 --> 00:29:25.098
你若要實現Live Photo編輯
首先需要

00:29:25.165 --> 00:29:27.568
添加LivePhoto字符串

00:29:27.634 --> 00:29:31.071
爲你的擴展將其加入
支持的媒體類型數組

00:29:31.872 --> 00:29:36.510
然後
在startContentEditing實現中

00:29:38.478 --> 00:29:39.880
它會被自動調用

00:29:39.947 --> 00:29:44.017
你會得到你收到的編輯輸入的內容

00:29:44.084 --> 00:29:47.020
你還可以檢查媒體類型以及媒體子類型

00:29:47.087 --> 00:29:49.089
以確保它是張Live Photo

00:29:49.890 --> 00:29:50.824
好的

00:29:51.158 --> 00:29:54.328
另一方面
如果你創建一個PhotoKit應用

00:29:55.963 --> 00:29:59.499
你已從PHAsset
請求了contentEditingInput

00:29:59.566 --> 00:30:03.203
那麼你就可以以同樣方式來
檢查媒體類型和媒體子類型

00:30:04.705 --> 00:30:08.842
接下來要設置一個
LivePhotoEditingContext

00:30:08.976 --> 00:30:11.945
一個LivePhotoEditingContext
包含所有資源

00:30:12.012 --> 00:30:13.680
即編輯
Live Photos所需的

00:30:14.181 --> 00:30:16.116
它包含有關Live Photo信息

00:30:16.183 --> 00:30:19.319
諸如照片的持續時間

00:30:19.386 --> 00:30:22.756
Live Photo的尺寸
還有方向性

00:30:24.525 --> 00:30:27.127
它也有幀處理器屬性

00:30:27.194 --> 00:30:29.930
你可以用來編輯
Live Photo的內容

00:30:29.997 --> 00:30:31.899
我會後面再跟你們多介紹一些

00:30:33.467 --> 00:30:36.203
你也可以調整音頻的音量

00:30:36.670 --> 00:30:41.275
你可請求LivePhotoEditingContext
來爲Live Photo準備回放

00:30:42.409 --> 00:30:45.412
你可以請求
LivePhotoEditingContext

00:30:45.479 --> 00:30:49.116
來保存和處理Live Photo
用來保存到照片庫

00:30:50.717 --> 00:30:53.420
創建一個LivePhotoEditingContext
非常簡單

00:30:53.487 --> 00:30:55.489
你只需要創建一個新的

00:30:55.556 --> 00:30:58.425
從LivePhotoEditingInput
爲了Live Photo

00:31:00.260 --> 00:31:01.094
好了

00:31:01.161 --> 00:31:02.796
現在讓我們來看下如何

00:31:02.863 --> 00:31:05.098
使用我之前提到的幀處理器

00:31:05.832 --> 00:31:09.937
我會通過描述一個PHLivePhotoFrame對象
來介紹Live Photo的幀

00:31:10.003 --> 00:31:14.107
其包含了輸入圖像
也就是該幀的CIImage

00:31:14.875 --> 00:31:18.612
類型 即它是一個視頻幀還是相片幀

00:31:19.446 --> 00:31:22.449
和Live Photo中的時間幀

00:31:23.083 --> 00:31:26.220
還有該幀被渲染時的分辨率

00:31:28.555 --> 00:31:30.757
爲了實現一個幀處理器

00:31:30.991 --> 00:31:35.629
你要在LivePhotoEditingContext
中設置幀處理器屬性

00:31:35.696 --> 00:31:40.667
使其成爲一個塊來以參數形式接收一幀

00:31:40.734 --> 00:31:43.070
並返回一張圖片或者報錯

00:31:44.071 --> 00:31:47.474
我們剛返回了幀的輸入圖片

00:31:47.541 --> 00:31:50.711
它其實就是節點幀處理器

00:31:51.578 --> 00:31:53.714
現在讓我們看看真實的例子

00:31:53.847 --> 00:31:58.118
這是張Live Photo
就像你在Photos中看到的

00:31:58.185 --> 00:31:59.686
我可以播放一下

00:32:00.387 --> 00:32:01.388
就是這

00:32:02.289 --> 00:32:03.257
還有

00:32:03.457 --> 00:32:07.060
假如我們想要對Live Photo
做個簡單的調整

00:32:07.127 --> 00:32:09.663
就從一個簡單的矩形剪切功能開始吧

00:32:10.397 --> 00:32:11.431
這裏是如何實現

00:32:12.299 --> 00:32:14.935
對於你幀處理器的實現

00:32:15.002 --> 00:32:17.738
你要從幀的輸入圖像開始入手

00:32:17.804 --> 00:32:19.773
然後你需要計算剪切矩形的數據

00:32:20.874 --> 00:32:25.045
然後你可以用這裏的方法來剪切圖片

00:32:25.412 --> 00:32:28.882
即對rect調用剪切
然後返回剪切完成的圖片

00:32:28.949 --> 00:32:32.486
這樣就可以完成編輯和剪切
Live Photo

00:32:32.920 --> 00:32:34.021
這裏是得到的結果

00:32:34.788 --> 00:32:37.424
我可以放側面圖
你可以看出照片是被剪切過的

00:32:37.491 --> 00:32:39.626
而我播放的視頻也是被剪切過的

00:32:40.994 --> 00:32:41.828
好了

00:32:41.895 --> 00:32:45.799
這就是關於非常基本的靜態調整的例子

00:32:45.866 --> 00:32:49.803
如果我們想要做個更動態的調整

00:32:49.870 --> 00:32:52.973
這張照片依時間而改變

00:32:53.040 --> 00:32:55.642
Live Photo播放時隨之改變

00:32:55.709 --> 00:32:56.977
你也可以實現這個

00:32:57.044 --> 00:33:01.281
讓我們做個剪切的例子來實現動態剪切

00:33:02.349 --> 00:33:03.684
這裏是我們要如何實現

00:33:04.551 --> 00:33:08.488
首先我們需要獲得一些信息

00:33:08.555 --> 00:33:12.259
關於Live Photo的時間選擇
像是照片的確切時間

00:33:12.326 --> 00:33:14.995
因爲我們想保持相同的效果

00:33:15.229 --> 00:33:18.332
讓你的剪切矩形位於
Live Photo中心位置

00:33:18.966 --> 00:33:23.504
接下來是我們捕獲
Live Photo的時長

00:33:24.371 --> 00:33:27.975
你會注意到我們是在幀處理器
代碼塊之外完成它的

00:33:28.041 --> 00:33:31.245
以此來避免循環依賴

00:33:33.046 --> 00:33:37.851
在這代碼塊裏我們可以請求
關於該幀確切的時間

00:33:37.918 --> 00:33:40.053
然後我們可以寫一個時間的方法

00:33:40.120 --> 00:33:43.156
使用所有這些信息來幫助運行矩形剪切

00:33:44.358 --> 00:33:45.759
這裏是——

00:33:45.826 --> 00:33:48.695
結果 看得出來Live Photo
以相同方式被剪切

00:33:48.762 --> 00:33:51.064
就如照片一樣 但當我播放它時

00:33:51.265 --> 00:33:54.301
你可以看到矩形剪切
現在從底部移動到了頂部

00:33:56.537 --> 00:33:59.740
這裏是一個基於時間調整的例子

00:34:00.474 --> 00:34:02.342
現在讓我們看點別的

00:34:02.943 --> 00:34:05.112
這個效果很有意思

00:34:05.179 --> 00:34:08.181
因爲它是一個依賴於分辨率的效果

00:34:08.248 --> 00:34:13.887
意思就是濾鏡的參數是怎麼聲明的

00:34:15.222 --> 00:34:16.623
它們在像素中被聲明

00:34:16.690 --> 00:34:19.293
也就意味着你需要額外的仔細

00:34:19.359 --> 00:34:21.460
當你應用這類效果時要確保

00:34:21.527 --> 00:34:23.964
此效果是視覺上一致的

00:34:24.031 --> 00:34:27.534
無論Live Photo
所渲染的分辨率是多少

00:34:27.601 --> 00:34:30.904
在此我播放它 你可以看見視頻

00:34:31.205 --> 00:34:33.674
特效被如應用到照片那樣應用到視頻上

00:34:33.739 --> 00:34:34.574
真不錯

00:34:35.442 --> 00:34:37.143
讓我們看看怎麼能正確實現

00:34:38.110 --> 00:34:41.047
在你的幀處理器中你要注意

00:34:41.114 --> 00:34:43.717
幀上的renderScale屬性

00:34:43.784 --> 00:34:47.955
它會給你當前幀的分辨率

00:34:48.021 --> 00:34:51.725
與Live Photo中的一比一
全尺寸的靜態圖片相比

00:34:53.360 --> 00:34:54.928
所以請記住

00:34:55.996 --> 00:34:59.733
視頻幀和圖片也是不同的尺寸

00:34:59.800 --> 00:35:02.302
通常視頻會比照片小得多

00:35:02.803 --> 00:35:04.972
因此你要確保能正確的實現它

00:35:05.038 --> 00:35:06.106
爲了實現這個目的

00:35:07.140 --> 00:35:09.543
你可以使用這的比例尺

00:35:09.610 --> 00:35:12.813
來案例比縮小寬度參數以便一比一

00:35:12.880 --> 00:35:15.282
的全尺寸照片的參數將會是50

00:35:15.349 --> 00:35:17.784
但它會在小分辨率下變得更小

00:35:19.186 --> 00:35:24.091
另一個可以用來做出
依賴分辨率的調整的方法就是

00:35:24.358 --> 00:35:25.259
使用

00:35:26.026 --> 00:35:30.597
利用圖片的範圍
就如我現在這裏做的那樣——

00:35:30.731 --> 00:35:32.366
對inputCenter參數

00:35:32.432 --> 00:35:35.936
我實際上使用了圖片的中點 這也成功

00:35:36.003 --> 00:35:37.738
正確的縮放了

00:35:39.139 --> 00:35:40.040
好的

00:35:40.107 --> 00:35:42.910
對於這張圖片還有一個編輯的地方

00:35:43.710 --> 00:35:47.347
你們可以注意到我在這邊做了一個標識

00:35:47.714 --> 00:35:50.584
可能看上去很熟悉 當我播放它時

00:35:51.685 --> 00:35:54.154
你會看到標識從視頻中消失了

00:35:54.221 --> 00:35:58.992
就是關於如何將一個調整
只應用到照片上

00:35:59.059 --> 00:36:00.160
而不是視頻中

00:36:00.527 --> 00:36:01.962
這裏是如何實現的

00:36:02.763 --> 00:36:05.499
在你幀處理器的實現中

00:36:06.200 --> 00:36:10.571
你要看一下幀類型
在此我們要檢查下它是不是一張圖片

00:36:10.637 --> 00:36:15.642
然後我們將靜態標識整合到圖片中去
而不是視頻中

00:36:15.709 --> 00:36:17.177
就是這麼容易

00:36:17.244 --> 00:36:19.947
你們或許知道 有一些調整

00:36:20.013 --> 00:36:22.182
可能是一個本地廣告或是單個廣告

00:36:22.249 --> 00:36:24.685
你不想或者不能應用到視頻中

00:36:24.751 --> 00:36:26.720
而這麼做就能很好的實現這一功能

00:36:28.255 --> 00:36:29.089
好了

00:36:29.156 --> 00:36:31.325
我們現有了一張
編輯過的Live Photo

00:36:32.259 --> 00:36:35.495
讓我們看看如何在應用中預覽它吧

00:36:36.063 --> 00:36:41.201
你用PHLivePhotoView
來預覽一張Live Photo

00:36:41.268 --> 00:36:46.874
這個視圖在iOS中早就可用了
而今年引入了macOS中

00:36:48.342 --> 00:36:53.380
爲了預覽Live Photo
你需請求LivePhotoEditingContext

00:36:53.447 --> 00:36:57.217
以準備回放一張Live Photo
你要傳入

00:36:57.284 --> 00:37:03.056
目標尺寸
也就是你視圖的像素尺寸

00:37:03.123 --> 00:37:05.826
然後你要異步地回調

00:37:05.893 --> 00:37:09.363
附着一張渲染過的
Live Photo在主線程上

00:37:10.297 --> 00:37:11.865
接下來你要做的就是設置

00:37:11.932 --> 00:37:14.301
LivePhotoView
的Live Photo屬性

00:37:14.368 --> 00:37:19.673
以便你的用戶可與其
Live Photo交互且獲得

00:37:19.740 --> 00:37:22.209
編輯過的Live Photo
看起來如何的印象

00:37:23.810 --> 00:37:24.845
現在

00:37:24.912 --> 00:37:27.648
最後一步就是將其保存到照片庫中

00:37:27.714 --> 00:37:32.452
這取決於你開發的是一個照片編輯

00:37:32.519 --> 00:37:34.922
擴展或PhotoKit應用

00:37:35.923 --> 00:37:40.661
若是照片編輯擴展 你就要實現
finishContentEditing

00:37:40.961 --> 00:37:45.599
第一步 創建一個新的
contentEditingOutput

00:37:45.666 --> 00:37:48.802
從你早先接收到
contentEditingInput中

00:37:49.703 --> 00:37:53.240
接下來你要請求
LivePhotoEditingContext

00:37:53.307 --> 00:37:55.509
以保存Live Photo
到該輸出中

00:37:55.576 --> 00:37:59.379
這會處理全分辨率的
Live Photo

00:37:59.446 --> 00:38:03.517
以異步的方式 並且在主線程上回調

00:38:04.017 --> 00:38:05.319
成功還是報錯

00:38:05.385 --> 00:38:07.921
如果所有都順利的話

00:38:08.355 --> 00:38:12.259
你還要確保你除了編輯的內容
還保存了調整的數據

00:38:12.893 --> 00:38:15.162
這將會允許你的用戶回到

00:38:15.229 --> 00:38:18.899
接下來在你的應用或者擴展中
並繼續在那編輯

00:38:21.768 --> 00:38:24.238
最後要調用
completionHandler

00:38:24.304 --> 00:38:25.973
對於該擴展 然後你就完成了

00:38:27.174 --> 00:38:32.012
若你開發的是PhotoKit應用
步驟就很類似的

00:38:32.246 --> 00:38:35.883
唯一的區別就在於你要

00:38:35.949 --> 00:38:38.185
它們是來自於你本身的變化

00:38:38.252 --> 00:38:40.387
使用PHAssetChangeRequest

00:38:41.688 --> 00:38:44.424
現在我要給你們展示一個快速的演示

00:38:52.499 --> 00:38:53.333
好了

00:38:54.034 --> 00:38:57.704
我創建了一個Live Photo
擴展的簡單演示

00:38:57.771 --> 00:38:59.139
我今天想要展示給你們看

00:38:59.940 --> 00:39:03.977
我現在Photos應用裏
可以看到一些Live Photos

00:39:04.044 --> 00:39:05.746
可以來挑選看看這些內容

00:39:07.481 --> 00:39:09.816
我可以滑動來看它們活動起來

00:39:10.150 --> 00:39:12.219
這就是我今天要編輯的照片

00:39:12.653 --> 00:39:15.088
現在我要開始編輯了
正如我之前提到的

00:39:15.155 --> 00:39:18.425
我在Photos裏就能
編輯Live Photo

00:39:18.492 --> 00:39:19.526
讓我來編輯看看

00:39:19.593 --> 00:39:24.097
我想要應用下David之前
提到的這個新的亮度滑動條

00:39:24.831 --> 00:39:25.666
好了

00:39:26.400 --> 00:39:28.569
我可以在Photos應用中播放它

00:39:32.673 --> 00:39:33.807
當然了 我可以

00:39:33.874 --> 00:39:39.613
在這就停下
但我想也應用下我的示例編輯

00:39:40.013 --> 00:39:41.915
我要在這選擇我的擴展

00:39:45.686 --> 00:39:51.992
我們應用的是貫穿幻燈片
所提的相同的調整

00:39:52.326 --> 00:39:56.029
你們能看出來這是個挺簡單的擴展

00:39:56.096 --> 00:39:59.032
它顯示LivePhotoView
因此我可與之交互

00:39:59.099 --> 00:40:03.170
我可以點按來播放它
就像在我的擴展這樣

00:40:04.071 --> 00:40:04.972
這很簡單

00:40:05.038 --> 00:40:08.575
下面一步就是要點擊“完成”來保存

00:40:09.476 --> 00:40:13.013
而且要處理一個全分辨率
的Live Photo

00:40:13.847 --> 00:40:15.082
並將其發送回照片庫

00:40:16.316 --> 00:40:18.552
就是在Photos那兒

00:40:19.987 --> 00:40:20.821
好了

00:40:21.555 --> 00:40:23.257
這就是這個演示

00:40:23.757 --> 00:40:25.025
現在回到幻燈片上

00:40:30.330 --> 00:40:31.164
謝謝

00:40:31.932 --> 00:40:32.933
好的

00:40:33.166 --> 00:40:35.969
這裏是我們今天目前爲止
所介紹的一個簡要總結

00:40:36.436 --> 00:40:39.439
我們已經學到如何
獲得一張Live Photo

00:40:39.506 --> 00:40:42.442
從照片庫中

00:40:42.743 --> 00:40:46.046
如何使用和設置一個
LivePhotoEditingContext

00:40:46.113 --> 00:40:50.517
如何使用幀處理器來
編輯Live Photo的內容

00:40:50.984 --> 00:40:56.356
我們介紹瞭如何在你的應用中
利用LivePhotoView來預覽Live Photo

00:40:57.124 --> 00:41:01.495
我們看到了如何將
Live Photo保存到照片庫中

00:41:03.230 --> 00:41:06.266
我現在迫不及待地想看到
你們會用這個新API做出些什麼

00:41:07.134 --> 00:41:08.402
有幾點是需要記住的

00:41:09.903 --> 00:41:12.239
首先
如果你是要開發一個照片編輯擴展

00:41:12.306 --> 00:41:15.509
別忘記...
將LivePhotoEditing加到

00:41:15.576 --> 00:41:17.311
你info.plist中來擴展

00:41:17.377 --> 00:41:20.180
否則你得到的是一張靜態圖片
而非Live Photo

00:41:20.881 --> 00:41:24.852
就如我所說的
你要確保保存了調整數據

00:41:24.918 --> 00:41:28.455
以便你的用戶們可以回到你的應用中

00:41:28.522 --> 00:41:30.624
繼續無損的編輯

00:41:31.892 --> 00:41:37.064
最後 我覺得如果你已經
有了一個照片編輯應用

00:41:39.333 --> 00:41:43.070
採用Live Photo及添加對於
LivePhotoEditing的支持

00:41:43.136 --> 00:41:44.771
使用這新API實現就該非常容易

00:41:45.072 --> 00:41:48.308
特別是如果你的應用已經使用了
Core Image的情況下

00:41:48.375 --> 00:41:51.912
如果沒有
Core Image裏有個新API

00:41:51.979 --> 00:41:56.016
可以讓你將自定義的處理
集成到Core Image裏

00:41:56.083 --> 00:42:00.087
我會請Alex上臺給你們詳細介紹

00:42:00.153 --> 00:42:00.988
謝謝

00:42:06.793 --> 00:42:07.794
謝謝 Etienne

00:42:08.095 --> 00:42:09.296
我叫Alexandre Naaman

00:42:09.363 --> 00:42:11.331
我今天要講的是關於一些新功能

00:42:11.398 --> 00:42:15.102
關於Core Image之前
所沒有的額外特效

00:42:15.169 --> 00:42:18.639
這會用到一個叫
CIImageProcessor的新API

00:42:19.940 --> 00:42:22.943
就如David之前提到
在Core Image中 你可實現很多東西

00:42:23.010 --> 00:42:26.213
使用我們內置的180個濾鏡

00:42:26.280 --> 00:42:30.217
你還可通過編寫自定義的
kernel來做進一步的擴展

00:42:30.751 --> 00:42:33.954
有CIImageProcessor
我們能實現的就更多

00:42:34.388 --> 00:42:38.225
我們可以在渲染圖中插入一個新的節點

00:42:38.926 --> 00:42:41.195
它能實現我們想要的一切

00:42:41.461 --> 00:42:43.597
還與現存的圖完美融合

00:42:43.664 --> 00:42:47.501
我們可編寫自定義的CPU代碼...
或是Metal代碼

00:42:49.870 --> 00:42:52.773
使用CIImageProcessor時

00:42:53.073 --> 00:42:54.775
與編寫通用kernel有類似

00:42:54.842 --> 00:42:59.279
過去你寫通用kernel
要聲明某些字符串

00:43:00.080 --> 00:43:03.784
然後重寫你CIFilter中
的輸出圖像方法

00:43:05.652 --> 00:43:07.821
並且提供範圍 也就是

00:43:07.888 --> 00:43:09.790
你要創建的輸出圖片尺寸

00:43:10.791 --> 00:43:12.559
還有roiCallback函數

00:43:13.727 --> 00:43:15.062
最後

00:43:15.562 --> 00:43:18.465
無論你要將何參數傳入kernel中

00:43:19.499 --> 00:43:24.037
這與創建CIImageProcessors
有許多的相似性

00:43:24.104 --> 00:43:27.374
所以我們今天不會再深入討論它們了

00:43:27.441 --> 00:43:32.980
我們建議你去看看2014 WWDC
的演講515

00:43:33.113 --> 00:43:35.249
若你想創建一個
CIImageProcessors

00:43:35.315 --> 00:43:37.918
我們強烈推薦你回去看下那個講座

00:43:37.985 --> 00:43:40.254
因爲我們討論瞭如何處理範圍

00:43:40.320 --> 00:43:43.524
和ROI參數

00:43:45.425 --> 00:43:47.060
現在讓我們看下這個API

00:43:47.127 --> 00:43:49.162
用來創建CIImage處理器
的是什麼樣的

00:43:50.130 --> 00:43:51.899
這可能在將來更新中會有些許變化

00:43:51.965 --> 00:43:54.201
但是它現在的樣子

00:43:54.935 --> 00:43:56.637
相似性是這些

00:43:56.703 --> 00:43:57.804
我們需要提供範圍

00:43:57.871 --> 00:43:59.840
也就是我們要生成的輸出圖片的尺寸

00:43:59.907 --> 00:44:01.175
給它一個輸入圖像

00:44:02.142 --> 00:44:03.210
還有ROI

00:44:03.844 --> 00:44:06.880
我們需要提供很多額外的參數

00:44:06.947 --> 00:44:10.350
例如我們要創建的節點的描述

00:44:11.351 --> 00:44:14.488
我們需要提供一個摘要
有着某種哈希值

00:44:14.555 --> 00:44:16.056
對於我們所有的輸入參數

00:44:16.123 --> 00:44:18.025
這對於Core Image很重要

00:44:18.091 --> 00:44:19.993
因爲這是Core Image
如何決定

00:44:20.060 --> 00:44:22.129
我們是否要緩存那些值

00:44:22.196 --> 00:44:23.997
還有我們是否需要重渲染

00:44:24.198 --> 00:44:27.234
你需要確保每次你的參數改變的時候

00:44:27.668 --> 00:44:29.203
你要更新哈希值

00:44:30.304 --> 00:44:34.808
接下來我們可以聲明是輸入格式

00:44:34.875 --> 00:44:37.544
在這個例子中我們用了BGRA8

00:44:38.712 --> 00:44:40.314
但你也可以聲明爲0

00:44:40.380 --> 00:44:43.750
這意味着你會獲得對於
該上下文可用的格式——

00:44:44.351 --> 00:44:46.553
作爲一個輸入圖像格式

00:44:46.954 --> 00:44:48.989
你也可以聲明輸出格式

00:44:49.056 --> 00:44:51.325
在此我們用的是RGBAf
因爲我們詳細介紹

00:44:51.391 --> 00:44:53.093
的例子

00:44:53.160 --> 00:44:55.362
需要精度很高
因此我們需要在此使用全流量

00:44:56.597 --> 00:44:58.432
最後我們要看下處理器代碼塊

00:44:58.498 --> 00:45:00.767
在這我們有兩個參數

00:45:00.834 --> 00:45:05.806
CIImageProcessorInput
和CIImageProcessorOutput

00:45:06.874 --> 00:45:09.877
它們在這裏面以便我們
可以完成所需的所有工作

00:45:10.277 --> 00:45:12.779
讓我們看看如何來實現它

00:45:12.946 --> 00:45:14.548
還有你爲什麼要實現它

00:45:17.117 --> 00:45:19.486
CIImageProcessor
特別有用

00:45:19.553 --> 00:45:22.990
對於你有某個算法的時候
或者你想用一個庫

00:45:23.056 --> 00:45:25.192
其實現了Core Image外
某些東西

00:45:26.326 --> 00:45:28.729
且還是對於CIKernel語言
不合適的東西

00:45:28.795 --> 00:45:32.065
一個好例子就是積分圖像

00:45:32.633 --> 00:45:35.469
積分圖像就是憑藉輸出像素的圖像

00:45:35.536 --> 00:45:37.804
它包含了其上所有像素的總和

00:45:37.871 --> 00:45:39.606
還有它左邊的像素 包括它自身

00:45:40.841 --> 00:45:43.677
這是個好例子 對於不能完成的事情

00:45:43.744 --> 00:45:45.946
在數據平行類的着色器

00:45:46.013 --> 00:45:48.815
也就是當你編寫CIKernel時
所寫那種着色器

00:45:50.984 --> 00:45:52.653
讓我們來看下

00:45:53.187 --> 00:45:55.022
關於積分圖像的更多細節

00:45:55.088 --> 00:45:57.558
如果我們從左邊的輸入圖像開始

00:45:57.624 --> 00:46:01.428
也就是說
與某些單信道 8比特數據相對應

00:46:02.629 --> 00:46:04.631
我們的積分圖像會成爲右邊的圖像

00:46:04.698 --> 00:46:06.667
如果我們看下這邊的像素的話

00:46:06.733 --> 00:46:07.701
7

00:46:07.768 --> 00:46:11.705
它實際上對應着左邊所有像素的和

00:46:11.772 --> 00:46:14.474
也就是1加4加0加2

00:46:15.475 --> 00:46:19.346
對於另外的像素也是如此
45對應的是和

00:46:19.413 --> 00:46:22.382
也就是那些像素的上邊 左邊
再加上它自己

00:46:26.286 --> 00:46:29.056
讓我們來看看你會做些什麼

00:46:29.122 --> 00:46:33.527
如果你要寫CPU代碼
到圖像處理器代碼塊的話

00:46:33.861 --> 00:46:35.596
你也可以使用V Image

00:46:35.662 --> 00:46:37.965
或是我們系統裏有的其他任何庫

00:46:38.832 --> 00:46:40.000
首先重中之重的就是

00:46:40.334 --> 00:46:42.836
我們要獲取一些指針返回到輸入數據

00:46:42.903 --> 00:46:46.406
從CIImageProcessorInput
我們會得到基地址

00:46:47.241 --> 00:46:50.844
而且我們要確保使用8比特數據
也就是UInt8

00:46:51.512 --> 00:46:52.713
接着我們會得到
outputPointer

00:46:52.779 --> 00:46:54.615
也就是我們寫入所有結果的地方

00:46:54.681 --> 00:46:58.118
要作爲浮點類型寫入
因爲我們聲明要寫到RGBAf

00:47:00.287 --> 00:47:03.524
接下來我們要確保考慮到

00:47:04.024 --> 00:47:07.160
輸入輸出圖像相關的偏移量

00:47:07.694 --> 00:47:10.330
Core Image很可能提供給你

00:47:10.397 --> 00:47:13.300
更大的輸入圖像

00:47:13.367 --> 00:47:15.936
至少和你的輸出圖像不一樣大

00:47:16.003 --> 00:47:19.173
所以你要小心處理所有可能的偏移量

00:47:19.506 --> 00:47:22.342
當你創建輸出圖像
還有寫for循環的時候

00:47:23.544 --> 00:47:26.246
在這種情況下
一旦我們弄清楚所需要的偏移量

00:47:26.480 --> 00:47:30.117
就可以執行我們的for循環
來計算輸出值

00:47:30.184 --> 00:47:33.820
通過使用i-j位置的輸入

00:47:33.887 --> 00:47:35.455
加上我們得到的偏移量

00:47:38.625 --> 00:47:41.228
現在我們已經看到如何利用
定製CPU循環來實現它

00:47:41.295 --> 00:47:44.198
也看看如何利用Metal來實現

00:47:44.264 --> 00:47:45.699
在這個例子中我們會使用

00:47:46.567 --> 00:47:48.168
Metal性能着色器

00:47:49.102 --> 00:47:51.038
在Metal性能着色器中
有個很不錯的初始點

00:47:51.104 --> 00:47:54.074
來計算積分圖像 叫做
MPSImageIntegral

00:47:55.142 --> 00:47:59.413
從CIImageProcessorOutput中
我們可以得到commandBuffer

00:47:59.646 --> 00:48:02.449
Metal command buffer 所以我們創建了一個
MPSImageIntegral

00:48:02.516 --> 00:48:04.051
利用那個commandBuffer

00:48:05.152 --> 00:48:08.422
我們要小心留意需要處理的偏移量

00:48:10.090 --> 00:48:13.060
然後對該commandBuffer
編寫相應kernel即可

00:48:13.427 --> 00:48:16.096
還要提供我們得到的輸入紋理作爲輸入

00:48:16.163 --> 00:48:17.798
其是從
CIImageProcessorInput得到的

00:48:17.865 --> 00:48:20.934
還要將
output.MetalTexture作爲目的地

00:48:21.535 --> 00:48:24.171
這就是我們如何使用Metal

00:48:24.238 --> 00:48:26.240
在現存CIFilter圖之內

00:48:27.341 --> 00:48:29.243
現在讓我們看看我們能完成什麼

00:48:29.309 --> 00:48:31.044
通過目前得到的積分圖像

00:48:31.712 --> 00:48:33.647
我們從像是這麼一張圖片開始

00:48:33.714 --> 00:48:36.583
我們的目標是生成一張新的圖片

00:48:37.684 --> 00:48:41.054
其每像素變量都有盒裝模糊

00:48:41.121 --> 00:48:45.025
該張圖片的每個像素都有不同的模糊量

00:48:45.092 --> 00:48:48.595
我們利用積分圖像很快就可以實現

00:48:50.864 --> 00:48:53.834
我要說的是 盒狀模糊是很有用的

00:48:54.768 --> 00:48:56.837
對於實現快速盒狀相加

00:48:56.904 --> 00:48:58.805
如果我們就從這張輸入圖片開始 想要

00:48:58.872 --> 00:49:02.643
得到這九個像素點的和 通常來講

00:49:02.709 --> 00:49:06.313
這需要進行九次讀取
也就意味着這是個n平方複雜度的問題

00:49:06.747 --> 00:49:10.017
這可不會太快

00:49:11.718 --> 00:49:13.854
這不完全對 如果你稍微聰明點的話

00:49:13.921 --> 00:49:16.023
你可以通過多通道方法來實現它

00:49:16.089 --> 00:49:19.459
通過兩個n次讀取來實現
但你仍然要進行六次讀取

00:49:20.160 --> 00:49:22.196
也沒有明顯縮小多少

00:49:23.463 --> 00:49:25.933
不過利用積分圖像的話 我們就可以

00:49:25.999 --> 00:49:29.002
如果想得到這九個像素點的和

00:49:29.069 --> 00:49:30.637
我們只需要讀取幾個位置

00:49:30.704 --> 00:49:32.539
我們要讀取右下角的位置

00:49:34.107 --> 00:49:35.509
然後再讀取

00:49:35.576 --> 00:49:39.346
從一個到最左邊 所有值的和

00:49:39.780 --> 00:49:42.816
然後再從中減去我們讀取的頭一個值

00:49:43.884 --> 00:49:46.987
然後我們要讀取一個像素點
它就在我們所需的上面

00:49:47.054 --> 00:49:48.856
並減去目前爲止

00:49:48.922 --> 00:49:50.490
所有像素相加所對應的行

00:49:50.557 --> 00:49:52.392
你們現可看到我們將左上角設爲高亮

00:49:52.459 --> 00:49:55.028
設爲1 因爲我們已經減了兩次那個值

00:49:55.095 --> 00:49:56.463
所以我們要再把它加回來

00:49:59.066 --> 00:50:03.637
這意味着我們可以創建
一個任意尺寸的盒狀模糊

00:50:04.204 --> 00:50:05.672
就通過四次讀取

00:50:09.276 --> 00:50:10.944
如果我們要 謝謝你們

00:50:13.313 --> 00:50:14.481
如果我們要手動做計算

00:50:14.548 --> 00:50:16.350
你可以看出來這些數加起來是對的

00:50:16.416 --> 00:50:19.753
也就是2加4加6等等 完全相同

00:50:19.820 --> 00:50:23.090
和66減10減13加1

00:50:26.727 --> 00:50:30.297
讓我們回到Core Image
kernel語言

00:50:30.364 --> 00:50:34.334
看看我們如何使用積分圖像
該圖像或是我們利用CPU代碼計算的

00:50:34.768 --> 00:50:37.171
或使用Metal性能着色器
基類型得到的

00:50:38.305 --> 00:50:40.974
並繼續實現創建盒狀模糊特效

00:50:41.508 --> 00:50:44.511
我們要做的第一件事就是計算左下角

00:50:44.578 --> 00:50:46.880
和右上角 從我們的圖片中

00:50:46.947 --> 00:50:50.617
這會告訴我們需要要從哪進行加減

00:50:51.785 --> 00:50:54.354
然後我們要計算一些其他的值

00:50:54.421 --> 00:50:58.058
它們會幫助我們決定所需alpha值

00:50:58.125 --> 00:51:00.994
也就是我們當前要生成的像素的透明度

00:51:03.263 --> 00:51:05.832
我們取得四個角的樣值

00:51:07.167 --> 00:51:10.737
做了所需的加法和減法

00:51:10.804 --> 00:51:13.373
再乘上所決定的合適的

00:51:13.440 --> 00:51:15.742
對於該輸出像素的透明度

00:51:18.278 --> 00:51:21.915
該kernel接收單個參數

00:51:21.982 --> 00:51:24.318
作爲輸入半徑 也就是

00:51:24.384 --> 00:51:25.919
如果你要在圖片上調用它

00:51:25.986 --> 00:51:28.655
你會在整個圖片上應用相同的半徑

00:51:28.956 --> 00:51:31.325
不過我們可以簡單

00:51:32.392 --> 00:51:33.894
去創建一個盒裝模糊變量

00:51:33.961 --> 00:51:37.297
通過傳入一個掩膜圖像
我們可以利用該掩膜圖像

00:51:37.364 --> 00:51:39.099
來決定多大

00:51:40.067 --> 00:51:43.036
的半徑對於每像素爲基礎合適

00:51:44.505 --> 00:51:46.740
我們要傳入一個額外的參數
也就是掩膜圖像

00:51:46.807 --> 00:51:47.741
我們從中進行讀取

00:51:49.309 --> 00:51:51.078
我們來看下紅信道中有什麼

00:51:51.144 --> 00:51:52.679
也可能從任何一個信道而來

00:51:52.746 --> 00:51:55.415
然後我們要把它乘上半徑

00:51:55.482 --> 00:51:59.386
如果我們的半徑是15
而在當前像素位置的值是0.5

00:51:59.453 --> 00:52:01.755
那麼最終的半徑是7.5

00:52:02.389 --> 00:52:04.658
我們可以得到這些值後 傳到

00:52:04.725 --> 00:52:06.727
我們剛寫好的盒狀模糊kernel中

00:52:06.894 --> 00:52:10.097
這就是我們如何創建一個盒狀模糊變量

00:52:10.464 --> 00:52:15.068
利用Metal性能着色器
和CIImageProcessor節點

00:52:18.205 --> 00:52:21.441
還有個我們今天沒有提到的事情是

00:52:21.508 --> 00:52:24.211
我們現在有了可以聲明的屬性

00:52:24.511 --> 00:52:26.847
它們在你所寫的CIKernels中

00:52:27.681 --> 00:52:31.652
實際上
我們現在就有一個 也就是輸出格式

00:52:31.718 --> 00:52:37.624
在這裏我們要請求RGBAf
不需要真的有用

00:52:37.691 --> 00:52:42.229
關鍵是說你想要寫

00:52:42.296 --> 00:52:44.798
單信道還是雙信道數據

00:52:44.865 --> 00:52:46.466
所以如果你想要

00:52:48.836 --> 00:52:50.437
如有些人所注意到
有個好方法

00:52:50.504 --> 00:52:56.376
來減少你的內存佔用 也可以來聲明

00:52:56.443 --> 00:53:00.180
對於某個特定kernel
你想要個確切的精度

00:53:00.247 --> 00:53:03.083
在可能和圖剩餘部分
不相對應的kernel

00:53:03.150 --> 00:53:06.186
就如我們在iOS上
處理RAW圖片那樣

00:53:06.253 --> 00:53:09.256
我們的所有kernel
都標記着RGBAh

00:53:12.993 --> 00:53:16.029
另外 我們要創建此特效還得

00:53:16.096 --> 00:53:17.598
提供某種掩膜圖像

00:53:17.664 --> 00:53:21.168
調用CIFilter(name,
就可輕鬆實現

00:53:21.235 --> 00:53:24.271
然後附帶參數請求一個
CIRadialGradient

00:53:24.338 --> 00:53:26.673
也就是要決定有多大

00:53:27.241 --> 00:53:30.244
的掩膜 還有它位於哪裏

00:53:30.310 --> 00:53:33.080
然後我們要在0和1間插入

00:53:33.146 --> 00:53:34.648
非黑即白

00:53:35.315 --> 00:53:37.718
然後我們要從CIFilter中
請求輸出圖像

00:53:37.985 --> 00:53:40.153
之後我們就有了一個完美可用的掩膜

00:53:42.356 --> 00:53:45.025
現在讓我們看看它實際看起來

00:53:45.092 --> 00:53:46.660
運行在設備上時是什麼樣的

00:53:46.727 --> 00:53:50.063
這是從iPhone 6S上錄製的

00:53:50.130 --> 00:53:52.833
如果我們從輸入圖像開始
並看看掩膜的話

00:53:52.900 --> 00:53:54.168
我們可以移動它

00:53:54.368 --> 00:53:55.702
它非常具有可交互性

00:53:56.336 --> 00:53:59.573
可以改變半徑 甚至將其設爲負數

00:54:01.341 --> 00:54:05.078
如果我們使用此掩膜圖像 並使用它在

00:54:05.145 --> 00:54:07.281
我們的盒狀模糊變量
kernel代碼中

00:54:08.549 --> 00:54:12.419
就可以得到這個類型的結果
它是非常可交互的

00:54:12.986 --> 00:54:15.422
因爲積分圖像也需要計算一次

00:54:15.489 --> 00:54:17.524
Core Image
爲你緩存這些結果

00:54:17.591 --> 00:54:20.093
它幾乎就是你現在所看到的這些東西

00:54:20.160 --> 00:54:22.930
就包括四次讀取 所以它非常的快

00:54:32.472 --> 00:54:35.876
有些要你們記住的
當你使用CIImageProcessor時

00:54:37.044 --> 00:54:40.314
如果你要使用的在圖像處理器中的數據

00:54:40.380 --> 00:54:44.985
不是在當前workingColorSpace
的上下文中

00:54:45.052 --> 00:54:47.654
你就要調用
CIImage.byColorMatching

00:54:47.721 --> 00:54:50.023
WorkingSpace(to,
來提供一個顏色空間

00:54:52.025 --> 00:54:55.429
類似的 在出口處如果你想要數據

00:54:55.495 --> 00:54:56.763
位於不同的顏色空間

00:54:56.830 --> 00:54:59.333
你就要調取
CIImage.byColorMatching

00:54:59.399 --> 00:55:02.135
ColorSpace(toWorking,
並給它一個顏色空間

00:55:05.639 --> 00:55:09.776
現在我們已經看到
如何創建CIImageProcessor

00:55:09.843 --> 00:55:10.844
並使用它

00:55:11.678 --> 00:55:13.247
讓我們來看看會發生什麼

00:55:13.313 --> 00:55:15.382
當我們使用環境變量
CI PRINT TREE時

00:55:15.449 --> 00:55:18.785
我們用它來得到實際的圖

00:55:18.852 --> 00:55:20.754
我們渲染完會是什麼樣

00:55:23.056 --> 00:55:24.658
它看起來就會是這樣的

00:55:24.725 --> 00:55:26.693
當你使用環境變量
CI PRINT TREE時

00:55:26.760 --> 00:55:28.028
而且將其值設爲1

00:55:28.228 --> 00:55:31.732
是自底向上讀取 而且它可以很冗長

00:55:32.432 --> 00:55:36.236
它從我們創建的
radialGradient輸入開始

00:55:36.904 --> 00:55:41.408
接下來我們得到與工作空間
相匹配的輸入圖像

00:55:42.776 --> 00:55:45.812
然後就是我們的處理器節點被調用

00:55:45.879 --> 00:55:49.449
此十六進制值就是我們已經計算過的摘要

00:55:50.851 --> 00:55:53.420
處理器和顏色kernel結果

00:55:53.487 --> 00:55:56.790
來自radialGradient的
被傳入variableBoxBlur中

00:55:57.691 --> 00:56:02.362
最後我們對於輸出顯示做顏色匹配

00:56:03.664 --> 00:56:07.301
這是我們的原始菜單

00:56:07.367 --> 00:56:11.305
用來聲明才特效
但它不是實際被渲染的那個

00:56:12.439 --> 00:56:15.642
如果我們將環境變量
CI PRINT TREE設爲8

00:56:15.709 --> 00:56:18.846
就可以看到很多東西都已經被壓塌了

00:56:19.146 --> 00:56:22.683
並且處理看來參與的少了

00:56:23.750 --> 00:56:26.286
我們還是有處理器節點

00:56:26.353 --> 00:56:27.855
單獨位於一行

00:56:27.921 --> 00:56:32.426
也就意味着它需要一箇中間緩存

00:56:32.492 --> 00:56:35.495
這就是CIImageProcessors
非常好的原因

00:56:35.562 --> 00:56:38.098
不過你只應該在特定情況下才使用

00:56:38.165 --> 00:56:40.701
當你要生成的特效 你所有的算法

00:56:40.767 --> 00:56:43.604
不能在CIKernel語言內
被表達時

00:56:44.671 --> 00:56:47.941
如你所見
處理的剩餘部分都會被連接到一起

00:56:48.008 --> 00:56:51.411
因此我們有variableBoxBlur
來處理剩餘的顏色匹配

00:56:51.478 --> 00:56:54.314
還有clamptoalpha
都在一次傳值中完成

00:56:54.515 --> 00:56:57.684
這也是爲什麼總要
在這些API中有所取捨的原因

00:56:57.751 --> 00:57:00.721
如果你可以的話就應該
寫在CIKernel語言內

00:57:04.291 --> 00:57:06.159
這可能會有點難讀

00:57:07.261 --> 00:57:09.730
所以你也可以聲明

00:57:09.796 --> 00:57:12.266
使用了CI PRINT
TREE 即graphviz

00:57:12.799 --> 00:57:16.303
在這裏我們使用了
CI PRINT TREE=8

00:57:17.104 --> 00:57:18.772
通過利用graphviz選項

00:57:19.339 --> 00:57:22.009
我們可以看到處理器節點 還有其與

00:57:22.075 --> 00:57:23.410
圖的其他部分完全融合

00:57:23.877 --> 00:57:27.080
我們還可以看到
所請求的RGBAf輸出

00:57:30.684 --> 00:57:33.754
我們複習下今天都學了些什麼吧

00:57:34.221 --> 00:57:37.424
David給我們展示了
如何在iOS上編輯RAW圖像

00:57:38.025 --> 00:57:39.159
然後Etienne跟我們講了

00:57:39.226 --> 00:57:42.429
你如何利用Core Image
編輯Live Photos

00:57:42.496 --> 00:57:45.365
最後我們看到了如何使用

00:57:45.432 --> 00:57:47.734
CIImage上叫做
CIImageProcessor的新API

00:57:47.801 --> 00:57:51.104
還有如何在你的kernels上
聲明一個輸出格式

00:57:51.171 --> 00:57:53.207
藉以減少內存佔用

00:57:54.942 --> 00:57:56.310
爲了獲取更多信息

00:57:56.376 --> 00:57:58.745
請訪問developer.apple.com

00:58:00.881 --> 00:58:03.116
有一些相關的演講
你們可能會感興趣

00:58:03.183 --> 00:58:06.353
特別是如果你打算
在iOS上做RAW處理的話

00:58:06.420 --> 00:58:09.156
還有Etienne提到的
“iOS攝影進階”

00:58:09.790 --> 00:58:13.794
今天晚些時候還有個講座叫
“用廣色域來工作”

00:58:14.161 --> 00:58:15.529
還是在這進行

00:58:16.930 --> 00:58:18.665
非常感謝大家的到來

00:58:18.732 --> 00:58:20.567
我希望你們在接下來的
WWDC過得愉快