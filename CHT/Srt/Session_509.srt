00:00:19.700 --> 00:00:20.567 
大家好

00:00:20.767 --> 00:00:24.367 
我是Henry Mason
是Siri語音識別工程師

00:00:25.433 --> 00:00:28.733 
今天我們非常激動地
發佈一項全新的API

00:00:28.933 --> 00:00:32.567 
它將讓語音識別
也能爲你的app解決問題

00:00:35.100 --> 00:00:37.767 
先快速回顧一下什麼是語音識別

00:00:38.300 --> 00:00:40.467 
語音識別是自動的過程

00:00:40.533 --> 00:00:43.500 
將人類語音的音頻轉換成文本

00:00:44.133 --> 00:00:46.267 
它取決於語音的語言

00:00:46.467 --> 00:00:49.533 
比如 英語會和漢語的識別不同

00:00:50.233 --> 00:00:52.333 
在iOS 大多數人會想到Siri

00:00:52.433 --> 00:00:55.367 
但語音識別對許多其他任務也有用

00:00:56.367 --> 00:00:58.767 
由於Siri與iPhone 4S
一起發佈

00:00:59.200 --> 00:01:01.600 
iOS也帶有keyboard聽寫

00:01:02.700 --> 00:01:06.267 
在iOS keyboard空格鍵旁
那個小小的麥克風按鍵

00:01:06.333 --> 00:01:10.067 
觸發對任何UI kit
文本輸入的語音識別

00:01:11.033 --> 00:01:13.733 
每天有成千上萬個應用使用這個功能

00:01:14.200 --> 00:01:17.300 
事實上 大約三分之一的請求
來自第三方應用

00:01:18.100 --> 00:01:20.067 
它使用起來極其方便

00:01:20.133 --> 00:01:23.400 
它處理錄音和錄音中斷

00:01:23.667 --> 00:01:25.567 
它顯示用戶界面

00:01:25.633 --> 00:01:27.433 
它不需要你再寫任何代碼

00:01:27.500 --> 00:01:29.700 
就能支持任何文本輸入

00:01:30.600 --> 00:01:32.700 
而且它從iOS 5開始就可供使用

00:01:32.767 --> 00:01:35.900 
iOS keyboard聽寫
從2011年起便可供使用

00:01:35.967 --> 00:01:38.333 
但它的簡化帶來很多限制

00:01:40.033 --> 00:01:43.567 
你的用戶界面
通常並不需要keyboard

00:01:44.433 --> 00:01:47.133 
當錄音開始時你不能控制

00:01:47.733 --> 00:01:49.867 
不能控制使用哪一種語言

00:01:49.933 --> 00:01:52.667 
只是剛好使用系統的
keyboard語言

00:01:53.167 --> 00:01:56.433 
甚至沒有辦法知道
聽寫鍵是否可用

00:01:58.100 --> 00:02:01.633 
默認錄音可能對你的使用案例不合理

00:02:02.267 --> 00:02:04.733 
你可能想要更多信息 而不只是文本

00:02:07.100 --> 00:02:09.133 
那麼現在在iOS 10

00:02:09.199 --> 00:02:11.567 
我們引入一種新的語音框架

00:02:11.667 --> 00:02:14.233 
語音識別API更加強大

00:02:14.300 --> 00:02:18.533 
它使用相同基本技術和Siri及
Dictation中所使用的一樣

00:02:19.500 --> 00:02:21.600 
它提供快速而準確的結果

00:02:21.833 --> 00:02:24.167 
顯而易見地定製給用戶

00:02:24.600 --> 00:02:26.800 
而無需你收集任何用戶數據

00:02:29.033 --> 00:02:31.633 
該框架也提供了識別的更多信息

00:02:33.300 --> 00:02:35.300 
而不只是文本

00:02:36.333 --> 00:02:38.900 
例如 我們也提供另外的解讀

00:02:38.967 --> 00:02:42.867 
關於你的用戶可能說了什麼
置信水平 以及定時信息

00:02:44.433 --> 00:02:47.800 
用於API的音頻可來自預錄文件

00:02:47.900 --> 00:02:49.600 
或現場來源 比如麥克風

00:02:49.667 --> 00:02:52.167 
語音識別API的可用性
深遠而廣泛 經過許可

00:02:52.233 --> 00:02:57.133 
iOS 10支持超過50種語言和
方言 從阿拉伯語到越南語

00:02:59.000 --> 00:03:01.433 
任何運行iOS 10的設備都支持

00:03:03.233 --> 00:03:06.200 
語音識別API
通常能勝任

00:03:06.267 --> 00:03:09.367 
在需要互聯網連接的大型服務器上

00:03:10.367 --> 00:03:15.800 
不過 某些新的設備確實
時刻都支持語音識別

00:03:16.400 --> 00:03:18.833 
我們提供可用性API以確定

00:03:18.900 --> 00:03:21.133 
某個既定語言當前是否可用

00:03:21.400 --> 00:03:25.233 
使用這個 而不是去尋找互聯網連接

00:03:28.267 --> 00:03:29.700 
由於語音識別需要

00:03:29.767 --> 00:03:32.100 
傳送用戶的音頻經過互聯網

00:03:32.633 --> 00:03:34.667 
用戶必須明確提供許可給你的應用

00:03:34.733 --> 00:03:37.767 
在可以使用語音識別之前

00:03:39.367 --> 00:03:40.767 
語音識別
解釋、授權、請求

00:03:40.833 --> 00:03:44.200 
有四個主要步驟
在你的應用中採用語音識別

00:03:46.733 --> 00:03:50.267 
首先在應用的Info.plist中
提供使用描述

00:03:51.533 --> 00:03:54.967 
例如 你的相機應用Phromage

00:03:55.033 --> 00:03:59.400 
可能用了語音識別的使用描述...

00:04:00.333 --> 00:04:04.167 
這能讓你只說cheese就能拍照

00:04:05.967 --> 00:04:10.367 
其次 請求授權
利用請求授權級別方法

00:04:11.467 --> 00:04:14.300 
你先前提供的解釋會被呈現給用戶

00:04:14.367 --> 00:04:16.533 
在一個熟悉的對話中

00:04:17.200 --> 00:04:18.800 
然後用戶將能夠決定

00:04:18.867 --> 00:04:21.666 
他們是否想要讓你的應用語音識別

00:04:23.200 --> 00:04:25.500 
接下來 創建語音識別請求

00:04:27.133 --> 00:04:29.500 
如果你已經有錄好的音頻文件

00:04:29.567 --> 00:04:33.433 
使用SFSpeechURL
RecognitionRequest級別

00:04:34.000 --> 00:04:35.100 
否則 你要使用

00:04:35.167 --> 00:04:38.800 
SFSpeechAudioBuffer
RecognitionRequest

00:04:40.767 --> 00:04:42.667 
最後 提交識別請求

00:04:42.733 --> 00:04:45.433 
給SFSpeech Recognizer
開始識別

00:04:46.333 --> 00:04:49.267 
你可以選擇保留返回的識別任務

00:04:49.333 --> 00:04:52.867 
這有助於監控識別過程

00:04:56.700 --> 00:04:58.567  
我們來看看這個在代碼中長什麼樣

00:04:59.300 --> 00:05:01.467  
假定我們已更新info.plist

00:05:01.533 --> 00:05:04.733  
通過準確的描述
關於如何使用它

00:05:05.467 --> 00:05:07.500  
下一步是請求授權

00:05:08.667 --> 00:05:10.467  
也許最好等到

00:05:10.533 --> 00:05:12.733  
用戶調用你的應用的功能後再這樣做

00:05:12.800 --> 00:05:14.667  
這個功能要依靠語音識別

00:05:17.267 --> 00:05:20.633  
請求授權級別方法
藉助完成處理程序

00:05:20.700 --> 00:05:23.433  
它不保證某個執行語境

00:05:24.533 --> 00:05:27.100  
應用通常要發送到主隊列

00:05:27.167 --> 00:05:31.000  
如果它們要做點什麼
比如開啓或關閉用戶界面按鈕

00:05:33.967 --> 00:05:37.600  
如果你的授權處理程序
已給出authorized狀態

00:05:38.200 --> 00:05:40.100  
你應該準備開始識別

00:05:41.567 --> 00:05:44.300 
否則 識別就無法對你的應用可用

00:05:45.500 --> 00:05:48.500 
重要的是採用合適的方法
禁用必要的功能

00:05:48.567 --> 00:05:50.267 
當用戶作出這個決定時

00:05:50.800 --> 00:05:54.767 
或當設備受限 無法使用語音識別時

00:05:55.500 --> 00:05:59.300 
授權可稍後修改
在設備的隱私設置裏

00:06:01.633 --> 00:06:04.900  
我們來看看如何識別
一個預錄的音頻文件

00:06:05.867 --> 00:06:08.133  
假設我們已有一個文件url

00:06:09.800 --> 00:06:14.867  
識別需要語音識別程序
它只識別一種語言

00:06:15.467 --> 00:06:19.833  
默認的SFSpeechRecognizer
啓動程序可能會失敗

00:06:20.533 --> 00:06:23.933  
於是我返回0
如果區域不支持的話

00:06:24.833 --> 00:06:27.867  
默認的啓動程序使用設備的當前區域

00:06:29.800 --> 00:06:32.400  
在這個功能中
我們只要返回1 在這個情況下

00:06:34.700 --> 00:06:38.633  
雖然這個語音識別可能受支持
但它也許不可用

00:06:38.700 --> 00:06:41.133  
可能由於沒有互聯網連接

00:06:41.900 --> 00:06:45.833  
使用isAvailable屬性
在你的識別程序中 以便監控它

00:06:48.833 --> 00:06:52.400  
現在我們創建一個識別請求
用錄好的文件的url

00:06:52.467 --> 00:06:57.300  
然後將它給予識別程序的識別任務方法

00:07:01.967 --> 00:07:03.800 
這個方法完成處理程序

00:07:03.867 --> 00:07:06.467 
藉助兩種可選的參數
result和error

00:07:07.600 --> 00:07:09.233 
如果result是0

00:07:09.300 --> 00:07:11.700 
那意味着出於某種原因 識別失敗

00:07:12.000 --> 00:07:14.267 
檢查error的參數 尋求解釋

00:07:15.667 --> 00:07:18.900 
否則 我們可以讀出
我們已經識別的語音

00:07:19.233 --> 00:07:20.367 
通過查看結果

00:07:21.633 --> 00:07:25.167 
注意 完成處理程序
可能會被喚起不止一次

00:07:25.233 --> 00:07:27.267 
當語音被逐步識別

00:07:28.200 --> 00:07:30.400 
你可以確定識別已完成

00:07:30.467 --> 00:07:33.900 
通過檢查結果的isFinal屬性

00:07:34.667 --> 00:07:37.600 
這裏我們只打印出最終識別的文本

00:07:43.833 --> 00:07:47.867  
識別來自設備麥克風的
現場音頻也很相似

00:07:47.933 --> 00:07:49.400  
但需要一些改動

00:07:50.500 --> 00:07:53.367  
我們要做出音頻緩衝識別請求

00:07:53.867 --> 00:07:56.933  
這能讓我們提供內存音頻緩衝的序列

00:07:57.000 --> 00:07:58.567  
而不是硬盤上的文件

00:07:59.633 --> 00:08:03.300  
我們使用AVAudioEngine
來獲取音頻緩衝流

00:08:04.933 --> 00:08:06.700  
然後將其附加到請求

00:08:07.467 --> 00:08:09.733  
注意 完全可以附加音頻緩衝

00:08:09.800 --> 00:08:13.533  
到識別請求
在開始識別之前和之後

00:08:17.333 --> 00:08:18.233 
一個不同之處在於

00:08:18.300 --> 00:08:22.767 
我們不再忽略識別任務方法的返回值

00:08:23.400 --> 00:08:25.733 
反而 我們要將它保存在
一個變量的屬性中

00:08:26.300 --> 00:08:27.533 
等會兒我們就知道爲什麼

00:08:28.833 --> 00:08:30.100 
當我們完成錄音後

00:08:31.133 --> 00:08:34.232 
我們需要通知請求
沒有更多音頻了

00:08:34.299 --> 00:08:35.967 
以便它能完成識別

00:08:36.933 --> 00:08:39.200 
使用endAudio方法來實現

00:08:40.267 --> 00:08:44.100 
但要是用戶取消錄音
或者錄音被中斷呢？

00:08:44.733 --> 00:08:47.333 
在這種情況下 我們真的不關心結果

00:08:47.400 --> 00:08:51.000 
而且我們應該釋放
仍在被語音識別使用的任何資源

00:08:52.700 --> 00:08:55.067 
只要取消我們開始的識別任務...

00:08:55.133 --> 00:08:57.000 
我們開始識別時保存的

00:08:57.367 --> 00:09:00.100 
這對於預錄音頻的識別也能做到

00:09:00.967 --> 00:09:02.100 
最佳做法

00:09:02.167 --> 00:09:04.633 
簡單說說一些最佳做法

00:09:05.833 --> 00:09:07.367 
資源
負責任

00:09:07.433 --> 00:09:10.667 
我們開放語音識別
給所有應用免費使用

00:09:11.233 --> 00:09:13.100 
但我們的確有設置一些合理的限制

00:09:13.167 --> 00:09:15.600 
以便這項服務一直對每個人可用

00:09:17.100 --> 00:09:20.033 
不同的設備可能受限於

00:09:20.100 --> 00:09:21.700 
每天可以識別的量

00:09:22.967 --> 00:09:26.900 
應用也會在全球範圍內被節流
根據每天的請求

00:09:28.600 --> 00:09:33.133 
正如API支持的其他服務
例如CLGO Coder

00:09:33.567 --> 00:09:36.733 
要有所準備以處理
網絡和速率受限的故障

00:09:38.233 --> 00:09:40.667 
如果你發現你經常達到節流的限制

00:09:40.733 --> 00:09:41.767 
請告訴我們

00:09:44.633 --> 00:09:46.833 
同樣重要的是 要注意語音識別

00:09:46.900 --> 00:09:50.467 
會極大地耗費電池和網絡流量

00:09:52.333 --> 00:09:56.900  
對於iOS 10我們開始限制
音頻長度爲大約一分鐘

00:09:56.967 --> 00:09:59.133  
類似於keyboard聽寫的時長

00:10:01.100 --> 00:10:02.767 
隱私和可用性
透明度

00:10:02.833 --> 00:10:06.500 
簡單說說關於透明度
以及尊重用戶的隱私

00:10:07.600 --> 00:10:09.267 
如果你在錄用戶的語音

00:10:09.333 --> 00:10:12.833 
最好在你的用戶界面中說得非常明確

00:10:13.533 --> 00:10:17.100 
播放錄製的聲音和/或
顯示可見的錄製指示

00:10:17.167 --> 00:10:20.167 
可讓用戶清楚知道他們正在被錄音

00:10:22.133 --> 00:10:24.733 
有些語音不適合識別

00:10:25.467 --> 00:10:29.133 
密碼、健康數據、財務信息
以及其他敏感語音

00:10:29.200 --> 00:10:31.333 
不應給予語音識別

00:10:33.733 --> 00:10:37.100 
顯示識別的語音
像Siri和Dictation做的

00:10:37.167 --> 00:10:40.333 
也能幫助用戶理解你的應用在做什麼

00:10:40.900 --> 00:10:42.467 
它對用戶很有幫助

00:10:42.533 --> 00:10:45.300 
以便他們可以在識別出錯時及時看到

00:10:46.500 --> 00:10:47.767 
總結

00:10:47.833 --> 00:10:49.300 
那麼 開發者們

00:10:49.367 --> 00:10:50.867 
你們的應用現在可以免費獲得

00:10:50.933 --> 00:10:54.233 
高性能的語音識別
可識別幾十種語言

00:10:54.933 --> 00:10:57.567 
但重要的是要得體地處理
當它不可用時的情況

00:10:57.633 --> 00:10:59.833 
或者用戶不想讓你的應用使用它

00:11:01.067 --> 00:11:03.233 
透明度是最好的政策

00:11:03.400 --> 00:11:06.500 
讓用戶清楚知道
什麼時候語音識別正在被使用

00:11:07.900 --> 00:11:12.300 
我們很興奮地期待
你們會爲語音識別帶來什麼新用途

00:11:13.200 --> 00:11:14.033 
更多信息

00:11:14.100 --> 00:11:18.400 
欲瞭解更多信息及一些樣本代碼
請查看本講的網頁

00:11:18.900 --> 00:11:21.700 
你可能會對部分關於
SiriKit的會話感興趣

00:11:21.867 --> 00:11:25.633 
週三有一場
週四有一場更高級別的

00:11:26.633 --> 00:11:29.233 
謝謝參與
祝你們在 WWDC 大有收穫