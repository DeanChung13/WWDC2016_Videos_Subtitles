00:00:19.653 --> 00:00:22.055
神經網絡和加速

00:00:23.624 --> 00:00:26.627
下午好 歡迎來到“加速”演講

00:00:27.394 --> 00:00:29.363
我是Eric Bainville...

00:00:29.863 --> 00:00:32.698
我是核心OS
向量和數值團隊的一員

00:00:34.735 --> 00:00:38.105
我們組提供對CPU性能優化的庫

00:00:38.972 --> 00:00:42.409
優化性能的庫通常意味着
我們要與底層的東西打交道

00:00:42.476 --> 00:00:46.380
能提供大計算量的函數
比如 求矩陣積

00:00:46.647 --> 00:00:48.482
傅立葉變換 之類的

00:00:49.516 --> 00:00:52.653
大多數這些函數被包括在
Accelerate框架裏

00:00:52.819 --> 00:00:56.990
我們有 像vImage
一個用於圖像處理的庫

00:00:57.691 --> 00:00:59.893
它能被用於類型轉換

00:00:59.960 --> 00:01:02.930
也能用於對圖像的幾何變換

00:01:04.298 --> 00:01:06.300
挨着vImage
你們會看到vDSP

00:01:06.366 --> 00:01:09.169
它主要被用於信號處理
像傅立葉變換

00:01:09.436 --> 00:01:11.605
和其它信號處理的用途

00:01:13.340 --> 00:01:18.979
然後 我們有BLAS
一個用於線性代數的庫

00:01:19.179 --> 00:01:21.381
它已經很老了
它創建於70年代

00:01:21.648 --> 00:01:24.484
幾年前
我們添加了SparseBLAS

00:01:24.551 --> 00:01:27.221
用於向量和矩陣的稀疏計算

00:01:27.521 --> 00:01:30.390
我們也在LinearAlgebra裏
提供了LAPACK

00:01:30.457 --> 00:01:33.060
一個用於線性代數的高級庫

00:01:34.127 --> 00:01:38.131
在Accelerate之外
我們還有一些庫

00:01:38.465 --> 00:01:40.567
比如simd 它包含了一組標頭

00:01:40.901 --> 00:01:45.305
能讓你們對向量指令和類型
直接進行讀寫

00:01:45.372 --> 00:01:48.609
但它們不會操控CPU的向量單元

00:01:48.675 --> 00:01:53.280
它們介於中層和外層
不會改寫彙編代碼

00:01:54.248 --> 00:01:56.783
我們還在去年添加了
compression

00:01:56.850 --> 00:01:58.385
用於無損壓縮

00:01:59.419 --> 00:02:03.557
對所支持的CPU
我們爲所提供的技術進行了優化

00:02:03.690 --> 00:02:06.293
所以 當你們拿到新手機
我們爲它的代碼進行優化

00:02:06.860 --> 00:02:08.294
這樣你們就不用爲此擔心了

00:02:08.996 --> 00:02:10.264
好 那今天...

00:02:11.198 --> 00:02:13.834
首先 我們來簡單地回顧下
compression

00:02:15.302 --> 00:02:18.639
然後 我們將介紹兩個
在Accelerate裏新的庫

00:02:19.039 --> 00:02:23.777
BNNS 它是一組用於神經網絡
低級計算的函數

00:02:25.612 --> 00:02:27.214
還有Quadrature

00:02:27.381 --> 00:02:31.752
它是一個用於求
函數數值積分的小型的庫

00:02:32.019 --> 00:02:34.154
之後 我的同事Steve會上臺

00:02:34.221 --> 00:02:36.657
介紹simd的新添項

00:02:37.658 --> 00:02:39.359
好 首先 在我們開始之前

00:02:39.493 --> 00:02:42.262
讓我向你們簡單介紹下
Accelerate的使用

00:02:42.896 --> 00:02:45.599
基於你們對語言的選擇

00:02:45.766 --> 00:02:50.003
你們要用import或
include導入函數的聲明

00:02:50.537 --> 00:02:53.941
之後 你們要鏈接
Accelerate框架

00:02:54.074 --> 00:02:57.644
那從Xcode的你們的項目設置裏
你們要瀏覽至

00:02:57.744 --> 00:03:02.049
target
然後點擊build phases

00:03:02.816 --> 00:03:04.051
出現一個窗口

00:03:04.218 --> 00:03:06.753
點擊Link Binary With Libraries

00:03:06.820 --> 00:03:07.821
打開它

00:03:08.655 --> 00:03:09.489
好的

00:03:09.756 --> 00:03:12.426
點開這裏有個小加號的地方

00:03:13.427 --> 00:03:16.964
你們會看到一個
所有能被鏈接的庫和框架的列表

00:03:17.030 --> 00:03:18.832
Accelerate在第一個

00:03:24.938 --> 00:03:27.441
好的

00:03:27.508 --> 00:03:30.444
那如果它不在第一個
在上面有個搜索欄

00:03:30.511 --> 00:03:32.779
若要找compression
輸入compression

00:03:32.846 --> 00:03:34.114
我知道compression
一定會在裏面

00:03:34.481 --> 00:03:36.683
好的 現你們就在使用
Accelerate了

00:03:36.750 --> 00:03:38.886
好

00:03:39.052 --> 00:03:40.220
那compression...

00:03:40.287 --> 00:03:43.090
記得當去年Sebastian

00:03:43.156 --> 00:03:46.493
在平臺詳情諮文介紹LZFSE時

00:03:46.560 --> 00:03:48.562
我們都不知道他們是誰

00:03:48.729 --> 00:03:53.400
但今天我們要宣佈對LZFSE開源

00:03:53.867 --> 00:03:55.669
你們可以在GitHub上找到它

00:03:55.769 --> 00:03:58.305
我們以BSD許可的形式發佈它

00:03:59.940 --> 00:04:03.277
讓我提一下 你們會想用它的理由

00:04:03.710 --> 00:04:06.947
這些是平臺比較
在LZFSE

00:04:07.014 --> 00:04:09.616
和zlib之間 使用相同的選項

00:04:10.284 --> 00:04:14.621
我們的編碼速度要快1.4倍
解碼速度要快2.6倍

00:04:16.023 --> 00:04:17.891
好的
這就是我們的compression

00:04:18.257 --> 00:04:19.793
現在讓我們來看下BNNS

00:04:20.194 --> 00:04:22.262
“基礎神經網絡子程序”

00:04:22.829 --> 00:04:24.598
這個名字看起來很像BLAS

00:04:24.665 --> 00:04:26.900
BLAS是指“基礎線性代數子程序”

00:04:27.100 --> 00:04:29.903
如我之前所提
它起源於70年代

00:04:30.671 --> 00:04:35.943
BNNS提供了一組低級計算例程

00:04:36.109 --> 00:04:38.912
我稍後細說

00:04:40.581 --> 00:04:42.082
我們只做低級計算

00:04:42.149 --> 00:04:44.718
像求矩陣積 但針對於神經網絡

00:04:45.986 --> 00:04:48.822
在我細講它的作用

00:04:49.022 --> 00:04:50.257
和相關的API之前

00:04:50.324 --> 00:04:54.728
讓我們來回顧下神經網絡

00:04:55.395 --> 00:04:57.598
假設我們有這樣一個網絡

00:04:57.965 --> 00:05:00.701
我們訓練了它去識別動物

00:05:00.767 --> 00:05:02.536
那作爲輸入 你們有一個圖像

00:05:02.603 --> 00:05:04.571
然後 你們有這個橘色的大框

00:05:04.805 --> 00:05:08.709
在橘色的框裏
這個紅色的框代表了權值

00:05:09.142 --> 00:05:11.545
這些是這個網絡的參數

00:05:11.612 --> 00:05:14.448
作爲輸出 我們有四個值

00:05:14.615 --> 00:05:17.017
這些是相應的概率
對於是一隻貓 一隻狗

00:05:17.084 --> 00:05:18.685
一隻長頸鹿或一條蛇

00:05:19.386 --> 00:05:21.255
好的　那首先你們要訓練它

00:05:21.321 --> 00:05:22.823
假設你們有個貓的圖像

00:05:23.657 --> 00:05:27.761
你們通過網絡處理這貓的圖像
並得到一個答案

00:05:28.428 --> 00:05:30.764
這是最高的概率
它說是隻狗

00:05:31.465 --> 00:05:33.467
呵呵 這就是你們需要訓練它的原因

00:05:33.800 --> 00:05:37.004
事實上是隻貓 那你們要做的是

00:05:37.471 --> 00:05:39.473
反向傳播正確答案

00:05:39.540 --> 00:05:41.842
如果我稍許改動下權值 會怎麼樣

00:05:42.543 --> 00:05:47.314
那現在這個網絡會稍偏向
貓的方向

00:05:47.781 --> 00:05:53.587
你們要使用大量的圖像
做這個成千上萬次

00:05:53.820 --> 00:05:55.122
在某一刻

00:05:56.023 --> 00:05:59.159
你們會有一個訓練好的網絡
能正確回答

00:05:59.226 --> 00:06:00.961
每一個請求

00:06:01.028 --> 00:06:03.463
如果是隻長頸鹿

00:06:05.032 --> 00:06:07.334
它會說是隻長頸鹿
因爲你們正確地訓練了它

00:06:08.735 --> 00:06:10.938
好的　這就是神經網絡所能做的

00:06:11.004 --> 00:06:13.574
注意訓練和推測的區別

00:06:13.640 --> 00:06:15.843
在推測時 我們不改變權值

00:06:16.076 --> 00:06:18.312
那一般來說 假設你們有這樣一個應用

00:06:18.912 --> 00:06:21.748
你們要在線下做這些訓練

00:06:21.949 --> 00:06:23.817
當你們創建應用時
做你們的訓練

00:06:23.884 --> 00:06:26.253
那當你們改動應用時
你們要改動權值

00:06:26.320 --> 00:06:28.222
和網絡拓撲

00:06:28.322 --> 00:06:31.592
最後能讓它在設備上進行推測

00:06:32.526 --> 00:06:35.495
好的
那在這個橘色的框裏有些什麼？

00:06:35.562 --> 00:06:36.797
讓我給你們個例子

00:06:36.864 --> 00:06:39.600
若你們去了“Metal的新特性
第二部分”演講

00:06:39.933 --> 00:06:42.936
一個昨天的講座
你們已經見過了個更大型的例子

00:06:43.270 --> 00:06:45.572
一個場景識別網絡

00:06:45.672 --> 00:06:48.008
和一個對笑臉識別網絡的展示

00:06:48.108 --> 00:06:51.011
這都是些進階的網絡
它們有成百上千的層面

00:06:51.178 --> 00:06:54.281
這個是五年前最前沿的技術

00:06:54.348 --> 00:06:58.986
它描述了一個百數位識別網絡

00:06:59.620 --> 00:07:01.288
那作爲輸入
你們有個小型的圖像

00:07:01.455 --> 00:07:04.758
一個對手寫的捕捉

00:07:05.225 --> 00:07:07.127
然後它被遞入各個層面

00:07:07.461 --> 00:07:09.763
這裏你們有個5x5的卷積

00:07:10.063 --> 00:07:12.566
輸出會是一個含五個圖像的堆棧

00:07:13.367 --> 00:07:16.703
這個輸出是五個有着不同權值的卷積

00:07:17.104 --> 00:07:19.239
然後 你們添加另一個層面

00:07:19.773 --> 00:07:23.710
你們對這五個圖像應用更多的卷積

00:07:23.777 --> 00:07:25.779
你們會得到一個更大的堆棧

00:07:26.146 --> 00:07:29.149
包含五十個5x5像素的圖像

00:07:29.349 --> 00:07:33.854
那這樣 你們從圖像空間

00:07:33.921 --> 00:07:37.090
一層層地來到了特徵空間

00:07:37.758 --> 00:07:41.028
這些小型圖像的內容變得
越來越抽象

00:07:41.094 --> 00:07:43.096
最後就只有特徵

00:07:43.197 --> 00:07:45.399
那會告訴你們那是個零或那是個一

00:07:45.465 --> 00:07:47.100
這是你們想要的輸出

00:07:47.501 --> 00:07:48.335
好的

00:07:48.735 --> 00:07:51.104
那通過使用少量的層面

00:07:51.238 --> 00:07:54.174
你們可以達到目的
並且效果還不錯

00:07:54.641 --> 00:07:59.079
那在這些卷積之後
我們把這些5x5x50的值

00:07:59.880 --> 00:08:01.949
作爲一個大型的向量

00:08:02.449 --> 00:08:05.085
對其應用一個全面連接層面

00:08:05.152 --> 00:08:07.054
其實就是求個大型的矩陣積

00:08:07.120 --> 00:08:11.658
它會將所有值混合
然後輸出一組100個值

00:08:12.392 --> 00:08:15.362
在這個模型裏 被稱爲隱藏層面

00:08:16.396 --> 00:08:21.635
之後你們需要最後一步
使這100個值

00:08:21.935 --> 00:08:24.771
混合在一起
然後產生10個你們你們想要的輸出

00:08:24.905 --> 00:08:27.040
這裏 你們在計算未來空間

00:08:27.474 --> 00:08:31.211
這裏的每個數值對應着
成爲一個具體數字的概率

00:08:31.945 --> 00:08:32.779
好的

00:08:32.846 --> 00:08:34.581
這就是這個網絡的結構

00:08:34.648 --> 00:08:38.452
如你們所見
我們有兩個不同類別的層面

00:08:38.519 --> 00:08:40.153
這正是我們在BNNS所實現的

00:08:40.220 --> 00:08:42.623
我們提供對這些層面的計算部分

00:08:44.258 --> 00:08:47.227
好　在我們開始討論計算

00:08:47.294 --> 00:08:49.396
和相關API之前
讓我向你們展示些數字

00:08:49.463 --> 00:08:52.533
這裏我們將用Caffe作對比

00:08:52.933 --> 00:08:56.770
它是一個知名的
神經網絡計算程序包

00:08:57.337 --> 00:08:59.473
這是Caffe有關卷積的部分

00:08:59.573 --> 00:09:02.042
我們有14個不同卷積的大小

00:09:02.509 --> 00:09:03.810
在這裏 你們可以看下

00:09:04.545 --> 00:09:08.649
這是Caffe的處理時間...

00:09:09.616 --> 00:09:11.652
這是速度
所以值越高越好

00:09:11.718 --> 00:09:13.720
通過Caffe處理這些卷積

00:09:13.987 --> 00:09:15.923
這是你們用BNNS所得的結果

00:09:16.790 --> 00:09:18.892
從平均來看 BNNS要快2.1倍

00:09:18.959 --> 00:09:21.028
如果你們有更大的卷積

00:09:21.094 --> 00:09:23.397
你們可以幾乎達到快4倍的速度

00:09:25.365 --> 00:09:27.968
好的　這就是所有的數字

00:09:28.035 --> 00:09:31.038
現在讓我來介紹下BNNS的構架

00:09:32.039 --> 00:09:34.074
它是一個低級計算函數的集合

00:09:34.141 --> 00:09:37.010
與BLAS十分相似
這也是我們將其取名爲BNNS的原因

00:09:37.678 --> 00:09:41.048
它並不知道
什麼是神經網絡

00:09:41.248 --> 00:09:43.650
這意味着
那是你們要知道的事

00:09:43.784 --> 00:09:46.954
它只提供計算的部分

00:09:48.689 --> 00:09:51.058
並且它只執行推測

00:09:51.792 --> 00:09:52.793
事實上

00:09:52.860 --> 00:09:55.629
我覺得 在設備上運行訓練不合理

00:09:55.696 --> 00:09:56.730
成本太高

00:09:56.797 --> 00:09:59.333
你們會要有數以萬計的圖像和計算

00:09:59.600 --> 00:10:00.701
這不會合適

00:10:00.968 --> 00:10:04.104
那一般來說 推測會在線下完成
如我所述

00:10:04.404 --> 00:10:07.774
你們會在應用上執行推測

00:10:08.041 --> 00:10:10.143
我們提供三個不同類別的層面

00:10:10.377 --> 00:10:12.212
卷積層 池化層

00:10:12.279 --> 00:10:14.081
和全面連接層

00:10:14.348 --> 00:10:15.549
爲什麼？ 因爲...

00:10:16.116 --> 00:10:20.554
實際上 在現代的網絡
你們會花費百分之七十五的時間

00:10:20.621 --> 00:10:22.022
於計算卷積

00:10:22.389 --> 00:10:24.625
接下來是池化層

00:10:24.691 --> 00:10:26.627
使用約百分之十五

00:10:27.094 --> 00:10:29.496
全面連接層也會花費許多時間

00:10:29.563 --> 00:10:32.733
但你們通常在網絡的末端看見它

00:10:33.233 --> 00:10:35.435
像在例子裏見到的 只有兩個

00:10:35.802 --> 00:10:37.838
在末端的全面連接層

00:10:38.205 --> 00:10:40.140
但這還是要花費許多時間

00:10:40.741 --> 00:10:44.278
好的　現在我們瞭解了構架

00:10:44.344 --> 00:10:47.281
我將細講這三個不同類別的層面

00:10:47.447 --> 00:10:51.585
和我們計算些什麼
還有如何通過API來創建它們

00:10:52.252 --> 00:10:54.488
讓我們從卷積層開始

00:10:55.322 --> 00:10:56.523
這是一個卷積

00:10:56.590 --> 00:10:58.158
它使用一個輸入圖像

00:10:58.692 --> 00:11:01.662
一組權值 中間橘色的矩陣

00:11:01.728 --> 00:11:03.797
然後輸出圖像裏的每一個像素

00:11:04.531 --> 00:11:08.335
是通過計算對每一組輸入像素

00:11:08.502 --> 00:11:10.470
與權值的的積

00:11:10.604 --> 00:11:13.373
之後將結果相加
得到你們上方的像素

00:11:13.774 --> 00:11:16.510
你們要對每一個輸出像素
執行上述步驟

00:11:16.877 --> 00:11:19.179
那如果你數下
這是個四維的循環

00:11:19.246 --> 00:11:21.181
因爲你們要循環x和y

00:11:21.415 --> 00:11:23.250
還有內核的維數

00:11:24.084 --> 00:11:26.520
現實裏 要比上述更復雜些

00:11:26.587 --> 00:11:29.323
因爲我們的輸入不僅是一個圖像

00:11:29.389 --> 00:11:30.858
我們有一堆圖像

00:11:31.191 --> 00:11:33.227
那我們要複製權值

00:11:33.927 --> 00:11:37.998
並知道在每一層
我們在計算此卷積

00:11:38.298 --> 00:11:40.133
然後再將它們相加

00:11:40.200 --> 00:11:42.336
獲取我們的輸出像素

00:11:42.836 --> 00:11:45.239
那現在循環就是五維的了

00:11:45.706 --> 00:11:48.275
我在公式裏添加了IC參數

00:11:48.909 --> 00:11:51.044
這其實不是我們要計算的

00:11:51.278 --> 00:11:53.380
因爲我們還要有個輸出堆棧

00:11:53.780 --> 00:11:56.550
那實際上 我們在卷積裏是在
做這樣的計算

00:11:56.750 --> 00:12:00.721
我們重複這個多次
每一次爲一個輸出層

00:12:01.288 --> 00:12:03.557
那現在我們有個六維的循環

00:12:04.024 --> 00:12:06.827
這意味着 即使每個維度都很小

00:12:06.894 --> 00:12:10.731
像在這個例子裏
我們沒有大於264的

00:12:11.098 --> 00:12:13.800
這的確很小 但你們將它們相乘

00:12:13.867 --> 00:12:15.969
你們會有幾十億的操作

00:12:16.036 --> 00:12:18.672
這相當於幾十毫秒的計算量

00:12:19.373 --> 00:12:21.975
那對大很多的整個網絡來講

00:12:22.543 --> 00:12:25.245
你們會有數以兆計的浮點運算操作

00:12:25.312 --> 00:12:27.814
這相當於幾秒的CPU時間

00:12:28.682 --> 00:12:30.851
好的　一個在卷積層的計算

00:12:30.918 --> 00:12:33.120
怎樣通過BNNS來實現？

00:12:33.320 --> 00:12:36.723
那首先 你們要描述你們的輸入堆棧

00:12:37.591 --> 00:12:41.094
你們要指定圖像的尺寸

00:12:41.361 --> 00:12:42.863
通道數

00:12:43.096 --> 00:12:46.200
還有在內存裏的分層

00:12:46.300 --> 00:12:51.104
包括兩行之間的增量和
兩層面間的增量

00:12:51.305 --> 00:12:53.273
還有很重要的是

00:12:53.440 --> 00:12:55.976
他們的儲存類型

00:12:57.444 --> 00:13:01.915
舉例 我們使用32位浮點數
或甚至64位浮點數

00:13:02.482 --> 00:13:04.885
在神經網絡裏
我們無需這樣的精確度

00:13:04.952 --> 00:13:07.554
一般人們會用16位浮點數

00:13:08.188 --> 00:13:10.390
那很好 因爲這會削減一半的儲存空間

00:13:11.024 --> 00:13:13.493
那本來20兆字節 我們只需10

00:13:13.660 --> 00:13:16.129
如果你們能用整數
8位的整數

00:13:16.196 --> 00:13:17.998
那你們只需5兆字節

00:13:18.298 --> 00:13:21.502
同樣 一般你們的輸出也無需
任何精確度

00:13:22.836 --> 00:13:26.006
所以 你們可以使用
與輸入相同的類型

00:13:26.673 --> 00:13:28.675
你們需要對輸出堆棧作相同的設定

00:13:29.076 --> 00:13:31.512
然後 你們要描述卷積自身

00:13:31.712 --> 00:13:33.313
這包括內核的尺寸

00:13:33.747 --> 00:13:37.417
對輸入的0填充

00:13:38.185 --> 00:13:41.421
x和y在循環裏的增幅

00:13:42.122 --> 00:13:44.157
還有 你們要重複

00:13:44.224 --> 00:13:47.794
輸入和輸出的通道數
還有權值

00:13:47.995 --> 00:13:50.731
那是之前中間橘色的部分

00:13:51.131 --> 00:13:53.667
列出權值 同樣
你們可以設置不同的

00:13:53.734 --> 00:13:55.602
儲存類型給權值

00:13:55.869 --> 00:14:00.274
一般你們將其設定爲16位或8位

00:14:00.741 --> 00:14:06.513
因爲那可以降低內存使用和
儲存空間

00:14:08.348 --> 00:14:09.650
當你們完成了這些

00:14:09.716 --> 00:14:12.653
你們能用這個函數來創建
卷積篩選器

00:14:13.220 --> 00:14:14.988
你們告訴它 這是我的輸入堆棧

00:14:15.055 --> 00:14:17.991
那是我的輸出堆棧
那是我的卷積 創建一個篩選器

00:14:18.458 --> 00:14:20.894
你會獲取一個篩選器對象
然後用它

00:14:20.994 --> 00:14:23.263
對你們的數據應用卷積

00:14:23.864 --> 00:14:25.165
在你們使用完它之後

00:14:25.232 --> 00:14:26.834
你們調用銷燬篩選器

00:14:27.201 --> 00:14:29.937
來移除它並釋放資源

00:14:30.804 --> 00:14:32.372
以上就是關於卷積層的內容

00:14:32.439 --> 00:14:35.075
現在 讓我們來看下池化層

00:14:35.342 --> 00:14:37.544
池化要比卷積簡單些

00:14:38.011 --> 00:14:39.646
要計算一個輸出像素

00:14:39.713 --> 00:14:42.783
你們要使用一組輸入像素

00:14:42.983 --> 00:14:45.152
然後取最大的平均值

00:14:45.385 --> 00:14:46.553
這就是你們的結果

00:14:46.620 --> 00:14:49.690
你們要對所有通道的所有像素
重複這樣的計算

00:14:50.724 --> 00:14:52.226
這就是這公式所形容的

00:14:52.893 --> 00:14:55.929
同樣 爲池化層創建一個篩選器

00:14:56.029 --> 00:14:58.932
你們要描述輸入和輸出堆棧

00:14:59.600 --> 00:15:02.669
與之前一樣
你們也要描述

00:15:03.103 --> 00:15:04.638
池化層自身

00:15:04.705 --> 00:15:07.508
同樣 包括
內核尺寸 填充 增幅

00:15:07.574 --> 00:15:09.176
這裏沒有權值

00:15:09.243 --> 00:15:12.145
那要使用哪個函數來計算輸出

00:15:12.212 --> 00:15:14.014
使用最大平均

00:15:15.549 --> 00:15:18.185
在你們完成這些後
你們就可以創建篩選器

00:15:18.252 --> 00:15:21.121
獲得一個和之前相似的
篩選器對象

00:15:21.722 --> 00:15:25.058
最後我們支持的層面是
全面連接層

00:15:26.426 --> 00:15:29.997
它儘管被稱爲全面連接層
這裏有個隱藏的矩陣積

00:15:30.063 --> 00:15:35.169
作爲輸入你們有一個向量
然後你們要將它與一個矩陣相乘

00:15:35.235 --> 00:15:38.372
加入向量偏量
然後獲取你們的輸出

00:15:39.173 --> 00:15:40.908
就是求個矩陣的積

00:15:41.842 --> 00:15:44.244
這裏 你們的向量裏沒有圖像

00:15:44.311 --> 00:15:47.381
所以 你們要描述向量 它的大小

00:15:47.848 --> 00:15:50.083
與數據對應並且
你們要指定使用的類型

00:15:50.150 --> 00:15:56.390
用於儲存這些值 你們可以使用
32或16位浮點數或整數

00:15:59.593 --> 00:16:04.498
然後你們要通過矩陣的尺寸
來描述這個層面自身

00:16:04.798 --> 00:16:06.500
和矩陣的係數

00:16:07.768 --> 00:16:10.771
偏量不在演示稿裏
但你們有偏量

00:16:11.505 --> 00:16:13.874
之後 你們可以創建一個卷積篩選器

00:16:15.676 --> 00:16:17.945
同樣與之前的篩選器相似

00:16:18.011 --> 00:16:20.848
接下來是怎樣應用篩選器

00:16:21.281 --> 00:16:23.750
你們將輸入數據當作輸出數據

00:16:24.151 --> 00:16:27.788
和你們的篩選器
你們有兩個應用它們的函數

00:16:29.556 --> 00:16:33.327
叫作篩選器應用
如果你們只有一對輸入和輸出

00:16:33.393 --> 00:16:35.229
如果你們有很多對

00:16:35.295 --> 00:16:37.431
你們要調用
篩選器批量應用

00:16:38.532 --> 00:16:41.568
你們告訴它對數

00:16:41.635 --> 00:16:43.737
並且怎樣從一對到另一對

00:16:43.804 --> 00:16:45.339
就是怎樣在內存裏邁進

00:16:47.107 --> 00:16:50.177
好的 這些就是關於BNNS的內容
讓我們總結下

00:16:50.677 --> 00:16:55.415
BNNS是一組針對神經網絡計算的
低級函數

00:16:56.683 --> 00:16:59.219
很低　我們着重於計算
我們完善它

00:16:59.286 --> 00:17:00.254
我們提高它的處理速度

00:17:00.988 --> 00:17:03.624
但它不知道什麼是神經網絡

00:17:03.824 --> 00:17:05.592
它只針對於計算

00:17:07.661 --> 00:17:10.364
我們優化它
讓它變得更快 更省能源

00:17:11.898 --> 00:17:15.636
最主要的是
他支持各種數據類型

00:17:18.405 --> 00:17:19.839
以上就是BNNS的內容

00:17:19.940 --> 00:17:21.308
接下來 Quadrature

00:17:21.441 --> 00:17:23.109
我們收到請求...

00:17:23.810 --> 00:17:29.183
許多人要我們開發一個
用於求數值積分的庫

00:17:29.316 --> 00:17:30.417
那 這就是

00:17:30.817 --> 00:17:33.887
好 那還記得你們在學校裏學的

00:17:34.154 --> 00:17:37.491
它能計算一個函數在區間a b
上的積分

00:17:37.858 --> 00:17:40.694
也就是在曲線和軸之間綠色的部分

00:17:42.496 --> 00:17:45.499
那要使用這個
你們首先要描述函數

00:17:45.933 --> 00:17:47.434
你們要提供一個回調

00:17:47.501 --> 00:17:50.237
我們做的改動之一
與之前的

00:17:50.404 --> 00:17:52.139
舊的庫裏不一樣的是

00:17:52.406 --> 00:17:56.210
回調接收一組點並求值

00:17:56.910 --> 00:17:58.846
通常當你們計算積分

00:17:58.912 --> 00:18:01.281
你們要在許多點上計算函數值

00:18:01.348 --> 00:18:05.452
如果你們有一個向量化的回調
能提高速度 那很好

00:18:05.519 --> 00:18:10.257
你們可以使其更快
通過使用這個多x的回調

00:18:10.324 --> 00:18:13.694
它會通過x遞給你們多個值

00:18:13.760 --> 00:18:18.131
你們填入每一個對應的y的值
通過計算f(xi)

00:18:19.399 --> 00:18:22.803
這就是你們的函數
然後要告訴它如何計算積分

00:18:22.870 --> 00:18:25.639
那我們提供了三個
計算積分的方法

00:18:26.173 --> 00:18:28.375
它們有不同的的複雜度和運行時間

00:18:29.076 --> 00:18:32.045
有些還可以積分至無限

00:18:32.179 --> 00:18:35.249
你們可以在Quadrature標頭
找到更多的細節

00:18:36.450 --> 00:18:40.254
你們也要指定輸出的誤差

00:18:40.954 --> 00:18:43.223
和細分區間的最大數量

00:18:43.290 --> 00:18:45.259
用於計算結果

00:18:45.459 --> 00:18:47.895
然後你們將它遞入
integrate函數

00:18:49.363 --> 00:18:51.465
你們還要告訴函數 a和b

00:18:51.532 --> 00:18:54.868
你們也要遞入一個點
用於接收誤差

00:18:55.135 --> 00:18:59.239
它被稱爲估計誤差

00:18:59.706 --> 00:19:01.942
它會在結果裏返回估計誤差

00:19:02.009 --> 00:19:04.745
和狀態
我們接受計算的狀態

00:19:04.811 --> 00:19:07.147
因爲如果你要求一個很低的誤差

00:19:07.214 --> 00:19:09.116
有時無法被轉換

00:19:09.183 --> 00:19:11.418
那我們可以在狀態裏看到

00:19:11.718 --> 00:19:13.387
這就是Quadrature所有內容

00:19:14.555 --> 00:19:16.456
現在讓我請Steve上臺

00:19:16.557 --> 00:19:18.992
他會來講下關於simd的新添項

00:19:19.860 --> 00:19:20.928
十分感謝 Eric

00:19:21.228 --> 00:19:22.196
我是Steve Canon

00:19:22.262 --> 00:19:24.431
我與Eric一起在
向量與數值團隊工作

00:19:24.598 --> 00:19:27.734
Eric剛纔將你們帶回了
學微積分的日子裏

00:19:27.801 --> 00:19:29.770
我現在將帶你們前進些

00:19:29.837 --> 00:19:31.505
來到線性代數

00:19:33.674 --> 00:19:35.309
我們有這樣一個很有用的模塊
叫simd

00:19:35.609 --> 00:19:39.513
它能提供幾何操作和向量操作

00:19:39.980 --> 00:19:43.517
針對C、Objective-C、
C++和Swift

00:19:44.518 --> 00:19:47.654
它很好地對應了Metal着色語言

00:19:48.488 --> 00:19:51.892
它能與SceneKit和
Model I/O緊密結合

00:19:51.959 --> 00:19:53.660
還有各種圖形的庫

00:19:53.794 --> 00:19:57.130
如果你們在寫向量相關的代碼來執行

00:19:57.197 --> 00:20:01.535
小型的3x3、4x4之類的
線性代數的操作

00:20:01.802 --> 00:20:04.538
這個庫就是你們想要的
你們就不用去自己寫了

00:20:04.605 --> 00:20:06.607
我們有大部分你們想要的

00:20:06.673 --> 00:20:08.742
如果沒有 可以請求我們添加它

00:20:08.809 --> 00:20:10.644
它十分的快 讓我們來細看

00:20:10.777 --> 00:20:11.945
那有些什麼？

00:20:13.080 --> 00:20:14.348
我們有一大堆類型

00:20:14.515 --> 00:20:17.684
有浮點數的向量和雙精確度的向量

00:20:18.018 --> 00:20:21.054
有帶符號和不帶符號的整數
像2、3和4

00:20:22.222 --> 00:20:25.425
我們還有相同尺寸的
浮點數和雙精確度的矩陣

00:20:26.560 --> 00:20:29.396
這些只是在所有語言裏都有的

00:20:30.163 --> 00:20:31.899
在C、C++
和Objective-C裏

00:20:31.965 --> 00:20:33.233
還有其它許多類型

00:20:33.300 --> 00:20:36.236
那些會對你們寫自己泛型的
向量代碼很有用

00:20:36.303 --> 00:20:39.306
但我將着重於共有的子集

00:20:39.373 --> 00:20:42.242
在所有的語言裏和平臺上
在今天的講座裏

00:20:43.143 --> 00:20:45.112
顯然 我們還有類型相關的操作

00:20:45.179 --> 00:20:48.815
有一般的算術操作

00:20:48.882 --> 00:20:50.717
用於向量和矩陣

00:20:51.585 --> 00:20:54.121
還有我們所熟悉的
幾何和着色函數

00:20:54.188 --> 00:20:55.756
若你們有過任何着色編程的經驗

00:20:55.822 --> 00:20:58.659
大多數你們想用的 這裏都有

00:20:58.892 --> 00:21:00.861
我現在來展示個小型的例子

00:21:01.762 --> 00:21:05.732
這是一個相同的函數
被用三種語言編寫

00:21:06.300 --> 00:21:09.837
有Objective-C在最上面
有C++在中間

00:21:09.903 --> 00:21:11.672
Swift在底部

00:21:12.072 --> 00:21:13.674
你們可以看到模版

00:21:13.740 --> 00:21:15.409
在各個語言之間有些不同

00:21:15.475 --> 00:21:18.345
只是因爲函數聲明在
這些語言之間有所不同

00:21:18.512 --> 00:21:21.448
但如果我們注意
實際計算的部分

00:21:21.748 --> 00:21:23.851
在各語言裏 基本上都一樣

00:21:23.917 --> 00:21:26.386
同時 它也很對應

00:21:26.587 --> 00:21:29.122
你們在數學裏表達的方式

00:21:29.456 --> 00:21:30.991
不會有許多奇怪的函數調用

00:21:31.058 --> 00:21:33.427
你們也不用寫for循環之類的

00:21:33.527 --> 00:21:35.963
你們能自然流暢地寫
你們的代碼

00:21:36.230 --> 00:21:38.732
我們替你們翻譯

00:21:38.999 --> 00:21:40.467
編寫變得友好和簡單

00:21:40.534 --> 00:21:43.770
這用Metal代碼寫
看起來也一樣

00:21:43.837 --> 00:21:46.573
那這裏湊巧已經有了
reflect函數

00:21:46.640 --> 00:21:47.875
在庫裏面

00:21:47.941 --> 00:21:49.743
那你們就不用自己編寫了

00:21:50.811 --> 00:21:54.615
在各種語言之間調用函數
像很多在model I/O裏的

00:21:54.681 --> 00:21:57.584
能通過使用接受這些類型的
Objective-C API

00:21:58.018 --> 00:21:59.553
很不錯

00:21:59.620 --> 00:22:01.788
向量類型是編譯器的擴展

00:22:01.855 --> 00:22:04.291
在C、Objective-C
和C++裏

00:22:05.125 --> 00:22:07.561
在Swift裏
它們被定義爲structs

00:22:07.628 --> 00:22:10.898
但編譯器知道如何爲你們
映射它們

00:22:11.598 --> 00:22:13.367
所以 你們根本不用做任何事

00:22:13.834 --> 00:22:15.202
這裏有個簡單的例子

00:22:15.302 --> 00:22:16.904
若我有個Objective-C的函數

00:22:16.970 --> 00:22:19.606
我在這裏調用某個對向量類型
執行操作的函數

00:22:20.307 --> 00:22:21.808
並且我想調用那個函數

00:22:21.942 --> 00:22:23.944
通過Swift
使用Swift向量類型

00:22:24.011 --> 00:22:25.746
我可以成功的這麼做

00:22:25.812 --> 00:22:27.414
我無需做任何進階的事

00:22:27.548 --> 00:22:28.782
這些類型都有相同的佈局

00:22:28.849 --> 00:22:31.418
所以 沒有轉換開銷之類的

00:22:32.252 --> 00:22:33.987
相似的 對於矩陣

00:22:34.188 --> 00:22:36.823
Swift的矩陣類型佈局和

00:22:36.890 --> 00:22:39.126
C、Objective-C
和C++類型相匹配

00:22:39.660 --> 00:22:42.529
那如果我要使用它們
這裏我有Swift

00:22:42.796 --> 00:22:45.666
我來創建一個Swift的類型
通過C的類型

00:22:46.300 --> 00:22:48.168
我所要做的就是使用init函數

00:22:48.235 --> 00:22:49.069
很好用

00:22:49.136 --> 00:22:50.637
沒有任何的計算開銷

00:22:50.704 --> 00:22:53.106
就好像 不知不覺地改變了類型

00:22:53.173 --> 00:22:55.742
相似的 我可以使用C的
矩陣屬性

00:22:56.109 --> 00:23:00.848
如果我要通過C的類型調用C或
Objective-C或C++的函數

00:23:01.415 --> 00:23:04.318
我們今年有些新的東西
我想向你們展示

00:23:05.619 --> 00:23:07.020
我們有三個新的函數

00:23:07.087 --> 00:23:09.656
simd orient和simd incircle
還有simd insphere

00:23:09.723 --> 00:23:12.693
它們已被重載
爲支持許多不一樣的類型

00:23:12.759 --> 00:23:14.628
和不同的長度 之類的

00:23:14.695 --> 00:23:16.797
基本上所有在simd庫裏的都這樣

00:23:16.864 --> 00:23:18.565
所以 僅管我們只有三個新函數

00:23:18.632 --> 00:23:20.567
實際上 有許多新東西

00:23:21.768 --> 00:23:23.103
我會從orient開始講

00:23:23.637 --> 00:23:25.672
orient讓我們回答這樣的問題：

00:23:25.739 --> 00:23:27.641
一組向量是否都朝向正面？

00:23:28.108 --> 00:23:31.044
如果你們不記得線性代數
意思是

00:23:31.445 --> 00:23:33.046
它們是否遵循右手螺旋法則？

00:23:33.313 --> 00:23:35.015
你們可能記得在物理裏見過它

00:23:35.082 --> 00:23:37.384
或 相等同的
是否有正值的行列式？

00:23:38.018 --> 00:23:40.621
如果在座的有數學專業的
你們現在會抗議

00:23:40.687 --> 00:23:43.657
一組向量是沒有行列式的

00:23:43.757 --> 00:23:45.726
我的意思是你們把它們

00:23:45.792 --> 00:23:47.794
放到一個矩陣裏

00:23:48.095 --> 00:23:49.730
計算矩陣的行列式

00:23:49.796 --> 00:23:51.098
是不是正的？

00:23:51.798 --> 00:23:53.567
那我們爲什麼關心這個？

00:23:53.667 --> 00:23:55.502
這很明顯

00:23:56.103 --> 00:24:00.240
你們能用這回答許多
計算幾何的問題

00:24:00.307 --> 00:24:01.308
會很有用

00:24:01.542 --> 00:24:04.211
比如 這個三角形是
面朝我還是背朝我？

00:24:04.278 --> 00:24:06.079
如果你們想象個四面體

00:24:06.146 --> 00:24:08.515
有兩個面朝着你們

00:24:08.582 --> 00:24:11.251
也有兩個面揹着你們

00:24:11.318 --> 00:24:13.020
如果你們在進行圖形操作

00:24:13.086 --> 00:24:15.756
知道面朝你們的面
會是很有用的

00:24:15.822 --> 00:24:17.791
因爲那些是你們要處理的面

00:24:18.192 --> 00:24:21.628
相似的 如果我有一個點和一條線
我想回答這樣個問題

00:24:21.695 --> 00:24:24.965
點在不在線上
或 如果不在 那它在線的哪側？

00:24:25.632 --> 00:24:28.101
我能用orient判斷
去回答那個問題

00:24:28.335 --> 00:24:31.038
那 這看起來很簡單的樣子
的確很簡單

00:24:31.104 --> 00:24:33.941
除了實際回答這個問題
可能會很難

00:24:34.007 --> 00:24:37.110
當點離線很近時
我們會在下面細說

00:24:38.045 --> 00:24:39.913
這裏有個這樣的例子

00:24:40.447 --> 00:24:44.051
在顯示的右側 我有個平面

00:24:44.117 --> 00:24:46.320
我會在平面上加些點

00:24:47.020 --> 00:24:50.190
我有三個點
a和b還有c

00:24:50.257 --> 00:24:53.861
我將使用的simd orient
查詢它們的朝向

00:24:54.194 --> 00:24:56.396
由於我們是通過
逆時針的方向

00:24:56.663 --> 00:24:59.233
從a到b到c

00:24:59.766 --> 00:25:01.768
我們說它們是
正朝向

00:25:01.835 --> 00:25:04.505
這是在平面裏對
正朝向的定義

00:25:04.571 --> 00:25:09.142
如果我們移動其中一點
變成順時針方向

00:25:09.343 --> 00:25:11.144
現在就是負朝向了

00:25:12.412 --> 00:25:16.550
那如果我移動點c
讓它正好在a和b之間的線上

00:25:16.817 --> 00:25:19.653
那它們共線 朝向是0

00:25:19.720 --> 00:25:21.355
或許 你們會說它是虛的

00:25:21.555 --> 00:25:25.492
判定點是否正好在線上
一般是件很難的事

00:25:25.559 --> 00:25:27.594
特別是利用浮點數的座標

00:25:27.661 --> 00:25:30.931
因爲朝向數值的不穩定性

00:25:31.532 --> 00:25:33.567
由於浮點數的取捨

00:25:33.634 --> 00:25:36.203
如果行列式的結果接近0

00:25:36.336 --> 00:25:38.138
你們很有可能得到一個錯誤的符號

00:25:38.205 --> 00:25:40.574
對於一些算法來說
這無關緊要

00:25:40.641 --> 00:25:43.143
但對於其它算法
你們可能會遇到無法收斂的情況

00:25:43.210 --> 00:25:45.779
或 當使用它時
你們也許會獲得錯誤的的結果

00:25:45.846 --> 00:25:47.381
像在碰撞檢測之類的情況裏

00:25:47.447 --> 00:25:50.017
能回答這個問題變得很重要

00:25:50.083 --> 00:25:53.420
還有像使用三角網格建立模型
之類的

00:25:53.487 --> 00:25:56.123
這會是個重要的問題
要求有準確的答案

00:25:57.691 --> 00:26:01.028
讓我們來看個難回答的例子

00:26:02.563 --> 00:26:04.865
我在平面裏建立兩個向量
u和v

00:26:04.932 --> 00:26:07.501
它們幾乎相同

00:26:07.568 --> 00:26:10.771
它們只有一點點的不同

00:26:11.705 --> 00:26:15.375
我在右側將它們放大了很多倍

00:26:15.442 --> 00:26:16.810
那樣你們能看見它們的不同

00:26:16.877 --> 00:26:20.080
如果我將它們按真實比例來畫
它們會全部重疊

00:26:20.547 --> 00:26:25.219
如果我們用通常的方式來
計算朝向

00:26:25.285 --> 00:26:28.021
我們會得到結果0
因爲浮點數的取捨

00:26:28.088 --> 00:26:30.157
這是個簡單的
結果爲0的例子

00:26:30.324 --> 00:26:32.426
如果維度大於2x2

00:26:32.559 --> 00:26:34.995
我們會得到一個完全錯誤的符號

00:26:35.062 --> 00:26:37.164
不只是結果爲0
當它不應該是0時

00:26:37.464 --> 00:26:39.333
但若我們使用
simd orient函數

00:26:39.600 --> 00:26:41.335
我們會得到一個很小的正數

00:26:41.401 --> 00:26:44.371
是正確的結果
這些是正朝向的

00:26:44.838 --> 00:26:48.442
我要提醒的是
不要詮釋

00:26:48.509 --> 00:26:50.544
這個極小的正數
對任何情況都有意義

00:26:50.611 --> 00:26:52.012
這不是一個行列式的值

00:26:52.513 --> 00:26:54.948
有時候是行列式的值

00:26:55.015 --> 00:26:57.251
但有時只是有個準確的符號

00:26:57.317 --> 00:27:00.187
所以 我們這裏真正關心的是
這個數字的符號

00:27:00.387 --> 00:27:01.622
那我們是怎麼做到的？

00:27:01.722 --> 00:27:04.024
這些我今天像你們展示的
幾何判定

00:27:04.091 --> 00:27:06.059
都是使用自適應精度

00:27:06.159 --> 00:27:09.263
我們計算至我們需要的位

00:27:09.363 --> 00:27:10.497
來獲取正確的結果

00:27:10.564 --> 00:27:14.034
這讓我們在大部分的時候
能很快返回正確的結果

00:27:14.401 --> 00:27:16.403
但如果我們要進一步

00:27:16.470 --> 00:27:18.739
進行精確的計算
爲你們取得正確的結果

00:27:18.906 --> 00:27:20.007
我們也可以這麼做

00:27:20.073 --> 00:27:22.209
你們可以相信這在你們代碼裏會給出正確答案

00:27:22.276 --> 00:27:24.344
你們不用擔心

00:27:25.445 --> 00:27:27.247
Incircle很相似

00:27:27.414 --> 00:27:28.916
我們在平面裏取三點

00:27:29.016 --> 00:27:30.150
那決定一個圓

00:27:30.217 --> 00:27:32.486
你們會注意到
它們是 正朝向的

00:27:32.553 --> 00:27:34.555
圍着圓　這很重要

00:27:34.922 --> 00:27:37.257
如果我在圓里加個點 x

00:27:37.424 --> 00:27:39.826
然後simd incircle
能告訴我點是否在圓內

00:27:40.027 --> 00:27:42.162
如在圓內 我得到個正值

00:27:42.462 --> 00:27:45.032
如在圓上 我得到0

00:27:45.599 --> 00:27:48.035
如在圓外 我得到個負值

00:27:48.535 --> 00:27:51.972
insphere也是相同的

00:27:54.241 --> 00:27:55.576
只是現在是三維的了

00:27:55.642 --> 00:27:57.444
我需要四個維度來定義球體

00:27:57.511 --> 00:27:59.246
我設定點x
然後得到相應的結果

00:28:00.647 --> 00:28:02.416
我向你們展示
一個之前提過的例子

00:28:02.482 --> 00:28:05.519
判斷一個三角形的面是
正對還是背對着你們

00:28:06.153 --> 00:28:09.456
這裏我有個簡單的struct
用來在Swift裏代表三角形

00:28:09.890 --> 00:28:13.660
三角形由三個點定義
我把它們放一個集合裏

00:28:14.428 --> 00:28:17.464
我用這個判定
IsFacing來告訴我

00:28:17.831 --> 00:28:20.501
三角形是否面對相機

00:28:21.201 --> 00:28:23.237
那通常你們的計算方式是

00:28:23.303 --> 00:28:26.773
運用叉乘積來計算
一個對三角形面的法向量

00:28:27.241 --> 00:28:30.811
然後計算它與
對着相機的向量的點積

00:28:30.878 --> 00:28:33.413
如果值爲正
那三角形正對着相機

00:28:33.480 --> 00:28:36.884
我們可以簡化這些代碼
並準確計算結果

00:28:38.318 --> 00:28:41.121
通過使用simd orient判定

00:28:41.321 --> 00:28:42.389
那我的代碼變簡單了

00:28:42.789 --> 00:28:44.758
它很快 還能給我正確的答案

00:28:44.825 --> 00:28:46.426
這都是我想要的

00:28:46.493 --> 00:28:48.829
這就是我們嘗試着
在Accelerate實現的

00:28:48.896 --> 00:28:50.264
給予你們簡單的東西

00:28:50.330 --> 00:28:52.332
用於複雜的數學計算

00:28:53.967 --> 00:28:55.969
那我們今天向你們展示了
許多新的東西

00:28:58.438 --> 00:29:00.474
我們有些全新的庫

00:29:00.607 --> 00:29:02.743
我們有BNNS用於神經網絡

00:29:03.277 --> 00:29:04.678
我們有Quadrature

00:29:04.745 --> 00:29:06.947
我們還有些新的功能

00:29:07.614 --> 00:29:09.716
simd裏的
orientation和incircle

00:29:09.783 --> 00:29:12.286
這每一個新功能和庫

00:29:12.686 --> 00:29:16.757
都是爲迴應開發者的需求
所添加的

00:29:16.857 --> 00:29:19.660
所以 我們很想知道你們所想要的

00:29:19.927 --> 00:29:22.663
通過我們能添加的東西
能簡化你們的計算工作

00:29:22.729 --> 00:29:24.498
我們想給予你們簡單的接口

00:29:24.698 --> 00:29:27.067
它能讓你們有效率地
完成你們要做的事

00:29:27.634 --> 00:29:29.636
我們今年還做了許多其它的事

00:29:30.137 --> 00:29:33.207
在vImage裏
Eric在簡介裏帶過的

00:29:33.907 --> 00:29:37.277
我們有一組全套的幾何操作用於
交叉存取的色度平面

00:29:37.344 --> 00:29:39.613
這絕對是最頻繁的請求

00:29:39.680 --> 00:29:41.114
我們在近年裏所收到的

00:29:41.281 --> 00:29:42.883
所以 我們很樂意地添加了它

00:29:42.950 --> 00:29:44.685
如果你們不知道那是什麼
無需擔心

00:29:44.751 --> 00:29:47.321
但如果你們知道
那你們會明白它的有用之處

00:29:47.588 --> 00:29:49.656
我們還擴展了

00:29:49.723 --> 00:29:52.025
vImage裏的轉換例程
用於新的格式

00:29:52.092 --> 00:29:54.795
這爲許多你們或許聽說過的關於
深色的東西奠定了基礎

00:29:54.862 --> 00:29:57.030
所以這個對那來說很重要

00:29:58.565 --> 00:30:00.434
我們提高了性能

00:30:00.501 --> 00:30:02.536
針對vDSP裏的交織複雜格式

00:30:02.603 --> 00:30:06.707
通過FFT 我們支持交織和截面佈局

00:30:06.773 --> 00:30:08.108
複雜和虛的部分

00:30:08.175 --> 00:30:09.977
要麼被分開 要麼放在一起

00:30:11.745 --> 00:30:14.281
我們一般使用截面佈局
進行操作

00:30:14.348 --> 00:30:18.218
我們推薦這麼做
但如果你們只有交織的數據

00:30:18.285 --> 00:30:21.021
你們現在可以使用FFT
它們很快

00:30:22.022 --> 00:30:24.858
我們也提高了所有
Level II BLAS操作性能

00:30:24.925 --> 00:30:27.861
有些是由你們所見到的
BNNS員工發起的

00:30:27.928 --> 00:30:30.497
有些是我們所預見並跟進的機會

00:30:30.564 --> 00:30:33.133
Accelerate裏
還有許多新的東西

00:30:33.200 --> 00:30:34.535
許多改進了的東西

00:30:34.868 --> 00:30:38.205
每當有新處理器發佈
我們一定會針對它們進行優化

00:30:38.272 --> 00:30:41.508
我們想解決所有的那些低級計算細節

00:30:41.575 --> 00:30:44.378
讓你們能注重於
編寫高級算法

00:30:44.578 --> 00:30:46.146
基於低級細節層面

00:30:46.213 --> 00:30:48.081
讓你們能達成你們想做的

00:30:49.183 --> 00:30:52.019
總結下
我們想成爲你們一站式購物的地方

00:30:52.085 --> 00:30:53.820
爲計算的算法

00:30:54.288 --> 00:30:56.657
我們能提供給你們的實現是準確

00:30:56.857 --> 00:30:59.193
快速和節省能源的

00:30:59.493 --> 00:31:01.662
並且我們會針對新硬件
進行優化

00:31:01.728 --> 00:31:04.097
當它們發佈時
這樣你們就不用爲此擔心

00:31:04.164 --> 00:31:08.035
如果你們想自己優化
那我們有了新的芯片

00:31:08.101 --> 00:31:10.504
你們就需要對其更新

00:31:10.571 --> 00:31:12.739
如果你們交給我們來處理

00:31:12.806 --> 00:31:14.274
那你們就不用擔心了

00:31:15.309 --> 00:31:18.212
繼續提交你們的請求
我們很高興能收到它們

00:31:18.278 --> 00:31:20.247
我們今天在實驗室和
你們許多人交談了

00:31:20.314 --> 00:31:22.549
我們已經得到了許多將來的請求

00:31:22.616 --> 00:31:24.985
能將雷達歸檔
我們想要這個功能

00:31:25.686 --> 00:31:30.224
如果你們想見到更多相關信息
這個講座的連接在這裏

00:31:30.757 --> 00:31:33.493
我也推薦你們去看下
前幾年的講座

00:31:33.560 --> 00:31:37.464
有關於這些庫的其它方面
有用的細節

00:31:38.232 --> 00:31:40.267
有兩個很好的關於
Metal的演講

00:31:40.334 --> 00:31:43.437
我高度推薦你們去看下
昨天的演講

00:31:43.504 --> 00:31:45.906
特別是如果
你們對這些感興趣的話

00:31:45.973 --> 00:31:47.808
十分感謝你們的到來